
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://digitalphonetics.github.io/adviser/api/tools/" rel="canonical"/>
<link href="../../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.1, mkdocs-material-5.1.4" name="generator"/>
<title>Tools - Adviser</title>
<link href="../../assets/stylesheets/main.c4007cdc.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
<link href="../../custom.css" rel="stylesheet"/>
</head>
<body dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#tools">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header-nav md-grid">
<a aria-label="Adviser" class="md-header-nav__button md-logo" href="https://digitalphonetics.github.io/adviser/" title="Adviser">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"></path></svg>
</a>
<label class="md-header-nav__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header-nav__title" data-md-component="header-title">
<div class="md-header-nav__ellipsis">
<span class="md-header-nav__topic md-ellipsis">
            Adviser
          </span>
<span class="md-header-nav__topic md-ellipsis">
            
              Tools
            
          </span>
</div>
</div>
<label class="md-header-nav__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</label>
<button aria-label="Clear" class="md-search__icon md-icon" data-md-component="search-reset" tabindex="-1" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg>
</button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header-nav__source">
<a class="md-source" href="https://github.com/DigitalPhonetics/adviser/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Adviser" class="md-nav__button md-logo" href="https://digitalphonetics.github.io/adviser/" title="Adviser">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"></path></svg>
</a>
    Adviser
  </label>
<div class="md-nav__source">
<a class="md-source" href="https://github.com/DigitalPhonetics/adviser/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../.." title="Home">
      Home
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../getting-started/" title="Getting Started">
      Getting Started
    </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      Reference
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Reference" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Reference
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../services/" title="Services">
      Services
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../examples/" title="Examples">
      Examples
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../utils/" title="Utils">
      Utils
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        Tools
        <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"></path></svg>
</span>
</label>
<a class="md-nav__link md-nav__link--active" href="./" title="Tools">
      Tools
    </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools">
    adviser.tools
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology">
    create_ontology
  </a>
<nav aria-label="create_ontology" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database">
    Database
  </a>
<nav aria-label="Database" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_slot_values">
    get_slot_values()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_slots">
    get_slots()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_tables">
    get_tables()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable">
    DatabaseTable
  </a>
<nav aria-label="DatabaseTable" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.get_slot_values">
    get_slot_values()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.get_slots">
    get_slots()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.get_defaults">
    get_defaults()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.run_questions">
    run_questions()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal">
    espnet_minimal
  </a>
<nav aria-label="espnet_minimal" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr">
    asr
  </a>
<nav aria-label="asr" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils">
    asr_utils
  </a>
<nav aria-label="asr_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.add_gradient_noise">
    add_gradient_noise()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.get_model_conf">
    get_model_conf()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_load">
    torch_load()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_save">
    torch_save()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend">
    pytorch_backend
  </a>
<nav aria-label="pytorch_backend" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init">
    asr_init
  </a>
<nav aria-label="asr_init" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.filter_modules">
    filter_modules()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_asr_mt_state_dict">
    get_partial_asr_mt_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_lm_state_dict">
    get_partial_lm_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_root_dir">
    get_root_dir()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_trained_model_state_dict">
    get_trained_model_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_model">
    load_trained_model()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_modules">
    load_trained_modules()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.transfer_verification">
    transfer_verification()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin">
    bin
  </a>
<nav aria-label="bin" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog">
    asr_recog
  </a>
<nav aria-label="asr_recog" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train">
    asr_train
  </a>
<nav aria-label="asr_train" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train">
    lm_train
  </a>
<nav aria-label="lm_train" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans">
    mt_trans
  </a>
<nav aria-label="mt_trans" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans">
    st_trans
  </a>
<nav aria-label="st_trans" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode">
    tts_decode
  </a>
<nav aria-label="tts_decode" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets">
    nets
  </a>
<nav aria-label="nets" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface">
    asr_interface
  </a>
<nav aria-label="asr_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface">
    ASRInterface
  </a>
<nav aria-label="ASRInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.attention_plot_class">
    attention_plot_class
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.build">
    build()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.encode">
    encode()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize">
    recognize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize_batch">
    recognize_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.scorers">
    scorers()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.dynamic_import_asr">
    dynamic_import_asr()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search">
    batch_beam_search
  </a>
<nav aria-label="batch_beam_search" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch">
    BatchBeamSearch
  </a>
<nav aria-label="BatchBeamSearch" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batch_beam">
    batch_beam()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batchfy">
    batchfy()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.init_hyp">
    init_hyp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.post_process">
    post_process()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.search">
    search()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.unbatchfy">
    unbatchfy()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis">
    BatchHypothesis
  </a>
<nav aria-label="BatchHypothesis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__getnewargs__">
    __getnewargs__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__len__">
    __len__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__new__">
    __new__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__repr__">
    __repr__()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search">
    beam_search
  </a>
<nav aria-label="beam_search" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch">
    BeamSearch
  </a>
<nav aria-label="BeamSearch" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.append_token">
    append_token()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.beam">
    beam()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.init_hyp">
    init_hyp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_scores">
    merge_scores()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_states">
    merge_states()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.post_process">
    post_process()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_full">
    score_full()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_partial">
    score_partial()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.search">
    search()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis">
    Hypothesis
  </a>
<nav aria-label="Hypothesis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__getnewargs__">
    __getnewargs__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__new__">
    __new__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__repr__">
    __repr__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.asdict">
    asdict()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.beam_search">
    beam_search()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score">
    ctc_prefix_score
  </a>
<nav aria-label="ctc_prefix_score" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore">
    CTCPrefixScore
  </a>
<nav aria-label="CTCPrefixScore" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.initial_state">
    initial_state()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH">
    CTCPrefixScoreTH
  </a>
<nav aria-label="CTCPrefixScoreTH" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state">
    index_select_state()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common">
    e2e_asr_common
  </a>
<nav aria-label="e2e_asr_common" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator">
    ErrorCalculator
  </a>
<nav aria-label="ErrorCalculator" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer">
    calculate_cer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc">
    calculate_cer_ctc()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_wer">
    calculate_wer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.convert_to_char">
    convert_to_char()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.end_detect">
    end_detect()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.get_vgg2l_odim">
    get_vgg2l_odim()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.label_smoothing_dist">
    label_smoothing_dist()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface">
    mt_interface
  </a>
<nav aria-label="mt_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface">
    MTInterface
  </a>
<nav aria-label="MTInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.attention_plot_class">
    attention_plot_class
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.build">
    build()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate">
    translate()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate_batch">
    translate_batch()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend">
    pytorch_backend
  </a>
<nav aria-label="pytorch_backend" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc">
    ctc
  </a>
<nav aria-label="ctc" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC">
    CTC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.ctc_for">
    ctc_for()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr">
    e2e_asr
  </a>
<nav aria-label="e2e_asr" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E">
    E2E
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer">
    e2e_asr_transformer
  </a>
<nav aria-label="e2e_asr_transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E">
    E2E
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech">
    e2e_tts_fastspeech
  </a>
<nav aria-label="e2e_tts_fastspeech" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer">
    FeedForwardTransformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss">
    FeedForwardTransformerLoss
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2">
    e2e_tts_tacotron2
  </a>
<nav aria-label="e2e_tts_tacotron2" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss">
    GuidedAttentionLoss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2">
    Tacotron2
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss">
    Tacotron2Loss
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer">
    e2e_tts_transformer
  </a>
<nav aria-label="e2e_tts_transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss">
    GuidedMultiHeadAttentionLoss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer">
    Transformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.TTSPlot">
    TTSPlot
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech">
    fastspeech
  </a>
<nav aria-label="fastspeech" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator">
    duration_calculator
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor">
    duration_predictor
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator">
    length_regulator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization">
    initialization
  </a>
<nav aria-label="initialization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.lecun_normal_init_parameters">
    lecun_normal_init_parameters()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.set_forget_bias_to_one">
    set_forget_bias_to_one()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.uniform_init_parameters">
    uniform_init_parameters()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils">
    nets_utils
  </a>
<nav aria-label="nets_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_non_pad_mask">
    make_non_pad_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_pad_mask">
    make_pad_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.mask_by_length">
    mask_by_length()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.pad_list">
    pad_list()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.th_accuracy">
    th_accuracy()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_device">
    to_device()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_torch_tensor">
    to_torch_tensor()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn">
    rnn
  </a>
<nav aria-label="rnn" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions">
    attentions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders">
    decoders
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders">
    encoders
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming">
    streaming
  </a>
<nav aria-label="streaming" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment">
    segment
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window">
    window
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2">
    tacotron2
  </a>
<nav aria-label="tacotron2" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg">
    cbhg
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder">
    decoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder">
    encoder
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer">
    transformer
  </a>
<nav aria-label="transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.add_sos_eos">
    add_sos_eos
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention">
    attention
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder">
    decoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer">
    decoder_layer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding">
    embedding
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder">
    encoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer">
    encoder_layer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.initializer">
    initializer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss">
    label_smoothing_loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm">
    layer_norm
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask">
    mask
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv">
    multi_layer_conv
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer">
    optimizer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot">
    plot
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward">
    positionwise_feed_forward
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat">
    repeat
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling">
    subsampling
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet">
    wavenet
  </a>
<nav aria-label="wavenet" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d">
    CausalConv1d
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot">
    OneHot
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling">
    UpSampling
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet">
    WaveNet
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.decode_mu_law">
    decode_mu_law()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.encode_mu_law">
    encode_mu_law()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.initialize">
    initialize()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface">
    scorer_interface
  </a>
<nav aria-label="scorer_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface">
    BatchScorerInterface
  </a>
<nav aria-label="BatchScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface.score">
    score()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface">
    PartialScorerInterface
  </a>
<nav aria-label="PartialScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface.score_partial">
    score_partial()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface">
    ScorerInterface
  </a>
<nav aria-label="ScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.final_score">
    final_score()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.init_state">
    init_state()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.score">
    score()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.select_state">
    select_state()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers">
    scorers
  </a>
<nav aria-label="scorers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers.ctc">
    ctc
  </a>
<nav aria-label="ctc" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer">
    CTCPrefixScorer
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface">
    tts_interface
  </a>
<nav aria-label="tts_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface">
    TTSInterface
  </a>
<nav aria-label="TTSInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.base_plot_keys">
    base_plot_keys
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.inference">
    inference()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.load_pretrained_model">
    load_pretrained_model()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils">
    utils
  </a>
<nav aria-label="utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.check_kwargs">
    check_kwargs
  </a>
<nav aria-label="check_kwargs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.check_kwargs.check_kwargs">
    check_kwargs()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers">
    cli_readers
  </a>
<nav aria-label="cli_readers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader">
    HDF5Reader
  </a>
<nav aria-label="HDF5Reader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader">
    KaldiReader
  </a>
<nav aria-label="KaldiReader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader">
    SoundHDF5Reader
  </a>
<nav aria-label="SoundHDF5Reader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader">
    SoundReader
  </a>
<nav aria-label="SoundReader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.file_reader_helper">
    file_reader_helper()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils">
    cli_utils
  </a>
<nav aria-label="cli_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.assert_scipy_wav_style">
    assert_scipy_wav_style()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.get_commandline_args">
    get_commandline_args()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.is_scipy_wav_style">
    is_scipy_wav_style()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.strtobool">
    strtobool()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers">
    cli_writers
  </a>
<nav aria-label="cli_writers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter">
    BaseWriter
  </a>
<nav aria-label="BaseWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__enter__">
    __enter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__exit__">
    __exit__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__setitem__">
    __setitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.close">
    close()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer">
    HDF5Writer
  </a>
<nav aria-label="HDF5Writer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter">
    KaldiWriter
  </a>
<nav aria-label="KaldiWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer">
    SoundHDF5Writer
  </a>
<nav aria-label="SoundHDF5Writer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter">
    SoundWriter
  </a>
<nav aria-label="SoundWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.file_writer_helper">
    file_writer_helper()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.get_num_frames_writer">
    get_num_frames_writer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.parse_wspecifier">
    parse_wspecifier()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset">
    dataset
  </a>
<nav aria-label="dataset" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader">
    ChainerDataLoader
  </a>
<nav aria-label="ChainerDataLoader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.epoch_detail">
    epoch_detail
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__iter__">
    __iter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.finalize">
    finalize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.next">
    next()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.serialize">
    serialize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.start_shuffle">
    start_shuffle()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset">
    TransformDataset
  </a>
<nav aria-label="TransformDataset" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__getitem__">
    __getitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__len__">
    __len__()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils">
    deterministic_utils
  </a>
<nav aria-label="deterministic_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_chainer">
    set_deterministic_chainer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_pytorch">
    set_deterministic_pytorch()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dynamic_import">
    dynamic_import
  </a>
<nav aria-label="dynamic_import" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dynamic_import.dynamic_import">
    dynamic_import()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.fill_missing_args">
    fill_missing_args
  </a>
<nav aria-label="fill_missing_args" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.fill_missing_args.fill_missing_args">
    fill_missing_args()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils">
    io_utils
  </a>
<nav aria-label="io_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets">
    LoadInputsAndTargets
  </a>
<nav aria-label="LoadInputsAndTargets" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__init__">
    __init__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File">
    SoundHDF5File
  </a>
<nav aria-label="SoundHDF5File" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__contains__">
    __contains__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__enter__">
    __enter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__exit__">
    __exit__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__getitem__">
    __getitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__iter__">
    __iter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__len__">
    __len__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__repr__">
    __repr__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__setitem__">
    __setitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.close">
    close()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.create_dataset">
    create_dataset()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.items">
    items()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.keys">
    keys()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.values">
    values()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment">
    spec_augment
  </a>
<nav aria-label="spec_augment" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.apply_interpolation">
    apply_interpolation()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.create_dense_flows">
    create_dense_flows()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.cross_squared_distance_matrix">
    cross_squared_distance_matrix()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.dense_image_warp">
    dense_image_warp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.flatten_grid_locations">
    flatten_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.freq_mask">
    freq_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_flat_grid_locations">
    get_flat_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_grid_locations">
    get_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_bilinear">
    interpolate_bilinear()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_spline">
    interpolate_spline()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.phi">
    phi()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.solve_interpolation">
    solve_interpolation()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.sparse_image_warp">
    sparse_image_warp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.specaug">
    specaug()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_mask">
    time_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_warp">
    time_warp()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training">
    training
  </a>
<nav aria-label="training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy">
    batchfy
  </a>
<nav aria-label="batchfy" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_bin">
    batchfy_by_bin()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_frame">
    batchfy_by_frame()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_seq">
    batchfy_by_seq()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_shuffle">
    batchfy_shuffle()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.make_batchset">
    make_batchset()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.evaluator">
    evaluator
  </a>
<nav aria-label="evaluator" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.evaluator.BaseEvaluator">
    BaseEvaluator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators">
    iterators
  </a>
<nav aria-label="iterators" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler">
    ShufflingEnabler
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator">
    ToggleableShufflingMultiprocessIterator
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator">
    ToggleableShufflingSerialIterator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger">
    tensorboard_logger
  </a>
<nav aria-label="tensorboard_logger" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger">
    TensorboardLogger
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils">
    train_utils
  </a>
<nav aria-label="train_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils.check_early_stop">
    check_early_stop()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils.set_early_stop">
    set_early_stop()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      Tutorials
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Tutorials" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Tutorials
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorials/introduction/" title="Introduction">
      Introduction
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorials/services/" title="Services">
      Services
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorials/dialogsystem/" title="Dialog System">
      Dialog System
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorials/advanced/" title="Advanced">
      Advanced
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../faq/" title="FAQ">
      FAQ
    </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools">
    adviser.tools
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology">
    create_ontology
  </a>
<nav aria-label="create_ontology" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database">
    Database
  </a>
<nav aria-label="Database" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_slot_values">
    get_slot_values()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_slots">
    get_slots()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.Database.get_tables">
    get_tables()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable">
    DatabaseTable
  </a>
<nav aria-label="DatabaseTable" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.get_slot_values">
    get_slot_values()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.DatabaseTable.get_slots">
    get_slots()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.get_defaults">
    get_defaults()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.create_ontology.run_questions">
    run_questions()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal">
    espnet_minimal
  </a>
<nav aria-label="espnet_minimal" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr">
    asr
  </a>
<nav aria-label="asr" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils">
    asr_utils
  </a>
<nav aria-label="asr_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.add_gradient_noise">
    add_gradient_noise()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.get_model_conf">
    get_model_conf()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_load">
    torch_load()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_save">
    torch_save()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend">
    pytorch_backend
  </a>
<nav aria-label="pytorch_backend" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init">
    asr_init
  </a>
<nav aria-label="asr_init" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.filter_modules">
    filter_modules()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_asr_mt_state_dict">
    get_partial_asr_mt_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_lm_state_dict">
    get_partial_lm_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_root_dir">
    get_root_dir()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_trained_model_state_dict">
    get_trained_model_state_dict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_model">
    load_trained_model()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_modules">
    load_trained_modules()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.transfer_verification">
    transfer_verification()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin">
    bin
  </a>
<nav aria-label="bin" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog">
    asr_recog
  </a>
<nav aria-label="asr_recog" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_recog.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train">
    asr_train
  </a>
<nav aria-label="asr_train" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.asr_train.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train">
    lm_train
  </a>
<nav aria-label="lm_train" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.lm_train.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans">
    mt_trans
  </a>
<nav aria-label="mt_trans" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.mt_trans.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans">
    st_trans
  </a>
<nav aria-label="st_trans" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.st_trans.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode">
    tts_decode
  </a>
<nav aria-label="tts_decode" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode.get_parser">
    get_parser()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.bin.tts_decode.main">
    main()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets">
    nets
  </a>
<nav aria-label="nets" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface">
    asr_interface
  </a>
<nav aria-label="asr_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface">
    ASRInterface
  </a>
<nav aria-label="ASRInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.attention_plot_class">
    attention_plot_class
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.build">
    build()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.encode">
    encode()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize">
    recognize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize_batch">
    recognize_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.scorers">
    scorers()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.asr_interface.dynamic_import_asr">
    dynamic_import_asr()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search">
    batch_beam_search
  </a>
<nav aria-label="batch_beam_search" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch">
    BatchBeamSearch
  </a>
<nav aria-label="BatchBeamSearch" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batch_beam">
    batch_beam()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batchfy">
    batchfy()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.init_hyp">
    init_hyp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.post_process">
    post_process()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.search">
    search()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.unbatchfy">
    unbatchfy()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis">
    BatchHypothesis
  </a>
<nav aria-label="BatchHypothesis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__getnewargs__">
    __getnewargs__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__len__">
    __len__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__new__">
    __new__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__repr__">
    __repr__()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search">
    beam_search
  </a>
<nav aria-label="beam_search" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch">
    BeamSearch
  </a>
<nav aria-label="BeamSearch" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.append_token">
    append_token()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.beam">
    beam()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.init_hyp">
    init_hyp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_scores">
    merge_scores()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_states">
    merge_states()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.post_process">
    post_process()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_full">
    score_full()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_partial">
    score_partial()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.search">
    search()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis">
    Hypothesis
  </a>
<nav aria-label="Hypothesis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__getnewargs__">
    __getnewargs__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__new__">
    __new__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__repr__">
    __repr__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.asdict">
    asdict()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.beam_search.beam_search">
    beam_search()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score">
    ctc_prefix_score
  </a>
<nav aria-label="ctc_prefix_score" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore">
    CTCPrefixScore
  </a>
<nav aria-label="CTCPrefixScore" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.initial_state">
    initial_state()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH">
    CTCPrefixScoreTH
  </a>
<nav aria-label="CTCPrefixScoreTH" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state">
    index_select_state()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common">
    e2e_asr_common
  </a>
<nav aria-label="e2e_asr_common" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator">
    ErrorCalculator
  </a>
<nav aria-label="ErrorCalculator" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer">
    calculate_cer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc">
    calculate_cer_ctc()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_wer">
    calculate_wer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.convert_to_char">
    convert_to_char()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.end_detect">
    end_detect()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.get_vgg2l_odim">
    get_vgg2l_odim()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.label_smoothing_dist">
    label_smoothing_dist()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface">
    mt_interface
  </a>
<nav aria-label="mt_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface">
    MTInterface
  </a>
<nav aria-label="MTInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.attention_plot_class">
    attention_plot_class
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.build">
    build()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate">
    translate()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate_batch">
    translate_batch()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend">
    pytorch_backend
  </a>
<nav aria-label="pytorch_backend" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc">
    ctc
  </a>
<nav aria-label="ctc" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC">
    CTC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.ctc_for">
    ctc_for()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr">
    e2e_asr
  </a>
<nav aria-label="e2e_asr" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E">
    E2E
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer">
    e2e_asr_transformer
  </a>
<nav aria-label="e2e_asr_transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E">
    E2E
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech">
    e2e_tts_fastspeech
  </a>
<nav aria-label="e2e_tts_fastspeech" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer">
    FeedForwardTransformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss">
    FeedForwardTransformerLoss
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2">
    e2e_tts_tacotron2
  </a>
<nav aria-label="e2e_tts_tacotron2" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss">
    GuidedAttentionLoss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2">
    Tacotron2
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss">
    Tacotron2Loss
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer">
    e2e_tts_transformer
  </a>
<nav aria-label="e2e_tts_transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss">
    GuidedMultiHeadAttentionLoss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer">
    Transformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.TTSPlot">
    TTSPlot
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech">
    fastspeech
  </a>
<nav aria-label="fastspeech" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator">
    duration_calculator
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor">
    duration_predictor
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator">
    length_regulator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization">
    initialization
  </a>
<nav aria-label="initialization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.lecun_normal_init_parameters">
    lecun_normal_init_parameters()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.set_forget_bias_to_one">
    set_forget_bias_to_one()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.uniform_init_parameters">
    uniform_init_parameters()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils">
    nets_utils
  </a>
<nav aria-label="nets_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_non_pad_mask">
    make_non_pad_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_pad_mask">
    make_pad_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.mask_by_length">
    mask_by_length()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.pad_list">
    pad_list()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.th_accuracy">
    th_accuracy()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_device">
    to_device()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_torch_tensor">
    to_torch_tensor()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn">
    rnn
  </a>
<nav aria-label="rnn" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions">
    attentions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders">
    decoders
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders">
    encoders
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming">
    streaming
  </a>
<nav aria-label="streaming" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment">
    segment
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window">
    window
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2">
    tacotron2
  </a>
<nav aria-label="tacotron2" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg">
    cbhg
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder">
    decoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder">
    encoder
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer">
    transformer
  </a>
<nav aria-label="transformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.add_sos_eos">
    add_sos_eos
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention">
    attention
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder">
    decoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer">
    decoder_layer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding">
    embedding
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder">
    encoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer">
    encoder_layer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.initializer">
    initializer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss">
    label_smoothing_loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm">
    layer_norm
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask">
    mask
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv">
    multi_layer_conv
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer">
    optimizer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot">
    plot
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward">
    positionwise_feed_forward
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat">
    repeat
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling">
    subsampling
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet">
    wavenet
  </a>
<nav aria-label="wavenet" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d">
    CausalConv1d
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot">
    OneHot
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling">
    UpSampling
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet">
    WaveNet
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.decode_mu_law">
    decode_mu_law()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.encode_mu_law">
    encode_mu_law()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.initialize">
    initialize()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface">
    scorer_interface
  </a>
<nav aria-label="scorer_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface">
    BatchScorerInterface
  </a>
<nav aria-label="BatchScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface.score">
    score()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface">
    PartialScorerInterface
  </a>
<nav aria-label="PartialScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface.score_partial">
    score_partial()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface">
    ScorerInterface
  </a>
<nav aria-label="ScorerInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.final_score">
    final_score()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.init_state">
    init_state()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.score">
    score()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.select_state">
    select_state()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers">
    scorers
  </a>
<nav aria-label="scorers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers.ctc">
    ctc
  </a>
<nav aria-label="ctc" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer">
    CTCPrefixScorer
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface">
    tts_interface
  </a>
<nav aria-label="tts_interface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface">
    TTSInterface
  </a>
<nav aria-label="TTSInterface" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.base_plot_keys">
    base_plot_keys
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.add_arguments">
    add_arguments()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.calculate_all_attentions">
    calculate_all_attentions()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.forward">
    forward()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.inference">
    inference()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.load_pretrained_model">
    load_pretrained_model()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils">
    utils
  </a>
<nav aria-label="utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.check_kwargs">
    check_kwargs
  </a>
<nav aria-label="check_kwargs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.check_kwargs.check_kwargs">
    check_kwargs()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers">
    cli_readers
  </a>
<nav aria-label="cli_readers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader">
    HDF5Reader
  </a>
<nav aria-label="HDF5Reader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader">
    KaldiReader
  </a>
<nav aria-label="KaldiReader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader">
    SoundHDF5Reader
  </a>
<nav aria-label="SoundHDF5Reader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader">
    SoundReader
  </a>
<nav aria-label="SoundReader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__iter__">
    __iter__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_readers.file_reader_helper">
    file_reader_helper()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils">
    cli_utils
  </a>
<nav aria-label="cli_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.assert_scipy_wav_style">
    assert_scipy_wav_style()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.get_commandline_args">
    get_commandline_args()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.is_scipy_wav_style">
    is_scipy_wav_style()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_utils.strtobool">
    strtobool()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers">
    cli_writers
  </a>
<nav aria-label="cli_writers" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter">
    BaseWriter
  </a>
<nav aria-label="BaseWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__enter__">
    __enter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__exit__">
    __exit__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__setitem__">
    __setitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.close">
    close()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer">
    HDF5Writer
  </a>
<nav aria-label="HDF5Writer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter">
    KaldiWriter
  </a>
<nav aria-label="KaldiWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer">
    SoundHDF5Writer
  </a>
<nav aria-label="SoundHDF5Writer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter">
    SoundWriter
  </a>
<nav aria-label="SoundWriter" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__setitem__">
    __setitem__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.file_writer_helper">
    file_writer_helper()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.get_num_frames_writer">
    get_num_frames_writer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.cli_writers.parse_wspecifier">
    parse_wspecifier()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset">
    dataset
  </a>
<nav aria-label="dataset" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader">
    ChainerDataLoader
  </a>
<nav aria-label="ChainerDataLoader" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.epoch_detail">
    epoch_detail
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__iter__">
    __iter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.finalize">
    finalize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.next">
    next()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.serialize">
    serialize()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.start_shuffle">
    start_shuffle()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset">
    TransformDataset
  </a>
<nav aria-label="TransformDataset" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__getitem__">
    __getitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__len__">
    __len__()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils">
    deterministic_utils
  </a>
<nav aria-label="deterministic_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_chainer">
    set_deterministic_chainer()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_pytorch">
    set_deterministic_pytorch()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dynamic_import">
    dynamic_import
  </a>
<nav aria-label="dynamic_import" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.dynamic_import.dynamic_import">
    dynamic_import()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.fill_missing_args">
    fill_missing_args
  </a>
<nav aria-label="fill_missing_args" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.fill_missing_args.fill_missing_args">
    fill_missing_args()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils">
    io_utils
  </a>
<nav aria-label="io_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets">
    LoadInputsAndTargets
  </a>
<nav aria-label="LoadInputsAndTargets" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__call__">
    __call__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__init__">
    __init__()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File">
    SoundHDF5File
  </a>
<nav aria-label="SoundHDF5File" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__contains__">
    __contains__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__enter__">
    __enter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__exit__">
    __exit__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__getitem__">
    __getitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__iter__">
    __iter__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__len__">
    __len__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__repr__">
    __repr__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__setitem__">
    __setitem__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.close">
    close()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.create_dataset">
    create_dataset()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.items">
    items()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.keys">
    keys()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.values">
    values()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment">
    spec_augment
  </a>
<nav aria-label="spec_augment" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.apply_interpolation">
    apply_interpolation()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.create_dense_flows">
    create_dense_flows()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.cross_squared_distance_matrix">
    cross_squared_distance_matrix()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.dense_image_warp">
    dense_image_warp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.flatten_grid_locations">
    flatten_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.freq_mask">
    freq_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_flat_grid_locations">
    get_flat_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_grid_locations">
    get_grid_locations()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_bilinear">
    interpolate_bilinear()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_spline">
    interpolate_spline()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.phi">
    phi()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.solve_interpolation">
    solve_interpolation()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.sparse_image_warp">
    sparse_image_warp()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.specaug">
    specaug()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_mask">
    time_mask()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_warp">
    time_warp()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training">
    training
  </a>
<nav aria-label="training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy">
    batchfy
  </a>
<nav aria-label="batchfy" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_bin">
    batchfy_by_bin()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_frame">
    batchfy_by_frame()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_seq">
    batchfy_by_seq()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_shuffle">
    batchfy_shuffle()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.batchfy.make_batchset">
    make_batchset()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.evaluator">
    evaluator
  </a>
<nav aria-label="evaluator" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.evaluator.BaseEvaluator">
    BaseEvaluator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators">
    iterators
  </a>
<nav aria-label="iterators" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler">
    ShufflingEnabler
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator">
    ToggleableShufflingMultiprocessIterator
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator">
    ToggleableShufflingSerialIterator
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger">
    tensorboard_logger
  </a>
<nav aria-label="tensorboard_logger" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger">
    TensorboardLogger
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils">
    train_utils
  </a>
<nav aria-label="train_utils" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils.check_early_stop">
    check_early_stop()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#adviser.tools.espnet_minimal.utils.training.train_utils.set_early_stop">
    set_early_stop()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/DigitalPhonetics/adviser/edit/master/docs/api/tools.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<h1 id="tools">Tools<a class="headerlink" href="#tools" title="Permanent link">¶</a></h1>
<div class="doc doc-object doc-module">
<h2 class="hidden-toc" href="#adviser.tools" id="adviser.tools" style="visibility: hidden; width: 0; height: 0;">
<a class="headerlink" href="#adviser.tools" title="Permanent link">¶</a></h2>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="adviser.tools.create_ontology">
<code>create_ontology</code>
<a class="headerlink" href="#adviser.tools.create_ontology" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="adviser.tools.create_ontology.Database">
<code>Database</code>
<a class="headerlink" href="#adviser.tools.create_ontology.Database" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.Database.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.create_ontology.Database.__init__" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tables</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># result will be (type, name, tbl_name, rootpage, sql)</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">"SELECT * FROM sqlite_master where type='table'"</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span> <span class="o">=</span> <span class="n">DatabaseTable</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># get fields/slots</span>
        <span class="c1"># result will be (id, name, type, not null, default, primary key)</span>
        <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PRAGMA table_info(</span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">);"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">fields</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
        <span class="c1"># make sure that fields are sorted according to field index (should be already anyway)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">fields</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">fields</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">field</span><span class="p">:</span> <span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># get entries (especially for possible values) </span>
        <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">f</span><span class="s2">"SELECT * FROM </span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">entries</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.Database.get_slot_values">
<code class="highlight language-python">
get_slot_values<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">slot</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.Database.get_slot_values" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>102
103</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_slot_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">slot</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">get_slot_values</span><span class="p">(</span><span class="n">slot</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.Database.get_slots">
<code class="highlight language-python">
get_slots<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.Database.get_slots" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 99
100</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_slots</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="n">table</span><span class="p">]</span><span class="o">.</span><span class="n">get_slots</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.Database.get_tables">
<code class="highlight language-python">
get_tables<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.Database.get_tables" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>96
97</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_tables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tables</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="adviser.tools.create_ontology.DatabaseTable">
<code>DatabaseTable</code>
<a class="headerlink" href="#adviser.tools.create_ontology.DatabaseTable" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.DatabaseTable.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.create_ontology.DatabaseTable.__init__" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>47
48
49
50</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fields</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.DatabaseTable.get_slot_values">
<code class="highlight language-python">
get_slot_values<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slot</span><span class="p">,</span> <span class="n">dontcare</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.DatabaseTable.get_slot_values" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>61
62
63
64
65
66
67
68</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_slot_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slot</span><span class="p">,</span> <span class="n">dontcare</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="c1"># get slot id</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_slot_id</span><span class="p">(</span><span class="n">slot</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">id</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Slot '</span><span class="si">{</span><span class="n">slot</span><span class="si">}</span><span class="s2">' is not part of the database table '</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">'"</span>
    <span class="n">values</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">entry</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">entries</span><span class="p">])))</span>
    <span class="k">if</span> <span class="n">dontcare</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="s1">'dontcare'</span> <span class="ow">in</span> <span class="n">values</span> <span class="ow">or</span> <span class="s2">"do n't care"</span> <span class="ow">in</span> <span class="n">values</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'dontcare'</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">values</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" id="adviser.tools.create_ontology.DatabaseTable.get_slots">
<code class="highlight language-python">
get_slots<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.DatabaseTable.get_slots" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>58
59</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_slots</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">field</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fields</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="adviser.tools.create_ontology.get_defaults">
<code class="highlight language-python">
get_defaults<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.get_defaults" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>105
106
107
108</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_defaults</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">'discourseAct'</span><span class="p">:</span> <span class="p">[</span><span class="s2">"ack"</span><span class="p">,</span> <span class="s2">"hello"</span><span class="p">,</span> <span class="s2">"none"</span><span class="p">,</span> <span class="s2">"silence"</span><span class="p">,</span> <span class="s2">"thanks"</span><span class="p">,</span> <span class="s2">"bad"</span><span class="p">],</span>
            <span class="s1">'method'</span><span class="p">:</span> <span class="p">[</span><span class="s2">"none"</span><span class="p">,</span> <span class="s2">"byconstraints"</span><span class="p">,</span> <span class="s2">"byprimarykey"</span><span class="p">,</span> <span class="s2">"finished"</span><span class="p">,</span> <span class="s2">"byalternatives"</span><span class="p">,</span> <span class="s2">"restart"</span><span class="p">],</span>
            <span class="s1">'key'</span><span class="p">:</span> <span class="s1">'name'</span><span class="p">}</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="adviser.tools.create_ontology.run_questions">
<code class="highlight language-python">
run_questions<span class="p">(</span><span class="n">db</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.create_ontology.run_questions" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/create_ontology.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">run_questions</span><span class="p">(</span><span class="n">db</span><span class="p">:</span> <span class="n">Database</span><span class="p">):</span>
    <span class="c1"># initialize with default values</span>
    <span class="n">answers</span> <span class="o">=</span> <span class="n">get_defaults</span><span class="p">()</span>

    <span class="n">questions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'list'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Select table to create ontology for'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'table'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'key'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span> <span class="s1">'name'</span><span class="p">:</span> <span class="n">table</span><span class="p">,</span> <span class="s1">'value'</span><span class="p">:</span> <span class="n">table</span><span class="p">}</span> <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">table</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">db</span><span class="o">.</span><span class="n">get_tables</span><span class="p">())],</span>
            <span class="s1">'validate'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answer</span><span class="p">:</span> <span class="s1">'You must choose at least one table.'</span> \
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'input'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Enter the name of the domain:'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'domain'</span><span class="p">,</span>
            <span class="s1">'default'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answers</span><span class="p">:</span> <span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'list'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'key'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Which slot will be used as key? (The key uniquely identifies an entity in the database, e.g. the name in case of restaurants)'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answers</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">db</span><span class="o">.</span><span class="n">get_slots</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">])]</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'checkbox'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'requestable'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Select user requestables'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answers</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">,</span> <span class="s1">'checked'</span><span class="p">:</span> <span class="n">slot</span> <span class="o">!=</span> <span class="s1">'id'</span><span class="p">}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">db</span><span class="o">.</span><span class="n">get_slots</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">])]</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'checkbox'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'system_requestable'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Select system requestables'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answers</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">db</span><span class="o">.</span><span class="n">get_slots</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">])]</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'checkbox'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'informable'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Select informable slots'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">answers</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">db</span><span class="o">.</span><span class="n">get_slots</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">])]</span>
        <span class="p">}]</span>
    <span class="n">answers_</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">custom_style_2</span><span class="p">)</span>
    <span class="c1"># check whether there are answers (e.g. if the user cancels the prompt using Ctrl+c)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">answers_</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">()</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">answers_</span><span class="p">)</span>

    <span class="c1"># get values for informable slots</span>
    <span class="n">questions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'checkbox'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="sa">f</span><span class="s1">'Select values for informable slot </span><span class="si">{</span><span class="n">slot</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">value</span><span class="p">,</span> <span class="s1">'checked'</span><span class="p">:</span> <span class="n">value</span> <span class="o">!=</span> <span class="s1">'dontcare'</span><span class="p">}</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">db</span><span class="o">.</span><span class="n">get_slot_values</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">],</span> <span class="n">slot</span><span class="p">)]</span>
        <span class="p">}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">[</span><span class="s1">'informable'</span><span class="p">]</span>
    <span class="p">]</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">custom_style_2</span><span class="p">)</span>
    <span class="c1"># merge informable slot values with informable slots</span>
    <span class="n">answers</span><span class="p">[</span><span class="s1">'informable'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">slot</span><span class="p">:</span> <span class="n">values</span><span class="p">[</span><span class="n">slot</span><span class="p">]</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">[</span><span class="s1">'informable'</span><span class="p">]</span> <span class="k">if</span> <span class="n">slot</span> <span class="ow">in</span> <span class="n">values</span><span class="p">}</span>

    <span class="c1"># get binary slots</span>
    <span class="n">questions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'checkbox'</span><span class="p">,</span>
            <span class="s1">'qmark'</span><span class="p">:</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'binary'</span><span class="p">,</span>
            <span class="s1">'message'</span><span class="p">:</span> <span class="s1">'Select binary slots'</span><span class="p">,</span>
            <span class="s1">'choices'</span><span class="p">:</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="n">slot</span><span class="p">,</span> <span class="s1">'checked'</span><span class="p">:</span> <span class="nb">set</span><span class="p">(</span><span class="n">db</span><span class="o">.</span><span class="n">get_slot_values</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'table'</span><span class="p">],</span> <span class="n">slot</span><span class="p">))</span> <span class="o">==</span> <span class="p">{</span><span class="s1">'true'</span><span class="p">,</span> <span class="s1">'false'</span><span class="p">}}</span> <span class="k">for</span> <span class="n">slot</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s1">'informable'</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="n">answers</span><span class="p">[</span><span class="s1">'requestable'</span><span class="p">]</span> <span class="o">+</span> <span class="n">answers</span><span class="p">[</span><span class="s1">'system_requestable'</span><span class="p">]]</span>
        <span class="p">}</span>
    <span class="p">]</span>
    <span class="n">answers_</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">custom_style_2</span><span class="p">)</span>
    <span class="c1"># check whether there are answers (e.g. if the user cancels the prompt using Ctrl+c)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">answers_</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">()</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">answers_</span><span class="p">)</span>


    <span class="k">return</span> <span class="n">answers</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="adviser.tools.espnet_minimal">
<code>espnet_minimal</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h3 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr">
<code>asr</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.asr_utils">
<code>asr_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.asr_utils" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.asr_utils.add_gradient_noise">
<code class="highlight language-python">
add_gradient_noise<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mf">0.55</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.asr_utils.add_gradient_noise" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Adds noise from a standard normal distribution to the gradients.</p>
<p>The standard deviation (<code>sigma</code>) is controlled by the three hyper-parameters below.
<code>sigma</code> goes to zero (no noise) with more iterations.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code>torch.nn.model</code></td>
<td>
<p>Model.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>iteration</code></td>
<td><code>int</code></td>
<td>
<p>Number of iterations.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>duration</code></td>
<td><code>int) {100, 1000}</code></td>
<td>
<p>Number of durations to control the interval of the <code>sigma</code> change.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>eta</code></td>
<td><code>float) {0.01, 0.3, 1.0}</code></td>
<td>
<p>The magnitude of <code>sigma</code>.</p>
</td>
<td><code>1.0</code></td>
</tr>
<tr>
<td><code>scale_factor</code></td>
<td><code>float) {0.55}</code></td>
<td>
<p>The scale of <code>sigma</code>.</p>
</td>
<td><code>0.55</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/asr_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">add_gradient_noise</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mf">0.55</span><span class="p">):</span>
    <span class="sd">"""Adds noise from a standard normal distribution to the gradients.</span>

<span class="sd">    The standard deviation (`sigma`) is controlled by the three hyper-parameters below.</span>
<span class="sd">    `sigma` goes to zero (no noise) with more iterations.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.model): Model.</span>
<span class="sd">        iteration (int): Number of iterations.</span>
<span class="sd">        duration (int) {100, 1000}: Number of durations to control the interval of the `sigma` change.</span>
<span class="sd">        eta (float) {0.01, 0.3, 1.0}: The magnitude of `sigma`.</span>
<span class="sd">        scale_factor (float) {0.55}: The scale of `sigma`.</span>
<span class="sd">    """</span>
    <span class="n">interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">iteration</span> <span class="o">//</span> <span class="n">duration</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">/</span> <span class="n">interval</span> <span class="o">**</span> <span class="n">scale_factor</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_shape</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">+=</span> <span class="n">noise</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.asr_utils.get_model_conf">
<code class="highlight language-python">
get_model_conf<span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">conf_path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.asr_utils.get_model_conf" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get model config information by reading a model config file (model.json).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_path</code></td>
<td><code>str</code></td>
<td>
<p>Model path.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>conf_path</code></td>
<td><code>str</code></td>
<td>
<p>Optional model config path.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list[int, int, dict[str, Any]]</code></td>
<td>
<p>Config information loaded from json file.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/asr_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_model_conf</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">conf_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Get model config information by reading a model config file (model.json).</span>

<span class="sd">    Args:</span>
<span class="sd">        model_path (str): Model path.</span>
<span class="sd">        conf_path (str): Optional model config path.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list[int, int, dict[str, Any]]: Config information loaded from json file.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">conf_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model_conf</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'/model.json'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_conf</span> <span class="o">=</span> <span class="n">conf_path</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_conf</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'reading a config file from '</span> <span class="o">+</span> <span class="n">model_conf</span><span class="p">)</span>
        <span class="n">confs</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">confs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># for lm</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">confs</span>
        <span class="k">return</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># for asr, tts, mt</span>
        <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">confs</span>
        <span class="k">return</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.asr_utils.torch_load">
<code class="highlight language-python">
torch_load<span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_load" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Load torch model states.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>str</code></td>
<td>
<p>Model path or snapshot file path to be loaded.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>model</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Torch model.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/asr_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">torch_load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="sd">"""Load torch model states.</span>

<span class="sd">    Args:</span>
<span class="sd">        path (str): Model path or snapshot file path to be loaded.</span>
<span class="sd">        model (torch.nn.Module): Torch model.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="s1">'snapshot'</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="n">model_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">)[</span><span class="s1">'model'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">)</span>

    <span class="c1"># debugging:</span>
    <span class="c1"># print(model_state_dict)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'module'</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">)</span>

    <span class="k">del</span> <span class="n">model_state_dict</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.asr_utils.torch_save">
<code class="highlight language-python">
torch_save<span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.asr_utils.torch_save" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Save torch model states.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>str</code></td>
<td>
<p>Model path to be saved.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>model</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Torch model.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/asr_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>70
71
72
73
74
75
76
77
78
79
80
81</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">torch_save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="sd">"""Save torch model states.</span>

<span class="sd">    Args:</span>
<span class="sd">        path (str): Model path to be saved.</span>
<span class="sd">        model (torch.nn.Module): Torch model.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'module'</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend">
<code>pytorch_backend</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init">
<code>asr_init</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Finetuning methods.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.filter_modules">
<code class="highlight language-python">
filter_modules<span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.filter_modules" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Filter non-matched modules in module_state_dict.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_state_dict</code></td>
<td><code>OrderedDict</code></td>
<td>
<p>trained model state_dict</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>modules</code></td>
<td><code>list</code></td>
<td>
<p>specified module list for transfer</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>new_mods (list)</code></td>
<td>
<p>the update module list</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">filter_modules</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
    <span class="sd">"""Filter non-matched modules in module_state_dict.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_state_dict (OrderedDict): trained model state_dict</span>
<span class="sd">        modules (list): specified module list for transfer</span>

<span class="sd">    Return:</span>
<span class="sd">        new_mods (list): the update module list</span>

<span class="sd">    """</span>
    <span class="n">new_mods</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">incorrect_mods</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">mods_model</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">mods_model</span><span class="p">):</span>
            <span class="n">new_mods</span> <span class="o">+=</span> <span class="p">[</span><span class="n">mod</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">incorrect_mods</span> <span class="o">+=</span> <span class="p">[</span><span class="n">mod</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">incorrect_mods</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"module(s) </span><span class="si">%s</span><span class="s2"> don</span><span class="se">\'</span><span class="s2">t match or (partially match) "</span>
                        <span class="s2">"available modules in model."</span><span class="p">,</span> <span class="n">incorrect_mods</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'for information, the existing modules in model are:'</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'</span><span class="si">%s</span><span class="s1">'</span><span class="p">,</span> <span class="n">mods_model</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_mods</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_asr_mt_state_dict">
<code class="highlight language-python">
get_partial_asr_mt_state_dict<span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_asr_mt_state_dict" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Create state_dict with specified modules matching input model modules.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_state_dict</code></td>
<td><code>OrderedDict</code></td>
<td>
<p>trained model state_dict</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>modules</code></td>
<td><code>list</code></td>
<td>
<p>specified module list for transfer</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>new_state_dict (OrderedDict)</code></td>
<td>
<p>the updated state_dict</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_partial_asr_mt_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
    <span class="sd">"""Create state_dict with specified modules matching input model modules.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_state_dict (OrderedDict): trained model state_dict</span>
<span class="sd">        modules (list): specified module list for transfer</span>

<span class="sd">    Return:</span>
<span class="sd">        new_state_dict (OrderedDict): the updated state_dict</span>

<span class="sd">    """</span>
    <span class="n">new_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">model_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">):</span>
            <span class="n">new_state_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="n">new_state_dict</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_lm_state_dict">
<code class="highlight language-python">
get_partial_lm_state_dict<span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_partial_lm_state_dict" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Create compatible ASR state_dict from model_state_dict (LM).</p>
<p>The keys for specified modules are modified to match ASR decoder modules keys.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_state_dict</code></td>
<td><code>OrderedDict</code></td>
<td>
<p>trained model state_dict</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>modules</code></td>
<td><code>list</code></td>
<td>
<p>specified module list for transfer</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>new_state_dict (OrderedDict)</code></td>
<td>
<p>the updated state_dict
new_mods (list): the updated module list</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_partial_lm_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
    <span class="sd">"""Create compatible ASR state_dict from model_state_dict (LM).</span>

<span class="sd">    The keys for specified modules are modified to match ASR decoder modules keys.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_state_dict (OrderedDict): trained model state_dict</span>
<span class="sd">        modules (list): specified module list for transfer</span>

<span class="sd">    Return:</span>
<span class="sd">        new_state_dict (OrderedDict): the updated state_dict</span>
<span class="sd">        new_mods (list): the updated module list</span>

<span class="sd">    """</span>
    <span class="n">new_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="n">new_modules</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">"predictor.embed.weight"</span> <span class="ow">and</span> <span class="s2">"predictor.embed."</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
            <span class="n">new_key</span> <span class="o">=</span> <span class="s2">"dec.embed.weight"</span>
            <span class="n">new_state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">new_modules</span> <span class="o">+=</span> <span class="p">[</span><span class="n">new_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">"predictor.rnn."</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">and</span> <span class="s2">"predictor.rnn."</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
            <span class="n">new_key</span> <span class="o">=</span> <span class="s2">"dec.decoder."</span> <span class="o">+</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"predictor.rnn."</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">new_state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">new_modules</span> <span class="o">+=</span> <span class="p">[</span><span class="n">new_key</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">new_state_dict</span><span class="p">,</span> <span class="n">new_modules</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_root_dir">
<code class="highlight language-python">
get_root_dir<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_root_dir" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>16
17</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_root_dir</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))))))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_trained_model_state_dict">
<code class="highlight language-python">
get_trained_model_state_dict<span class="p">(</span><span class="n">model_path</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.get_trained_model_state_dict" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Extract the trained model state dict for pre-initialization.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_path</code></td>
<td><code>str</code></td>
<td>
<p>Path to model.***.best</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model.state_dict() (OrderedDict)</code></td>
<td>
<p>the loaded model state_dict
(str): Type of model. Either ASR/MT or LM.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_trained_model_state_dict</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
    <span class="sd">"""Extract the trained model state dict for pre-initialization.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_path (str): Path to model.***.best</span>

<span class="sd">    Return:</span>
<span class="sd">        model.state_dict() (OrderedDict): the loaded model state_dict</span>
<span class="sd">        (str): Type of model. Either ASR/MT or LM.</span>

<span class="sd">    """</span>
    <span class="n">conf_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_path</span><span class="p">),</span> <span class="s1">'model.json'</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">'rnnlm'</span> <span class="ow">in</span> <span class="n">model_path</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'reading model parameters from </span><span class="si">%s</span><span class="s1">'</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">),</span> <span class="s1">'lm'</span>

    <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">get_model_conf</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">conf_path</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'reading model parameters from '</span> <span class="o">+</span> <span class="n">model_path</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"model_module"</span><span class="p">):</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model_module</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="s2">"services.hci.speech.espnet_minimal.nets.pytorch_backend.e2e_asr:E2E"</span>

    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import</span><span class="p">(</span><span class="n">model_module</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="n">torch_load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">MTInterface</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ASRInterface</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'asr-mt'</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_model">
<code class="highlight language-python">
load_trained_model<span class="p">(</span><span class="n">model_path</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_model" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Load the trained model for recognition.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_path</code></td>
<td><code>str</code></td>
<td>
<p>Path to model.***.best</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">load_trained_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
    <span class="sd">"""Load the trained model for recognition.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_path (str): Path to model.***.best</span>

<span class="sd">    """</span>
    <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">train_args</span> <span class="o">=</span> <span class="n">get_model_conf</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">get_root_dir</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_path</span><span class="p">),</span> <span class="s1">'model.json'</span><span class="p">))</span>

    <span class="c1"># logging.warning('reading model parameters from ' + model_path)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_args</span><span class="p">,</span> <span class="s2">"model_module"</span><span class="p">):</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="n">train_args</span><span class="o">.</span><span class="n">model_module</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="s2">"services.hci.speech.espnet_minimal.nets.pytorch_backend.e2e_asr:E2E"</span>
    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import</span><span class="p">(</span><span class="n">model_module</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">train_args</span><span class="p">)</span>

    <span class="n">torch_load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_args</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_modules">
<code class="highlight language-python">
load_trained_modules<span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">interface</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">tools</span><span class="o">.</span><span class="n">espnet_minimal</span><span class="o">.</span><span class="n">nets</span><span class="o">.</span><span class="n">asr_interface</span><span class="o">.</span><span class="n">ASRInterface</span><span class="s1">'&gt;)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.load_trained_modules" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Load model encoder or/and decoder modules with ESPNET pre-trained model(s).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>initial input dimension.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>initial output dimension.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>args</code></td>
<td><code>Namespace</code></td>
<td>
<p>The initial model arguments.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>interface</code></td>
<td><code>Interface</code></td>
<td>
<p>ASRInterface or STInterface</p>
</td>
<td><code>&lt;class 'tools.espnet_minimal.nets.asr_interface.ASRInterface'&gt;</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model (torch.nn.Module)</code></td>
<td>
<p>The model with pretrained modules.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">load_trained_modules</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="n">ASRInterface</span><span class="p">):</span>
    <span class="sd">"""Load model encoder or/and decoder modules with ESPNET pre-trained model(s).</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): initial input dimension.</span>
<span class="sd">        odim (int): initial output dimension.</span>
<span class="sd">        args (Namespace): The initial model arguments.</span>
<span class="sd">        interface (Interface): ASRInterface or STInterface</span>

<span class="sd">    Return:</span>
<span class="sd">        model (torch.nn.Module): The model with pretrained modules.</span>

<span class="sd">    """</span>
    <span class="n">enc_model_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">enc_init</span>
    <span class="n">dec_model_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">dec_init</span>
    <span class="n">enc_modules</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">enc_init_mods</span>
    <span class="n">dec_modules</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">dec_init_mods</span>

    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_module</span><span class="p">)</span>
    <span class="n">main_model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">main_model</span><span class="p">,</span> <span class="n">interface</span><span class="p">)</span>

    <span class="n">main_state_dict</span> <span class="o">=</span> <span class="n">main_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'model(s) found for pre-initialization'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">modules</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">enc_model_path</span><span class="p">,</span> <span class="n">enc_modules</span><span class="p">),</span>
                                <span class="p">(</span><span class="n">dec_model_path</span><span class="p">,</span> <span class="n">dec_modules</span><span class="p">)]:</span>
        <span class="k">if</span> <span class="n">model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
                <span class="n">model_state_dict</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="n">get_trained_model_state_dict</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

                <span class="n">modules</span> <span class="o">=</span> <span class="n">filter_modules</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">'lm'</span><span class="p">:</span>
                    <span class="n">partial_state_dict</span><span class="p">,</span> <span class="n">modules</span> <span class="o">=</span> <span class="n">get_partial_lm_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">partial_state_dict</span> <span class="o">=</span> <span class="n">get_partial_asr_mt_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">partial_state_dict</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">transfer_verification</span><span class="p">(</span><span class="n">main_state_dict</span><span class="p">,</span> <span class="n">partial_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
                            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'loading </span><span class="si">%s</span><span class="s1"> from model: </span><span class="si">%s</span><span class="s1">'</span><span class="p">,</span> <span class="n">modules</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">partial_state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'override </span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="n">k</span><span class="p">)</span>
                            <span class="n">main_state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">partial_state_dict</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'modules </span><span class="si">%s</span><span class="s1"> in model </span><span class="si">%s</span><span class="s1"> don</span><span class="se">\'</span><span class="s1">t match your training config'</span><span class="p">,</span>
                                            <span class="n">modules</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'model was not found : </span><span class="si">%s</span><span class="s1">'</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>

    <span class="n">main_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">main_state_dict</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">main_model</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.transfer_verification">
<code class="highlight language-python">
transfer_verification<span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">partial_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.asr.pytorch_backend.asr_init.transfer_verification" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Verify tuples (key, shape) for input model modules match specified modules.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_state_dict</code></td>
<td><code>OrderedDict</code></td>
<td>
<p>the initial model state_dict</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>partial_state_dict</code></td>
<td><code>OrderedDict</code></td>
<td>
<p>the trained model state_dict</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>modules</code></td>
<td><code>list</code></td>
<td>
<p>specified module list for transfer</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>(boolean)</code></td>
<td>
<p>allow transfer</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/asr/pytorch_backend/asr_init.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">transfer_verification</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">,</span> <span class="n">partial_state_dict</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
    <span class="sd">"""Verify tuples (key, shape) for input model modules match specified modules.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_state_dict (OrderedDict): the initial model state_dict</span>
<span class="sd">        partial_state_dict (OrderedDict): the trained model state_dict</span>
<span class="sd">        modules (list): specified module list for transfer</span>

<span class="sd">    Return:</span>
<span class="sd">        (boolean): allow transfer</span>

<span class="sd">    """</span>
    <span class="n">partial_modules</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">key_p</span><span class="p">,</span> <span class="n">value_p</span> <span class="ow">in</span> <span class="n">partial_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key_p</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">value_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">model_state_dict</span><span class="p">[</span><span class="n">key_p</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">partial_modules</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">key_p</span><span class="p">,</span> <span class="n">value_p</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">partial_modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h3 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin">
<code>bin</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_recog">
<code>asr_recog</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_recog" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>End-to-end speech recognition model decoding script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_recog.get_parser">
<code class="highlight language-python">
get_parser<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_recog.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get default arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/asr_recog.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">():</span>
    <span class="sd">"""Get default arguments."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">'Transcribe text from speech using a speech recognition model on one CPU or GPU'</span><span class="p">,</span>
        <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Second config file path that overwrites the settings in `--config`'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Third config file path that overwrites the settings in `--config` and `--config2`'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dtype'</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">(</span><span class="s2">"float16"</span><span class="p">,</span> <span class="s2">"float32"</span><span class="p">,</span> <span class="s2">"float64"</span><span class="p">),</span> <span class="n">default</span><span class="o">=</span><span class="s2">"float32"</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Float precision (only available in --api v2)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'chainer'</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batchsize'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Batch size for beam search (0: means no batch processing)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--preprocess-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The configuration file for the pre-processing'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--api'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"v1"</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"v1"</span><span class="p">,</span> <span class="s2">"v2"</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'''Beam search APIs</span>
<span class="s1">        v1: Default API. It only supports the ASRInterface.recognize method and DefaultRNNLM.</span>
<span class="s1">        v2: Experimental API. It supports any models that implements ScorerInterface.'''</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--recog-json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of recognition data (json)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--result-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of result label data (json)'</span><span class="p">)</span>
    <span class="c1"># model (parameter) related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model file parameters to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model config file'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--num-spkrs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of speakers in the speech'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--num-encs'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoders in the model.'</span><span class="p">)</span>
    <span class="c1"># search related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--nbest'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output N-best hypotheses'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--beam-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Beam size'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--penalty'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Incertion penalty'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Input length ratio to obtain max output length.</span>
<span class="s2">                        If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="s2">                        to automatically find maximum hypothesis lengths"""</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Input length ratio to obtain min output length'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ctc-weight'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'CTC weight in joint decoding'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--weights-ctc-dec'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'append'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'ctc weight assigned to each encoder during decoding.[in multi-encoder mode only]'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ctc-window-margin'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Use CTC window with margin parameter to accelerate</span>
<span class="s2">                        CTC/attention decoding especially on GPU. Smaller magin</span>
<span class="s2">                        makes decoding faster, but may increase search errors.</span>
<span class="s2">                        If margin=0 (default), this function is disabled"""</span><span class="p">)</span>
    <span class="c1"># transducer related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--score-norm-transducer'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Normalize transducer scores by length'</span><span class="p">)</span>
    <span class="c1"># rnnlm related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-dict'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word list to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lm-weight'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM weight'</span><span class="p">)</span>
    <span class="c1"># streaming related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--streaming-mode'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'window'</span><span class="p">,</span> <span class="s1">'segment'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Use streaming recognizer for inference.</span>
<span class="s2">                        `--batchsize` must be set to 0 to enable this mode"""</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--streaming-window'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Window size'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--streaming-min-blank-dur'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Minimum blank duration threshold'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--streaming-onset-margin'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Onset margin'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--streaming-offset-margin'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Offset margin'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_recog.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_recog.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Run the main decoding function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/asr_recog.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Run the main decoding function."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"float16"</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> does not support the CPU backend."</span><span class="p">)</span>

    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span>
                            <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Skip DEBUG/INFO messages"</span><span class="p">)</span>

    <span class="c1"># check CUDA_VISIBLE_DEVICES</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"#gpus is not matched with CUDA_VISIBLE_DEVICES."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># TODO(mn5k): support of multiple GPUs</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"The program only supports ngpu=1."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># seed setting</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'set random seed = </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># validate rnn options</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rnnlm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">word_rnnlm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"It seems that both --rnnlm and --word-rnnlm are specified. Please use either option."</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># recog</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_spkrs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"chainer"</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.chainer_backend.asr</span> <span class="kn">import</span> <span class="n">recog</span>
            <span class="n">recog</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Experimental API that supports custom LMs</span>
                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">api</span> <span class="o">==</span> <span class="s2">"v2"</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.recog</span> <span class="kn">import</span> <span class="n">recog_v2</span>
                    <span class="n">recog_v2</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.asr</span> <span class="kn">import</span> <span class="n">recog</span>
                    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="s2">"float32"</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"`--dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">` is only available with `--api v2`"</span><span class="p">)</span>
                    <span class="n">recog</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">api</span> <span class="o">==</span> <span class="s2">"v2"</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--num-encs </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_encs</span><span class="si">}</span><span class="s2"> &gt; 1 is not supported in --api v2"</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.asr</span> <span class="kn">import</span> <span class="n">recog</span>
                    <span class="n">recog</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only chainer and pytorch are supported."</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">num_spkrs</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.asr_mix</span> <span class="kn">import</span> <span class="n">recog</span>
            <span class="n">recog</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only pytorch is supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_train">
<code>asr_train</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_train" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Automatic speech recognition model training script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_train.get_parser">
<code class="highlight language-python">
get_parser<span class="p">(</span><span class="n">parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_train.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get default arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/asr_train.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">(</span><span class="n">parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Get default arguments."""</span>
    <span class="k">if</span> <span class="n">parser</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">"Train an automatic speech recognition (ASR) model on one CPU, one or multiple GPUs"</span><span class="p">,</span>
            <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
            <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'second config file path that overwrites the settings in `--config`.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'third config file path that overwrites the settings in `--config` and `--config2`.'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs. If not given, use all visible devices'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--train-dtype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"float32"</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"float16"</span><span class="p">,</span> <span class="s2">"float32"</span><span class="p">,</span> <span class="s2">"float64"</span><span class="p">,</span> <span class="s2">"O0"</span><span class="p">,</span> <span class="s2">"O1"</span><span class="p">,</span> <span class="s2">"O2"</span><span class="p">,</span> <span class="s2">"O3"</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Data type for training (only pytorch backend). '</span>
                             <span class="s1">'O0,O1,.. flags require apex. See https://nvidia.github.io/apex/amp.html#opt-levels'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--outdir'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output directory'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dict'</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Dictionary'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugdir'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output directory for debugging'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--resume'</span><span class="p">,</span> <span class="s1">'-r'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Resume the training from snapshot'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minibatches'</span><span class="p">,</span> <span class="s1">'-N'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'-1'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Process only N minibatches (for debug)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--tensorboard-dir'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Tensorboard log dir path"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--report-interval-iters'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Report interval iterations"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-interval-iters'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Save snapshot interval iterations"</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--train-json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of train label data (json)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--valid-json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of validation label data (json)'</span><span class="p">)</span>
    <span class="c1"># network architecture</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model-module'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'model defined module (default: services.hci.speech.espnet_minimal.nets.xxx_backend.e2e_asr:E2E)'</span><span class="p">)</span>
    <span class="c1"># encoder</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--num-encs'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoders in the model.'</span><span class="p">)</span>
    <span class="c1"># loss related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ctc_type'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'warpctc'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'builtin'</span><span class="p">,</span> <span class="s1">'warpctc'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Type of CTC implementation to calculate loss.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--mtlalpha'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Multitask learning coefficient, alpha: alpha*ctc_loss + (1-alpha)*att_loss '</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lsm-weight'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Label smoothing weight'</span><span class="p">)</span>
    <span class="c1"># recognition options to compute CER/WER</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--report-cer'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Compute CER on development set'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--report-wer'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Compute WER on development set'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--nbest'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output N-best hypotheses'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--beam-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Beam size'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--penalty'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Incertion penalty'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlenratio'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Input length ratio to obtain max output length.</span>
<span class="s2">                        If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="s2">                        to automatically find maximum hypothesis lengths"""</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minlenratio'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Input length ratio to obtain min output length'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ctc-weight'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'CTC weight in joint decoding'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lm-weight'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM weight.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--sym-space'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'&lt;space&gt;'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Space symbol'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--sym-blank'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'&lt;blank&gt;'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Blank symbol'</span><span class="p">)</span>
    <span class="c1"># minibatch related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--sortagrad'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"How many epochs to use sortagrad for. 0 = deactivated, -1 = all epochs"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-count'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="n">BATCH_COUNT_CHOICES</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'How to count batch_size. The default (auto) will find how to count by args.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-size'</span><span class="p">,</span> <span class="s1">'--batch-seqs'</span><span class="p">,</span> <span class="s1">'-b'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum seqs in a minibatch (0 to disable)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-bins'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum bins in a minibatch (0 to disable)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-frames-in'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum input frames in a minibatch (0 to disable)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-frames-out'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum output frames in a minibatch (0 to disable)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-frames-inout'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum input+output frames in a minibatch (0 to disable)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlen-in'</span><span class="p">,</span> <span class="s1">'--batch-seq-maxlen-in'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'ML'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'When --batch-count=seq, batch size is reduced if the input sequence length &gt; ML.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlen-out'</span><span class="p">,</span> <span class="s1">'--batch-seq-maxlen-out'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'ML'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'When --batch-count=seq, batch size is reduced if the output sequence length &gt; ML'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--n-iter-processes'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of processes of iterator'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--preprocess-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The configuration file for the pre-processing'</span><span class="p">)</span>
    <span class="c1"># optimization related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--opt'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'adadelta'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'adadelta'</span><span class="p">,</span> <span class="s1">'adam'</span><span class="p">,</span> <span class="s1">'noam'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Optimizer'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--accum-grad'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of gradient accumuration'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eps'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Epsilon constant for optimizer'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eps-decay'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Decaying ratio of epsilon'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--weight-decay'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Weight decay ratio'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--criterion'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'acc'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'acc'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Criterion to perform epsilon decay'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--threshold'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Threshold to stop iteration'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--epochs'</span><span class="p">,</span> <span class="s1">'-e'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum number of epochs'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--early-stop-criterion'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'validation/main/acc'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Value to monitor to trigger an early stopping of the training"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--patience'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Number of epochs to wait without improvement before stopping the training"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--grad-clip'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Gradient norm threshold to clip'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--num-save-attention'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of samples of attention to be saved'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--grad-noise'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The flag to switch to use noise injection to gradients during training'</span><span class="p">)</span>
    <span class="c1"># asr_mix related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--num-spkrs'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of speakers in the speech.'</span><span class="p">)</span>
    <span class="c1"># decoder related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--context-residual'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The flag to switch to use context vector residual in the decoder network'</span><span class="p">)</span>
    <span class="c1"># finetuning related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--enc-init'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Pre-trained ASR model to initialize encoder.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--enc-init-mods'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'enc.enc.'</span><span class="p">,</span>
                        <span class="nb">type</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)</span> <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="s1">''</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'List of encoder modules to initialize, separated by a comma.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dec-init'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Pre-trained ASR, MT or LM model to initialize decoder.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dec-init-mods'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'att., dec.'</span><span class="p">,</span>
                        <span class="nb">type</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)</span> <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="s1">''</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'List of decoder modules to initialize, separated by a comma.'</span><span class="p">)</span>
    <span class="c1"># front end related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-frontend'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The flag to switch to use frontend system.'</span><span class="p">)</span>

    <span class="c1"># WPE related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-wpe'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Apply Weighted Prediction Error'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wtype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'blstmp'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="s1">'blstm'</span><span class="p">,</span> <span class="s1">'lstmp'</span><span class="p">,</span> <span class="s1">'blstmp'</span><span class="p">,</span> <span class="s1">'vgglstmp'</span><span class="p">,</span> <span class="s1">'vggblstmp'</span><span class="p">,</span> <span class="s1">'vgglstm'</span><span class="p">,</span> <span class="s1">'vggblstm'</span><span class="p">,</span>
                                 <span class="s1">'gru'</span><span class="p">,</span> <span class="s1">'bgru'</span><span class="p">,</span> <span class="s1">'grup'</span><span class="p">,</span> <span class="s1">'bgrup'</span><span class="p">,</span> <span class="s1">'vgggrup'</span><span class="p">,</span> <span class="s1">'vggbgrup'</span><span class="p">,</span> <span class="s1">'vgggru'</span><span class="p">,</span> <span class="s1">'vggbgru'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Type of encoder network architecture '</span>
                             <span class="s1">'of the mask estimator for WPE. '</span>
                             <span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wlayers'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wunits'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wprojs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wdropout-rate'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wpe-taps'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--wpe-delay'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-dnn-mask-for-wpe'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Use DNN to estimate the power spectrogram. '</span>
                             <span class="s1">'This option is experimental.'</span><span class="p">)</span>
    <span class="c1"># Beamformer related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-beamformer'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--btype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'blstmp'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="s1">'blstm'</span><span class="p">,</span> <span class="s1">'lstmp'</span><span class="p">,</span> <span class="s1">'blstmp'</span><span class="p">,</span> <span class="s1">'vgglstmp'</span><span class="p">,</span> <span class="s1">'vggblstmp'</span><span class="p">,</span> <span class="s1">'vgglstm'</span><span class="p">,</span> <span class="s1">'vggblstm'</span><span class="p">,</span>
                                 <span class="s1">'gru'</span><span class="p">,</span> <span class="s1">'bgru'</span><span class="p">,</span> <span class="s1">'grup'</span><span class="p">,</span> <span class="s1">'bgrup'</span><span class="p">,</span> <span class="s1">'vgggrup'</span><span class="p">,</span> <span class="s1">'vggbgrup'</span><span class="p">,</span> <span class="s1">'vgggru'</span><span class="p">,</span> <span class="s1">'vggbgru'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Type of encoder network architecture '</span>
                             <span class="s1">'of the mask estimator for Beamformer.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--blayers'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--bunits'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--bprojs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--badim'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--bnmask'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of beamforming masks, '</span>
                             <span class="s1">'default is 2 for [speech, noise].'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ref-channel'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The reference channel used for beamformer. '</span>
                             <span class="s1">'By default, the channel is estimated by DNN.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--bdropout-rate'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="c1"># Feature transform: Normalization</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--stats-file'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The stats file for the feature normalization'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--apply-uttmvn'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Apply utterance level mean '</span>
                             <span class="s1">'variance normalization.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--uttmvn-norm-means'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--uttmvn-norm-vars'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="c1"># Feature transform: Fbank</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--fbank-fs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The sample frequency used for '</span>
                             <span class="s1">'the mel-fbank creation.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--n-mels'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The number of mel-frequency bins.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--fbank-fmin'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--fbank-fmax'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.asr_train.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.asr_train.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Run the main training function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/asr_train.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">):</span>
    <span class="sd">"""Run the main training function."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"chainer"</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span> <span class="o">!=</span> <span class="s2">"float32"</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"chainer backend does not support --train-dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="si">}</span><span class="s2">."</span>
            <span class="s2">"Use --dtype float32."</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"O0"</span><span class="p">,</span> <span class="s2">"O1"</span><span class="p">,</span> <span class="s2">"O2"</span><span class="p">,</span> <span class="s2">"O3"</span><span class="p">,</span> <span class="s2">"float16"</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--train-dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="si">}</span><span class="s2"> does not support the CPU backend."</span><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">tools.espnet_minimal</span> <span class="kn">import</span> <span class="n">dynamic_import</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">model_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="s2">"services.hci.speech.espnet_minimal.nets."</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">+</span> <span class="s2">"_backend.e2e_asr:E2E"</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_module</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model_module</span>
    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import</span><span class="p">(</span><span class="n">model_module</span><span class="p">)</span>
    <span class="n">model_class</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span>
    <span class="n">args</span><span class="o">.</span><span class="n">model_module</span> <span class="o">=</span> <span class="n">model_module</span>
    <span class="k">if</span> <span class="s1">'chainer_backend'</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">model_module</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="s1">'chainer'</span>
    <span class="k">if</span> <span class="s1">'pytorch_backend'</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">model_module</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="s1">'pytorch'</span>

    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'Skip DEBUG/INFO messages'</span><span class="p">)</span>

    <span class="c1"># If --ngpu is not given,</span>
    <span class="c1">#   1. if CUDA_VISIBLE_DEVICES is set, all visible devices</span>
    <span class="c1">#   2. if nvidia-smi exists, use all devices</span>
    <span class="c1">#   3. else ngpu=0</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ngpu</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s1">'nvidia-smi'</span><span class="p">,</span> <span class="s1">'-L'</span><span class="p">],</span>
                                   <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span>
                                   <span class="n">stderr</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">,</span> <span class="ne">FileNotFoundError</span><span class="p">):</span>
                <span class="n">ngpu</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ngpu</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_torch_1_2_plus</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"There are some bugs with multi-GPU processing in PyTorch 1.2+"</span> \
                                   <span class="s2">" (see https://github.com/pytorch/pytorch/issues/21108)"</span>
        <span class="n">ngpu</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"ngpu: </span><span class="si">{</span><span class="n">ngpu</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># set random seed</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'random seed = </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># load dictionary for debug log</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dict</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">dictionary</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
        <span class="n">char_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                     <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">]</span>
        <span class="n">char_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">'&lt;blank&gt;'</span><span class="p">)</span>
        <span class="n">char_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;eos&gt;'</span><span class="p">)</span>
        <span class="n">args</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="n">char_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># train</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_spkrs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"chainer"</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.chainer_backend.asr</span> <span class="kn">import</span> <span class="n">train</span>
            <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.asr</span> <span class="kn">import</span> <span class="n">train</span>
            <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only chainer and pytorch are supported."</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># FIXME(kamo): Support --model-module</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.asr.pytorch_backend.asr_mix</span> <span class="kn">import</span> <span class="n">train</span>
            <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only pytorch is supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.lm_train">
<code>lm_train</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.lm_train" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Language model training script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.lm_train.get_parser">
<code class="highlight language-python">
get_parser<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.lm_train.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/lm_train.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">():</span>
    <span class="sd">"""Get parser."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">'Train a new language model on one CPU or one GPU'</span><span class="p">,</span>
        <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'second config file path that overwrites the settings in `--config`.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'third config file path that overwrites the settings in `--config` and `--config2`.'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs. If not given, use all visible devices'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--train-dtype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"float32"</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"float16"</span><span class="p">,</span> <span class="s2">"float32"</span><span class="p">,</span> <span class="s2">"float64"</span><span class="p">,</span> <span class="s2">"O0"</span><span class="p">,</span> <span class="s2">"O1"</span><span class="p">,</span> <span class="s2">"O2"</span><span class="p">,</span> <span class="s2">"O3"</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Data type for training (only pytorch backend). '</span>
                             <span class="s1">'O0,O1,.. flags require apex. See https://nvidia.github.io/apex/amp.html#opt-levels'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--outdir'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output directory'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dict'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Dictionary'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--resume'</span><span class="p">,</span> <span class="s1">'-r'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Resume the training from snapshot'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--tensorboard-dir'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Tensorboard log dir path"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--report-interval-iters'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Report interval iterations"</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--train-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of train label data'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--valid-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of validation label data'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--test-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of test label data'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dump-hdf5-path'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Path to dump a preprocessed dataset as hdf5'</span><span class="p">)</span>
    <span class="c1"># training configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--opt'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'sgd'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'sgd'</span><span class="p">,</span> <span class="s1">'adam'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Optimizer'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--sortagrad'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"How many epochs to use sortagrad for. 0 = deactivated, -1 = all epochs"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batchsize'</span><span class="p">,</span> <span class="s1">'-b'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of examples in each mini-batch'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--epoch'</span><span class="p">,</span> <span class="s1">'-e'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of sweeps over the dataset to train'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--early-stop-criterion'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'validation/main/loss'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Value to monitor to trigger an early stopping of the training"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--patience'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"Number of epochs to wait without improvement before stopping the training"</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--gradclip'</span><span class="p">,</span> <span class="s1">'-c'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Gradient norm threshold to clip'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlen'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Batch size is reduced if the input sequence &gt; ML'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model-module'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'default'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'model defined module (default: services.hci.speech.espnet_minimal.nets.xxx_backend.lm.default:DefaultRNNLM)'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.lm_train.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.lm_train.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Train LM.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/lm_train.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">):</span>
    <span class="sd">"""Train LM."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"chainer"</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span> <span class="o">!=</span> <span class="s2">"float32"</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"chainer backend does not support --train-dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="si">}</span><span class="s2">."</span>
            <span class="s2">"Use --dtype float32."</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"O0"</span><span class="p">,</span> <span class="s2">"O1"</span><span class="p">,</span> <span class="s2">"O2"</span><span class="p">,</span> <span class="s2">"O3"</span><span class="p">,</span> <span class="s2">"float16"</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--train-dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="si">}</span><span class="s2"> does not support the CPU backend."</span><span class="p">)</span>

    <span class="c1"># parse model-specific arguments dynamically</span>
    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import_lm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_module</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="n">model_class</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">cmd_args</span><span class="p">)</span>
    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'Skip DEBUG/INFO messages'</span><span class="p">)</span>

    <span class="c1"># If --ngpu is not given,</span>
    <span class="c1">#   1. if CUDA_VISIBLE_DEVICES is set, all visible devices</span>
    <span class="c1">#   2. if nvidia-smi exists, use all devices</span>
    <span class="c1">#   3. else ngpu=0</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ngpu</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s1">'nvidia-smi'</span><span class="p">,</span> <span class="s1">'-L'</span><span class="p">],</span>
                                   <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span>
                                   <span class="n">stderr</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">,</span> <span class="ne">FileNotFoundError</span><span class="p">):</span>
                <span class="n">ngpu</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ngpu</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ngpu</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"ngpu: </span><span class="si">{</span><span class="n">ngpu</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># seed setting</span>
    <span class="n">nseed</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">nseed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">nseed</span><span class="p">)</span>

    <span class="c1"># load dictionary</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dict</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">char_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">]</span>
    <span class="n">char_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">'&lt;blank&gt;'</span><span class="p">)</span>
    <span class="n">char_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;eos&gt;'</span><span class="p">)</span>
    <span class="n">args</span><span class="o">.</span><span class="n">char_list_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">char_list</span><span class="p">)}</span>
    <span class="n">args</span><span class="o">.</span><span class="n">n_vocab</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">)</span>

    <span class="c1"># train</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"chainer"</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal</span> <span class="kn">import</span> <span class="n">train</span>
        <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.lm.pytorch_backend.lm</span> <span class="kn">import</span> <span class="n">train</span>
        <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only chainer and pytorch are supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.mt_trans">
<code>mt_trans</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.mt_trans" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Neural machine translation model decoding script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.mt_trans.get_parser">
<code class="highlight language-python">
get_parser<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.mt_trans.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get default arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/mt_trans.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">():</span>
    <span class="sd">"""Get default arguments."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">'Translate text from speech using a speech translation model on one CPU or GPU'</span><span class="p">,</span>
        <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Second config file path that overwrites the settings in `--config`'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Third config file path that overwrites the settings in `--config` and `--config2`'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dtype'</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">(</span><span class="s2">"float16"</span><span class="p">,</span> <span class="s2">"float32"</span><span class="p">,</span> <span class="s2">"float64"</span><span class="p">),</span> <span class="n">default</span><span class="o">=</span><span class="s2">"float32"</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Float precision (only available in --api v2)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'chainer'</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batchsize'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Batch size for beam search (0: means no batch processing)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--preprocess-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The configuration file for the pre-processing'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--api'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"v1"</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"v1"</span><span class="p">,</span> <span class="s2">"v2"</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'''Beam search APIs</span>
<span class="s1">        v1: Default API. It only supports the ASRInterface.recognize method and DefaultRNNLM.</span>
<span class="s1">        v2: Experimental API. It supports any models that implements ScorerInterface.'''</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--trans-json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of translation data (json)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--result-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of result label data (json)'</span><span class="p">)</span>
    <span class="c1"># model (parameter) related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model file parameters to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model config file'</span><span class="p">)</span>
    <span class="c1"># search related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--nbest'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output N-best hypotheses'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--beam-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Beam size'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--penalty'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Incertion penalty'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Input length ratio to obtain max output length.</span>
<span class="s2">                        If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="s2">                        to automatically find maximum hypothesis lengths"""</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Input length ratio to obtain min output length'</span><span class="p">)</span>
    <span class="c1"># rnnlm related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lm-weight'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM weight'</span><span class="p">)</span>
    <span class="c1"># multilingual related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--tgt-lang'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'target language ID (e.g., &lt;en&gt;, &lt;de&gt;, and &lt;fr&gt; etc.)'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.mt_trans.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.mt_trans.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Run the main decoding function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/mt_trans.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Run the main decoding function."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span>
                            <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Skip DEBUG/INFO messages"</span><span class="p">)</span>

    <span class="c1"># check CUDA_VISIBLE_DEVICES</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"#gpus is not matched with CUDA_VISIBLE_DEVICES."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># TODO(mn5k): support of multiple GPUs</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"The program only supports ngpu=1."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># seed setting</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'set random seed = </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># trans</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
        <span class="c1"># Experimental API that supports custom LMs</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.mt.pytorch_backend.mt</span> <span class="kn">import</span> <span class="n">trans</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="s2">"float32"</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"`--dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">` is only available with `--api v2`"</span><span class="p">)</span>
        <span class="n">trans</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only pytorch are supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.st_trans">
<code>st_trans</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.st_trans" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>End-to-end speech translation model decoding script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.st_trans.get_parser">
<code class="highlight language-python">
get_parser<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.st_trans.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get default arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/st_trans.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">():</span>
    <span class="sd">"""Get default arguments."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">'Translate text from speech using a speech translation model on one CPU or GPU'</span><span class="p">,</span>
        <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Second config file path that overwrites the settings in `--config`'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'Third config file path that overwrites the settings in `--config` and `--config2`'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dtype'</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">(</span><span class="s2">"float16"</span><span class="p">,</span> <span class="s2">"float32"</span><span class="p">,</span> <span class="s2">"float64"</span><span class="p">),</span> <span class="n">default</span><span class="o">=</span><span class="s2">"float32"</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Float precision (only available in --api v2)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'chainer'</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batchsize'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Batch size for beam search (0: means no batch processing)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--preprocess-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The configuration file for the pre-processing'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--api'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"v1"</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"v1"</span><span class="p">,</span> <span class="s2">"v2"</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'''Beam search APIs</span>
<span class="s1">        v1: Default API. It only supports the ASRInterface.recognize method and DefaultRNNLM.</span>
<span class="s1">        v2: Experimental API. It supports any models that implements ScorerInterface.'''</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--trans-json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of translation data (json)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--result-label'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of result label data (json)'</span><span class="p">)</span>
    <span class="c1"># model (parameter) related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model file parameters to read'</span><span class="p">)</span>
    <span class="c1"># search related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--nbest'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output N-best hypotheses'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--beam-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Beam size'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--penalty'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Incertion penalty'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">"""Input length ratio to obtain max output length.</span>
<span class="s2">                        If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="s2">                        to automatically find maximum hypothesis lengths"""</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Input length ratio to obtain min output length'</span><span class="p">)</span>
    <span class="c1"># rnnlm related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-rnnlm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word RNNLM model file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-rnnlm-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word RNNLM model config file to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--word-dict'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Word list to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lm-weight'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'RNNLM weight'</span><span class="p">)</span>
    <span class="c1"># multilingual related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--tgt-lang'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'target language ID (e.g., &lt;en&gt;, &lt;de&gt;, and &lt;fr&gt; etc.)'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.st_trans.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.st_trans.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Run the main decoding function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/st_trans.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Run the main decoding function."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span>
                            <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"</span><span class="si">%(asctime)s</span><span class="s2"> (</span><span class="si">%(module)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">) </span><span class="si">%(levelname)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Skip DEBUG/INFO messages"</span><span class="p">)</span>

    <span class="c1"># check CUDA_VISIBLE_DEVICES</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"#gpus is not matched with CUDA_VISIBLE_DEVICES."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># TODO(mn5k): support of multiple GPUs</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"The program only supports ngpu=1."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># seed setting</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'set random seed = </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># validate rnn options</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rnnlm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">word_rnnlm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"It seems that both --rnnlm and --word-rnnlm are specified. Please use either option."</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># trans</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
        <span class="c1"># Experimental API that supports custom LMs</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal</span> <span class="kn">import</span> <span class="n">trans</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="s2">"float32"</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"`--dtype </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">` is only available with `--api v2`"</span><span class="p">)</span>
        <span class="n">trans</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Only pytorch are supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.tts_decode">
<code>tts_decode</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.tts_decode" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>TTS decoding script.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.tts_decode.get_parser">
<code class="highlight language-python">
get_parser<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.tts_decode.get_parser" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Get parser of decoding arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/tts_decode.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">():</span>
    <span class="sd">"""Get parser of decoding arguments."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">'Synthesize speech from text using a TTS model on one CPU'</span><span class="p">,</span>
        <span class="n">config_file_parser_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">YAMLConfigFileParser</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">configargparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>
    <span class="c1"># general configuration</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'config file path'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config2'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'second config file path that overwrites the settings in `--config`.'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'--config3'</span><span class="p">,</span> <span class="n">is_config_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">help</span><span class="o">=</span><span class="s1">'third config file path that overwrites the settings in `--config` and `--config2`.'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--ngpu'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GPUs'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backend'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'pytorch'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'chainer'</span><span class="p">,</span> <span class="s1">'pytorch'</span><span class="p">],</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backend library'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--debugmode'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Debugmode'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Random seed'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--out'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Output filename'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--verbose'</span><span class="p">,</span> <span class="s1">'-V'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Verbose option'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--preprocess-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'The configuration file for the pre-processing'</span><span class="p">)</span>
    <span class="c1"># task related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--json'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Filename of train label data (json)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model file parameters to read'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--model-conf'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Model config file'</span><span class="p">)</span>
    <span class="c1"># decoding related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--maxlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Maximum length ratio in decoding'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--minlenratio'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Minimum length ratio in decoding'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--threshold'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Threshold value in decoding'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-att-constraint'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use the attention constraint'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--backward-window'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Backward window size in the attention constraint'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--forward-window'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Forward window size in the attention constraint'</span><span class="p">)</span>
    <span class="c1"># save related</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-durations'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to save durations converted from attentions'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-focus-rates'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to save focus rates of attentions'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.bin.tts_decode.main">
<code class="highlight language-python">
main<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.bin.tts_decode.main" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Run deocding.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/bin/tts_decode.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Run deocding."""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">()</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># logging info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'</span><span class="si">%(asctime)s</span><span class="s1"> (</span><span class="si">%(module)s</span><span class="s1">:</span><span class="si">%(lineno)d</span><span class="s1">) </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">'</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'Skip DEBUG/INFO messages'</span><span class="p">)</span>

    <span class="c1"># check CUDA_VISIBLE_DEVICES</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># python 2 case</span>
        <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">python_version_tuple</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'2'</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">"clsp.jhu.edu"</span> <span class="ow">in</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">"hostname"</span><span class="p">,</span> <span class="s2">"-f"</span><span class="p">]):</span>
                <span class="n">cvd</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">"/usr/local/bin/free-gpu"</span><span class="p">,</span> <span class="s2">"-n"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">)])</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'CLSP: use gpu'</span> <span class="o">+</span> <span class="n">cvd</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'CUDA_VISIBLE_DEVICES'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cvd</span>
        <span class="c1"># python 3 case</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">"clsp.jhu.edu"</span> <span class="ow">in</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">"hostname"</span><span class="p">,</span> <span class="s2">"-f"</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">():</span>
                <span class="n">cvd</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">"/usr/local/bin/free-gpu"</span><span class="p">,</span> <span class="s2">"-n"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">)])</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'CLSP: use gpu'</span> <span class="o">+</span> <span class="n">cvd</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'CUDA_VISIBLE_DEVICES'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cvd</span>

        <span class="n">cvd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cvd</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES is not set."</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cvd</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"#gpus is not matched with CUDA_VISIBLE_DEVICES."</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># display PYTHONPATH</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'python path = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PYTHONPATH'</span><span class="p">,</span> <span class="s1">'(None)'</span><span class="p">))</span>

    <span class="c1"># extract</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'backend = '</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.tts.pytorch_backend.tts</span> <span class="kn">import</span> <span class="n">decode</span>
        <span class="n">decode</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Only pytorch is supported."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h3 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets">
<code>nets</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface">
<code>asr_interface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>ASR Interface module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface">
<code>ASRInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>ASR Interface for ESPnet model implementation.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.attention_plot_class">
<code class="highlight">
attention_plot_class        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.attention_plot_class" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get attention plot class.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.add_arguments" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Add arguments to parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments to parser."""</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.build">
<code class="highlight language-python">
build<span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.build" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize this class with python-level args.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>The number of an input feature dim.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>The number of output vocab.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ASRinterface</code></td>
<td>
<p>A new instance of ASRInterface.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">idim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">odim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Initialize this class with python-level args.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): The number of an input feature dim.</span>
<span class="sd">        odim (int): The number of output vocab.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ASRinterface: A new instance of ASRInterface.</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">get_parser</span><span class="p">(</span><span class="n">parser</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">wrap</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.calculate_all_attentions" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Caluculate attention.</p>
<p>:param list xs_pad: list of padded input sequences [(T1, idim), (T2, idim), ...]
:param ndarray ilens: batch of lengths of input sequences (B)
:param list ys: list of character id sequence tensor [(L1), (L2), (L3), ...]
:return: attention weights (B, Lmax, Tmax)
:rtype: float ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>79
80
81
82
83
84
85
86
87
88</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Caluculate attention.</span>

<span class="sd">    :param list xs_pad: list of padded input sequences [(T1, idim), (T2, idim), ...]</span>
<span class="sd">    :param ndarray ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param list ys: list of character id sequence tensor [(L1), (L2), (L3), ...]</span>
<span class="sd">    :return: attention weights (B, Lmax, Tmax)</span>
<span class="sd">    :rtype: float ndarray</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"calculate_all_attentions method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.encode">
<code class="highlight language-python">
encode<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.encode" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Encode feature in <code>beam_search</code> (optional).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>numpy.ndarray</code></td>
<td>
<p>input feature (T, D)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.Tensor for pytorch, chainer.Variable for chainer</code></td>
<td>
<p>encoded feature (T, D)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 96
 97
 98
 99
100
101
102
103
104
105
106</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">):</span>
    <span class="sd">"""Encode feature in `beam_search` (optional).</span>

<span class="sd">    Args:</span>
<span class="sd">        x (numpy.ndarray): input feature (T, D)</span>
<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor for pytorch, chainer.Variable for chainer:</span>
<span class="sd">            encoded feature (T, D)</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"encode method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.forward" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Compute loss for training.</p>
<p>:param xs:
    For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
    For chainer, list of source sequences chainer.Variable
:param ilens: batch of lengths of source sequences (B)
    For pytorch, torch.Tensor
    For chainer, list of int
:param ys:
    For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
    For chainer, list of source sequences chainer.Variable
:return: loss value
:rtype: torch.Tensor for pytorch, chainer.Variable for chainer</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Compute loss for training.</span>

<span class="sd">    :param xs:</span>
<span class="sd">        For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)</span>
<span class="sd">        For chainer, list of source sequences chainer.Variable</span>
<span class="sd">    :param ilens: batch of lengths of source sequences (B)</span>
<span class="sd">        For pytorch, torch.Tensor</span>
<span class="sd">        For chainer, list of int</span>
<span class="sd">    :param ys:</span>
<span class="sd">        For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)</span>
<span class="sd">        For chainer, list of source sequences chainer.Variable</span>
<span class="sd">    :return: loss value</span>
<span class="sd">    :rtype: torch.Tensor for pytorch, chainer.Variable for chainer</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"forward method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize">
<code class="highlight language-python">
recognize<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Recognize x for evaluation.</p>
<p>:param ndarray x: input acouctic feature (B, T, D) or (T, D)
:param namespace recog_args: argment namespace contraining options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>55
56
57
58
59
60
61
62
63
64
65</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Recognize x for evaluation.</span>

<span class="sd">    :param ndarray x: input acouctic feature (B, T, D) or (T, D)</span>
<span class="sd">    :param namespace recog_args: argment namespace contraining options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"recognize method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize_batch">
<code class="highlight language-python">
recognize_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.recognize_batch" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Beam search implementation for batch.</p>
<p>:param torch.Tensor x: encoder hidden state sequences (B, Tmax, Henc)
:param namespace recog_args: argument namespace containing options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>67
68
69
70
71
72
73
74
75
76
77</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Beam search implementation for batch.</span>

<span class="sd">    :param torch.Tensor x: encoder hidden state sequences (B, Tmax, Henc)</span>
<span class="sd">    :param namespace recog_args: argument namespace containing options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Batch decoding is not supported yet."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.scorers">
<code class="highlight language-python">
scorers<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.ASRInterface.scorers" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get scorers for <code>beam_search</code> (optional).</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dict[str, ScorerInterface]</code></td>
<td>
<p>dict of <code>ScorerInterface</code> objects</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>108
109
110
111
112
113
114
115</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">scorers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Get scorers for `beam_search` (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict[str, ScorerInterface]: dict of `ScorerInterface` objects</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"decoders method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.asr_interface.dynamic_import_asr">
<code class="highlight language-python">
dynamic_import_asr<span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.asr_interface.dynamic_import_asr" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Import ASR models dynamically.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>module</code></td>
<td><code>str</code></td>
<td>
<p>module_name:class_name or alias in <code>predefined_asr</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>backend</code></td>
<td><code>str</code></td>
<td>
<p>NN backend. e.g., pytorch, chainer</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>type</code></td>
<td>
<p>ASR class</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/asr_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>130
131
132
133
134
135
136
137
138
139
140
141
142
143</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">dynamic_import_asr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">backend</span><span class="p">):</span>
    <span class="sd">"""Import ASR models dynamically.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (str): module_name:class_name or alias in `predefined_asr`</span>
<span class="sd">        backend (str): NN backend. e.g., pytorch, chainer</span>

<span class="sd">    Returns:</span>
<span class="sd">        type: ASR class</span>

<span class="sd">    """</span>
    <span class="n">model_class</span> <span class="o">=</span> <span class="n">dynamic_import</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">predefined_asr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="nb">dict</span><span class="p">()))</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">model_class</span><span class="p">,</span> <span class="n">ASRInterface</span><span class="p">),</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2"> does not implement ASRInterface"</span>
    <span class="k">return</span> <span class="n">model_class</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search">
<code>batch_beam_search</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Parallel beam search module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch">
<code>BatchBeamSearch</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Batch beam search implementation.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batch_beam">
<code class="highlight language-python">
batch_beam<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weighted_scores</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batch_beam" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Batch-compute topk full token ids and partial token ids.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>weighted_scores</code></td>
<td><code>Tensor</code></td>
<td>
<p>The weighted sum scores for each tokens.
Its shape is <code>(n_beam, self.vocab_size)</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ids</code></td>
<td><code>Tensor</code></td>
<td>
<p>The partial token ids to compute topk.
Its shape is <code>(n_beam, self.pre_beam_size)</code>.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</code></td>
<td>
<p>Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
    The topk full (prev_hyp, new_token) ids and partial (prev_hyp, new_token) ids.
    Their shapes are all <code>(self.beam_size,)</code></p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batch_beam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weighted_scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> \
        <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sd">"""Batch-compute topk full token ids and partial token ids.</span>

<span class="sd">    Args:</span>
<span class="sd">        weighted_scores (torch.Tensor): The weighted sum scores for each tokens.</span>
<span class="sd">            Its shape is `(n_beam, self.vocab_size)`.</span>
<span class="sd">        ids (torch.Tensor): The partial token ids to compute topk.</span>
<span class="sd">            Its shape is `(n_beam, self.pre_beam_size)`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:</span>
<span class="sd">            The topk full (prev_hyp, new_token) ids and partial (prev_hyp, new_token) ids.</span>
<span class="sd">            Their shapes are all `(self.beam_size,)`</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_pre_beam</span><span class="p">:</span>
        <span class="n">top_ids</span> <span class="o">=</span> <span class="n">weighted_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Because of the flatten above, `top_ids` is organized as:</span>
        <span class="c1"># [hyp1 * V + token1, hyp2 * V + token2, ..., hypK * V + tokenK],</span>
        <span class="c1"># where V is `self.n_vocab` and K is `self.beam_size`</span>
        <span class="n">prev_hyp_ids</span> <span class="o">=</span> <span class="n">top_ids</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span>
        <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">top_ids</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span>
        <span class="k">return</span> <span class="n">prev_hyp_ids</span><span class="p">,</span> <span class="n">new_token_ids</span><span class="p">,</span> <span class="n">prev_hyp_ids</span><span class="p">,</span> <span class="n">new_token_ids</span>

    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"batch decoding with PartialScorer is not supported yet."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batchfy">
<code class="highlight language-python">
batchfy<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyps</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.batchfy" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Convert list to batch.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>33
34
35
36
37
38
39
40
41
42
43</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batchfy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">BatchHypothesis</span><span class="p">:</span>
    <span class="sd">"""Convert list to batch."""</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BatchHypothesis</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">BatchHypothesis</span><span class="p">(</span>
        <span class="n">yseq</span><span class="o">=</span><span class="n">pad_sequence</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">yseq</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">),</span>
        <span class="n">length</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">yseq</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">score</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">score</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">]),</span>
        <span class="n">scores</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="p">},</span>
        <span class="n">states</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="p">}</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.init_hyp">
<code class="highlight language-python">
init_hyp<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.init_hyp" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get an initial hypothesis data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoder output feature</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BatchHypothesis</code></td>
<td>
<p>Hypothesis: The initial hypothesis.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_hyp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchHypothesis</span><span class="p">:</span>
    <span class="sd">"""Get an initial hypothesis data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The encoder output feature</span>

<span class="sd">    Returns:</span>
<span class="sd">        Hypothesis: The initial hypothesis.</span>

<span class="sd">    """</span>
    <span class="n">init_states</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">init_scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">init_states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">init_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchfy</span><span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init_hyp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.post_process">
<code class="highlight language-python">
post_process<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">,</span> <span class="n">ended_hyps</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.post_process" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform post-processing of beam search iterations.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>i</code></td>
<td><code>int</code></td>
<td>
<p>The length of hypothesis tokens.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>maxlen</code></td>
<td><code>int</code></td>
<td>
<p>The maximum length of tokens in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>maxlenratio</code></td>
<td><code>float</code></td>
<td>
<p>The maximum length ratio in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>running_hyps</code></td>
<td><code>BatchHypothesis</code></td>
<td>
<p>The running hypotheses in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ended_hyps</code></td>
<td><code>List[tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>The ended hypotheses in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BatchHypothesis</code></td>
<td>
<p>BatchHypothesis: The new running hypotheses.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">post_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">running_hyps</span><span class="p">:</span> <span class="n">BatchHypothesis</span><span class="p">,</span> <span class="n">ended_hyps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">BatchHypothesis</span><span class="p">:</span>
    <span class="sd">"""Perform post-processing of beam search iterations.</span>

<span class="sd">    Args:</span>
<span class="sd">        i (int): The length of hypothesis tokens.</span>
<span class="sd">        maxlen (int): The maximum length of tokens in beam search.</span>
<span class="sd">        maxlenratio (int): The maximum length ratio in beam search.</span>
<span class="sd">        running_hyps (BatchHypothesis): The running hypotheses in beam search.</span>
<span class="sd">        ended_hyps (List[Hypothesis]): The ended hypotheses in beam search.</span>

<span class="sd">    Returns:</span>
<span class="sd">        BatchHypothesis: The new running hypotheses.</span>

<span class="sd">    """</span>
    <span class="n">n_batch</span><span class="p">,</span> <span class="n">maxlen</span> <span class="o">=</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">'the number of running hypothes: </span><span class="si">{</span><span class="n">n_batch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"best hypo: "</span> <span class="o">+</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">token_list</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">running_hyps</span><span class="o">.</span><span class="n">length</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]))</span>
    <span class="c1"># add eos in the final loop to avoid that there are no ended hyps</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"adding &lt;eos&gt; in the last position in the loop"</span><span class="p">)</span>
        <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">maxlen</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span>
        <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="o">.</span><span class="n">index_fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>

    <span class="c1"># add ended hypotheses to a final list, and removed them from current hypotheses</span>
    <span class="c1"># (this will be a probmlem, number of hyps &lt; beam)</span>
    <span class="n">is_eos</span> <span class="o">=</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_batch</span><span class="p">),</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">is_eos</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">ended_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>
    <span class="n">remained_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">is_eos</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_select</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">,</span> <span class="n">remained_ids</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.search">
<code class="highlight language-python">
search<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.search" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Search new tokens for running hypotheses and encoded speech x.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>running_hyps</code></td>
<td><code>BatchHypothesis</code></td>
<td>
<p>Running hypotheses on beam</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Encoded speech feature (T, D)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BatchHypothesis</code></td>
<td>
<p>BatchHypothesis: Best sorted hypotheses</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">:</span> <span class="n">BatchHypothesis</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchHypothesis</span><span class="p">:</span>
    <span class="sd">"""Search new tokens for running hypotheses and encoded speech x.</span>

<span class="sd">    Args:</span>
<span class="sd">        running_hyps (BatchHypothesis): Running hypotheses on beam</span>
<span class="sd">        x (torch.Tensor): Encoded speech feature (T, D)</span>

<span class="sd">    Returns:</span>
<span class="sd">        BatchHypothesis: Best sorted hypotheses</span>

<span class="sd">    """</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">)</span>

    <span class="c1"># batch scoring</span>
    <span class="n">scores</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_full</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_pre_beam</span><span class="p">:</span>
        <span class="n">part_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_score_key</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">part_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">)</span>
    <span class="n">part_scores</span><span class="p">,</span> <span class="n">part_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_partial</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">,</span> <span class="n">part_ids</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="c1"># weighted sum scores</span>
    <span class="n">weighted_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="p">:</span>
        <span class="n">weighted_scores</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="p">:</span>
        <span class="n">weighted_scores</span><span class="p">[</span><span class="n">part_ids</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">part_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="n">weighted_scores</span> <span class="o">+=</span> <span class="n">running_hyps</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># TODO(karita): do not use list. use batch instead</span>
    <span class="c1"># update hyps</span>
    <span class="n">best_hyps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_hyps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unbatchfy</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">full_prev_hyp_id</span><span class="p">,</span> <span class="n">full_new_token_id</span><span class="p">,</span> <span class="n">part_prev_hyp_id</span><span class="p">,</span> <span class="n">part_new_token_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_beam</span><span class="p">(</span><span class="n">weighted_scores</span><span class="p">,</span> <span class="n">part_ids</span><span class="p">)):</span>
        <span class="n">prev_hyp</span> <span class="o">=</span> <span class="n">prev_hyps</span><span class="p">[</span><span class="n">full_prev_hyp_id</span><span class="p">]</span>
        <span class="n">best_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hypothesis</span><span class="p">(</span>
            <span class="n">score</span><span class="o">=</span><span class="n">weighted_scores</span><span class="p">[</span><span class="n">full_prev_hyp_id</span><span class="p">,</span> <span class="n">full_new_token_id</span><span class="p">],</span>
            <span class="n">yseq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="n">prev_hyp</span><span class="o">.</span><span class="n">yseq</span><span class="p">,</span> <span class="n">full_new_token_id</span><span class="p">),</span>
            <span class="n">scores</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">merge_scores</span><span class="p">(</span>
                <span class="n">prev_hyp</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">full_prev_hyp_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scores</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span> <span class="n">full_new_token_id</span><span class="p">,</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">part_prev_hyp_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">part_scores</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span> <span class="n">part_new_token_id</span><span class="p">),</span>
            <span class="n">states</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">merge_states</span><span class="p">(</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">select_state</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">full_prev_hyp_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">states</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">select_state</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">part_prev_hyp_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">part_states</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="n">part_new_token_id</span><span class="p">)</span>
        <span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchfy</span><span class="p">(</span><span class="n">best_hyps</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.unbatchfy">
<code class="highlight language-python">
unbatchfy<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_hyps</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchBeamSearch.unbatchfy" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Revert batch to list.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>63
64
65
66
67
68
69
70
71
72</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">unbatchfy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_hyps</span><span class="p">:</span> <span class="n">BatchHypothesis</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]:</span>
    <span class="sd">"""Revert batch to list."""</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">Hypothesis</span><span class="p">(</span>
            <span class="n">yseq</span><span class="o">=</span><span class="n">batch_hyps</span><span class="o">.</span><span class="n">yseq</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">batch_hyps</span><span class="o">.</span><span class="n">length</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
            <span class="n">score</span><span class="o">=</span><span class="n">batch_hyps</span><span class="o">.</span><span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">scores</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">batch_hyps</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="p">},</span>
            <span class="n">states</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">select_state</span><span class="p">(</span>
                <span class="n">batch_hyps</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_hyps</span><span class="o">.</span><span class="n">length</span><span class="p">))]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis">
<code>BatchHypothesis</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Batchfied/Vectorized hypothesis data type.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__getnewargs__">
<code class="highlight language-python">
__getnewargs__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__getnewargs__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return self as a plain tuple.  Used by copy and pickle.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>427
428
429</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">__getnewargs__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Return self as a plain tuple.  Used by copy and pickle.'</span>
    <span class="k">return</span> <span class="n">_tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__len__">
<code class="highlight language-python">
__len__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__len__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return a batch size.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>25
26
27</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Return a batch size."""</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__new__">
<code class="highlight language-python">
__new__<span class="p">(</span><span class="n">_cls</span><span class="p">,</span> <span class="n">yseq</span><span class="o">=</span><span class="n">tensor</span><span class="p">([]),</span> <span class="n">score</span><span class="o">=</span><span class="n">tensor</span><span class="p">([]),</span> <span class="n">length</span><span class="o">=</span><span class="n">tensor</span><span class="p">([]),</span> <span class="n">scores</span><span class="o">=</span><span class="p">{},</span> <span class="n">states</span><span class="o">=</span><span class="p">{})</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__new__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Create new instance of BatchHypothesis(yseq, score, length, scores, states)</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__repr__">
<code class="highlight language-python">
__repr__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.batch_beam_search.BatchHypothesis.__repr__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return a nicely formatted representation string</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/batch_beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>419
420
421</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Return a nicely formatted representation string'</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="n">repr_fmt</span> <span class="o">%</span> <span class="bp">self</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search">
<code>beam_search</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Beam search module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch">
<code>BeamSearch</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Beam search implementation.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">token_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pre_beam_ratio</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">pre_beam_score_key</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize beam search.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>scorers</code></td>
<td><code>Dict[str, tools.espnet_minimal.nets.scorer_interface.ScorerInterface]</code></td>
<td>
<p>Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <code>None</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>weights</code></td>
<td><code>Dict[str, float]</code></td>
<td>
<p>Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>beam_size</code></td>
<td><code>int</code></td>
<td>
<p>The number of hypotheses kept during search</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>vocab_size</code></td>
<td><code>int</code></td>
<td>
<p>The number of vocabulary</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>sos</code></td>
<td><code>int</code></td>
<td>
<p>Start of sequence id</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>eos</code></td>
<td><code>int</code></td>
<td>
<p>End of sequence id</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>token_list</code></td>
<td><code>List[str]</code></td>
<td>
<p>List of tokens for debug log</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>pre_beam_score_key</code></td>
<td><code>str</code></td>
<td>
<p>key of scores to perform pre-beam search</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>pre_beam_ratio</code></td>
<td><code>float</code></td>
<td>
<p>beam size in the pre-beam search will be <code>int(pre_beam_ratio * beam_size)</code></p>
</td>
<td><code>1.5</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scorers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ScorerInterface</span><span class="p">],</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
             <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
             <span class="n">sos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">token_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">pre_beam_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">pre_beam_score_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Initialize beam search.</span>

<span class="sd">    Args:</span>
<span class="sd">        scorers (dict[str, ScorerInterface]): Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM</span>
<span class="sd">            The scorer will be ignored if it is `None`</span>
<span class="sd">        weights (dict[str, float]): Dict of weights for each scorers</span>
<span class="sd">            The scorer will be ignored if its weight is 0</span>
<span class="sd">        beam_size (int): The number of hypotheses kept during search</span>
<span class="sd">        vocab_size (int): The number of vocabulary</span>
<span class="sd">        sos (int): Start of sequence id</span>
<span class="sd">        eos (int): End of sequence id</span>
<span class="sd">        token_list (list[str]): List of tokens for debug log</span>
<span class="sd">        pre_beam_score_key (str): key of scores to perform pre-beam search</span>
<span class="sd">        pre_beam_ratio (float): beam size in the pre-beam search will be `int(pre_beam_ratio * beam_size)`</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># set scorers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="c1"># this module dict is required for recursive cast `self.to(device, dtype)` in `recog.py`</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ScorerInterface</span><span class="p">),</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="si">}</span><span class="s2">) does not implement ScorerInterface"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">PartialScorerInterface</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="c1"># set configurations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sos</span> <span class="o">=</span> <span class="n">sos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">token_list</span> <span class="o">=</span> <span class="n">token_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pre_beam_ratio</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span> <span class="o">=</span> <span class="n">beam_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="k">if</span> <span class="n">pre_beam_score_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pre_beam_score_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">pre_beam_score_key</span><span class="si">}</span><span class="s2"> is not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_score_key</span> <span class="o">=</span> <span class="n">pre_beam_score_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_pre_beam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_score_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> \
                       <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.append_token">
<code class="highlight language-python">
append_token<span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.append_token" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Append new token to prefix tokens.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>The prefix token</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>int</code></td>
<td>
<p>The new token to append</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>torch.Tensor: New tensor contains: xs + [x] with xs.dtype and xs.device</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>111
112
113
114
115
116
117
118
119
120
121
122
123
124</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">append_token</span><span class="p">(</span><span class="n">xs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""Append new token to prefix tokens.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (torch.Tensor): The prefix token</span>
<span class="sd">        x (int): The new token to append</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: New tensor contains: xs + [x] with xs.dtype and xs.device</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">xs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">xs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">xs</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.beam">
<code class="highlight language-python">
beam<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weighted_scores</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.beam" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Compute topk full token ids and partial token ids.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>weighted_scores</code></td>
<td><code>Tensor</code></td>
<td>
<p>The weighted sum scores for each tokens. Its shape is <code>(self.n_vocab,)</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ids</code></td>
<td><code>Tensor</code></td>
<td>
<p>The partial token ids to compute topk</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[torch.Tensor, torch.Tensor]</code></td>
<td>
<p>Tuple[torch.Tensor, torch.Tensor]: The topk full token ids and partial token ids.
    Their shapes are <code>(self.beam_size,)</code></p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">beam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weighted_scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sd">"""Compute topk full token ids and partial token ids.</span>

<span class="sd">    Args:</span>
<span class="sd">        weighted_scores (torch.Tensor): The weighted sum scores for each tokens. Its shape is `(self.n_vocab,)`.</span>
<span class="sd">        ids (torch.Tensor): The partial token ids to compute topk</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[torch.Tensor, torch.Tensor]: The topk full token ids and partial token ids.</span>
<span class="sd">            Their shapes are `(self.beam_size,)`</span>

<span class="sd">    """</span>
    <span class="c1"># no pre beam performed</span>
    <span class="k">if</span> <span class="n">weighted_scores</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">top_ids</span> <span class="o">=</span> <span class="n">weighted_scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">top_ids</span><span class="p">,</span> <span class="n">top_ids</span>

    <span class="c1"># mask pruned in pre-beam not to select in topk</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">weighted_scores</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span>
    <span class="n">weighted_scores</span><span class="p">[:]</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
    <span class="n">weighted_scores</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
    <span class="n">top_ids</span> <span class="o">=</span> <span class="n">weighted_scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">local_ids</span> <span class="o">=</span> <span class="n">weighted_scores</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">top_ids</span><span class="p">,</span> <span class="n">local_ids</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">minlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.forward" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform beam search.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Encoded speech feature (T, D)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>maxlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>minlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Input length ratio to obtain min output length.</p>
</td>
<td><code>0.0</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>list[Hypothesis]: N-best decoding results</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">minlenratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]:</span>
    <span class="sd">"""Perform beam search.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Encoded speech feature (T, D)</span>
<span class="sd">        maxlenratio (float): Input length ratio to obtain max output length.</span>
<span class="sd">            If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="sd">            to automatically find maximum hypothesis lengths</span>
<span class="sd">        minlenratio (float): Input length ratio to obtain min output length.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list[Hypothesis]: N-best decoding results</span>

<span class="sd">    """</span>
    <span class="c1"># set length bounds</span>
    <span class="k">if</span> <span class="n">maxlenratio</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">maxlenratio</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">minlenratio</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'max output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'min output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">minlen</span><span class="p">))</span>

    <span class="c1"># main loop of prefix search</span>
    <span class="n">running_hyps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_hyp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ended_hyps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxlen</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'position '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="n">best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="c1"># post process of one iteration</span>
        <span class="n">running_hyps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_process</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">,</span> <span class="n">best</span><span class="p">,</span> <span class="n">ended_hyps</span><span class="p">)</span>
        <span class="c1"># end detection</span>
        <span class="k">if</span> <span class="n">maxlenratio</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">end_detect</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">asdict</span><span class="p">()</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">ended_hyps</span><span class="p">],</span> <span class="n">i</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'end detected at </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'no hypothesis. Finish decoding.'</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">'remeined hypothes: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

    <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># check number of hypotheis</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'there is no N-best results, perform recognition again with smaller minlenratio.'</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">minlenratio</span> <span class="o">&lt;</span> <span class="mf">0.1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">minlenratio</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">))</span>

    <span class="c1"># report the best result</span>
    <span class="n">best</span> <span class="o">=</span> <span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'total log probability: </span><span class="si">{</span><span class="n">best</span><span class="o">.</span><span class="n">score</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'normalized log probability: </span><span class="si">{</span><span class="n">best</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">best</span><span class="o">.</span><span class="n">yseq</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nbest_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.init_hyp">
<code class="highlight language-python">
init_hyp<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.init_hyp" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get an initial hypothesis data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoder output feature</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Hypothesis</code></td>
<td>
<p>Hypothesis: The initial hypothesis.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_hyp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Hypothesis</span><span class="p">:</span>
    <span class="sd">"""Get an initial hypothesis data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The encoder output feature</span>

<span class="sd">    Returns:</span>
<span class="sd">        Hypothesis: The initial hypothesis.</span>

<span class="sd">    """</span>
    <span class="n">init_states</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">init_scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">init_states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">init_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">Hypothesis</span><span class="p">(</span>
        <span class="n">score</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">init_scores</span><span class="p">,</span> <span class="n">states</span><span class="o">=</span><span class="n">init_states</span><span class="p">,</span>
        <span class="n">yseq</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">))]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_scores">
<code class="highlight language-python">
merge_scores<span class="p">(</span><span class="n">prev_scores</span><span class="p">,</span> <span class="n">next_full_scores</span><span class="p">,</span> <span class="n">full_idx</span><span class="p">,</span> <span class="n">next_part_scores</span><span class="p">,</span> <span class="n">part_idx</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_scores" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Merge scores for new hypothesis.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prev_scores</code></td>
<td><code>Dict[str, float]</code></td>
<td>
<p>The previous hypothesis scores by <code>self.scorers</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>next_full_scores</code></td>
<td><code>Dict[str, torch.Tensor]</code></td>
<td>
<p>scores by <code>self.full_scorers</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>full_idx</code></td>
<td><code>int</code></td>
<td>
<p>The next token id for <code>next_full_scores</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>next_part_scores</code></td>
<td><code>Dict[str, torch.Tensor]</code></td>
<td>
<p>scores of partial tokens by <code>self.part_scorers</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>part_idx</code></td>
<td><code>int</code></td>
<td>
<p>The new token id for <code>next_part_scores</code></p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Dict[str, torch.Tensor]</code></td>
<td>
<p>Dict[str, torch.Tensor]: The new score dict.
    Its keys are names of <code>self.full_scorers</code> and <code>self.part_scorers</code>.
    Its values are scalar tensors by the scorers.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">merge_scores</span><span class="p">(</span><span class="n">prev_scores</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">next_full_scores</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">full_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">next_part_scores</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">part_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sd">"""Merge scores for new hypothesis.</span>

<span class="sd">    Args:</span>
<span class="sd">        prev_scores (Dict[str, float]): The previous hypothesis scores by `self.scorers`</span>
<span class="sd">        next_full_scores (Dict[str, torch.Tensor]): scores by `self.full_scorers`</span>
<span class="sd">        full_idx (int): The next token id for `next_full_scores`</span>
<span class="sd">        next_part_scores (Dict[str, torch.Tensor]): scores of partial tokens by `self.part_scorers`</span>
<span class="sd">        part_idx (int): The new token id for `next_part_scores`</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: The new score dict.</span>
<span class="sd">            Its keys are names of `self.full_scorers` and `self.part_scorers`.</span>
<span class="sd">            Its values are scalar tensors by the scorers.</span>

<span class="sd">    """</span>
    <span class="n">new_scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">next_full_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">new_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">[</span><span class="n">full_idx</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">next_part_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">new_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">part_idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">new_scores</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_states">
<code class="highlight language-python">
merge_states<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">part_states</span><span class="p">,</span> <span class="n">part_idx</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.merge_states" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Merge states for new hypothesis.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>states</code></td>
<td><code>Any</code></td>
<td>
<p>states of <code>self.full_scorers</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>part_states</code></td>
<td><code>Any</code></td>
<td>
<p>states of <code>self.part_scorers</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>part_idx</code></td>
<td><code>int</code></td>
<td>
<p>The new token id for <code>part_scores</code></p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Any</code></td>
<td>
<p>Dict[str, torch.Tensor]: The new score dict.
    Its keys are names of <code>self.full_scorers</code> and <code>self.part_scorers</code>.
    Its values are states of the scorers.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">merge_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">part_states</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">part_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">"""Merge states for new hypothesis.</span>

<span class="sd">    Args:</span>
<span class="sd">        states: states of `self.full_scorers`</span>
<span class="sd">        part_states: states of `self.part_scorers`</span>
<span class="sd">        part_idx (int): The new token id for `part_scores`</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: The new score dict.</span>
<span class="sd">            Its keys are names of `self.full_scorers` and `self.part_scorers`.</span>
<span class="sd">            Its values are states of the scorers.</span>

<span class="sd">    """</span>
    <span class="n">new_states</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">states</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">new_states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">new_states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">select_state</span><span class="p">(</span><span class="n">part_states</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">part_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_states</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.post_process">
<code class="highlight language-python">
post_process<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">,</span> <span class="n">ended_hyps</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.post_process" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform post-processing of beam search iterations.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>i</code></td>
<td><code>int</code></td>
<td>
<p>The length of hypothesis tokens.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>maxlen</code></td>
<td><code>int</code></td>
<td>
<p>The maximum length of tokens in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>maxlenratio</code></td>
<td><code>float</code></td>
<td>
<p>The maximum length ratio in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>running_hyps</code></td>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>The running hypotheses in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ended_hyps</code></td>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>The ended hypotheses in beam search.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>List[Hypothesis]: The new running hypotheses.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">post_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">running_hyps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">],</span> <span class="n">ended_hyps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]:</span>
    <span class="sd">"""Perform post-processing of beam search iterations.</span>

<span class="sd">    Args:</span>
<span class="sd">        i (int): The length of hypothesis tokens.</span>
<span class="sd">        maxlen (int): The maximum length of tokens in beam search.</span>
<span class="sd">        maxlenratio (int): The maximum length ratio in beam search.</span>
<span class="sd">        running_hyps (List[Hypothesis]): The running hypotheses in beam search.</span>
<span class="sd">        ended_hyps (List[Hypothesis]): The ended hypotheses in beam search.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Hypothesis]: The new running hypotheses.</span>

<span class="sd">    """</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">'the number of running hypothes: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">running_hyps</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"best hypo: "</span> <span class="o">+</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">token_list</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">running_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">yseq</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]))</span>
    <span class="c1"># add eos in the final loop to avoid that there are no ended hyps</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"adding &lt;eos&gt; in the last position in the loop"</span><span class="p">)</span>
        <span class="n">running_hyps</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">yseq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">yseq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">))</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">running_hyps</span><span class="p">]</span>

    <span class="c1"># add ended hypotheses to a final list, and removed them from current hypotheses</span>
    <span class="c1"># (this will be a probmlem, number of hyps &lt; beam)</span>
    <span class="n">remained_hyps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">running_hyps</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">hyp</span><span class="o">.</span><span class="n">yseq</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">:</span>
            <span class="c1"># e.g., Word LM needs to add final &lt;eos&gt; score</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">final_score</span><span class="p">(</span><span class="n">hyp</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="n">hyp</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">s</span>
                <span class="n">hyp</span> <span class="o">=</span> <span class="n">hyp</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="n">hyp</span><span class="o">.</span><span class="n">score</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
            <span class="n">ended_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remained_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">remained_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_full">
<code class="highlight language-python">
score_full<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_full" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score new hypothesis by <code>self.full_scorers</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hyp</code></td>
<td><code>Hypothesis</code></td>
<td>
<p>Hypothesis with prefix tokens to score</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Corresponding input feature</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</code></td>
<td>
<p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]: Tuple of
    score dict of <code>hyp</code> that has string keys of <code>self.full_scorers</code>
    and tensor score values of shape: <code>(self.n_vocab,)</code>,
    and state dict that has string keys and state values of <code>self.full_scorers</code></p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score_full</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">:</span> <span class="n">Hypothesis</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
    <span class="sd">"""Score new hypothesis by `self.full_scorers`.</span>

<span class="sd">    Args:</span>
<span class="sd">        hyp (Hypothesis): Hypothesis with prefix tokens to score</span>
<span class="sd">        x (torch.Tensor): Corresponding input feature</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Dict[str, torch.Tensor], Dict[str, Any]]: Tuple of</span>
<span class="sd">            score dict of `hyp` that has string keys of `self.full_scorers`</span>
<span class="sd">            and tensor score values of shape: `(self.n_vocab,)`,</span>
<span class="sd">            and state dict that has string keys and state values of `self.full_scorers`</span>

<span class="sd">    """</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">states</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">hyp</span><span class="o">.</span><span class="n">yseq</span><span class="p">,</span> <span class="n">hyp</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">states</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_partial">
<code class="highlight language-python">
score_partial<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.score_partial" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score new hypothesis by <code>self.part_scorers</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hyp</code></td>
<td><code>Hypothesis</code></td>
<td>
<p>Hypothesis with prefix tokens to score</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ids</code></td>
<td><code>Tensor</code></td>
<td>
<p>1D tensor of new partial tokens to score</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Corresponding input feature</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</code></td>
<td>
<p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]: Tuple of
    score dict of <code>hyp</code> that has string keys of <code>self.part_scorers</code>
    and tensor score values of shape: <code>(len(ids),)</code>,
    and state dict that has string keys and state values of <code>self.part_scorers</code></p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score_partial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">:</span> <span class="n">Hypothesis</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> \
        <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
    <span class="sd">"""Score new hypothesis by `self.part_scorers`.</span>

<span class="sd">    Args:</span>
<span class="sd">        hyp (Hypothesis): Hypothesis with prefix tokens to score</span>
<span class="sd">        ids (torch.Tensor): 1D tensor of new partial tokens to score</span>
<span class="sd">        x (torch.Tensor): Corresponding input feature</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Dict[str, torch.Tensor], Dict[str, Any]]: Tuple of</span>
<span class="sd">            score dict of `hyp` that has string keys of `self.part_scorers`</span>
<span class="sd">            and tensor score values of shape: `(len(ids),)`,</span>
<span class="sd">            and state dict that has string keys and state values of `self.part_scorers`</span>

<span class="sd">    """</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">states</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">score_partial</span><span class="p">(</span><span class="n">hyp</span><span class="o">.</span><span class="n">yseq</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">hyp</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">states</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.search">
<code class="highlight language-python">
search<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.BeamSearch.search" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Search new tokens for running hypotheses and encoded speech x.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>running_hyps</code></td>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>Running hypotheses on beam</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Encoded speech feature (T, D)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[adviser.tools.espnet_minimal.nets.beam_search.Hypothesis]</code></td>
<td>
<p>List[Hypotheses]: Best sorted hypotheses</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_hyps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]:</span>
    <span class="sd">"""Search new tokens for running hypotheses and encoded speech x.</span>

<span class="sd">    Args:</span>
<span class="sd">        running_hyps (List[Hypothesis]): Running hypotheses on beam</span>
<span class="sd">        x (torch.Tensor): Encoded speech feature (T, D)</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Hypotheses]: Best sorted hypotheses</span>

<span class="sd">    """</span>
    <span class="n">best_hyps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">part_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># no pre-beam</span>
    <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">running_hyps</span><span class="p">:</span>
        <span class="c1"># scoring</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_full</span><span class="p">(</span><span class="n">hyp</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_pre_beam</span><span class="p">:</span>
            <span class="n">part_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_score_key</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_beam_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">part_scores</span><span class="p">,</span> <span class="n">part_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_partial</span><span class="p">(</span><span class="n">hyp</span><span class="p">,</span> <span class="n">part_ids</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="c1"># weighted sum scores</span>
        <span class="n">weighted_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_scorers</span><span class="p">:</span>
            <span class="n">weighted_scores</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_scorers</span><span class="p">:</span>
            <span class="n">weighted_scores</span><span class="p">[</span><span class="n">part_ids</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">part_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">weighted_scores</span> <span class="o">+=</span> <span class="n">hyp</span><span class="o">.</span><span class="n">score</span>

        <span class="c1"># update hyps</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">part_j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">beam</span><span class="p">(</span><span class="n">weighted_scores</span><span class="p">,</span> <span class="n">part_ids</span><span class="p">)):</span>
            <span class="c1"># will be (2 x beam at most)</span>
            <span class="n">best_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hypothesis</span><span class="p">(</span>
                <span class="n">score</span><span class="o">=</span><span class="n">weighted_scores</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                <span class="n">yseq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="n">hyp</span><span class="o">.</span><span class="n">yseq</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span>
                <span class="n">scores</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">merge_scores</span><span class="p">(</span>
                    <span class="n">hyp</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">part_scores</span><span class="p">,</span> <span class="n">part_j</span><span class="p">),</span>
                <span class="n">states</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">merge_states</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">part_states</span><span class="p">,</span> <span class="n">part_j</span><span class="p">)))</span>

        <span class="c1"># sort and prune 2 x beam -&gt; beam</span>
        <span class="n">best_hyps</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">best_hyps</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_hyps</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">best_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.Hypothesis">
<code>Hypothesis</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Hypothesis data type.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__getnewargs__">
<code class="highlight language-python">
__getnewargs__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__getnewargs__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return self as a plain tuple.  Used by copy and pickle.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>427
428
429</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">__getnewargs__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Return self as a plain tuple.  Used by copy and pickle.'</span>
    <span class="k">return</span> <span class="n">_tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__new__">
<code class="highlight language-python">
__new__<span class="p">(</span><span class="n">_cls</span><span class="p">,</span> <span class="n">yseq</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="p">{},</span> <span class="n">states</span><span class="o">=</span><span class="p">{})</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__new__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Create new instance of Hypothesis(yseq, score, scores, states)</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__repr__">
<code class="highlight language-python">
__repr__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.__repr__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return a nicely formatted representation string</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>419
420
421</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Return a nicely formatted representation string'</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="n">repr_fmt</span> <span class="o">%</span> <span class="bp">self</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.asdict">
<code class="highlight language-python">
asdict<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.Hypothesis.asdict" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Convert data to JSON-friendly dict.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>26
27
28
29
30
31
32</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""Convert data to JSON-friendly dict."""</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span>
        <span class="n">yseq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">yseq</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="n">score</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">),</span>
        <span class="n">scores</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.beam_search.beam_search">
<code class="highlight language-python">
beam_search<span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">token_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">minlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">pre_beam_ratio</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">pre_beam_score_key</span><span class="o">=</span><span class="s1">'decoder'</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.beam_search.beam_search" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Perform beam search with scorers.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Encoded speech feature (T, D)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>sos</code></td>
<td><code>int</code></td>
<td>
<p>Start of sequence id</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>eos</code></td>
<td><code>int</code></td>
<td>
<p>End of sequence id</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>beam_size</code></td>
<td><code>int</code></td>
<td>
<p>The number of hypotheses kept during search</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>vocab_size</code></td>
<td><code>int</code></td>
<td>
<p>The number of vocabulary</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>scorers</code></td>
<td><code>Dict[str, tools.espnet_minimal.nets.scorer_interface.ScorerInterface]</code></td>
<td>
<p>Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <code>None</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>weights</code></td>
<td><code>Dict[str, float]</code></td>
<td>
<p>Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>token_list</code></td>
<td><code>List[str]</code></td>
<td>
<p>List of tokens for debug log</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>maxlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>minlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Input length ratio to obtain min output length.</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>pre_beam_score_key</code></td>
<td><code>str</code></td>
<td>
<p>key of scores to perform pre-beam search</p>
</td>
<td><code>'decoder'</code></td>
</tr>
<tr>
<td><code>pre_beam_ratio</code></td>
<td><code>float</code></td>
<td>
<p>beam size in the pre-beam search will be <code>int(pre_beam_ratio * beam_size)</code></p>
</td>
<td><code>1.5</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list</code></td>
<td>
<p>list: N-best decoding results</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/beam_search.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">beam_search</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                <span class="n">scorers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ScorerInterface</span><span class="p">],</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
                <span class="n">token_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">minlenratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                <span class="n">pre_beam_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">pre_beam_score_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"decoder"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Perform beam search with scorers.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Encoded speech feature (T, D)</span>
<span class="sd">        sos (int): Start of sequence id</span>
<span class="sd">        eos (int): End of sequence id</span>
<span class="sd">        beam_size (int): The number of hypotheses kept during search</span>
<span class="sd">        vocab_size (int): The number of vocabulary</span>
<span class="sd">        scorers (dict[str, ScorerInterface]): Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM</span>
<span class="sd">            The scorer will be ignored if it is `None`</span>
<span class="sd">        weights (dict[str, float]): Dict of weights for each scorers</span>
<span class="sd">            The scorer will be ignored if its weight is 0</span>
<span class="sd">        token_list (list[str]): List of tokens for debug log</span>
<span class="sd">        maxlenratio (float): Input length ratio to obtain max output length.</span>
<span class="sd">            If maxlenratio=0.0 (default), it uses a end-detect function</span>
<span class="sd">            to automatically find maximum hypothesis lengths</span>
<span class="sd">        minlenratio (float): Input length ratio to obtain min output length.</span>
<span class="sd">        pre_beam_score_key (str): key of scores to perform pre-beam search</span>
<span class="sd">        pre_beam_ratio (float): beam size in the pre-beam search will be `int(pre_beam_ratio * beam_size)`</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: N-best decoding results</span>

<span class="sd">    """</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">BeamSearch</span><span class="p">(</span>
        <span class="n">scorers</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
        <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
        <span class="n">pre_beam_ratio</span><span class="o">=</span><span class="n">pre_beam_ratio</span><span class="p">,</span>
        <span class="n">pre_beam_score_key</span><span class="o">=</span><span class="n">pre_beam_score_key</span><span class="p">,</span>
        <span class="n">sos</span><span class="o">=</span><span class="n">sos</span><span class="p">,</span>
        <span class="n">eos</span><span class="o">=</span><span class="n">eos</span><span class="p">,</span>
        <span class="n">token_list</span><span class="o">=</span><span class="n">token_list</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">maxlenratio</span><span class="o">=</span><span class="n">maxlenratio</span><span class="p">,</span>
        <span class="n">minlenratio</span><span class="o">=</span><span class="n">minlenratio</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">asdict</span><span class="p">()</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score">
<code>ctc_prefix_score</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore">
<code>CTCPrefixScore</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Compute CTC label sequence scores</p>
<div class="codehilite">
<pre><span></span><code><span class="err">which is based on Algorithm 2 in WATANABE et al.</span>
<span class="err">"HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,"</span>
<span class="err">but extended to efficiently compute the probablities of multiple labels</span>
<span class="err">simultaneously</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cs</span><span class="p">,</span> <span class="n">r_prev</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__call__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Compute CTC prefix scores for next labels</p>
<p>:param y     : prefix label sequence
:param cs    : array of next labels
:param r_prev: previous CTC state
:return ctc_scores, ctc_states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cs</span><span class="p">,</span> <span class="n">r_prev</span><span class="p">):</span>
    <span class="sd">"""Compute CTC prefix scores for next labels</span>

<span class="sd">    :param y     : prefix label sequence</span>
<span class="sd">    :param cs    : array of next labels</span>
<span class="sd">    :param r_prev: previous CTC state</span>
<span class="sd">    :return ctc_scores, ctc_states</span>
<span class="sd">    """</span>
    <span class="c1"># initialize CTC states</span>
    <span class="n">output_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># ignore sos</span>
    <span class="c1"># new CTC states are prepared as a frame x (n or b) x n_labels tensor</span>
    <span class="c1"># that corresponds to r_t^n(h) and r_t^b(h).</span>
    <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cs</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[:,</span> <span class="n">cs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">output_length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">r</span><span class="p">[</span><span class="n">output_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>

    <span class="c1"># prepare forward probabilities for the last label</span>
    <span class="n">r_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># log(r_t^n(g) + r_t^b(g))</span>
    <span class="n">last</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">output_length</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">last</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">:</span>
        <span class="n">log_phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cs</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cs</span><span class="p">)):</span>
            <span class="n">log_phi</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">r_sum</span> <span class="k">if</span> <span class="n">cs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">last</span> <span class="k">else</span> <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">log_phi</span> <span class="o">=</span> <span class="n">r_sum</span>

    <span class="c1"># compute forward probabilities log(r_t^n(h)), log(r_t^b(h)),</span>
    <span class="c1"># and log prefix probabilites log(psi)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">output_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">log_psi</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">start</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">log_phi</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">]</span>
        <span class="n">log_psi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">log_psi</span><span class="p">,</span> <span class="n">log_phi</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>

    <span class="c1"># get P(...eos|X) that ends with the prefix itself</span>
    <span class="n">eos_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eos_pos</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">log_psi</span><span class="p">[</span><span class="n">eos_pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">r_sum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># log(r_T^n(g) + r_T^b(g))</span>

    <span class="c1"># return the log prefix probability and CTC states, where the label axis</span>
    <span class="c1"># of the CTC states is moved to the first axis to slice it easily</span>
    <span class="k">return</span> <span class="n">log_psi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">rollaxis</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>202
203
204
205
206
207
208</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">xp</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">xp</span> <span class="o">=</span> <span class="n">xp</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000000000.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">blank</span> <span class="o">=</span> <span class="n">blank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.initial_state">
<code class="highlight language-python">
initial_state<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScore.initial_state" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Obtain an initial CTC state</p>
<p>:return: CTC state</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>210
211
212
213
214
215
216
217
218
219
220
221
222</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Obtain an initial CTC state</span>

<span class="sd">    :return: CTC state</span>
<span class="sd">    """</span>
    <span class="c1"># initial CTC state is made of a frame x 2 tensor that corresponds to</span>
    <span class="c1"># r_t^n(&lt;sos&gt;) and r_t^b(&lt;sos&gt;), where 0 and 1 of axis=1 represent</span>
    <span class="c1"># superscripts n and b (non-blank and blank), respectively.</span>
    <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">r</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH">
<code>CTCPrefixScoreTH</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Batch processing of CTCPrefixScore</p>
<div class="codehilite">
<pre><span></span><code><span class="err">which is based on Algorithm 2 in WATANABE et al.</span>
<span class="err">"HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,"</span>
<span class="err">but extended to efficiently compute the probablities of multiple labels</span>
<span class="err">simultaneously</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">pre_scores</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">att_w</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__call__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Compute CTC prefix scores for next labels</p>
<p>:param list y: prefix label sequences
:param tuple state: previous CTC state
:param torch.Tensor pre_scores: scores for pre-selection of hypotheses (BW, O)
:param torch.Tensor att_w: attention weights to decide CTC window
:return new_state, ctc_local_scores (BW, O)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">pre_scores</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">att_w</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Compute CTC prefix scores for next labels</span>

<span class="sd">    :param list y: prefix label sequences</span>
<span class="sd">    :param tuple state: previous CTC state</span>
<span class="sd">    :param torch.Tensor pre_scores: scores for pre-selection of hypotheses (BW, O)</span>
<span class="sd">    :param torch.Tensor att_w: attention weights to decide CTC window</span>
<span class="sd">    :return new_state, ctc_local_scores (BW, O)</span>
<span class="sd">    """</span>
    <span class="n">output_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># ignore sos</span>
    <span class="n">last_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">yi</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>  <span class="c1"># last output label ids</span>
    <span class="c1"># prepare state info</span>
    <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">r_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">r_prev</span> <span class="o">=</span> <span class="n">r_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">r_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">s_prev</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">f_min_prev</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">f_max_prev</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">r_prev</span><span class="p">,</span> <span class="n">s_prev</span><span class="p">,</span> <span class="n">f_min_prev</span><span class="p">,</span> <span class="n">f_max_prev</span> <span class="o">=</span> <span class="n">state</span>

    <span class="c1"># select input dimensions for scoring</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">pre_scores</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pre_scores</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>  <span class="c1"># ignore blank from pre-selection</span>
        <span class="n">scoring_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">pre_scores</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">scoring_idmap</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">snum</span> <span class="o">=</span> <span class="n">scoring_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">scoring_idmap</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bb_idx</span><span class="p">,</span> <span class="n">scoring_ids</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">snum</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">scoring_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">scoring_ids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_o</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">),</span>
                                <span class="mi">2</span><span class="p">,</span> <span class="n">scoring_idx</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="n">snum</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scoring_ids</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">scoring_idmap</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">snum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>

    <span class="c1"># new CTC forward probs are prepared as a (T x 2 x BW x S) tensor</span>
    <span class="c1"># that corresponds to r_t^n(h) and r_t^b(h) in a batch.</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="n">snum</span><span class="p">),</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output_length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">r_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">r_prev</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">log_phi</span> <span class="o">=</span> <span class="n">r_sum</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">snum</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scoring_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">):</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="n">scoring_idmap</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">last_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
            <span class="k">if</span> <span class="n">pos</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">log_phi</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">):</span>
            <span class="n">log_phi</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">last_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span>

    <span class="c1"># decide start and end frames based on attention weights</span>
    <span class="k">if</span> <span class="n">att_w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">f_arg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frame_ids</span><span class="p">)</span>
        <span class="n">f_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">f_arg</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span> <span class="n">f_min_prev</span><span class="p">)</span>
        <span class="n">f_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">f_arg</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span> <span class="n">f_max_prev</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">f_max_prev</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">f_min</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">f_max</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f_min</span> <span class="o">=</span> <span class="n">f_max</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">output_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span>

    <span class="c1"># compute forward probabilities log(r_t^n(h)) and log(r_t^b(h))</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
        <span class="n">rp</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">rr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">rp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">log_phi</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">rp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rp</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="n">snum</span><span class="p">)</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span>

    <span class="c1"># compute log prefix probabilites log(psi)</span>
    <span class="n">log_phi_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">log_phi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">log_phi</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">scoring_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log_psi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">log_psi_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">log_phi_x</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="n">start</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">si</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">):</span>
            <span class="n">log_psi</span><span class="p">[</span><span class="n">si</span><span class="p">,</span> <span class="n">scoring_ids</span><span class="p">[</span><span class="n">si</span><span class="p">]]</span> <span class="o">=</span> <span class="n">log_psi_</span><span class="p">[</span><span class="n">si</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">log_psi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">log_phi_x</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="n">start</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">si</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">):</span>
        <span class="n">log_psi</span><span class="p">[</span><span class="n">si</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">]</span> <span class="o">=</span> <span class="n">r_sum</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_frames</span><span class="p">[</span><span class="n">si</span><span class="p">],</span> <span class="n">si</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">log_psi</span><span class="p">,</span> <span class="n">f_min</span><span class="p">,</span> <span class="n">f_max</span><span class="p">,</span> <span class="n">scoring_idmap</span><span class="p">),</span> <span class="n">log_psi</span> <span class="o">-</span> <span class="n">s_prev</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">xlens</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">scoring_ratio</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Construct CTC prefix scorer</p>
<p>:param torch.Tensor x: input label posterior sequences (B, T, O)
:param torch.Tensor xlens: input lengths (B,)
:param int blank: blank label id
:param int eos: end-of-sequence id
:param int beam: beam size
:param float scoring_ratio: ratio of #scored hypos to beam size
:param int margin: margin parameter for windowing (0 means no windowing)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">xlens</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">scoring_ratio</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Construct CTC prefix scorer</span>

<span class="sd">    :param torch.Tensor x: input label posterior sequences (B, T, O)</span>
<span class="sd">    :param torch.Tensor xlens: input lengths (B,)</span>
<span class="sd">    :param int blank: blank label id</span>
<span class="sd">    :param int eos: end-of-sequence id</span>
<span class="sd">    :param int beam: beam size</span>
<span class="sd">    :param float scoring_ratio: ratio of #scored hypos to beam size</span>
<span class="sd">    :param int margin: margin parameter for windowing (0 means no windowing)</span>
<span class="sd">    """</span>
    <span class="c1"># In the comment lines, we assume T: input_length, B: batch size, W: beam width, O: output dim.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000000000.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">blank</span> <span class="o">=</span> <span class="n">blank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beam</span> <span class="o">=</span> <span class="n">beam</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">*</span> <span class="n">beam</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda:</span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">x</span><span class="o">.</span><span class="n">get_device</span><span class="p">())</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
    <span class="c1"># Pad the rest of posteriors in the batch</span>
    <span class="c1"># TODO(takaaki-hori): need a better way without for-loops</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xlens</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">l</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">:</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="p">:,</span> <span class="n">blank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Set the number of scoring hypotheses (scoring_num=0 means all)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">beam</span> <span class="o">*</span> <span class="n">scoring_ratio</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Expand input posteriors for fast computation</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">xn</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xn</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">xb</span> <span class="o">=</span> <span class="n">xn</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">xn</span><span class="p">,</span> <span class="n">xb</span><span class="p">])</span>  <span class="c1"># (2, T, B, O) or (2, T, BW, O)</span>
    <span class="c1"># Setup CTC windowing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
    <span class="k">if</span> <span class="n">margin</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frame_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># Precompute end frames (BW,)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">end_frames</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">xlens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">beam</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Precompute base indices to convert label ids to corresponding element indices</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_b</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">beam</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_bo</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">beam</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_o</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">beam</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bb_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state">
<code class="highlight language-python">
index_select_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">best_ids</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Select CTC states according to best ids</p>
<p>:param state    : CTC state
:param best_ids : index numbers selected by beam pruning (B, W)
:return selected_state</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/ctc_prefix_score.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">index_select_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">best_ids</span><span class="p">):</span>
    <span class="sd">"""Select CTC states according to best ids</span>

<span class="sd">    :param state    : CTC state</span>
<span class="sd">    :param best_ids : index numbers selected by beam pruning (B, W)</span>
<span class="sd">    :return selected_state</span>
<span class="sd">    """</span>
    <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">f_min</span><span class="p">,</span> <span class="n">f_max</span><span class="p">,</span> <span class="n">scoring_idmap</span> <span class="o">=</span> <span class="n">state</span>
    <span class="c1"># convert ids to BWO space</span>
    <span class="n">vidx</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_ids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_bo</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># select hypothesis scores</span>
    <span class="n">s_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
    <span class="n">s_new</span> <span class="o">=</span> <span class="n">s_new</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
    <span class="c1"># convert ids to BWS space (S: scoring_num)</span>
    <span class="k">if</span> <span class="n">scoring_idmap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">snum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring_num</span>
        <span class="n">beam_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">best_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_b</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">label_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">best_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">score_idx</span> <span class="o">=</span> <span class="n">scoring_idmap</span><span class="p">[</span><span class="n">beam_idx</span><span class="p">,</span> <span class="n">label_ids</span><span class="p">]</span>
        <span class="n">score_idx</span><span class="p">[</span><span class="n">score_idx</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">vidx</span> <span class="o">=</span> <span class="n">score_idx</span> <span class="o">+</span> <span class="n">beam_idx</span> <span class="o">*</span> <span class="n">snum</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">snum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span>
    <span class="c1"># select forward probabilities</span>
    <span class="n">r_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span> <span class="o">*</span> <span class="n">snum</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bb</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">r_new</span><span class="p">,</span> <span class="n">s_new</span><span class="p">,</span> <span class="n">f_min</span><span class="p">,</span> <span class="n">f_max</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common">
<code>e2e_asr_common</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator">
<code>ErrorCalculator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Calculate CER and WER for E2E_ASR and CTC models during training</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param y_hats: numpy array with predicted text</span>
<span class="err">:param y_pads: numpy array with true (target) text</span>
<span class="err">:param char_list:</span>
<span class="err">:param sym_space:</span>
<span class="err">:param sym_blank:</span>
<span class="err">:return:</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">is_ctc</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__call__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>112
113
114
115
116
117
118
119
120
121
122
123
124
125</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">is_ctc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">is_ctc</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_cer_ctc</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span>

    <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_char</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span><span class="p">:</span>
        <span class="n">cer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_cer</span><span class="p">(</span><span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span><span class="p">:</span>
        <span class="n">wer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_wer</span><span class="p">(</span><span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">sym_space</span><span class="p">,</span> <span class="n">sym_blank</span><span class="p">,</span> <span class="n">report_cer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">report_wer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 98
 99
100
101
102
103
104
105
106
107
108
109
110</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">sym_space</span><span class="p">,</span> <span class="n">sym_blank</span><span class="p">,</span>
             <span class="n">report_cer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">report_wer</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ErrorCalculator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="n">char_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">space</span> <span class="o">=</span> <span class="n">sym_space</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">blank</span> <span class="o">=</span> <span class="n">sym_blank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span> <span class="o">=</span> <span class="n">report_cer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span> <span class="o">=</span> <span class="n">report_wer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idx_blank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">space</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx_space</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer">
<code class="highlight language-python">
calculate_cer<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>167
168
169
170
171
172
173
174</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_cer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">):</span>
    <span class="n">char_eds</span><span class="p">,</span> <span class="n">char_ref_lens</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq_hat_text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seqs_hat</span><span class="p">):</span>
        <span class="n">seq_true_text</span> <span class="o">=</span> <span class="n">seqs_true</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">hyp_chars</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
        <span class="n">ref_chars</span> <span class="o">=</span> <span class="n">seq_true_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
        <span class="n">char_ref_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ref_chars</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">char_eds</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">char_ref_lens</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc">
<code class="highlight language-python">
calculate_cer_ctc<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_cer_ctc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="n">cers</span><span class="p">,</span> <span class="n">char_ref_lens</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">groupby</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">seq_hat</span><span class="p">,</span> <span class="n">seq_true</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_hat</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_blank</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_space</span><span class="p">:</span>
                <span class="n">seq_hat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)])</span>

        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_true</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_blank</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_space</span><span class="p">:</span>
                <span class="n">seq_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)])</span>

        <span class="n">hyp_chars</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_hat</span><span class="p">)</span>
        <span class="n">ref_chars</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span>

    <span class="n">cer_ctc</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">cers</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">char_ref_lens</span><span class="p">)</span> <span class="k">if</span> <span class="n">cers</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">cer_ctc</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_wer">
<code class="highlight language-python">
calculate_wer<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.calculate_wer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>176
177
178
179
180
181
182
183</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_wer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span><span class="p">):</span>
    <span class="n">word_eds</span><span class="p">,</span> <span class="n">word_ref_lens</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq_hat_text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seqs_hat</span><span class="p">):</span>
        <span class="n">seq_true_text</span> <span class="o">=</span> <span class="n">seqs_true</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">hyp_words</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">ref_words</span> <span class="o">=</span> <span class="n">seq_true_text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word_ref_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ref_words</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">word_eds</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">word_ref_lens</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.convert_to_char">
<code class="highlight language-python">
convert_to_char<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.ErrorCalculator.convert_to_char" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">convert_to_char</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">):</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">eos_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_true</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">eos_true</span> <span class="o">=</span> <span class="n">eos_true</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eos_true</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="c1"># To avoid wrong higger WER than the one obtained from the decoding</span>
        <span class="c1"># eos from y_true is used to mark the eos in y_hat</span>
        <span class="c1"># because of that y_hats has not padded outs with -1.</span>
        <span class="n">seq_hat</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_hat</span><span class="p">[:</span><span class="n">eos_true</span><span class="p">]]</span>
        <span class="n">seq_true</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_true</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_hat</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
        <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
        <span class="n">seq_true_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
        <span class="n">seqs_hat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_hat_text</span><span class="p">)</span>
        <span class="n">seqs_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_true_text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">seqs_hat</span><span class="p">,</span> <span class="n">seqs_true</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.end_detect">
<code class="highlight language-python">
end_detect<span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">D_end</span><span class="o">=-</span><span class="mf">10.0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.end_detect" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>End detection</p>
<p>desribed in Eq. (50) of S. Watanabe et al
"Hybrid CTC/Attention Architecture for End-to-End Speech Recognition"</p>
<p>:param ended_hyps:
:param i:
:param M:
:param D_end:
:return:</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">end_detect</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">D_end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">))):</span>
    <span class="sd">"""End detection</span>

<span class="sd">    desribed in Eq. (50) of S. Watanabe et al</span>
<span class="sd">    "Hybrid CTC/Attention Architecture for End-to-End Speech Recognition"</span>

<span class="sd">    :param ended_hyps:</span>
<span class="sd">    :param i:</span>
<span class="sd">    :param M:</span>
<span class="sd">    :param D_end:</span>
<span class="sd">    :return:</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_hyp</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="c1"># get ended_hyps with their length is i - m</span>
        <span class="n">hyp_length</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="n">m</span>
        <span class="n">hyps_same_length</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ended_hyps</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])</span> <span class="o">==</span> <span class="n">hyp_length</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyps_same_length</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_hyp_same_length</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">hyps_same_length</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">best_hyp_same_length</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">-</span> <span class="n">best_hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">D_end</span><span class="p">:</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="n">M</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.get_vgg2l_odim">
<code class="highlight language-python">
get_vgg2l_odim<span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.get_vgg2l_odim" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>80
81
82
83
84</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_vgg2l_odim</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span> <span class="o">/</span> <span class="n">in_channel</span>
    <span class="n">idim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 1st max pooling</span>
    <span class="n">idim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 2nd max pooling</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">idim</span><span class="p">)</span> <span class="o">*</span> <span class="n">out_channel</span>  <span class="c1"># numer of channels</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.e2e_asr_common.label_smoothing_dist">
<code class="highlight language-python">
label_smoothing_dist<span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">lsm_type</span><span class="p">,</span> <span class="n">transcript</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.e2e_asr_common.label_smoothing_dist" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Obtain label distribution for loss smoothing</p>
<p>:param odim:
:param lsm_type:
:param blank:
:param transcript:
:return:</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/e2e_asr_common.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">label_smoothing_dist</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">lsm_type</span><span class="p">,</span> <span class="n">transcript</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Obtain label distribution for loss smoothing</span>

<span class="sd">    :param odim:</span>
<span class="sd">    :param lsm_type:</span>
<span class="sd">    :param blank:</span>
<span class="sd">    :param transcript:</span>
<span class="sd">    :return:</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">transcript</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">transcript</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">trans_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="s1">'utts'</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">lsm_type</span> <span class="o">==</span> <span class="s1">'unigram'</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">transcript</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">'transcript is required for </span><span class="si">%s</span><span class="s1"> label smoothing'</span> <span class="o">%</span> <span class="n">lsm_type</span>
        <span class="n">labelcount</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">odim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">trans_json</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">v</span><span class="p">[</span><span class="s1">'output'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'tokenid'</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>
            <span class="c1"># to avoid an error when there is no text in an uttrance</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">labelcount</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">labelcount</span><span class="p">[</span><span class="n">odim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>  <span class="c1"># count &lt;eos&gt;</span>
        <span class="n">labelcount</span><span class="p">[</span><span class="n">labelcount</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># flooring</span>
        <span class="n">labelcount</span><span class="p">[</span><span class="n">blank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># remove counts for blank</span>
        <span class="n">labeldist</span> <span class="o">=</span> <span class="n">labelcount</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labelcount</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
            <span class="s2">"Error: unexpected label smoothing type: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="n">lsm_type</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">labeldist</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface">
<code>mt_interface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>MT Interface module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface">
<code>MTInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>MT Interface for ESPnet model implementation.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.attention_plot_class">
<code class="highlight">
attention_plot_class        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.attention_plot_class" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get attention plot class.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.add_arguments" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Add arguments to parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>11
12
13
14</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments to parser."""</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.build">
<code class="highlight language-python">
build<span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.build" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize this class with python-level args.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>The number of an input feature dim.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>The number of output vocab.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ASRinterface</code></td>
<td>
<p>A new instance of ASRInterface.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">idim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">odim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Initialize this class with python-level args.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): The number of an input feature dim.</span>
<span class="sd">        odim (int): The number of output vocab.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ASRinterface: A new instance of ASRInterface.</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">get_parser</span><span class="p">(</span><span class="n">parser</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">wrap</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.calculate_all_attentions" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Caluculate attention.</p>
<p>:param list xs_pad: list of padded input sequences [(T1, idim), (T2, idim), ...]
:param ndarray ilens: batch of lengths of input sequences (B)
:param list ys: list of character id sequence tensor [(L1), (L2), (L3), ...]
:return: attention weights (B, Lmax, Tmax)
:rtype: float ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>78
79
80
81
82
83
84
85
86
87</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Caluculate attention.</span>

<span class="sd">    :param list xs_pad: list of padded input sequences [(T1, idim), (T2, idim), ...]</span>
<span class="sd">    :param ndarray ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param list ys: list of character id sequence tensor [(L1), (L2), (L3), ...]</span>
<span class="sd">    :return: attention weights (B, Lmax, Tmax)</span>
<span class="sd">    :rtype: float ndarray</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"calculate_all_attentions method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.forward" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Compute loss for training.</p>
<p>:param xs:
    For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
    For chainer, list of source sequences chainer.Variable
:param ilens: batch of lengths of source sequences (B)
    For pytorch, torch.Tensor
    For chainer, list of int
:param ys:
    For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
    For chainer, list of source sequences chainer.Variable
:return: loss value
:rtype: torch.Tensor for pytorch, chainer.Variable for chainer</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Compute loss for training.</span>

<span class="sd">    :param xs:</span>
<span class="sd">        For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)</span>
<span class="sd">        For chainer, list of source sequences chainer.Variable</span>
<span class="sd">    :param ilens: batch of lengths of source sequences (B)</span>
<span class="sd">        For pytorch, torch.Tensor</span>
<span class="sd">        For chainer, list of int</span>
<span class="sd">    :param ys:</span>
<span class="sd">        For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)</span>
<span class="sd">        For chainer, list of source sequences chainer.Variable</span>
<span class="sd">    :return: loss value</span>
<span class="sd">    :rtype: torch.Tensor for pytorch, chainer.Variable for chainer</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"forward method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate">
<code class="highlight language-python">
translate<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">trans_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Translate x for evaluation.</p>
<p>:param ndarray x: input acouctic feature (B, T, D) or (T, D)
:param namespace trans_args: argment namespace contraining options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>54
55
56
57
58
59
60
61
62
63
64</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">trans_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Translate x for evaluation.</span>

<span class="sd">    :param ndarray x: input acouctic feature (B, T, D) or (T, D)</span>
<span class="sd">    :param namespace trans_args: argment namespace contraining options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"translate method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate_batch">
<code class="highlight language-python">
translate_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">trans_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.mt_interface.MTInterface.translate_batch" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Beam search implementation for batch.</p>
<p>:param torch.Tensor x: encoder hidden state sequences (B, Tmax, Henc)
:param namespace trans_args: argument namespace containing options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/mt_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>66
67
68
69
70
71
72
73
74
75
76</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">translate_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">trans_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Beam search implementation for batch.</span>

<span class="sd">    :param torch.Tensor x: encoder hidden state sequences (B, Tmax, Henc)</span>
<span class="sd">    :param namespace trans_args: argument namespace containing options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Batch decoding is not supported yet."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend">
<code>pytorch_backend</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc">
<code>ctc</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC">
<code>CTC</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>CTC module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int odim: dimension of outputs</span>
<span class="err">:param int eprojs: number of encoder projection units</span>
<span class="err">:param float dropout_rate: dropout rate (0.0 ~ 1.0)</span>
<span class="err">:param str ctc_type: builtin or warpctc</span>
<span class="err">:param bool reduce: reduce the CTC loss into a scalar</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">ctc_type</span><span class="o">=</span><span class="s1">'warpctc'</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">ctc_type</span><span class="o">=</span><span class="s1">'warpctc'</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ctc_lo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">odim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">=</span> <span class="n">ctc_type</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">==</span> <span class="s1">'builtin'</span><span class="p">:</span>
        <span class="n">reduction_type</span> <span class="o">=</span> <span class="s1">'sum'</span> <span class="k">if</span> <span class="n">reduce</span> <span class="k">else</span> <span class="s1">'none'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CTCLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction_type</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">==</span> <span class="s1">'warpctc'</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">warpctc_pytorch</span> <span class="k">as</span> <span class="nn">warp_ctc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">warp_ctc</span><span class="o">.</span><span class="n">CTCLoss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'ctc_type must be "builtin" or "warpctc": </span><span class="si">{}</span><span class="s1">'</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduce</span> <span class="o">=</span> <span class="n">reduce</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="argmax()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC.argmax">
<code class="highlight language-python">
argmax<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>argmax of frame activations</p>
<p>:param torch.Tensor hs_pad: 3d tensor (B, Tmax, eprojs)
:return: argmax applied 2d tensor (B, Tmax)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>110
111
112
113
114
115
116
117</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">):</span>
    <span class="sd">"""argmax of frame activations</span>

<span class="sd">    :param torch.Tensor hs_pad: 3d tensor (B, Tmax, eprojs)</span>
<span class="sd">    :return: argmax applied 2d tensor (B, Tmax)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_lo</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>CTC forward</p>
<p>:param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)
:param torch.Tensor hlens: batch of lengths of hidden state sequences (B)
:param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)
:return: ctc loss value
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="sd">"""CTC forward</span>

<span class="sd">    :param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)</span>
<span class="sd">    :param torch.Tensor hlens: batch of lengths of hidden state sequences (B)</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)</span>
<span class="sd">    :return: ctc loss value</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="c1"># TODO(kan-bayashi): need to make more smart way</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys_pad</span><span class="p">]</span>  <span class="c1"># parse padded ys</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">hlens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="n">hlens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="n">olens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
        <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>

    <span class="c1"># zero padding for hs</span>
    <span class="n">ys_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_lo</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">))</span>

    <span class="c1"># zero padding for ys</span>
    <span class="n">ys_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>  <span class="c1"># batch x olen</span>

    <span class="c1"># get length info</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' input lengths:  '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">hlens</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' output lengths: '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)))</span>

    <span class="c1"># get ctc loss</span>
    <span class="c1"># expected shape of seqLength x batchSize x alphabet_size</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">ys_hat</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">ys_hat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">==</span> <span class="s2">"warpctc"</span><span class="p">:</span>
        <span class="c1"># warpctc only supports float32</span>
        <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">ys_hat</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># use GPU when using the cuDNN implementation</span>
        <span class="n">ys_true</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys_true</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_true</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">olens</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce</span><span class="p">:</span>
        <span class="c1"># NOTE: sum() is needed to keep consistency since warpctc return as tensor w/ shape (1,)</span>
        <span class="c1"># but builtin return as tensor w/o shape (scalar).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'ctc loss:'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)))</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="log_softmax()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC.log_softmax">
<code class="highlight language-python">
log_softmax<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>log_softmax of frame activations</p>
<p>:param torch.Tensor hs_pad: 3d tensor (B, Tmax, eprojs)
:return: log softmax applied 3d tensor (B, Tmax, odim)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>101
102
103
104
105
106
107
108</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">):</span>
    <span class="sd">"""log_softmax of frame activations</span>

<span class="sd">    :param torch.Tensor hs_pad: 3d tensor (B, Tmax, eprojs)</span>
<span class="sd">    :return: log softmax applied 3d tensor (B, Tmax, odim)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_lo</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="loss_fn()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.CTC.loss_fn">
<code class="highlight language-python">
loss_fn<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">th_pred</span><span class="p">,</span> <span class="n">th_target</span><span class="p">,</span> <span class="n">th_ilen</span><span class="p">,</span> <span class="n">th_olen</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">th_pred</span><span class="p">,</span> <span class="n">th_target</span><span class="p">,</span> <span class="n">th_ilen</span><span class="p">,</span> <span class="n">th_olen</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">==</span> <span class="s1">'builtin'</span><span class="p">:</span>
        <span class="n">th_pred</span> <span class="o">=</span> <span class="n">th_pred</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># Use the deterministic CuDNN implementation of CTC loss to avoid</span>
        <span class="c1">#  [issue#17798](https://github.com/pytorch/pytorch/issues/17798)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">flags</span><span class="p">(</span><span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span><span class="n">th_pred</span><span class="p">,</span> <span class="n">th_target</span><span class="p">,</span> <span class="n">th_ilen</span><span class="p">,</span> <span class="n">th_olen</span><span class="p">)</span>
        <span class="c1"># Batch-size average</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">th_pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_type</span> <span class="o">==</span> <span class="s1">'warpctc'</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span><span class="n">th_pred</span><span class="p">,</span> <span class="n">th_target</span><span class="p">,</span> <span class="n">th_ilen</span><span class="p">,</span> <span class="n">th_olen</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.ctc_for">
<code class="highlight language-python">
ctc_for<span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.ctc.ctc_for" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Returns the CTC module for the given args and output dimension</p>
<p>:param Namespace args: the program args
:param int odim : The output dimension
:param bool reduce : return the CTC loss in a scalar
:return: the corresponding CTC module</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">ctc_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Returns the CTC module for the given args and output dimension</span>

<span class="sd">    :param Namespace args: the program args</span>
<span class="sd">    :param int odim : The output dimension</span>
<span class="sd">    :param bool reduce : return the CTC loss in a scalar</span>
<span class="sd">    :return: the corresponding CTC module</span>
<span class="sd">    """</span>
    <span class="n">num_encs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"num_encs"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># use getattr to keep compatibility</span>
    <span class="k">if</span> <span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># compatible with single encoder asr mode</span>

        <span class="k">return</span> <span class="n">CTC</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">ctc_type</span><span class="o">=</span><span class="s1">'builtin'</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">)</span>
        <span class="c1"># changed this to use builtin ctc rather</span>
        <span class="c1"># than warpctc, so we have nothing to</span>
        <span class="c1"># install and it's just about the loss anyways.</span>

    <span class="k">elif</span> <span class="n">num_encs</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ctcs_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">share_ctc</span><span class="p">:</span>
            <span class="c1"># use dropout_rate of the first encoder</span>
            <span class="n">ctc</span> <span class="o">=</span> <span class="n">CTC</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ctc_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ctc_type</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">)</span>
            <span class="n">ctcs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ctc</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">ctc</span> <span class="o">=</span> <span class="n">CTC</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">ctc_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ctc_type</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">)</span>
                <span class="n">ctcs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ctc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ctcs_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Number of encoders needs to be more than one. </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_encs</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr">
<code>e2e_asr</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>RNN sequence-to-sequence speech recognition model (pytorch).</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E">
<code>E2E</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>E2E module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: dimension of inputs</span>
<span class="err">:param int odim: dimension of outputs</span>
<span class="err">:param Namespace args: argument Namespace containing options</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Construct an E2E object.</p>
<p>:param int idim: dimension of inputs
:param int odim: dimension of outputs
:param Namespace args: argument Namespace containing options</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Construct an E2E object.</span>

<span class="sd">    :param int idim: dimension of inputs</span>
<span class="sd">    :param int odim: dimension of outputs</span>
<span class="sd">    :param Namespace args: argument Namespace containing options</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">E2E</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  <span class="c1"># This loads default arguments,</span>
    <span class="c1"># but not calling this yields the same error, so it's not why things break.</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">mtlalpha</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">"mtlalpha should be [0.0, 1.0]"</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">etype</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">etype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span>
    <span class="c1"># NOTE: for self.build method</span>
    <span class="n">args</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"char_list"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">char_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outdir</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">outdir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">space</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">sym_space</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">blank</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">sym_blank</span>

    <span class="c1"># below means the last number becomes eos/sos ID</span>
    <span class="c1"># note that sos/eos IDs are identical</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sos</span> <span class="o">=</span> <span class="n">odim</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">odim</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># subsample info</span>
    <span class="c1"># +1 means input (+1) and layers outputs (args.elayer)</span>
    <span class="n">subsample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">etype</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">"p"</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">etype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"vgg"</span><span class="p">):</span>
        <span class="n">ss</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">subsample</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"_"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ss</span><span class="p">))):</span>
            <span class="n">subsample</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ss</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s1">'Subsampling is not performed for vgg*. It is performed in max pooling layers at CNN.'</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'subsample: '</span> <span class="o">+</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subsample</span><span class="p">]))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="n">subsample</span>

    <span class="c1"># label smoothing info</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">lsm_type</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_json</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Use label smoothing with "</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">lsm_type</span><span class="p">)</span>
        <span class="n">labeldist</span> <span class="o">=</span> <span class="n">label_smoothing_dist</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">lsm_type</span><span class="p">,</span> <span class="n">transcript</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_json</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">labeldist</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"use_frontend"</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>  <span class="c1"># use getattr to keep compatibility</span>
        <span class="c1"># Relative importing because of using python3 syntax</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.nets.pytorch_backend.frontends.feature_transform</span> \
            <span class="kn">import</span> <span class="nn">feature_transform_for</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.nets.pytorch_backend.frontends.frontend</span> \
            <span class="kn">import</span> <span class="nn">frontend_for</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="o">=</span> <span class="n">frontend_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">idim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_transform</span> <span class="o">=</span> <span class="n">feature_transform_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="p">(</span><span class="n">idim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">idim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">n_mels</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># encoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">encoder_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">)</span>
    <span class="c1"># ctc</span>
    <span class="c1"># self.ctc = ctc_for(args, odim) &lt;-- if this is executed, the shapes don't match.</span>
    <span class="c1"># The missing/unexpected arguments are not fixed by removing this however.</span>
    <span class="c1"># attention</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">att_for</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="c1"># decoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec</span> <span class="o">=</span> <span class="n">decoder_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">,</span> <span class="n">labeldist</span><span class="p">)</span>

    <span class="c1"># weight initialization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_like_chainer</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnnlm</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000000000.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">acc</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>44
45
46
47
48
49
50</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments."""</span>
    <span class="n">E2E</span><span class="o">.</span><span class="n">encoder_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">E2E</span><span class="o">.</span><span class="n">attention_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">E2E</span><span class="o">.</span><span class="n">decoder_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="attention_add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.attention_add_arguments">
<code class="highlight language-python">
attention_add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add arguments for the attention.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">attention_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments for the attention."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"E2E attention setting"</span><span class="p">)</span>
    <span class="c1"># attention</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--atype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'noatt'</span><span class="p">,</span> <span class="s1">'dot'</span><span class="p">,</span> <span class="s1">'add'</span><span class="p">,</span> <span class="s1">'location'</span><span class="p">,</span> <span class="s1">'coverage'</span><span class="p">,</span>
                                <span class="s1">'coverage_location'</span><span class="p">,</span> <span class="s1">'location2d'</span><span class="p">,</span> <span class="s1">'location_recurrent'</span><span class="p">,</span>
                                <span class="s1">'multi_head_dot'</span><span class="p">,</span> <span class="s1">'multi_head_add'</span><span class="p">,</span> <span class="s1">'multi_head_loc'</span><span class="p">,</span>
                                <span class="s1">'multi_head_multi_res_loc'</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Type of attention architecture'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--adim'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention transformation dimensions'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--awin'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Window size for location2d attention'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aheads'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of heads for multi head attention'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aconv-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention convolution channels </span><span class="se">\</span>
<span class="s1">                       (negative value indicates no location-aware attention)'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aconv-filts'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention convolution filters </span><span class="se">\</span>
<span class="s1">                       (negative value indicates no location-aware attention)'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dropout-rate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Dropout rate for the encoder'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E attention calculation.</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)
:return: attention weights with the following shape,
    1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
    2) other case =&gt; attention weights (B, Lmax, Tmax).
:rtype: float ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="sd">"""E2E attention calculation.</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)</span>
<span class="sd">    :return: attention weights with the following shape,</span>
<span class="sd">        1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),</span>
<span class="sd">        2) other case =&gt; attention weights (B, Lmax, Tmax).</span>
<span class="sd">    :rtype: float ndarray</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># 0. Frontend</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span><span class="p">(</span><span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">),</span> <span class="n">ilens</span><span class="p">)</span>
            <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_transform</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span>

        <span class="c1"># 1. Encoder</span>
        <span class="n">hpad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>

        <span class="c1"># 2. Decoder</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">calculate_all_attentions</span><span class="p">(</span><span class="n">hpad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="decoder_add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.decoder_add_arguments">
<code class="highlight language-python">
decoder_add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add arguments for the decoder.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">decoder_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments for the decoder."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"E2E encoder setting"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dtype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="s1">'gru'</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Type of decoder network architecture'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dlayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dunits'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder hidden units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dropout-rate-decoder'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Dropout rate for the decoder'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--sampling-probability'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Ratio of predicted labels fed back to decoder'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lsm-type'</span><span class="p">,</span> <span class="n">const</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">''</span><span class="p">,</span> <span class="s1">'unigram'</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Apply label smoothing with a specified distribution type'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="encode()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.encode">
<code class="highlight language-python">
encode<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Encode acoustic features.</p>
<p>:param ndarray x: input acoustic feature (T, D)
:return: encoder outputs
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Encode acoustic features.</span>

<span class="sd">    :param ndarray x: input acoustic feature (T, D)</span>
<span class="sd">    :return: encoder outputs</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="c1"># subsample frame</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[::</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># make a utt list (1) to use the same interface for encoder</span>
    <span class="n">hs</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># 0. Frontend</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">enhanced</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
        <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_transform</span><span class="p">(</span><span class="n">enhanced</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="n">hs</span><span class="p">,</span> <span class="n">ilens</span>

    <span class="c1"># 1. encoder</span>
    <span class="n">hs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="encoder_add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.encoder_add_arguments">
<code class="highlight language-python">
encoder_add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add arguments for the encoder.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">encoder_add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments for the encoder."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"E2E encoder setting"</span><span class="p">)</span>
    <span class="c1"># encoder</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--etype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">'blstmp'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="s1">'blstm'</span><span class="p">,</span> <span class="s1">'lstmp'</span><span class="p">,</span> <span class="s1">'blstmp'</span><span class="p">,</span> <span class="s1">'vgglstmp'</span><span class="p">,</span> <span class="s1">'vggblstmp'</span><span class="p">,</span> <span class="s1">'vgglstm'</span><span class="p">,</span> <span class="s1">'vggblstm'</span><span class="p">,</span>
                                <span class="s1">'gru'</span><span class="p">,</span> <span class="s1">'bgru'</span><span class="p">,</span> <span class="s1">'grup'</span><span class="p">,</span> <span class="s1">'bgrup'</span><span class="p">,</span> <span class="s1">'vgggrup'</span><span class="p">,</span> <span class="s1">'vggbgrup'</span><span class="p">,</span> <span class="s1">'vgggru'</span><span class="p">,</span> <span class="s1">'vggbgru'</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Type of encoder network architecture'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--elayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder layers (for shared recognition part in multi-speaker asr mode)'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eunits'</span><span class="p">,</span> <span class="s1">'-u'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder hidden units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eprojs'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder projection units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--subsample'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"1"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Subsample input frames x_y_z means subsample every x frame at 1st layer, '</span>
                            <span class="s1">'every y frame at 2nd layer etc.'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="enhance()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.enhance">
<code class="highlight language-python">
enhance<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Forward only in the frontend stage.</p>
<p>:param ndarray xs: input acoustic feature (T, C, F)
:return: enhaned feature
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">enhance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
    <span class="sd">"""Forward only in the frontend stage.</span>

<span class="sd">    :param ndarray xs: input acoustic feature (T, C, F)</span>
<span class="sd">    :return: enhaned feature</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Frontend does</span><span class="se">\'</span><span class="s1">t exist'</span><span class="p">)</span>
    <span class="n">prev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">((</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

    <span class="c1"># subsample frame</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">xx</span><span class="p">[::</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">enhanced</span><span class="p">,</span> <span class="n">hlensm</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">prev</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">enhanced</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">mask</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">ilens</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E forward.</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)
:return: loss value
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="sd">"""E2E forward.</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)</span>
<span class="sd">    :return: loss value</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="c1"># 0. Frontend</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span><span class="p">(</span><span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">),</span> <span class="n">ilens</span><span class="p">)</span>
        <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_transform</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span>

    <span class="c1"># 1. Encoder</span>
    <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>

    <span class="c1"># 2. CTC loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>

    <span class="c1"># 3. attention loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span>

    <span class="c1"># 4. compute cer without beam search</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cer_ctc</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">y_hats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_hats</span><span class="p">):</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">groupby</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
            <span class="n">y_true</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">seq_hat</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_hat</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">seq_true</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_true</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_hat</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
            <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
            <span class="n">seq_true_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>

            <span class="n">hyp_chars</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
            <span class="n">ref_chars</span> <span class="o">=</span> <span class="n">seq_true_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>

        <span class="n">cer_ctc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cers</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">cers</span><span class="p">)</span> <span class="k">if</span> <span class="n">cers</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># 5. compute cer/wer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span><span class="p">):</span>
        <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>
        <span class="c1"># oracle_cer, oracle_wer = 0.0, 0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">lpz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lpz</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">word_eds</span><span class="p">,</span> <span class="n">word_ref_lens</span><span class="p">,</span> <span class="n">char_eds</span><span class="p">,</span> <span class="n">char_ref_lens</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam_batch</span><span class="p">(</span>
            <span class="n">hs_pad</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">hlens</span><span class="p">),</span> <span class="n">lpz</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recog_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnnlm</span><span class="p">)</span>
        <span class="c1"># remove &lt;sos&gt; and &lt;eos&gt;</span>
        <span class="n">y_hats</span> <span class="o">=</span> <span class="p">[</span><span class="n">nbest_hyp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'yseq'</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">nbest_hyp</span> <span class="ow">in</span> <span class="n">nbest_hyps</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_hats</span><span class="p">):</span>
            <span class="n">y_true</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">seq_hat</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_hat</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">seq_true</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_true</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_hat</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recog_args</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
            <span class="n">seq_hat_text</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recog_args</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
            <span class="n">seq_true_text</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recog_args</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>

            <span class="n">hyp_words</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">ref_words</span> <span class="o">=</span> <span class="n">seq_true_text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">word_ref_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ref_words</span><span class="p">))</span>
            <span class="n">hyp_chars</span> <span class="o">=</span> <span class="n">seq_hat_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
            <span class="n">ref_chars</span> <span class="o">=</span> <span class="n">seq_true_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
            <span class="n">char_ref_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ref_chars</span><span class="p">))</span>

        <span class="n">wer</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_wer</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">word_eds</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">word_ref_lens</span><span class="p">)</span>
        <span class="n">cer</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_cer</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">char_eds</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">char_ref_lens</span><span class="p">)</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span><span class="p">)</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_att</span><span class="p">)</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_ctc</span><span class="p">)</span>

    <span class="n">loss_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss_data</span> <span class="o">&lt;</span> <span class="n">CTC_LOSS_THRESHOLD</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss_data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss_ctc_data</span><span class="p">,</span> <span class="n">loss_att_data</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">cer_ctc</span><span class="p">,</span> <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span><span class="p">,</span> <span class="n">loss_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'loss (=</span><span class="si">%f</span><span class="s1">) is not correct'</span><span class="p">,</span> <span class="n">loss_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="init_like_chainer()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.init_like_chainer">
<code class="highlight language-python">
init_like_chainer<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Initialize weight like chainer.</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in <strong> -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in</strong>-0.5, fan_in**-0.5)
however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_like_chainer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Initialize weight like chainer.</span>

<span class="sd">    chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0</span>
<span class="sd">    pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)</span>
<span class="sd">    however, there are two exceptions as far as I know.</span>
<span class="sd">    - EmbedID.W ~ Normal(0, 1)</span>
<span class="sd">    - LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</span>
<span class="sd">    """</span>
    <span class="n">lecun_normal_init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="c1"># exceptions</span>
    <span class="c1"># embed weight ~ Normal(0, 1)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">embed</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># forget-bias = 1.0</span>
    <span class="c1"># https://discuss.pytorch.org/t/set-forget-gate-bias-of-lstm/1745</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">decoder</span><span class="p">)):</span>
        <span class="n">set_forget_bias_to_one</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">bias_ih</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="recognize()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.recognize">
<code class="highlight language-python">
recognize<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E beam search.</p>
<p>:param ndarray x: input acoustic feature (T, D)
:param Namespace recog_args: argument Namespace containing options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""E2E beam search.</span>

<span class="sd">    :param ndarray x: input acoustic feature (T, D)</span>
<span class="sd">    :param Namespace recog_args: argument Namespace containing options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># calculate log P(z_t|X) for CTC scores</span>
    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">hs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># 2. Decoder</span>
    <span class="c1"># decode the first utterance</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="recognize_batch()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.recognize_batch">
<code class="highlight language-python">
recognize_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E beam search.</p>
<p>:param list xs: list of input acoustic feature arrays [(T_1, D), (T_2, D), ...]
:param Namespace recog_args: argument Namespace containing options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""E2E beam search.</span>

<span class="sd">    :param list xs: list of input acoustic feature arrays [(T_1, D), (T_2, D), ...]</span>
<span class="sd">    :param Namespace recog_args: argument Namespace containing options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="n">prev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">((</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

    <span class="c1"># subsample frame</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">xx</span><span class="p">[::</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># 0. Frontend</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">enhanced</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frontend</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
        <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_transform</span><span class="p">(</span><span class="n">enhanced</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span>

    <span class="c1"># 1. Encoder</span>
    <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)</span>

    <span class="c1"># calculate log P(z_t|X) for CTC scores</span>
    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">)</span>
        <span class="n">normalize_score</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">normalize_score</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># 2. Decoder</span>
    <span class="n">hlens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">hlens</span><span class="p">)))</span>  <span class="c1"># make sure hlens is tensor</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam_batch</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span>
                                      <span class="n">rnnlm</span><span class="p">,</span> <span class="n">normalize_score</span><span class="o">=</span><span class="n">normalize_score</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="scorers()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.scorers">
<code class="highlight language-python">
scorers<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Scorers.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>328
329
330</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">scorers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Scorers."""</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="p">,</span> <span class="n">ctc</span><span class="o">=</span><span class="n">CTCPrefixScorer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="subsample_frames()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr.E2E.subsample_frames">
<code class="highlight language-python">
subsample_frames<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Subsample speeh frames in the encoder.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>477
478
479
480
481
482
483
484
485</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">subsample_frames</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Subsample speeh frames in the encoder."""</span>
    <span class="c1"># subsample frame</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[::</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
    <span class="n">ilen</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
    <span class="n">h</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">h</span><span class="p">,</span> <span class="n">ilen</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer">
<code>e2e_asr_transformer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Transformer speech recognition model (pytorch).</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E">
<code>E2E</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>E2E module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: dimension of inputs</span>
<span class="err">:param int odim: dimension of outputs</span>
<span class="err">:param Namespace args: argument Namespace containing options</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="attention_plot_class" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.attention_plot_class">
<code class="highlight">
attention_plot_class        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return PlotAttentionReport.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">ignore_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Construct an E2E object.</p>
<p>:param int idim: dimension of inputs
:param int odim: dimension of outputs
:param Namespace args: argument Namespace containing options</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">ignore_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Construct an E2E object.</span>

<span class="sd">    :param int idim: dimension of inputs</span>
<span class="sd">    :param int odim: dimension of outputs</span>
<span class="sd">    :param Namespace args: argument Namespace containing options</span>
<span class="sd">    """</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">transformer_attn_dropout_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">transformer_attn_dropout_rate</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">,</span>
        <span class="n">input_layer</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_input_layer</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_attn_dropout_rate</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span>
        <span class="n">odim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dlayers</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="n">self_attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">src_attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_attn_dropout_rate</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sos</span> <span class="o">=</span> <span class="n">odim</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">odim</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span> <span class="o">=</span> <span class="n">ignore_id</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># self.lsm_weight = a</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">LabelSmoothingLoss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">lsm_weight</span><span class="p">,</span>
                                        <span class="n">args</span><span class="o">.</span><span class="n">transformer_length_normalized_loss</span><span class="p">)</span>
    <span class="c1"># self.verbose = args.verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">mtlalpha</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span> <span class="o">=</span> <span class="n">CTC</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">ctc_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ctc_type</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">report_cer</span> <span class="ow">or</span> <span class="n">args</span><span class="o">.</span><span class="n">report_wer</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal</span> <span class="kn">import</span> <span class="n">ErrorCalculator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span> <span class="o">=</span> <span class="n">ErrorCalculator</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">char_list</span><span class="p">,</span>
                                                <span class="n">args</span><span class="o">.</span><span class="n">sym_space</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">sym_blank</span><span class="p">,</span>
                                                <span class="n">args</span><span class="o">.</span><span class="n">report_cer</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">report_wer</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnnlm</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add arguments.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add arguments."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"transformer model setting"</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-init"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"pytorch"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"pytorch"</span><span class="p">,</span> <span class="s2">"xavier_uniform"</span><span class="p">,</span> <span class="s2">"xavier_normal"</span><span class="p">,</span>
                                <span class="s2">"kaiming_uniform"</span><span class="p">,</span> <span class="s2">"kaiming_normal"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'how to initialize transformer parameters'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-input-layer"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"conv2d"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"conv2d"</span><span class="p">,</span> <span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"embed"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'transformer input layer type'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--transformer-attn-dropout-rate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'dropout in transformer attention. use --dropout-rate if None is set'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--transformer-lr'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Initial value of learning rate'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--transformer-warmup-steps'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">25000</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'optimizer warmup steps'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--transformer-length-normalized-loss'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'normalize loss by length'</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dropout-rate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Dropout rate for the encoder'</span><span class="p">)</span>
    <span class="c1"># Encoder</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--elayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder layers (for shared recognition part in multi-speaker asr mode)'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eunits'</span><span class="p">,</span> <span class="s1">'-u'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder hidden units'</span><span class="p">)</span>
    <span class="c1"># Attention</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--adim'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention transformation dimensions'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aheads'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of heads for multi head attention'</span><span class="p">)</span>
    <span class="c1"># Decoder</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dlayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dunits'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">320</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder hidden units'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E attention calculation.</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)
:return: attention weights with the following shape,
    1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
    2) other case =&gt; attention weights (B, Lmax, Tmax).
:rtype: float ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="sd">"""E2E attention calculation.</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded token id sequence tensor (B, Lmax)</span>
<span class="sd">    :return: attention weights with the following shape,</span>
<span class="sd">        1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),</span>
<span class="sd">        2) other case =&gt; attention weights (B, Lmax, Tmax).</span>
<span class="sd">    :rtype: float ndarray</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultiHeadedAttention</span><span class="p">):</span>
            <span class="n">ret</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ret</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="encode()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.encode">
<code class="highlight language-python">
encode<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Encode acoustic features.</p>
<p>:param ndarray x: source acoustic feature (T, D)
:return: encoder outputs
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>223
224
225
226
227
228
229
230
231
232
233</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Encode acoustic features.</span>

<span class="sd">    :param ndarray x: source acoustic feature (T, D)</span>
<span class="sd">    :return: encoder outputs</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">enc_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">enc_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>E2E forward.</p>
<p>:param torch.Tensor xs_pad: batch of padded source sequences (B, Tmax, idim)
:param torch.Tensor ilens: batch of lengths of source sequences (B)
:param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)
:return: ctc loass value
:rtype: torch.Tensor
:return: attention loss value
:rtype: torch.Tensor
:return: accuracy in attention decoder
:rtype: float</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">):</span>
    <span class="sd">"""E2E forward.</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded source sequences (B, Tmax, idim)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of source sequences (B)</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)</span>
<span class="sd">    :return: ctc loass value</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: attention loss value</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: accuracy in attention decoder</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    """</span>
    <span class="c1"># 1. forward encoder</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)]</span>  <span class="c1"># for data parallel</span>
    <span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">ilens</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xs_pad</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hs_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hs_pad</span> <span class="o">=</span> <span class="n">hs_pad</span>

    <span class="c1"># 2. forward decoder</span>
    <span class="n">ys_in_pad</span><span class="p">,</span> <span class="n">ys_out_pad</span> <span class="o">=</span> <span class="n">add_sos_eos</span><span class="p">(</span><span class="n">ys_pad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>
    <span class="n">ys_mask</span> <span class="o">=</span> <span class="n">target_mask</span><span class="p">(</span><span class="n">ys_in_pad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>
    <span class="n">pred_pad</span><span class="p">,</span> <span class="n">pred_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">ys_in_pad</span><span class="p">,</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hs_mask</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pred_pad</span> <span class="o">=</span> <span class="n">pred_pad</span>

    <span class="c1"># 3. compute attention loss</span>
    <span class="n">loss_att</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">pred_pad</span><span class="p">,</span> <span class="n">ys_out_pad</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">acc</span> <span class="o">=</span> <span class="n">th_accuracy</span><span class="p">(</span><span class="n">pred_pad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">),</span> <span class="n">ys_out_pad</span><span class="p">,</span>
                           <span class="n">ignore_label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>

    <span class="c1"># TODO(karita) show predicted text</span>
    <span class="c1"># TODO(karita) calculate these stats</span>
    <span class="n">cer_ctc</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">loss_ctc</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">hs_len</span> <span class="o">=</span> <span class="n">hs_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss_ctc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="p">(</span><span class="n">hs_pad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">adim</span><span class="p">),</span> <span class="n">hs_len</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ys_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">hs_pad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">adim</span><span class="p">))</span><span class="o">.</span><span class="n">data</span>
            <span class="n">cer_ctc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span><span class="p">(</span><span class="n">ys_hat</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">is_ctc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 5. compute cer/wer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">pred_pad</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_calculator</span><span class="p">(</span><span class="n">ys_hat</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

    <span class="c1"># copyied from e2e_asr</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtlalpha</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_att</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_att</span><span class="p">)</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_ctc</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_ctc</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">loss_ctc</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">loss_att</span>
        <span class="n">loss_att_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_att</span><span class="p">)</span>
        <span class="n">loss_ctc_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_ctc</span><span class="p">)</span>

    <span class="n">loss_data</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss_data</span> <span class="o">&lt;</span> <span class="n">CTC_LOSS_THRESHOLD</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss_data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss_ctc_data</span><span class="p">,</span> <span class="n">loss_att_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acc</span><span class="p">,</span> <span class="n">cer_ctc</span><span class="p">,</span> <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span><span class="p">,</span> <span class="n">loss_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'loss (=</span><span class="si">%f</span><span class="s1">) is not correct'</span><span class="p">,</span> <span class="n">loss_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="recognize()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.recognize">
<code class="highlight language-python">
recognize<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_jit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Recognize input speech.</p>
<p>:param ndnarray x: input acoustic feature (B, T, D) or (T, D)
:param Namespace recog_args: argment Namespace contraining options
:param list char_list: list of characters
:param torch.nn.Module rnnlm: language model module
:return: N-best decoding results
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_jit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Recognize input speech.</span>

<span class="sd">    :param ndnarray x: input acoustic feature (B, T, D) or (T, D)</span>
<span class="sd">    :param Namespace recog_args: argment Namespace contraining options</span>
<span class="sd">    :param list char_list: list of characters</span>
<span class="sd">    :param torch.nn.Module rnnlm: language model module</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>
    <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">enc_output</span><span class="p">)</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="n">lpz</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">h</span> <span class="o">=</span> <span class="n">enc_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'input lengths: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="c1"># search parms</span>
    <span class="n">beam</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">beam_size</span>
    <span class="n">penalty</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">penalty</span>
    <span class="n">ctc_weight</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">ctc_weight</span>

    <span class="c1"># preprare sos</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos</span>
    <span class="n">vy</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># maxlen &gt;= 1</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">*</span> <span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">*</span> <span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'max output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'min output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">minlen</span><span class="p">))</span>

    <span class="c1"># initialize hypothesis</span>
    <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'score'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">'yseq'</span><span class="p">:</span> <span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="s1">'rnnlm_prev'</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'score'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">'yseq'</span><span class="p">:</span> <span class="p">[</span><span class="n">y</span><span class="p">]}</span>
    <span class="k">if</span> <span class="n">lpz</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">numpy</span>

        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.nets.ctc_prefix_score</span> <span class="kn">import</span> <span class="n">CTCPrefixScore</span>

        <span class="n">ctc_prefix_score</span> <span class="o">=</span> <span class="n">CTCPrefixScore</span><span class="p">(</span><span class="n">lpz</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="n">numpy</span><span class="p">)</span>
        <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctc_prefix_score</span><span class="o">.</span><span class="n">initial_state</span><span class="p">()</span>
        <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="n">ctc_weight</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># pre-pruning based on attention scores</span>
            <span class="kn">from</span> <span class="nn">tools.espnet_minimal.nets.pytorch_backend.rnn.decoders</span> <span class="kn">import</span> \
                <span class="n">CTC_SCORING_RATIO</span>
            <span class="n">ctc_beam</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">lpz</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">int</span><span class="p">(</span><span class="n">beam</span> <span class="o">*</span> <span class="n">CTC_SCORING_RATIO</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ctc_beam</span> <span class="o">=</span> <span class="n">lpz</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">hyps</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyp</span><span class="p">]</span>
    <span class="n">ended_hyps</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="kn">import</span> <span class="nn">six</span>
    <span class="n">traced_decoder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">maxlen</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'position '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="n">hyps_best_kept</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
            <span class="n">vy</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">vy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># get nbest local scores and their ids</span>
            <span class="n">ys_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># FIXME: jit does not match non-jit result</span>
            <span class="k">if</span> <span class="n">use_jit</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">traced_decoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">traced_decoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward_one_step</span><span class="p">,</span>
                                                     <span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">))</span>
                <span class="n">local_att_scores</span> <span class="o">=</span> <span class="n">traced_decoder</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">local_att_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward_one_step</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                <span class="n">rnnlm_state</span><span class="p">,</span> <span class="n">local_lm_scores</span> <span class="o">=</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">],</span> <span class="n">vy</span><span class="p">)</span>
                <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_att_scores</span> <span class="o">+</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">local_lm_scores</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_att_scores</span>

            <span class="k">if</span> <span class="n">lpz</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
                    <span class="n">local_att_scores</span><span class="p">,</span> <span class="n">ctc_beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ctc_scores</span><span class="p">,</span> <span class="n">ctc_states</span> <span class="o">=</span> <span class="n">ctc_prefix_score</span><span class="p">(</span>
                    <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">],</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">])</span>
                <span class="n">local_scores</span> <span class="o">=</span> \
                    <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">ctc_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">local_att_scores</span><span class="p">[:,</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> \
                    <span class="o">+</span> <span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ctc_scores</span> <span class="o">-</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                    <span class="n">local_scores</span> <span class="o">+=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">local_lm_scores</span><span class="p">[:,</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">joint_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">local_scores</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">local_best_ids</span><span class="p">[:,</span> <span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">local_scores</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">beam</span><span class="p">):</span>
                <span class="n">new_hyp</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+</span> <span class="nb">float</span><span class="p">(</span><span class="n">local_best_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]))</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rnnlm_state</span>
                <span class="k">if</span> <span class="n">lpz</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctc_states</span><span class="p">[</span><span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctc_scores</span><span class="p">[</span><span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span>
                <span class="c1"># will be (2 x beam) hyps at most</span>
                <span class="n">hyps_best_kept</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_hyp</span><span class="p">)</span>

            <span class="n">hyps_best_kept</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">hyps_best_kept</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">beam</span><span class="p">]</span>

        <span class="c1"># sort and get nbest</span>
        <span class="n">hyps</span> <span class="o">=</span> <span class="n">hyps_best_kept</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'number of pruned hypothes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">char_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="s1">'best hypo: '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'yseq'</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span>

        <span class="c1"># add eos in the final loop to avoid that there are no ended hyps</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'adding &lt;eos&gt; in the last postion in the loop'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
                <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>

        <span class="c1"># add ended hypothes to a final list, and removed them from current hypothes</span>
        <span class="c1"># (this will be a probmlem, number of hyps &lt; beam)</span>
        <span class="n">remained_hyps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">:</span>
                <span class="c1"># only store the sequence that has more than minlen outputs</span>
                <span class="c1"># also add penalty</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">minlen</span><span class="p">:</span>
                    <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">penalty</span>
                    <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>  <span class="c1"># Word LM needs to add final &lt;eos&gt; score</span>
                        <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">final</span><span class="p">(</span>
                            <span class="n">hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">])</span>
                    <span class="n">ended_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">remained_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>

        <span class="c1"># end detection</span>
        <span class="kn">from</span> <span class="nn">tools.espnet_minimal.nets.e2e_asr_common</span> <span class="kn">import</span> <span class="n">end_detect</span>
        <span class="k">if</span> <span class="n">end_detect</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">and</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'end detected at </span><span class="si">%d</span><span class="s1">'</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="n">hyps</span> <span class="o">=</span> <span class="n">remained_hyps</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'remeined hypothes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'no hypothesis. Finish decoding.'</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="k">if</span> <span class="n">char_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s1">'hypo: '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'number of ended hypothes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">)))</span>

    <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
        <span class="n">ended_hyps</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">),</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">nbest</span><span class="p">)]</span>

    <span class="c1"># check number of hypotheis</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'there is no N-best results, perform recognition again with smaller minlenratio.'</span><span class="p">)</span>
        <span class="c1"># should copy becasuse Namespace will be overwritten globally</span>
        <span class="n">recog_args</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">recog_args</span><span class="p">))</span>
        <span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">recognize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'total log probability: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'score'</span><span class="p">]))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'normalized log probability: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'yseq'</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">nbest_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="reset_parameters()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.reset_parameters">
<code class="highlight language-python">
reset_parameters<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Initialize parameters.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>142
143
144
145</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Initialize parameters."""</span>
    <span class="c1"># initialize parameters</span>
    <span class="n">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">transformer_init</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="scorers()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_asr_transformer.E2E.scorers">
<code class="highlight language-python">
scorers<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Scorers.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_asr_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>219
220
221</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">scorers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Scorers."""</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="n">ctc</span><span class="o">=</span><span class="n">CTCPrefixScorer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech">
<code>e2e_tts_fastspeech</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>FastSpeech related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer">
<code>FeedForwardTransformer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Feed Forward Transformer for TTS a.k.a. FastSpeech.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">FastSpeech</span><span class="p">,</span> <span class="n">feed</span><span class="o">-</span><span class="k">forward</span> <span class="n">Transformer</span> <span class="k">with</span> <span class="n">duration</span> <span class="n">predictor</span> <span class="n">described</span> <span class="k">in</span>
<span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="n">_</span><span class="p">,</span> <span class="n">which</span> <span class="n">does</span> <span class="k">not</span> <span class="n">require</span> <span class="k">any</span> <span class="n">auto</span><span class="o">-</span><span class="n">regressive</span>
<span class="n">processing</span> <span class="n">during</span> <span class="n">inference</span><span class="p">,</span> <span class="n">resulting</span> <span class="k">in</span> <span class="n">fast</span> <span class="n">decoding</span> <span class="n">compared</span> <span class="k">with</span> <span class="n">auto</span><span class="o">-</span><span class="n">regressive</span> <span class="n">Transformer</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1905</span><span class="p">.</span><span class="mi">09263</span><span class="p">.</span><span class="n">pdf</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="attention_plot_class" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.attention_plot_class">
<code class="highlight">
attention_plot_class        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return plot class for attention weight plot.</p>
</div>
</div>
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="base_plot_keys" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.base_plot_keys">
<code class="highlight">
base_plot_keys        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return base key names to plot during training. keys should match what <code>chainer.reporter</code> reports.</p>
<p>If you add the key <code>loss</code>, the reporter will report <code>main/loss</code> and <code>validation/main/loss</code> values.
also <code>loss.png</code> will be created as a figure visulizing <code>main/loss</code> and <code>validation/main/loss</code> values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list</code></td>
<td>
<p>List of strings which are base keys to plot during training.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize feed-forward Transformer module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>args</code></td>
<td><code>Namespace</code></td>
<td>
<ul>
<li>elayers (int): Number of encoder layers.</li>
<li>eunits (int): Number of encoder hidden units.</li>
<li>adim (int): Number of attention transformation dimensions.</li>
<li>aheads (int): Number of heads for multi head attention.</li>
<li>dlayers (int): Number of decoder layers.</li>
<li>dunits (int): Number of decoder hidden units.</li>
<li>use_scaled_pos_enc (bool): Whether to use trainable scaled positional encoding.</li>
<li>encoder_normalize_before (bool): Whether to perform layer normalization before encoder block.</li>
<li>decoder_normalize_before (bool): Whether to perform layer normalization before decoder block.</li>
<li>encoder_concat_after (bool): Whether to concatenate attention layer's input and output in encoder.</li>
<li>decoder_concat_after (bool): Whether to concatenate attention layer's input and output in decoder.</li>
<li>duration_predictor_layers (int): Number of duration predictor layers.</li>
<li>duration_predictor_chans (int): Number of duration predictor channels.</li>
<li>duration_predictor_kernel_size (int): Kernel size of duration predictor.</li>
<li>spk_embed_dim (int): Number of speaker embedding dimenstions.</li>
<li>spk_embed_integration_type: How to integrate speaker embedding.</li>
<li>teacher_model (str): Teacher auto-regressive transformer model path.</li>
<li>reduction_factor (int): Reduction factor.</li>
<li>transformer_init (float): How to initialize transformer parameters.</li>
<li>transformer_lr (float): Initial value of learning rate.</li>
<li>transformer_warmup_steps (int): Optimizer warmup steps.</li>
<li>transformer_enc_dropout_rate (float): Dropout rate in encoder except attention &amp; positional encoding.</li>
<li>transformer_enc_positional_dropout_rate (float): Dropout rate after encoder positional encoding.</li>
<li>transformer_enc_attn_dropout_rate (float): Dropout rate in encoder self-attention module.</li>
<li>transformer_dec_dropout_rate (float): Dropout rate in decoder except attention &amp; positional encoding.</li>
<li>transformer_dec_positional_dropout_rate (float): Dropout rate after decoder positional encoding.</li>
<li>transformer_dec_attn_dropout_rate (float): Dropout rate in deocoder self-attention module.</li>
<li>transformer_enc_dec_attn_dropout_rate (float): Dropout rate in encoder-deocoder attention module.</li>
<li>use_masking (bool): Whether to apply masking for padded part in loss calculation.</li>
<li>use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</li>
<li>transfer_encoder_from_teacher: Whether to transfer encoder using teacher encoder parameters.</li>
<li>transferred_encoder_module: Encoder module to be initialized using teacher parameters.</li>
</ul>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Initialize feed-forward Transformer module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        args (Namespace, optional):</span>
<span class="sd">            - elayers (int): Number of encoder layers.</span>
<span class="sd">            - eunits (int): Number of encoder hidden units.</span>
<span class="sd">            - adim (int): Number of attention transformation dimensions.</span>
<span class="sd">            - aheads (int): Number of heads for multi head attention.</span>
<span class="sd">            - dlayers (int): Number of decoder layers.</span>
<span class="sd">            - dunits (int): Number of decoder hidden units.</span>
<span class="sd">            - use_scaled_pos_enc (bool): Whether to use trainable scaled positional encoding.</span>
<span class="sd">            - encoder_normalize_before (bool): Whether to perform layer normalization before encoder block.</span>
<span class="sd">            - decoder_normalize_before (bool): Whether to perform layer normalization before decoder block.</span>
<span class="sd">            - encoder_concat_after (bool): Whether to concatenate attention layer's input and output in encoder.</span>
<span class="sd">            - decoder_concat_after (bool): Whether to concatenate attention layer's input and output in decoder.</span>
<span class="sd">            - duration_predictor_layers (int): Number of duration predictor layers.</span>
<span class="sd">            - duration_predictor_chans (int): Number of duration predictor channels.</span>
<span class="sd">            - duration_predictor_kernel_size (int): Kernel size of duration predictor.</span>
<span class="sd">            - spk_embed_dim (int): Number of speaker embedding dimenstions.</span>
<span class="sd">            - spk_embed_integration_type: How to integrate speaker embedding.</span>
<span class="sd">            - teacher_model (str): Teacher auto-regressive transformer model path.</span>
<span class="sd">            - reduction_factor (int): Reduction factor.</span>
<span class="sd">            - transformer_init (float): How to initialize transformer parameters.</span>
<span class="sd">            - transformer_lr (float): Initial value of learning rate.</span>
<span class="sd">            - transformer_warmup_steps (int): Optimizer warmup steps.</span>
<span class="sd">            - transformer_enc_dropout_rate (float): Dropout rate in encoder except attention &amp; positional encoding.</span>
<span class="sd">            - transformer_enc_positional_dropout_rate (float): Dropout rate after encoder positional encoding.</span>
<span class="sd">            - transformer_enc_attn_dropout_rate (float): Dropout rate in encoder self-attention module.</span>
<span class="sd">            - transformer_dec_dropout_rate (float): Dropout rate in decoder except attention &amp; positional encoding.</span>
<span class="sd">            - transformer_dec_positional_dropout_rate (float): Dropout rate after decoder positional encoding.</span>
<span class="sd">            - transformer_dec_attn_dropout_rate (float): Dropout rate in deocoder self-attention module.</span>
<span class="sd">            - transformer_enc_dec_attn_dropout_rate (float): Dropout rate in encoder-deocoder attention module.</span>
<span class="sd">            - use_masking (bool): Whether to apply masking for padded part in loss calculation.</span>
<span class="sd">            - use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</span>
<span class="sd">            - transfer_encoder_from_teacher: Whether to transfer encoder using teacher encoder parameters.</span>
<span class="sd">            - transferred_encoder_module: Encoder module to be initialized using teacher parameters.</span>

<span class="sd">    """</span>
    <span class="c1"># initialize base classes</span>
    <span class="n">TTSInterface</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="c1"># fill missing arguments</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">)</span>

    <span class="c1"># store hyperparameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_dim</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_integration_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_integration_type</span>

    <span class="c1"># use idx 0 as padding idx</span>
    <span class="n">padding_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># get positional encoding class</span>
    <span class="n">pos_enc_class</span> <span class="o">=</span> <span class="n">ScaledPositionalEncoding</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span> <span class="k">else</span> <span class="n">PositionalEncoding</span>

    <span class="c1"># define encoder</span>
    <span class="n">encoder_input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
        <span class="n">num_embeddings</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">embedding_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">,</span>
        <span class="n">input_layer</span><span class="o">=</span><span class="n">encoder_input_layer</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_positional_dropout_rate</span><span class="p">,</span>
        <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">pos_enc_class</span><span class="p">,</span>
        <span class="n">normalize_before</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">encoder_normalize_before</span><span class="p">,</span>
        <span class="n">concat_after</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">encoder_concat_after</span><span class="p">,</span>
        <span class="n">positionwise_layer_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_layer_type</span><span class="p">,</span>
        <span class="n">positionwise_conv_kernel_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_conv_kernel_size</span>
    <span class="p">)</span>

    <span class="c1"># define additional projection for speaker embedding</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_integration_type</span> <span class="o">==</span> <span class="s2">"add"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>

    <span class="c1"># define duration predictor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">duration_predictor</span> <span class="o">=</span> <span class="n">DurationPredictor</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">duration_predictor_layers</span><span class="p">,</span>
        <span class="n">n_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">duration_predictor_chans</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">duration_predictor_kernel_size</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">duration_predictor_dropout_rate</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># define length regulator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">length_regulator</span> <span class="o">=</span> <span class="n">LengthRegulator</span><span class="p">()</span>

    <span class="c1"># define decoder</span>
    <span class="c1"># NOTE: we use encoder as decoder because fastspeech's decoder is the same as encoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dlayers</span><span class="p">,</span>
        <span class="n">input_layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_positional_dropout_rate</span><span class="p">,</span>
        <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">pos_enc_class</span><span class="p">,</span>
        <span class="n">normalize_before</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">decoder_normalize_before</span><span class="p">,</span>
        <span class="n">concat_after</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">decoder_concat_after</span><span class="p">,</span>
        <span class="n">positionwise_layer_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_layer_type</span><span class="p">,</span>
        <span class="n">positionwise_conv_kernel_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_conv_kernel_size</span>
    <span class="p">)</span>

    <span class="c1"># define final projection</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span> <span class="n">odim</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>

    <span class="c1"># define postnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">postnet_layers</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">Postnet</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">odim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_layers</span><span class="p">,</span>
        <span class="n">n_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_chans</span><span class="p">,</span>
        <span class="n">n_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_filts</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_dropout_rate</span>
    <span class="p">)</span>

    <span class="c1"># initialize parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_init</span><span class="p">,</span>
                           <span class="n">init_enc_alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">initial_encoder_alpha</span><span class="p">,</span>
                           <span class="n">init_dec_alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">initial_decoder_alpha</span><span class="p">)</span>

    <span class="c1"># define teacher model</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">teacher_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_teacher_model</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">teacher_model</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># define duration calculator</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">duration_calculator</span> <span class="o">=</span> <span class="n">DurationCalculator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">duration_calculator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># transfer teacher parameters</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">transfer_encoder_from_teacher</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transfer_from_teacher</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">transferred_encoder_module</span><span class="p">)</span>

    <span class="c1"># define criterions</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">FeedForwardTransformerLoss</span><span class="p">(</span>
        <span class="n">use_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_masking</span><span class="p">,</span>
        <span class="n">use_weighted_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_weighted_masking</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add model-specific arguments to the parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add model-specific arguments to the parser."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"feed-forward transformer model setting"</span><span class="p">)</span>
    <span class="c1"># network structure related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--adim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of attention transformation dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--aheads"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of heads for multi head attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--elayers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eunits"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1536</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder hidden units"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dlayers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dunits"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1536</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder hidden units"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--positionwise-layer-type"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"conv1d"</span><span class="p">,</span> <span class="s2">"conv1d-linear"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Positionwise layer type."</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--positionwise-conv-kernel-size"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Kernel size of positionwise conv1d layer"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-layers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of postnet layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-chans"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of postnet channels"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-filts"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Filter size of postnet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-batch-norm"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use batch normalization"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-scaled-pos-enc"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Use trainable scaled positional encoding instead of the fixed scale one"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--encoder-normalize-before"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to apply layer norm before encoder block"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--decoder-normalize-before"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to apply layer norm before decoder block"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--encoder-concat-after"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to concatenate attention layer's input and output in encoder"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--decoder-concat-after"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to concatenate attention layer's input and output in decoder"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--duration-predictor-layers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of layers in duration predictor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--duration-predictor-chans"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of channels in duration predictor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--duration-predictor-kernel-size"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Kernel size in duration predictor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--teacher-model"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s2">"?"</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Teacher model file path"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--reduction-factor"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Reduction factor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spk-embed-dim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of speaker embedding dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spk-embed-integration-type"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"add"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"add"</span><span class="p">,</span> <span class="s2">"concat"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"How to integrate speaker embedding"</span><span class="p">)</span>
    <span class="c1"># training related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-init"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"pytorch"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"pytorch"</span><span class="p">,</span> <span class="s2">"xavier_uniform"</span><span class="p">,</span> <span class="s2">"xavier_normal"</span><span class="p">,</span>
                                <span class="s2">"kaiming_uniform"</span><span class="p">,</span> <span class="s2">"kaiming_normal"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"How to initialize transformer parameters"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--initial-encoder-alpha"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial alpha value in encoder's ScaledPositionalEncoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--initial-decoder-alpha"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial alpha value in decoder's ScaledPositionalEncoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-lr"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial value of learning rate"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-warmup-steps"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Optimizer warmup steps"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder except for attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-positional-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder positional encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder self-attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder except for attention and pos encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-positional-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder positional encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder self-attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-dec-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder-decoder attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--duration-predictor-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for duration predictor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate in postnet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transfer-encoder-from-teacher"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to transfer teacher's parameters"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transferred-encoder-module"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"all"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"all"</span><span class="p">,</span> <span class="s2">"embed"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Encoder modeules to be trasferred from teacher"</span><span class="p">)</span>
    <span class="c1"># loss related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-masking"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use masking in calculation of loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-weighted-masking"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use weighted masking in calculation of loss"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate all of the attention weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>extras</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of precalculated durations (B, Tmax, 1).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dict</code></td>
<td>
<p>Dict of attention weights and outputs.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate all of the attention weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>
<span class="sd">        extras (Tensor, optional): Batch of precalculated durations (B, Tmax, 1).</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Dict of attention weights and outputs.</span>

<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># remove unnecessary padded part (for multi-gpus)</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)]</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">extras</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extras</span> <span class="o">=</span> <span class="n">extras</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># forward propagation</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="n">spembs</span><span class="p">,</span> <span class="n">ds</span><span class="o">=</span><span class="n">extras</span><span class="p">,</span> <span class="n">is_inference</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">att_ws_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultiHeadedAttention</span><span class="p">):</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">"encoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">ilens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
            <span class="k">elif</span> <span class="s2">"decoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">"src"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ol</span><span class="p">,</span> <span class="p">:</span><span class="n">il</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">il</span><span class="p">,</span> <span class="n">ol</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">ilens</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">olens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
                <span class="k">elif</span> <span class="s2">"self"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">olens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"unknown attention module: "</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"unknown attention module: "</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
            <span class="n">att_ws_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn</span>
    <span class="n">att_ws_dict</span><span class="p">[</span><span class="s2">"predicted_fbank"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">[:</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">outs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">olens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>

    <span class="k">return</span> <span class="n">att_ws_dict</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>extras</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of precalculated durations (B, Tmax, 1).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>
<span class="sd">        extras (Tensor, optional): Batch of precalculated durations (B, Tmax, 1).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># remove unnecessary padded part (for multi-gpus)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)]</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">extras</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extras</span> <span class="o">=</span> <span class="n">extras</span><span class="p">[:,</span> <span class="p">:</span><span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># forward propagation</span>
    <span class="n">before_outs</span><span class="p">,</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">d_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span>
        <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="n">spembs</span><span class="p">,</span> <span class="n">ds</span><span class="o">=</span><span class="n">extras</span><span class="p">,</span> <span class="n">is_inference</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># modifiy mod part of groundtruth</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">olens</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">-</span> <span class="n">olen</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
        <span class="n">max_olen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_olen</span><span class="p">]</span>

    <span class="c1"># calculate loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l1_loss</span><span class="p">,</span> <span class="n">duration_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">d_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">l1_loss</span><span class="p">,</span> <span class="n">duration_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">d_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">l1_loss</span> <span class="o">+</span> <span class="n">duration_loss</span>
    <span class="n">report_keys</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">"l1_loss"</span><span class="p">:</span> <span class="n">l1_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s2">"duration_loss"</span><span class="p">:</span> <span class="n">duration_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s2">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
    <span class="p">]</span>

    <span class="c1"># report extra information</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span><span class="p">:</span>
        <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">"encoder_alpha"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">embed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
            <span class="p">{</span><span class="s2">"decoder_alpha"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">report_keys</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Generate the sequence of features given the sequences of characters.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input sequence of characters (T,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>inference_args</code></td>
<td><code>Namespace</code></td>
<td>
<p>Dummy for compatibility.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spemb</code></td>
<td><code>Tensor</code></td>
<td>
<p>Speaker embedding vector (spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Output sequence of features (L, odim).
None: Dummy for compatibility.
None: Dummy for compatibility.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Generate the sequence of features given the sequences of characters.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Input sequence of characters (T,).</span>
<span class="sd">        inference_args (Namespace): Dummy for compatibility.</span>
<span class="sd">        spemb (Tensor, optional): Speaker embedding vector (spk_embed_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Output sequence of features (L, odim).</span>
<span class="sd">        None: Dummy for compatibility.</span>
<span class="sd">        None: Dummy for compatibility.</span>

<span class="sd">    """</span>
    <span class="c1"># setup batch axis</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">spemb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">spembs</span> <span class="o">=</span> <span class="n">spemb</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">spembs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># inference</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">outs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="n">spembs</span><span class="p">,</span> <span class="n">is_inference</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (1, L, odim)</span>

    <span class="k">return</span> <span class="n">outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss">
<code>FeedForwardTransformerLoss</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Loss function module for feed-forward Transformer.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_weighted_masking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize feed-forward Transformer loss module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>use_masking</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to apply masking for padded part in loss calculation.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_weighted_masking</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to weighted masking in loss calculation.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_weighted_masking</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Initialize feed-forward Transformer loss module.</span>

<span class="sd">    Args:</span>
<span class="sd">        use_masking (bool): Whether to apply masking for padded part in loss calculation.</span>
<span class="sd">        use_weighted_masking (bool): Whether to weighted masking in loss calculation.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FeedForwardTransformerLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">use_masking</span> <span class="o">!=</span> <span class="n">use_weighted_masking</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_masking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span> <span class="o">=</span> <span class="n">use_masking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span> <span class="o">=</span> <span class="n">use_weighted_masking</span>

    <span class="c1"># define criterions</span>
    <span class="n">reduction</span> <span class="o">=</span> <span class="s2">"none"</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span> <span class="k">else</span> <span class="s2">"mean"</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">duration_criterion</span> <span class="o">=</span> <span class="n">DurationPredictorLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">d_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>after_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs after postnets (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>before_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs before postnets (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>d_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs of duration predictor (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ds</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of durations (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each input (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>L1 loss value.
Tensor: Duration predictor loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_fastspeech.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">d_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        after_outs (Tensor): Batch of outputs after postnets (B, Lmax, odim).</span>
<span class="sd">        before_outs (Tensor): Batch of outputs before postnets (B, Lmax, odim).</span>
<span class="sd">        d_outs (Tensor): Batch of outputs of duration predictor (B, Tmax).</span>
<span class="sd">        ys (Tensor): Batch of target features (B, Lmax, odim).</span>
<span class="sd">        ds (Tensor): Batch of durations (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of the lengths of each input (B,).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: L1 loss value.</span>
<span class="sd">        Tensor: Duration predictor loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># apply mask to remove padded part</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span><span class="p">:</span>
        <span class="n">duration_masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">d_outs</span> <span class="o">=</span> <span class="n">d_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">duration_masks</span><span class="p">)</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">duration_masks</span><span class="p">)</span>
        <span class="n">out_masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">before_outs</span> <span class="o">=</span> <span class="n">before_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">out_masks</span><span class="p">)</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">after_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">out_masks</span><span class="p">)</span> <span class="k">if</span> <span class="n">after_outs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">out_masks</span><span class="p">)</span>

    <span class="c1"># calculate loss</span>
    <span class="n">l1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span><span class="p">(</span><span class="n">before_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">after_outs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l1_loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="n">duration_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">duration_criterion</span><span class="p">(</span><span class="n">d_outs</span><span class="p">,</span> <span class="n">ds</span><span class="p">)</span>

    <span class="c1"># make weighted mask and apply it</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span><span class="p">:</span>
        <span class="n">out_masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out_weights</span> <span class="o">=</span> <span class="n">out_masks</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">out_masks</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">out_weights</span> <span class="o">/=</span> <span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">duration_masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">duration_weights</span> <span class="o">=</span> <span class="n">duration_masks</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">duration_masks</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">duration_weights</span> <span class="o">/=</span> <span class="n">ds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># apply weight</span>
        <span class="n">l1_loss</span> <span class="o">=</span> <span class="n">l1_loss</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">out_weights</span><span class="p">)</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">out_masks</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">duration_loss</span> <span class="o">=</span> <span class="n">duration_loss</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">duration_weights</span><span class="p">)</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">duration_masks</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">l1_loss</span><span class="p">,</span> <span class="n">duration_loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2">
<code>e2e_tts_tacotron2</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Tacotron 2 related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss">
<code>GuidedAttentionLoss</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Guided attention loss function module.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="n">module</span> <span class="n">calculates</span> <span class="n">the</span> <span class="n">guided</span> <span class="n">attention</span> <span class="n">loss</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="n">Efficiently</span> <span class="n">Trainable</span> <span class="nb">Text</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="n">Speech</span> <span class="k">System</span> <span class="n">Based</span>
<span class="k">on</span> <span class="n">Deep</span> <span class="n">Convolutional</span> <span class="n">Networks</span> <span class="k">with</span> <span class="n">Guided</span> <span class="n">Attention</span><span class="o">`</span><span class="n">_</span><span class="p">,</span> <span class="n">which</span> <span class="n">forces</span> <span class="n">the</span> <span class="n">attention</span> <span class="k">to</span> <span class="n">be</span> <span class="n">diagonal</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">Efficiently</span> <span class="n">Trainable</span> <span class="nb">Text</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="n">Speech</span> <span class="k">System</span> <span class="n">Based</span> <span class="k">on</span> <span class="n">Deep</span> <span class="n">Convolutional</span> <span class="n">Networks</span> <span class="k">with</span> <span class="n">Guided</span> <span class="n">Attention</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1710</span><span class="p">.</span><span class="mi">08969</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">reset_always</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize guided attention loss module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>sigma</code></td>
<td><code>float</code></td>
<td>
<p>Standard deviation to control how close attention to a diagonal.</p>
</td>
<td><code>0.4</code></td>
</tr>
<tr>
<td><code>alpha</code></td>
<td><code>float</code></td>
<td>
<p>Scaling coefficient (lambda).</p>
</td>
<td><code>1.0</code></td>
</tr>
<tr>
<td><code>reset_always</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to always reset masks.</p>
</td>
<td><code>True</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">reset_always</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Initialize guided attention loss module.</span>

<span class="sd">    Args:</span>
<span class="sd">        sigma (float, optional): Standard deviation to control how close attention to a diagonal.</span>
<span class="sd">        alpha (float, optional): Scaling coefficient (lambda).</span>
<span class="sd">        reset_always (bool, optional): Whether to always reset masks.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GuidedAttentionLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reset_always</span> <span class="o">=</span> <span class="n">reset_always</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>att_ws</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of attention weights (B, T_max_out, T_max_in).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of input lenghts (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of output lenghts (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Guided attention loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        att_ws (Tensor): Batch of attention weights (B, T_max_out, T_max_in).</span>
<span class="sd">        ilens (LongTensor): Batch of input lenghts (B,).</span>
<span class="sd">        olens (LongTensor): Batch of output lenghts (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Guided attention loss value.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_guided_attention_masks</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">att_ws</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_masks</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">att_ws</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="o">*</span> <span class="n">att_ws</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_always</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_masks</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2">
<code>Tacotron2</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Tacotron2 module for end-to-end text-to-speech (E2E-TTS).</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">Spectrogram</span> <span class="n">prediction</span> <span class="n">network</span> <span class="k">in</span> <span class="n">Tacotron2</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span>
<span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">,</span> <span class="n">which</span> <span class="n">converts</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">characters</span>
<span class="k">into</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">Mel</span><span class="o">-</span><span class="n">filterbanks</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="p">:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1712</span><span class="p">.</span><span class="mi">05884</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="base_plot_keys" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.base_plot_keys">
<code class="highlight">
base_plot_keys        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return base key names to plot during training. keys should match what <code>chainer.reporter</code> reports.</p>
<p>If you add the key <code>loss</code>, the reporter will report <code>main/loss</code> and <code>validation/main/loss</code> values.
also <code>loss.png</code> will be created as a figure visulizing <code>main/loss</code> and <code>validation/main/loss</code> values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list</code></td>
<td>
<p>List of strings which are base keys to plot during training.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize Tacotron2 module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>args</code></td>
<td><code>Namespace</code></td>
<td>
<ul>
<li>spk_embed_dim (int): Dimension of the speaker embedding.</li>
<li>embed_dim (int): Dimension of character embedding.</li>
<li>elayers (int): The number of encoder blstm layers.</li>
<li>eunits (int): The number of encoder blstm units.</li>
<li>econv_layers (int): The number of encoder conv layers.</li>
<li>econv_filts (int): The number of encoder conv filter size.</li>
<li>econv_chans (int): The number of encoder conv filter channels.</li>
<li>dlayers (int): The number of decoder lstm layers.</li>
<li>dunits (int): The number of decoder lstm units.</li>
<li>prenet_layers (int): The number of prenet layers.</li>
<li>prenet_units (int): The number of prenet units.</li>
<li>postnet_layers (int): The number of postnet layers.</li>
<li>postnet_filts (int): The number of postnet filter size.</li>
<li>postnet_chans (int): The number of postnet filter channels.</li>
<li>output_activation (int): The name of activation function for outputs.</li>
<li>adim (int): The number of dimension of mlp in attention.</li>
<li>aconv_chans (int): The number of attention conv filter channels.</li>
<li>aconv_filts (int): The number of attention conv filter size.</li>
<li>cumulate_att_w (bool): Whether to cumulate previous attention weight.</li>
<li>use_batch_norm (bool): Whether to use batch normalization.</li>
<li>use_concate (int): Whether to concatenate encoder embedding with decoder lstm outputs.</li>
<li>dropout_rate (float): Dropout rate.</li>
<li>zoneout_rate (float): Zoneout rate.</li>
<li>reduction_factor (int): Reduction factor.</li>
<li>spk_embed_dim (int): Number of speaker embedding dimenstions.</li>
<li>spc_dim (int): Number of spectrogram embedding dimenstions (only for use_cbhg=True).</li>
<li>use_cbhg (bool): Whether to use CBHG module.</li>
<li>cbhg_conv_bank_layers (int): The number of convoluional banks in CBHG.</li>
<li>cbhg_conv_bank_chans (int): The number of channels of convolutional bank in CBHG.</li>
<li>cbhg_proj_filts (int): The number of filter size of projection layeri in CBHG.</li>
<li>cbhg_proj_chans (int): The number of channels of projection layer in CBHG.</li>
<li>cbhg_highway_layers (int): The number of layers of highway network in CBHG.</li>
<li>cbhg_highway_units (int): The number of units of highway network in CBHG.</li>
<li>cbhg_gru_units (int): The number of units of GRU in CBHG.</li>
<li>use_masking (bool): Whether to apply masking for padded part in loss calculation.</li>
<li>use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</li>
<li>bce_pos_weight (float): Weight of positive sample of stop token (only for use_masking=True).</li>
<li>use-guided-attn-loss (bool): Whether to use guided attention loss.</li>
<li>guided-attn-loss-sigma (float) Sigma in guided attention loss.</li>
<li>guided-attn-loss-lamdba (float): Lambda in guided attention loss.</li>
</ul>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Initialize Tacotron2 module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        args (Namespace, optional):</span>
<span class="sd">            - spk_embed_dim (int): Dimension of the speaker embedding.</span>
<span class="sd">            - embed_dim (int): Dimension of character embedding.</span>
<span class="sd">            - elayers (int): The number of encoder blstm layers.</span>
<span class="sd">            - eunits (int): The number of encoder blstm units.</span>
<span class="sd">            - econv_layers (int): The number of encoder conv layers.</span>
<span class="sd">            - econv_filts (int): The number of encoder conv filter size.</span>
<span class="sd">            - econv_chans (int): The number of encoder conv filter channels.</span>
<span class="sd">            - dlayers (int): The number of decoder lstm layers.</span>
<span class="sd">            - dunits (int): The number of decoder lstm units.</span>
<span class="sd">            - prenet_layers (int): The number of prenet layers.</span>
<span class="sd">            - prenet_units (int): The number of prenet units.</span>
<span class="sd">            - postnet_layers (int): The number of postnet layers.</span>
<span class="sd">            - postnet_filts (int): The number of postnet filter size.</span>
<span class="sd">            - postnet_chans (int): The number of postnet filter channels.</span>
<span class="sd">            - output_activation (int): The name of activation function for outputs.</span>
<span class="sd">            - adim (int): The number of dimension of mlp in attention.</span>
<span class="sd">            - aconv_chans (int): The number of attention conv filter channels.</span>
<span class="sd">            - aconv_filts (int): The number of attention conv filter size.</span>
<span class="sd">            - cumulate_att_w (bool): Whether to cumulate previous attention weight.</span>
<span class="sd">            - use_batch_norm (bool): Whether to use batch normalization.</span>
<span class="sd">            - use_concate (int): Whether to concatenate encoder embedding with decoder lstm outputs.</span>
<span class="sd">            - dropout_rate (float): Dropout rate.</span>
<span class="sd">            - zoneout_rate (float): Zoneout rate.</span>
<span class="sd">            - reduction_factor (int): Reduction factor.</span>
<span class="sd">            - spk_embed_dim (int): Number of speaker embedding dimenstions.</span>
<span class="sd">            - spc_dim (int): Number of spectrogram embedding dimenstions (only for use_cbhg=True).</span>
<span class="sd">            - use_cbhg (bool): Whether to use CBHG module.</span>
<span class="sd">            - cbhg_conv_bank_layers (int): The number of convoluional banks in CBHG.</span>
<span class="sd">            - cbhg_conv_bank_chans (int): The number of channels of convolutional bank in CBHG.</span>
<span class="sd">            - cbhg_proj_filts (int): The number of filter size of projection layeri in CBHG.</span>
<span class="sd">            - cbhg_proj_chans (int): The number of channels of projection layer in CBHG.</span>
<span class="sd">            - cbhg_highway_layers (int): The number of layers of highway network in CBHG.</span>
<span class="sd">            - cbhg_highway_units (int): The number of units of highway network in CBHG.</span>
<span class="sd">            - cbhg_gru_units (int): The number of units of GRU in CBHG.</span>
<span class="sd">            - use_masking (bool): Whether to apply masking for padded part in loss calculation.</span>
<span class="sd">            - use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</span>
<span class="sd">            - bce_pos_weight (float): Weight of positive sample of stop token (only for use_masking=True).</span>
<span class="sd">            - use-guided-attn-loss (bool): Whether to use guided attention loss.</span>
<span class="sd">            - guided-attn-loss-sigma (float) Sigma in guided attention loss.</span>
<span class="sd">            - guided-attn-loss-lamdba (float): Lambda in guided attention loss.</span>

<span class="sd">    """</span>
    <span class="c1"># initialize base classes</span>
    <span class="n">TTSInterface</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="c1"># fill missing arguments</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">)</span>

    <span class="c1"># store hyperparameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cumulate_att_w</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_cbhg</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_cbhg</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_guided_attn_loss</span>

    <span class="c1"># define activation function for the final output</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">output_activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">output_activation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">output_activation</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'there is no such an activation function. (</span><span class="si">%s</span><span class="s1">)'</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">output_activation</span><span class="p">)</span>

    <span class="c1"># set padding idx</span>
    <span class="n">padding_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># define network modules</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
                       <span class="n">embed_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span>
                       <span class="n">elayers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">,</span>
                       <span class="n">eunits</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">,</span>
                       <span class="n">econv_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">econv_layers</span><span class="p">,</span>
                       <span class="n">econv_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">econv_chans</span><span class="p">,</span>
                       <span class="n">econv_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">econv_filts</span><span class="p">,</span>
                       <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">,</span>
                       <span class="n">use_residual</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_residual</span><span class="p">,</span>
                       <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
                       <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
    <span class="n">dec_idim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">eunits</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">eunits</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_dim</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">atype</span> <span class="o">==</span> <span class="s2">"location"</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttLoc</span><span class="p">(</span><span class="n">dec_idim</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">.</span><span class="n">aconv_chans</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">.</span><span class="n">aconv_filts</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">atype</span> <span class="o">==</span> <span class="s2">"forward"</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttForward</span><span class="p">(</span><span class="n">dec_idim</span><span class="p">,</span>
                         <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
                         <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
                         <span class="n">args</span><span class="o">.</span><span class="n">aconv_chans</span><span class="p">,</span>
                         <span class="n">args</span><span class="o">.</span><span class="n">aconv_filts</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"cumulation of attention weights is disabled in forward attention."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">atype</span> <span class="o">==</span> <span class="s2">"forward_ta"</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttForwardTA</span><span class="p">(</span><span class="n">dec_idim</span><span class="p">,</span>
                           <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
                           <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
                           <span class="n">args</span><span class="o">.</span><span class="n">aconv_chans</span><span class="p">,</span>
                           <span class="n">args</span><span class="o">.</span><span class="n">aconv_filts</span><span class="p">,</span>
                           <span class="n">odim</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"cumulation of attention weights is disabled in forward attention."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Support only location or forward"</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">idim</span><span class="o">=</span><span class="n">dec_idim</span><span class="p">,</span>
                       <span class="n">odim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
                       <span class="n">att</span><span class="o">=</span><span class="n">att</span><span class="p">,</span>
                       <span class="n">dlayers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dlayers</span><span class="p">,</span>
                       <span class="n">dunits</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
                       <span class="n">prenet_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">prenet_layers</span><span class="p">,</span>
                       <span class="n">prenet_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">prenet_units</span><span class="p">,</span>
                       <span class="n">postnet_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_layers</span><span class="p">,</span>
                       <span class="n">postnet_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_chans</span><span class="p">,</span>
                       <span class="n">postnet_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_filts</span><span class="p">,</span>
                       <span class="n">output_activation_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">,</span>
                       <span class="n">cumulate_att_w</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span><span class="p">,</span>
                       <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">,</span>
                       <span class="n">use_concate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_concate</span><span class="p">,</span>
                       <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
                       <span class="n">zoneout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">zoneout_rate</span><span class="p">,</span>
                       <span class="n">reduction_factor</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">taco2_loss</span> <span class="o">=</span> <span class="n">Tacotron2Loss</span><span class="p">(</span><span class="n">use_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_masking</span><span class="p">,</span>
                                    <span class="n">use_weighted_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_weighted_masking</span><span class="p">,</span>
                                    <span class="n">bce_pos_weight</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">bce_pos_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_loss</span> <span class="o">=</span> <span class="n">GuidedAttentionLoss</span><span class="p">(</span>
            <span class="n">sigma</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">guided_attn_loss_sigma</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">guided_attn_loss_lambda</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cbhg</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cbhg</span> <span class="o">=</span> <span class="n">CBHG</span><span class="p">(</span><span class="n">idim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
                         <span class="n">odim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">spc_dim</span><span class="p">,</span>
                         <span class="n">conv_bank_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_conv_bank_layers</span><span class="p">,</span>
                         <span class="n">conv_bank_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_conv_bank_chans</span><span class="p">,</span>
                         <span class="n">conv_proj_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_conv_proj_filts</span><span class="p">,</span>
                         <span class="n">conv_proj_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_conv_proj_chans</span><span class="p">,</span>
                         <span class="n">highway_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_highway_layers</span><span class="p">,</span>
                         <span class="n">highway_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_highway_units</span><span class="p">,</span>
                         <span class="n">gru_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cbhg_gru_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cbhg_loss</span> <span class="o">=</span> <span class="n">CBHGLoss</span><span class="p">(</span><span class="n">use_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_masking</span><span class="p">)</span>

    <span class="c1"># load pretrained model</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_pretrained_model</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add model-specific arguments to the parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add model-specific arguments to the parser."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"tacotron 2 model setting"</span><span class="p">)</span>
    <span class="c1"># encoder</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--embed-dim'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of dimension of embedding'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--elayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--eunits'</span><span class="p">,</span> <span class="s1">'-u'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder hidden units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--econv-layers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder convolution layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--econv-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of encoder convolution channels'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--econv-filts'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Filter size of encoder convolution'</span><span class="p">)</span>
    <span class="c1"># attention</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--atype'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"location"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"forward_ta"</span><span class="p">,</span> <span class="s2">"forward"</span><span class="p">,</span> <span class="s2">"location"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Type of attention mechanism'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--adim'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention transformation dimensions'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aconv-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of attention convolution channels'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--aconv-filts'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Filter size of attention convolution'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cumulate-att-w'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether or not to cumulate attention weights"</span><span class="p">)</span>
    <span class="c1"># decoder</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dlayers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dunits'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of decoder hidden units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--prenet-layers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of prenet layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--prenet-units'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of prenet hidden units'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--postnet-layers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of postnet layers'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--postnet-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of postnet channels'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--postnet-filts'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Filter size of postnet'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--output-activation'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">'?'</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Output activation function'</span><span class="p">)</span>
    <span class="c1"># cbhg</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-cbhg'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use CBHG module'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-conv-bank-layers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of convoluional bank layers in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-conv-bank-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of convoluional bank channles in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-conv-proj-filts'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Filter size of convoluional projection layer in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-conv-proj-chans'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of convoluional projection channels in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-highway-layers'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of highway layers in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-highway-units'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of highway units in CBHG'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--cbhg-gru-units'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Number of GRU units in CBHG'</span><span class="p">)</span>
    <span class="c1"># model (parameter) related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-batch-norm'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use batch normalization'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-concate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to concatenate encoder embedding with decoder outputs'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-residual'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use residual connection in conv layer'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--dropout-rate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Dropout rate'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--zoneout-rate'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Zoneout rate'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--reduction-factor'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Reduction factor'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spk-embed-dim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of speaker embedding dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spc-dim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of spectrogram dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--pretrained-model"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Pretrained model path"</span><span class="p">)</span>
    <span class="c1"># loss related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-masking'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use masking in calculation of loss'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--use-weighted-masking'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Whether to use weighted masking in calculation of loss'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--bce-pos-weight'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">20.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s1">'Positive sample weight in BCE calculation (only for use-masking=True)'</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-guided-attn-loss"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use guided attention loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--guided-attn-loss-sigma"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Sigma in guided attention loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--guided-attn-loss-lambda"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Lambda in guided attention loss"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_tensor</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate all of the attention weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>keep_tensor</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to keep original tensor.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Union[ndarray, Tensor]</code></td>
<td>
<p>Batch of attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_tensor</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate all of the attention weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>
<span class="sd">        keep_tensor (bool, optional): Whether to keep original tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[ndarray, Tensor]: Batch of attention weights (B, Lmax, Tmax).</span>

<span class="sd">    """</span>
    <span class="c1"># check ilens type (should be list of int)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">ilens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">ilens</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spembs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">spembs</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">hs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">hs</span><span class="p">,</span> <span class="n">spembs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">calculate_all_attentions</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">keep_tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">att_ws</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">att_ws</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>extras</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of groundtruth spectrograms (B, Lmax, spc_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extras</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>
<span class="sd">        extras (Tensor, optional): Batch of groundtruth spectrograms (B, Lmax, spc_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># remove unnecessary padded part (for multi-gpus)</span>
    <span class="n">max_in</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span>
    <span class="n">max_out</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_in</span> <span class="o">!=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_in</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_out</span> <span class="o">!=</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_out</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_out</span><span class="p">]</span>

    <span class="c1"># calculate tacotron2 outputs</span>
    <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">spembs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">spembs</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">hs</span><span class="p">,</span> <span class="n">spembs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

    <span class="c1"># modifiy mod part of groundtruth</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">olens</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">-</span> <span class="n">olen</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
        <span class="n">max_out</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_out</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_out</span><span class="p">]</span>
        <span class="n">labels</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># make sure at least one frame has 1</span>

    <span class="c1"># caluculate taco2 loss</span>
    <span class="n">l1_loss</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">bce_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">taco2_loss</span><span class="p">(</span>
        <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">l1_loss</span> <span class="o">+</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="n">bce_loss</span>
    <span class="n">report_keys</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">'l1_loss'</span><span class="p">:</span> <span class="n">l1_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s1">'mse_loss'</span><span class="p">:</span> <span class="n">mse_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s1">'bce_loss'</span><span class="p">:</span> <span class="n">bce_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
    <span class="p">]</span>

    <span class="c1"># caluculate attention loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span><span class="p">:</span>
        <span class="c1"># NOTE(kan-bayashi): length of output for auto-regressive input will be changed when r &gt; 1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">olens_in</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">olens_in</span> <span class="o">=</span> <span class="n">olens</span>
        <span class="n">attn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_loss</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">attn_loss</span>
        <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s1">'attn_loss'</span><span class="p">:</span> <span class="n">attn_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">]</span>

    <span class="c1"># caluculate cbhg loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cbhg</span><span class="p">:</span>
        <span class="c1"># remove unnecessary padded part (for multi-gpus)</span>
        <span class="k">if</span> <span class="n">max_out</span> <span class="o">!=</span> <span class="n">extras</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">extras</span> <span class="o">=</span> <span class="n">extras</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_out</span><span class="p">]</span>

        <span class="c1"># caluculate cbhg outputs &amp; loss and report them</span>
        <span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbhg</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
        <span class="n">cbhg_l1_loss</span><span class="p">,</span> <span class="n">cbhg_mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbhg_loss</span><span class="p">(</span><span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">extras</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">cbhg_l1_loss</span> <span class="o">+</span> <span class="n">cbhg_mse_loss</span>
        <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s1">'cbhg_l1_loss'</span><span class="p">:</span> <span class="n">cbhg_l1_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
            <span class="p">{</span><span class="s1">'cbhg_mse_loss'</span><span class="p">:</span> <span class="n">cbhg_mse_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">]</span>

    <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[{</span><span class="s1">'loss'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">report_keys</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Generate the sequence of features given the sequences of characters.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input sequence of characters (T,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>inference_args</code></td>
<td><code>Namespace</code></td>
<td>
<ul>
<li>threshold (float): Threshold in inference.</li>
<li>minlenratio (float): Minimum length ratio in inference.</li>
<li>maxlenratio (float): Maximum length ratio in inference.</li>
</ul>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spemb</code></td>
<td><code>Tensor</code></td>
<td>
<p>Speaker embedding vector (spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Attention weights (L, T).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Generate the sequence of features given the sequences of characters.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Input sequence of characters (T,).</span>
<span class="sd">        inference_args (Namespace):</span>
<span class="sd">            - threshold (float): Threshold in inference.</span>
<span class="sd">            - minlenratio (float): Minimum length ratio in inference.</span>
<span class="sd">            - maxlenratio (float): Maximum length ratio in inference.</span>
<span class="sd">        spemb (Tensor, optional): Speaker embedding vector (spk_embed_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Output sequence of features (L, odim).</span>
<span class="sd">        Tensor: Output sequence of stop probabilities (L,).</span>
<span class="sd">        Tensor: Attention weights (L, T).</span>

<span class="sd">    """</span>
    <span class="c1"># get options</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">threshold</span>
    <span class="n">minlenratio</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">minlenratio</span>
    <span class="n">maxlenratio</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">maxlenratio</span>
    <span class="n">use_att_constraint</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inference_args</span><span class="p">,</span> <span class="s2">"use_att_constraint"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># keep compatibility</span>
    <span class="n">backward_window</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">backward_window</span> <span class="k">if</span> <span class="n">use_att_constraint</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">forward_window</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">forward_window</span> <span class="k">if</span> <span class="n">use_att_constraint</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="c1"># inference</span>
    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">spemb</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">spemb</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h</span><span class="p">,</span> <span class="n">spemb</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">outs</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">minlenratio</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="p">,</span>
                                             <span class="n">use_att_constraint</span><span class="o">=</span><span class="n">use_att_constraint</span><span class="p">,</span>
                                             <span class="n">backward_window</span><span class="o">=</span><span class="n">backward_window</span><span class="p">,</span>
                                             <span class="n">forward_window</span><span class="o">=</span><span class="n">forward_window</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cbhg</span><span class="p">:</span>
        <span class="n">cbhg_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbhg</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">att_ws</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outs</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss">
<code>Tacotron2Loss</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Loss function module for Tacotron2.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_weighted_masking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bce_pos_weight</span><span class="o">=</span><span class="mf">20.0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize Tactoron2 loss module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>use_masking</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to apply masking for padded part in loss calculation.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_weighted_masking</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to apply weighted masking in loss calculation.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>bce_pos_weight</code></td>
<td><code>float</code></td>
<td>
<p>Weight of positive sample of stop token.</p>
</td>
<td><code>20.0</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_weighted_masking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bce_pos_weight</span><span class="o">=</span><span class="mf">20.0</span><span class="p">):</span>
    <span class="sd">"""Initialize Tactoron2 loss module.</span>

<span class="sd">    Args:</span>
<span class="sd">        use_masking (bool): Whether to apply masking for padded part in loss calculation.</span>
<span class="sd">        use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</span>
<span class="sd">        bce_pos_weight (float): Weight of positive sample of stop token.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Tacotron2Loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">use_masking</span> <span class="o">!=</span> <span class="n">use_weighted_masking</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_masking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span> <span class="o">=</span> <span class="n">use_masking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span> <span class="o">=</span> <span class="n">use_weighted_masking</span>

    <span class="c1"># define criterions</span>
    <span class="n">reduction</span> <span class="o">=</span> <span class="s2">"none"</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span> <span class="k">else</span> <span class="s2">"mean"</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mse_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bce_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">,</span>
                                                    <span class="n">pos_weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">bce_pos_weight</span><span class="p">))</span>

    <span class="c1"># NOTE(kan-bayashi): register pre hook function for the compatibility</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_register_load_state_dict_pre_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_state_dict_pre_hook</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>after_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs after postnets (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>before_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs before postnets (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>logits</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of stop logits (B, Lmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>labels</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the sequences of stop token labels (B, Lmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>L1 loss value.
Tensor: Mean square error loss value.
Tensor: Binary cross entropy loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_tacotron2.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        after_outs (Tensor): Batch of outputs after postnets (B, Lmax, odim).</span>
<span class="sd">        before_outs (Tensor): Batch of outputs before postnets (B, Lmax, odim).</span>
<span class="sd">        logits (Tensor): Batch of stop logits (B, Lmax).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        labels (LongTensor): Batch of the sequences of stop token labels (B, Lmax).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: L1 loss value.</span>
<span class="sd">        Tensor: Mean square error loss value.</span>
<span class="sd">        Tensor: Binary cross entropy loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># make mask and apply it</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span><span class="p">:</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">after_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
        <span class="n">before_outs</span> <span class="o">=</span> <span class="n">before_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="c1"># calculate loss</span>
    <span class="n">l1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_criterion</span><span class="p">(</span><span class="n">before_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="n">mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_criterion</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_criterion</span><span class="p">(</span><span class="n">before_outs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="n">bce_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bce_criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="c1"># make weighted mask and apply it</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_weighted_masking</span><span class="p">:</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">masks</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">out_weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">logit_weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># apply weight</span>
        <span class="n">l1_loss</span> <span class="o">=</span> <span class="n">l1_loss</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">out_weights</span><span class="p">)</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">out_weights</span><span class="p">)</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">bce_loss</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">logit_weights</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">l1_loss</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">bce_loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer">
<code>e2e_tts_transformer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>TTS-Transformer related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss">
<code>GuidedMultiHeadAttentionLoss</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Guided attention loss function module for multi head attention.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    sigma (float, optional): Standard deviation to control how close attention to a diagonal.</span>
<span class="err">    alpha (float, optional): Scaling coefficient (lambda).</span>
<span class="err">    reset_always (bool, optional): Whether to always reset masks.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>att_ws</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of multi head attention weights (B, H, T_max_out, T_max_in).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of input lenghts (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of output lenghts (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Guided attention loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        att_ws (Tensor): Batch of multi head attention weights (B, H, T_max_out, T_max_in).</span>
<span class="sd">        ilens (LongTensor): Batch of input lenghts (B,).</span>
<span class="sd">        olens (LongTensor): Batch of output lenghts (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Guided attention loss value.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_guided_attention_masks</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">att_ws</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_masks</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">att_ws</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">guided_attn_masks</span> <span class="o">*</span> <span class="n">att_ws</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_always</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_masks</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer">
<code>Transformer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Text-to-Speech Transformer module.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="nb">text</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="n">speech</span> <span class="n">Transformer</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="n">Neural</span> <span class="n">Speech</span> <span class="n">Synthesis</span> <span class="k">with</span> <span class="n">Transformer</span> <span class="n">Network</span><span class="o">`</span><span class="n">_</span><span class="p">,</span>
<span class="n">which</span> <span class="k">convert</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">characters</span> <span class="k">or</span> <span class="n">phonemes</span> <span class="k">into</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">Mel</span><span class="o">-</span><span class="n">filterbanks</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">Neural</span> <span class="n">Speech</span> <span class="n">Synthesis</span> <span class="k">with</span> <span class="n">Transformer</span> <span class="n">Network</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1809</span><span class="p">.</span><span class="mi">08895</span><span class="p">.</span><span class="n">pdf</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="attention_plot_class" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.attention_plot_class">
<code class="highlight">
attention_plot_class        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return plot class for attention weight plot.</p>
</div>
</div>
<div class="doc doc-object doc-attribute">
<h7 class="doc doc-heading" data-toc-label="base_plot_keys" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.base_plot_keys">
<code class="highlight">
base_plot_keys        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Return base key names to plot during training. keys should match what <code>chainer.reporter</code> reports.</p>
<p>If you add the key <code>loss</code>, the reporter will report <code>main/loss</code> and <code>validation/main/loss</code> values.
also <code>loss.png</code> will be created as a figure visulizing <code>main/loss</code> and <code>validation/main/loss</code> values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list</code></td>
<td>
<p>List of strings which are base keys to plot during training.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize TTS-Transformer module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>args</code></td>
<td><code>Namespace</code></td>
<td>
<ul>
<li>embed_dim (int): Dimension of character embedding.</li>
<li>eprenet_conv_layers (int): Number of encoder prenet convolution layers.</li>
<li>eprenet_conv_chans (int): Number of encoder prenet convolution channels.</li>
<li>eprenet_conv_filts (int): Filter size of encoder prenet convolution.</li>
<li>dprenet_layers (int): Number of decoder prenet layers.</li>
<li>dprenet_units (int): Number of decoder prenet hidden units.</li>
<li>elayers (int): Number of encoder layers.</li>
<li>eunits (int): Number of encoder hidden units.</li>
<li>adim (int): Number of attention transformation dimensions.</li>
<li>aheads (int): Number of heads for multi head attention.</li>
<li>dlayers (int): Number of decoder layers.</li>
<li>dunits (int): Number of decoder hidden units.</li>
<li>postnet_layers (int): Number of postnet layers.</li>
<li>postnet_chans (int): Number of postnet channels.</li>
<li>postnet_filts (int): Filter size of postnet.</li>
<li>use_scaled_pos_enc (bool): Whether to use trainable scaled positional encoding.</li>
<li>use_batch_norm (bool): Whether to use batch normalization in encoder prenet.</li>
<li>encoder_normalize_before (bool): Whether to perform layer normalization before encoder block.</li>
<li>decoder_normalize_before (bool): Whether to perform layer normalization before decoder block.</li>
<li>encoder_concat_after (bool): Whether to concatenate attention layer's input and output in encoder.</li>
<li>decoder_concat_after (bool): Whether to concatenate attention layer's input and output in decoder.</li>
<li>reduction_factor (int): Reduction factor.</li>
<li>spk_embed_dim (int): Number of speaker embedding dimenstions.</li>
<li>spk_embed_integration_type: How to integrate speaker embedding.</li>
<li>transformer_init (float): How to initialize transformer parameters.</li>
<li>transformer_lr (float): Initial value of learning rate.</li>
<li>transformer_warmup_steps (int): Optimizer warmup steps.</li>
<li>transformer_enc_dropout_rate (float): Dropout rate in encoder except attention &amp; positional encoding.</li>
<li>transformer_enc_positional_dropout_rate (float): Dropout rate after encoder positional encoding.</li>
<li>transformer_enc_attn_dropout_rate (float): Dropout rate in encoder self-attention module.</li>
<li>transformer_dec_dropout_rate (float): Dropout rate in decoder except attention &amp; positional encoding.</li>
<li>transformer_dec_positional_dropout_rate (float): Dropout rate after decoder positional encoding.</li>
<li>transformer_dec_attn_dropout_rate (float): Dropout rate in deocoder self-attention module.</li>
<li>transformer_enc_dec_attn_dropout_rate (float): Dropout rate in encoder-deocoder attention module.</li>
<li>eprenet_dropout_rate (float): Dropout rate in encoder prenet.</li>
<li>dprenet_dropout_rate (float): Dropout rate in decoder prenet.</li>
<li>postnet_dropout_rate (float): Dropout rate in postnet.</li>
<li>use_masking (bool): Whether to apply masking for padded part in loss calculation.</li>
<li>use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</li>
<li>bce_pos_weight (float): Positive sample weight in bce calculation (only for use_masking=true).</li>
<li>loss_type (str): How to calculate loss.</li>
<li>use_guided_attn_loss (bool): Whether to use guided attention loss.</li>
<li>num_heads_applied_guided_attn (int): Number of heads in each layer to apply guided attention loss.</li>
<li>num_layers_applied_guided_attn (int): Number of layers to apply guided attention loss.</li>
<li>modules_applied_guided_attn (list): List of module names to apply guided attention loss.</li>
<li>guided-attn-loss-sigma (float) Sigma in guided attention loss.</li>
<li>guided-attn-loss-lambda (float): Lambda in guided attention loss.</li>
</ul>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Initialize TTS-Transformer module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        args (Namespace, optional):</span>
<span class="sd">            - embed_dim (int): Dimension of character embedding.</span>
<span class="sd">            - eprenet_conv_layers (int): Number of encoder prenet convolution layers.</span>
<span class="sd">            - eprenet_conv_chans (int): Number of encoder prenet convolution channels.</span>
<span class="sd">            - eprenet_conv_filts (int): Filter size of encoder prenet convolution.</span>
<span class="sd">            - dprenet_layers (int): Number of decoder prenet layers.</span>
<span class="sd">            - dprenet_units (int): Number of decoder prenet hidden units.</span>
<span class="sd">            - elayers (int): Number of encoder layers.</span>
<span class="sd">            - eunits (int): Number of encoder hidden units.</span>
<span class="sd">            - adim (int): Number of attention transformation dimensions.</span>
<span class="sd">            - aheads (int): Number of heads for multi head attention.</span>
<span class="sd">            - dlayers (int): Number of decoder layers.</span>
<span class="sd">            - dunits (int): Number of decoder hidden units.</span>
<span class="sd">            - postnet_layers (int): Number of postnet layers.</span>
<span class="sd">            - postnet_chans (int): Number of postnet channels.</span>
<span class="sd">            - postnet_filts (int): Filter size of postnet.</span>
<span class="sd">            - use_scaled_pos_enc (bool): Whether to use trainable scaled positional encoding.</span>
<span class="sd">            - use_batch_norm (bool): Whether to use batch normalization in encoder prenet.</span>
<span class="sd">            - encoder_normalize_before (bool): Whether to perform layer normalization before encoder block.</span>
<span class="sd">            - decoder_normalize_before (bool): Whether to perform layer normalization before decoder block.</span>
<span class="sd">            - encoder_concat_after (bool): Whether to concatenate attention layer's input and output in encoder.</span>
<span class="sd">            - decoder_concat_after (bool): Whether to concatenate attention layer's input and output in decoder.</span>
<span class="sd">            - reduction_factor (int): Reduction factor.</span>
<span class="sd">            - spk_embed_dim (int): Number of speaker embedding dimenstions.</span>
<span class="sd">            - spk_embed_integration_type: How to integrate speaker embedding.</span>
<span class="sd">            - transformer_init (float): How to initialize transformer parameters.</span>
<span class="sd">            - transformer_lr (float): Initial value of learning rate.</span>
<span class="sd">            - transformer_warmup_steps (int): Optimizer warmup steps.</span>
<span class="sd">            - transformer_enc_dropout_rate (float): Dropout rate in encoder except attention &amp; positional encoding.</span>
<span class="sd">            - transformer_enc_positional_dropout_rate (float): Dropout rate after encoder positional encoding.</span>
<span class="sd">            - transformer_enc_attn_dropout_rate (float): Dropout rate in encoder self-attention module.</span>
<span class="sd">            - transformer_dec_dropout_rate (float): Dropout rate in decoder except attention &amp; positional encoding.</span>
<span class="sd">            - transformer_dec_positional_dropout_rate (float): Dropout rate after decoder positional encoding.</span>
<span class="sd">            - transformer_dec_attn_dropout_rate (float): Dropout rate in deocoder self-attention module.</span>
<span class="sd">            - transformer_enc_dec_attn_dropout_rate (float): Dropout rate in encoder-deocoder attention module.</span>
<span class="sd">            - eprenet_dropout_rate (float): Dropout rate in encoder prenet.</span>
<span class="sd">            - dprenet_dropout_rate (float): Dropout rate in decoder prenet.</span>
<span class="sd">            - postnet_dropout_rate (float): Dropout rate in postnet.</span>
<span class="sd">            - use_masking (bool): Whether to apply masking for padded part in loss calculation.</span>
<span class="sd">            - use_weighted_masking (bool): Whether to apply weighted masking in loss calculation.</span>
<span class="sd">            - bce_pos_weight (float): Positive sample weight in bce calculation (only for use_masking=true).</span>
<span class="sd">            - loss_type (str): How to calculate loss.</span>
<span class="sd">            - use_guided_attn_loss (bool): Whether to use guided attention loss.</span>
<span class="sd">            - num_heads_applied_guided_attn (int): Number of heads in each layer to apply guided attention loss.</span>
<span class="sd">            - num_layers_applied_guided_attn (int): Number of layers to apply guided attention loss.</span>
<span class="sd">            - modules_applied_guided_attn (list): List of module names to apply guided attention loss.</span>
<span class="sd">            - guided-attn-loss-sigma (float) Sigma in guided attention loss.</span>
<span class="sd">            - guided-attn-loss-lambda (float): Lambda in guided attention loss.</span>

<span class="sd">    """</span>
    <span class="c1"># initialize base classes</span>
    <span class="n">TTSInterface</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="c1"># fill missing arguments</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">)</span>

    <span class="c1"># store hyperparameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_dim</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_integration_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">spk_embed_integration_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">loss_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_guided_attn_loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">elayers</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">aheads</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modules_applied_guided_attn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">modules_applied_guided_attn</span>

    <span class="c1"># use idx 0 as padding idx</span>
    <span class="n">padding_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># get positional encoding class</span>
    <span class="n">pos_enc_class</span> <span class="o">=</span> <span class="n">ScaledPositionalEncoding</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span> <span class="k">else</span> <span class="n">PositionalEncoding</span>

    <span class="c1"># define transformer encoder</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">eprenet_conv_layers</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># encoder prenet</span>
        <span class="n">encoder_input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">EncoderPrenet</span><span class="p">(</span>
                <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
                <span class="n">embed_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span>
                <span class="n">elayers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">econv_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eprenet_conv_layers</span><span class="p">,</span>
                <span class="n">econv_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eprenet_conv_chans</span><span class="p">,</span>
                <span class="n">econv_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eprenet_conv_filts</span><span class="p">,</span>
                <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">,</span>
                <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eprenet_dropout_rate</span><span class="p">,</span>
                <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span>
            <span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">eprenet_conv_chans</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">encoder_input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">num_embeddings</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
            <span class="n">embedding_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">,</span>
        <span class="n">input_layer</span><span class="o">=</span><span class="n">encoder_input_layer</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_positional_dropout_rate</span><span class="p">,</span>
        <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">pos_enc_class</span><span class="p">,</span>
        <span class="n">normalize_before</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">encoder_normalize_before</span><span class="p">,</span>
        <span class="n">concat_after</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">encoder_concat_after</span><span class="p">,</span>
        <span class="n">positionwise_layer_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_layer_type</span><span class="p">,</span>
        <span class="n">positionwise_conv_kernel_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">positionwise_conv_kernel_size</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># define projection layer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_integration_type</span> <span class="o">==</span> <span class="s2">"add"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>

    <span class="c1"># define transformer decoder</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dprenet_layers</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># decoder prenet</span>
        <span class="n">decoder_input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">DecoderPrenet</span><span class="p">(</span>
                <span class="n">idim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
                <span class="n">n_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dprenet_layers</span><span class="p">,</span>
                <span class="n">n_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dprenet_units</span><span class="p">,</span>
                <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dprenet_dropout_rate</span>
            <span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dprenet_units</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">decoder_input_layer</span> <span class="o">=</span> <span class="s2">"linear"</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span>
        <span class="n">odim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span>
        <span class="n">attention_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">aheads</span><span class="p">,</span>
        <span class="n">linear_units</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dlayers</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_dropout_rate</span><span class="p">,</span>
        <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_positional_dropout_rate</span><span class="p">,</span>
        <span class="n">self_attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_dec_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">src_attention_dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_enc_dec_attn_dropout_rate</span><span class="p">,</span>
        <span class="n">input_layer</span><span class="o">=</span><span class="n">decoder_input_layer</span><span class="p">,</span>
        <span class="n">use_output_layer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">pos_enc_class</span><span class="p">,</span>
        <span class="n">normalize_before</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">decoder_normalize_before</span><span class="p">,</span>
        <span class="n">concat_after</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">decoder_concat_after</span>
    <span class="p">)</span>

    <span class="c1"># define final projection</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span> <span class="n">odim</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>

    <span class="c1"># define postnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">postnet_layers</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">Postnet</span><span class="p">(</span>
        <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
        <span class="n">odim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_layers</span><span class="p">,</span>
        <span class="n">n_chans</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_chans</span><span class="p">,</span>
        <span class="n">n_filts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_filts</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">postnet_dropout_rate</span>
    <span class="p">)</span>

    <span class="c1"># define loss function</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">TransformerLoss</span><span class="p">(</span><span class="n">use_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_masking</span><span class="p">,</span>
                                     <span class="n">use_weighted_masking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_weighted_masking</span><span class="p">,</span>
                                     <span class="n">bce_pos_weight</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">bce_pos_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_criterion</span> <span class="o">=</span> <span class="n">GuidedMultiHeadAttentionLoss</span><span class="p">(</span>
            <span class="n">sigma</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">guided_attn_loss_sigma</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">guided_attn_loss_lambda</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># initialize parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">(</span><span class="n">init_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_init</span><span class="p">,</span>
                           <span class="n">init_enc_alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">initial_encoder_alpha</span><span class="p">,</span>
                           <span class="n">init_dec_alpha</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">initial_decoder_alpha</span><span class="p">)</span>

    <span class="c1"># load pretrained model</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_pretrained_model</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="add_arguments()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Add model-specific arguments to the parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add model-specific arguments to the parser."""</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">"transformer model setting"</span><span class="p">)</span>
    <span class="c1"># network structure related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--embed-dim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dimension of character embedding in encoder prenet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eprenet-conv-layers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder prenet convolution layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eprenet-conv-chans"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder prenet convolution channels"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eprenet-conv-filts"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Filter size of encoder prenet convolution"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dprenet-layers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder prenet layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dprenet-units"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder prenet hidden units"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--elayers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eunits"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1536</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of encoder hidden units"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--adim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of attention transformation dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--aheads"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of heads for multi head attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dlayers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dunits"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1536</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of decoder hidden units"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--positionwise-layer-type"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"conv1d"</span><span class="p">,</span> <span class="s2">"conv1d-linear"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Positionwise layer type."</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--positionwise-conv-kernel-size"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Kernel size of positionwise conv1d layer"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-layers"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of postnet layers"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-chans"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of postnet channels"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-filts"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Filter size of postnet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-scaled-pos-enc"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Use trainable scaled positional encoding instead of the fixed scale one."</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-batch-norm"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use batch normalization"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--encoder-normalize-before"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to apply layer norm before encoder block"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--decoder-normalize-before"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to apply layer norm before decoder block"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--encoder-concat-after"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to concatenate attention layer's input and output in encoder"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--decoder-concat-after"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to concatenate attention layer's input and output in decoder"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--reduction-factor"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Reduction factor"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spk-embed-dim"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of speaker embedding dimensions"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--spk-embed-integration-type"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"add"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"add"</span><span class="p">,</span> <span class="s2">"concat"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"How to integrate speaker embedding"</span><span class="p">)</span>
    <span class="c1"># training related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-init"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"pytorch"</span><span class="p">,</span>
                       <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"pytorch"</span><span class="p">,</span> <span class="s2">"xavier_uniform"</span><span class="p">,</span> <span class="s2">"xavier_normal"</span><span class="p">,</span>
                                <span class="s2">"kaiming_uniform"</span><span class="p">,</span> <span class="s2">"kaiming_normal"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"How to initialize transformer parameters"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--initial-encoder-alpha"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial alpha value in encoder's ScaledPositionalEncoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--initial-decoder-alpha"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial alpha value in decoder's ScaledPositionalEncoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-lr"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Initial value of learning rate"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-warmup-steps"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Optimizer warmup steps"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder except for attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-positional-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder positional encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder self-attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder except for attention and pos encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-positional-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder positional encoding"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-dec-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer decoder self-attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--transformer-enc-dec-attn-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate for transformer encoder-decoder attention"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--eprenet-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate in encoder prenet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dprenet-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate in decoder prenet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--postnet-dropout-rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Dropout rate in postnet"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--pretrained-model"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Pretrained model path"</span><span class="p">)</span>
    <span class="c1"># loss related</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-masking"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use masking in calculation of loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-weighted-masking"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use weighted masking in calculation of loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--loss-type"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">"L1"</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">"L1"</span><span class="p">,</span> <span class="s2">"L2"</span><span class="p">,</span> <span class="s2">"L1+L2"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"How to calc loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--bce-pos-weight"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Positive sample weight in BCE calculation (only for use-masking=True)"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--use-guided-attn-loss"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">strtobool</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Whether to use guided attention loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--guided-attn-loss-sigma"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Sigma in guided attention loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--guided-attn-loss-lambda"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Lambda in guided attention loss"</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--num-heads-applied-guided-attn"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of heads in each layer to be applied guided attention loss"</span>
                            <span class="s2">"if set -1, all of the heads will be applied."</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--num-layers-applied-guided-attn"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Number of layers to be applied guided attention loss"</span>
                            <span class="s2">"if set -1, all of the layers will be applied."</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--modules-applied-guided-attn"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s2">"+"</span><span class="p">,</span>
                       <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">"encoder-decoder"</span><span class="p">],</span>
                       <span class="n">help</span><span class="o">=</span><span class="s2">"Module name list to be applied guided attention loss"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">skip_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_tensor</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate all of the attention weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>skip_output</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to skip calculate the final output.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>keep_tensor</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to keep original tensor.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dict</code></td>
<td>
<p>Dict of attention weights and outputs.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span>
                             <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">skip_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_tensor</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate all of the attention weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>
<span class="sd">        skip_output (bool, optional): Whether to skip calculate the final output.</span>
<span class="sd">        keep_tensor (bool, optional): Whether to keep original tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Dict of attention weights and outputs.</span>

<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># forward encoder</span>
        <span class="n">x_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span>
        <span class="n">hs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="p">)</span>

        <span class="c1"># integrate speaker embedding</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_integrate_with_spk_embed</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">spembs</span><span class="p">)</span>

        <span class="c1"># thin out frames for reduction factor (B, Lmax, odim) -&gt;  (B, Lmax//r, odim)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ys_in</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">]</span>
            <span class="n">olens_in</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ys_in</span><span class="p">,</span> <span class="n">olens_in</span> <span class="o">=</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span>

        <span class="c1"># add first zero frame and remove last frame for auto-regressive</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_first_frame_and_remove_last_frame</span><span class="p">(</span><span class="n">ys_in</span><span class="p">)</span>

        <span class="c1"># forward decoder</span>
        <span class="n">y_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_mask</span><span class="p">(</span><span class="n">olens_in</span><span class="p">)</span>
        <span class="n">xy_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source_to_target_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">)</span>
        <span class="n">zs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">ys_in</span><span class="p">,</span> <span class="n">y_masks</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">xy_masks</span><span class="p">)</span>

        <span class="c1"># calculate final outputs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_output</span><span class="p">:</span>
            <span class="n">before_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">(</span><span class="n">before_outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># modifiy mod part of output lengths due to reduction factor &gt; 1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">olens</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">-</span> <span class="n">olen</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>

    <span class="c1"># store into dict</span>
    <span class="n">att_ws_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">keep_tensor</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultiHeadedAttention</span><span class="p">):</span>
                <span class="n">att_ws_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">attn</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_output</span><span class="p">:</span>
            <span class="n">att_ws_dict</span><span class="p">[</span><span class="s2">"before_postnet_fbank"</span><span class="p">]</span> <span class="o">=</span> <span class="n">before_outs</span>
            <span class="n">att_ws_dict</span><span class="p">[</span><span class="s2">"after_postnet_fbank"</span><span class="p">]</span> <span class="o">=</span> <span class="n">after_outs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultiHeadedAttention</span><span class="p">):</span>
                <span class="n">attn</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">if</span> <span class="s2">"encoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">ilens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
                <span class="k">elif</span> <span class="s2">"decoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">"src"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                        <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ol</span><span class="p">,</span> <span class="p">:</span><span class="n">il</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">il</span><span class="p">,</span> <span class="n">ol</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">ilens</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">olens_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
                    <span class="k">elif</span> <span class="s2">"self"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                        <span class="n">attn</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">olens_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"unknown attention module: "</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"unknown attention module: "</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
                <span class="n">att_ws_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_output</span><span class="p">:</span>
            <span class="n">before_outs</span> <span class="o">=</span> <span class="n">before_outs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">after_outs</span> <span class="o">=</span> <span class="n">after_outs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">att_ws_dict</span><span class="p">[</span><span class="s2">"before_postnet_fbank"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">[:</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">before_outs</span><span class="p">,</span> <span class="n">olens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>
            <span class="n">att_ws_dict</span><span class="p">[</span><span class="s2">"after_postnet_fbank"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">[:</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">after_outs</span><span class="p">,</span> <span class="n">olens</span><span class="o">.</span><span class="n">tolist</span><span class="p">())]</span>

    <span class="k">return</span> <span class="n">att_ws_dict</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each target (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of padded character ids (B, Tmax).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of padded target features (B, Lmax, odim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each target (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># remove unnecessary padded part (for multi-gpus)</span>
    <span class="n">max_ilen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span>
    <span class="n">max_olen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_ilen</span> <span class="o">!=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_ilen</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_olen</span> <span class="o">!=</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_olen</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_olen</span><span class="p">]</span>

    <span class="c1"># forward encoder</span>
    <span class="n">x_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span>
    <span class="n">hs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="p">)</span>

    <span class="c1"># integrate speaker embedding</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_integrate_with_spk_embed</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">spembs</span><span class="p">)</span>

    <span class="c1"># thin out frames for reduction factor (B, Lmax, odim) -&gt;  (B, Lmax//r, odim)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">]</span>
        <span class="n">olens_in</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ys_in</span><span class="p">,</span> <span class="n">olens_in</span> <span class="o">=</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span>

    <span class="c1"># add first zero frame and remove last frame for auto-regressive</span>
    <span class="n">ys_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_first_frame_and_remove_last_frame</span><span class="p">(</span><span class="n">ys_in</span><span class="p">)</span>

    <span class="c1"># forward decoder</span>
    <span class="n">y_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_mask</span><span class="p">(</span><span class="n">olens_in</span><span class="p">)</span>
    <span class="n">xy_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source_to_target_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">)</span>
    <span class="n">zs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">ys_in</span><span class="p">,</span> <span class="n">y_masks</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">xy_masks</span><span class="p">)</span>
    <span class="c1"># (B, Lmax//r, odim * r) -&gt; (B, Lmax//r * r, odim)</span>
    <span class="n">before_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
    <span class="c1"># (B, Lmax//r, r) -&gt; (B, Lmax//r * r)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># postnet -&gt; (B, Lmax//r * r, odim)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">(</span><span class="n">before_outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># modifiy mod part of groundtruth</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">olens</span> <span class="o">=</span> <span class="n">olens</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">olen</span> <span class="o">-</span> <span class="n">olen</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="k">for</span> <span class="n">olen</span> <span class="ow">in</span> <span class="n">olens</span><span class="p">])</span>
        <span class="n">max_olen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_olen</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_olen</span><span class="p">]</span>
        <span class="n">labels</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># make sure at least one frame has 1</span>

    <span class="c1"># caluculate loss values</span>
    <span class="n">l1_loss</span><span class="p">,</span> <span class="n">l2_loss</span><span class="p">,</span> <span class="n">bce_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span>
        <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span> <span class="o">==</span> <span class="s2">"L1"</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">l1_loss</span> <span class="o">+</span> <span class="n">bce_loss</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span> <span class="o">==</span> <span class="s2">"L2"</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">l2_loss</span> <span class="o">+</span> <span class="n">bce_loss</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span> <span class="o">==</span> <span class="s2">"L1+L2"</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">l1_loss</span> <span class="o">+</span> <span class="n">l2_loss</span> <span class="o">+</span> <span class="n">bce_loss</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"unknown --loss-type "</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span><span class="p">)</span>
    <span class="n">report_keys</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">"l1_loss"</span><span class="p">:</span> <span class="n">l1_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s2">"l2_loss"</span><span class="p">:</span> <span class="n">l2_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s2">"bce_loss"</span><span class="p">:</span> <span class="n">bce_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">{</span><span class="s2">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
    <span class="p">]</span>

    <span class="c1"># calculate guided attention loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_guided_attn_loss</span><span class="p">:</span>
        <span class="c1"># calculate for encoder</span>
        <span class="k">if</span> <span class="s2">"encoder"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_applied_guided_attn</span><span class="p">:</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">encoders</span><span class="p">)))):</span>
                <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">attn</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span><span class="p">]]</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, H*L, T_in, T_in)</span>
            <span class="n">enc_attn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_criterion</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">enc_attn_loss</span>
            <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[{</span><span class="s2">"enc_attn_loss"</span><span class="p">:</span> <span class="n">enc_attn_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}]</span>
        <span class="c1"># calculate for decoder</span>
        <span class="k">if</span> <span class="s2">"decoder"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_applied_guided_attn</span><span class="p">:</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoders</span><span class="p">)))):</span>
                <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoders</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">attn</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span><span class="p">]]</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, H*L, T_out, T_out)</span>
            <span class="n">dec_attn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_criterion</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">dec_attn_loss</span>
            <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[{</span><span class="s2">"dec_attn_loss"</span><span class="p">:</span> <span class="n">dec_attn_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}]</span>
        <span class="c1"># calculate for encoder-decoder</span>
        <span class="k">if</span> <span class="s2">"encoder-decoder"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_applied_guided_attn</span><span class="p">:</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoders</span><span class="p">)))):</span>
                <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoders</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">src_attn</span><span class="o">.</span><span class="n">attn</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads_applied_guided_attn</span><span class="p">]]</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers_applied_guided_attn</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, H*L, T_out, T_in)</span>
            <span class="n">enc_dec_attn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_criterion</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens_in</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">enc_dec_attn_loss</span>
            <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[{</span><span class="s2">"enc_dec_attn_loss"</span><span class="p">:</span> <span class="n">enc_dec_attn_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}]</span>

    <span class="c1"># report extra information</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_scaled_pos_enc</span><span class="p">:</span>
        <span class="n">report_keys</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">"encoder_alpha"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">embed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
            <span class="p">{</span><span class="s2">"decoder_alpha"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()},</span>
        <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">report_keys</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.Transformer.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Generate the sequence of features given the sequences of characters.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input sequence of characters (T,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>inference_args</code></td>
<td><code>Namespace</code></td>
<td>
<ul>
<li>threshold (float): Threshold in inference.</li>
<li>minlenratio (float): Minimum length ratio in inference.</li>
<li>maxlenratio (float): Maximum length ratio in inference.</li>
</ul>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spemb</code></td>
<td><code>Tensor</code></td>
<td>
<p>Speaker embedding vector (spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Encoder-decoder (source) attention weights (#layers, #heads, L, T).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">,</span> <span class="n">spemb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Generate the sequence of features given the sequences of characters.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Input sequence of characters (T,).</span>
<span class="sd">        inference_args (Namespace):</span>
<span class="sd">            - threshold (float): Threshold in inference.</span>
<span class="sd">            - minlenratio (float): Minimum length ratio in inference.</span>
<span class="sd">            - maxlenratio (float): Maximum length ratio in inference.</span>
<span class="sd">        spemb (Tensor, optional): Speaker embedding vector (spk_embed_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Output sequence of features (L, odim).</span>
<span class="sd">        Tensor: Output sequence of stop probabilities (L,).</span>
<span class="sd">        Tensor: Encoder-decoder (source) attention weights (#layers, #heads, L, T).</span>

<span class="sd">    """</span>
    <span class="c1"># get options</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">threshold</span>
    <span class="n">minlenratio</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">minlenratio</span>
    <span class="n">maxlenratio</span> <span class="o">=</span> <span class="n">inference_args</span><span class="o">.</span><span class="n">maxlenratio</span>
    <span class="n">use_att_constraint</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inference_args</span><span class="p">,</span> <span class="s2">"use_att_constraint"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># keep compatibility</span>
    <span class="k">if</span> <span class="n">use_att_constraint</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Attention constraint is not yet supported in Transformer. Not enabled."</span><span class="p">)</span>

    <span class="c1"># forward encoder</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">hs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># integrate speaker embedding</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spk_embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">spembs</span> <span class="o">=</span> <span class="n">spemb</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_integrate_with_spk_embed</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">spembs</span><span class="p">)</span>

    <span class="c1"># set limits of length</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">maxlenratio</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">minlenratio</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">)</span>

    <span class="c1"># initialize</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
    <span class="n">outs</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="c1"># forward decoder step-by-step</span>
    <span class="n">z_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># update index</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># calculate output and stop prob at idx-th step</span>
        <span class="n">y_masks</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">z_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward_one_step</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">y_masks</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">z_cache</span><span class="p">)</span>  <span class="c1"># (B, adim)</span>
        <span class="n">outs</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)]</span>  <span class="c1"># [(r, odim), ...]</span>
        <span class="n">probs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span><span class="p">(</span><span class="n">z</span><span class="p">))[</span><span class="mi">0</span><span class="p">]]</span>  <span class="c1"># [(r), ...]</span>

        <span class="c1"># update next inputs</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ys</span><span class="p">,</span> <span class="n">outs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (1, idx + 1, odim)</span>

        <span class="c1"># get attention weights</span>
        <span class="n">att_ws_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultiHeadedAttention</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">"src"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">att_ws_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">attn</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>  <span class="c1"># [(#heads, 1, T),...]</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="n">att_ws_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># [(#heads, l, T), ...]</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">att_w</span><span class="p">,</span> <span class="n">att_w_</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">att_w</span><span class="p">,</span> <span class="n">att_w_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">att_ws_</span><span class="p">)]</span>

        <span class="c1"># check whether to finish generation</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">maxlen</span><span class="p">:</span>
            <span class="c1"># check mininum length</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">minlen</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (L, odim) -&gt; (1, L, odim) -&gt; (1, odim, L)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">outs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>  <span class="c1"># (1, odim, L)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (L, odim)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># concatenate attention weights -&gt; (#layers, #heads, L, T)</span>
    <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">outs</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.TTSPlot">
<code>TTSPlot</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.TTSPlot" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Attention plot module for TTS-Transformer.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="plotfn()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.e2e_tts_transformer.TTSPlot.plotfn">
<code class="highlight language-python">
plotfn<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="n">outdir</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">'png'</span><span class="p">,</span> <span class="n">savefn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Plot multi head attentions.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data</code></td>
<td><code>dict</code></td>
<td>
<p>Utts info from json file.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>attn_dict</code></td>
<td><code>dict</code></td>
<td>
<p>Multi head attention dict.
Values should be numpy.ndarray (H, L, T)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>outdir</code></td>
<td><code>str</code></td>
<td>
<p>Directory name to save figures.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>suffix</code></td>
<td><code>str</code></td>
<td>
<p>Filename suffix including image type (e.g., png).</p>
</td>
<td><code>'png'</code></td>
</tr>
<tr>
<td><code>savefn</code></td>
<td><code>function</code></td>
<td>
<p>Function to save figures.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/e2e_tts_transformer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">plotfn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="n">outdir</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s2">"png"</span><span class="p">,</span> <span class="n">savefn</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Plot multi head attentions.</span>

<span class="sd">    Args:</span>
<span class="sd">        data (dict): Utts info from json file.</span>
<span class="sd">        attn_dict (dict): Multi head attention dict.</span>
<span class="sd">            Values should be numpy.ndarray (H, L, T)</span>
<span class="sd">        outdir (str): Directory name to save figures.</span>
<span class="sd">        suffix (str): Filename suffix including image type (e.g., png).</span>
<span class="sd">        savefn (function): Function to save figures.</span>

<span class="sd">    """</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">att_ws</span> <span class="ow">in</span> <span class="n">attn_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">att_w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">att_ws</span><span class="p">):</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="s2">"</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">outdir</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="p">,</span> <span class="n">suffix</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">"fbank"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"frames"</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"fbank coeff"</span><span class="p">)</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">_plot_and_save_attention</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
            <span class="n">savefn</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech">
<code>fastspeech</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator">
<code>duration_calculator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Duration calculator related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="DurationCalculator" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator">
<code>DurationCalculator</code>
</h7>
<div class="doc doc-contents">
<p>Duration calculator module for FastSpeech.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! todo</span>
<span class="err">    * Fix the duplicated calculation of diagonal head decision</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">teacher_model</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize duration calculator module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>teacher_model</code></td>
<td><code>e2e_tts_transformer.Transformer</code></td>
<td>
<p>Pretrained auto-regressive Transformer.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_calculator.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">teacher_model</span><span class="p">):</span>
    <span class="sd">"""Initialize duration calculator module.</span>

<span class="sd">    Args:</span>
<span class="sd">        teacher_model (e2e_tts_transformer.Transformer): Pretrained auto-regressive Transformer.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DurationCalculator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">teacher_model</span><span class="p">,</span> <span class="n">Transformer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"diag_head_idx"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">teacher_model</span><span class="p">,</span> <span class="n">Tacotron2</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"teacher model should be the instance of e2e_tts_transformer.Transformer "</span>
                         <span class="s2">"or e2e_tts_tacotron2.Tacotron2."</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">teacher_model</span> <span class="o">=</span> <span class="n">teacher_model</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the padded sequences of character ids (B, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of lengths of each input sequence (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the padded sequence of target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of lengths of each output sequence (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spembs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of speaker embedding vectors (B, spk_embed_dim).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of durations (B, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_calculator.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of the padded sequences of character ids (B, Tmax).</span>
<span class="sd">        ilens (Tensor): Batch of lengths of each input sequence (B,).</span>
<span class="sd">        ys (Tensor): Batch of the padded sequence of target features (B, Lmax, odim).</span>
<span class="sd">        olens (Tensor): Batch of lengths of each output sequence (B,).</span>
<span class="sd">        spembs (Tensor, optional): Batch of speaker embedding vectors (B, spk_embed_dim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of durations (B, Tmax).</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher_model</span><span class="p">,</span> <span class="n">Transformer</span><span class="p">):</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_encoder_decoder_attentions</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">olens</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="n">spembs</span><span class="p">)</span>
        <span class="c1"># TODO(kan-bayashi): fix this issue</span>
        <span class="c1"># this does not work in multi-gpu case. registered buffer is not saved.</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">diag_head_idx</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_diagonal_head</span><span class="p">(</span><span class="n">att_ws</span><span class="p">)</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">att_ws</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diag_head_idx</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># NOTE(kan-bayashi): Here we assume that the teacher is tacotron 2</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher_model</span><span class="o">.</span><span class="n">calculate_all_attentions</span><span class="p">(</span>
            <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">spembs</span><span class="o">=</span><span class="n">spembs</span><span class="p">,</span> <span class="n">keep_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_calculate_duration</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="n">ilen</span><span class="p">,</span> <span class="n">olen</span><span class="p">)</span> <span class="k">for</span> <span class="n">att_w</span><span class="p">,</span> <span class="n">ilen</span><span class="p">,</span> <span class="n">olen</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">olens</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">durations</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor">
<code>duration_predictor</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Duration predictor related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="DurationPredictor" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor">
<code>DurationPredictor</code>
</h7>
<div class="doc doc-contents">
<p>Duration predictor module.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="n">of</span> <span class="n">duration</span> <span class="n">predictor</span> <span class="n">described</span> <span class="k">in</span> <span class="ss">`FastSpeech: Fast, Robust and Controllable Text to Speech`</span><span class="n">_</span><span class="p">.</span>
<span class="n">The</span> <span class="n">duration</span> <span class="n">predictor</span> <span class="n">predicts</span> <span class="n">a</span> <span class="n">duration</span> <span class="n">of</span> <span class="k">each</span> <span class="n">frame</span> <span class="k">in</span> <span class="n">log</span> <span class="n">domain</span> <span class="k">from</span> <span class="n">the</span> <span class="n">hidden</span> <span class="n">embeddings</span> <span class="n">of</span> <span class="n">encoder</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="ss">`FastSpeech: Fast, Robust and Controllable Text to Speech`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1905</span><span class="p">.</span><span class="mi">09263</span><span class="p">.</span><span class="n">pdf</span>

<span class="o">!!!</span> <span class="n">note</span>
    <span class="n">The</span> <span class="n">calculation</span> <span class="n">domain</span> <span class="n">of</span> <span class="n">outputs</span> <span class="k">is</span> <span class="n">different</span> <span class="k">between</span> <span class="k">in</span> <span class="ss">`forward`</span> <span class="k">and</span> <span class="k">in</span> <span class="ss">`inference`</span><span class="p">.</span> <span class="k">In</span> <span class="ss">`forward`</span><span class="p">,</span>
    <span class="n">the</span> <span class="n">outputs</span> <span class="n">are</span> <span class="n">calculated</span> <span class="k">in</span> <span class="n">log</span> <span class="n">domain</span> <span class="n">but</span> <span class="k">in</span> <span class="ss">`inference`</span><span class="p">,</span> <span class="n">those</span> <span class="n">are</span> <span class="n">calculated</span> <span class="k">in</span> <span class="n">linear</span> <span class="n">domain</span><span class="p">.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_chans</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initilize duration predictor module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Input dimension.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>n_layers</code></td>
<td><code>int</code></td>
<td>
<p>Number of convolutional layers.</p>
</td>
<td><code>2</code></td>
</tr>
<tr>
<td><code>n_chans</code></td>
<td><code>int</code></td>
<td>
<p>Number of channels of convolutional layers.</p>
</td>
<td><code>384</code></td>
</tr>
<tr>
<td><code>kernel_size</code></td>
<td><code>int</code></td>
<td>
<p>Kernel size of convolutional layers.</p>
</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>dropout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Dropout rate.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>offset</code></td>
<td><code>float</code></td>
<td>
<p>Offset value to avoid nan in log domain.</p>
</td>
<td><code>1.0</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_predictor.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_chans</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">"""Initilize duration predictor module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Input dimension.</span>
<span class="sd">        n_layers (int, optional): Number of convolutional layers.</span>
<span class="sd">        n_chans (int, optional): Number of channels of convolutional layers.</span>
<span class="sd">        kernel_size (int, optional): Kernel size of convolutional layers.</span>
<span class="sd">        dropout_rate (float, optional): Dropout rate.</span>
<span class="sd">        offset (float, optional): Offset value to avoid nan in log domain.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DurationPredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">in_chans</span> <span class="o">=</span> <span class="n">idim</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_chans</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">n_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_chans</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_chans</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input sequences (B, Tmax, idim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x_masks</code></td>
<td><code>ByteTensor</code></td>
<td>
<p>Batch of masks indicating padded part (B, Tmax).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of predicted durations in log domain (B, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_predictor.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>71
72
73
74
75
76
77
78
79
80
81
82</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of input sequences (B, Tmax, idim).</span>
<span class="sd">        x_masks (ByteTensor, optional): Batch of masks indicating padded part (B, Tmax).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of predicted durations in log domain (B, Tmax).</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Inference duration.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input sequences (B, Tmax, idim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x_masks</code></td>
<td><code>ByteTensor</code></td>
<td>
<p>Batch of masks indicating padded part (B, Tmax).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>LongTensor</code></td>
<td>
<p>Batch of predicted durations in linear domain (B, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_predictor.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>84
85
86
87
88
89
90
91
92
93
94
95</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Inference duration.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of input sequences (B, Tmax, idim).</span>
<span class="sd">        x_masks (ByteTensor, optional): Batch of masks indicating padded part (B, Tmax).</span>

<span class="sd">    Returns:</span>
<span class="sd">        LongTensor: Batch of predicted durations in linear domain (B, Tmax).</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x_masks</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="DurationPredictorLoss" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss">
<code>DurationPredictorLoss</code>
</h7>
<div class="doc doc-contents">
<p>Loss function module for duration predictor.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">The loss value is Calculated in log domain to make it Gaussian.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initilize duration predictor loss module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>offset</code></td>
<td><code>float</code></td>
<td>
<p>Offset value to avoid nan in log domain.</p>
</td>
<td><code>1.0</code></td>
</tr>
<tr>
<td><code>reduction</code></td>
<td><code>str</code></td>
<td>
<p>Reduction type in loss calculation.</p>
</td>
<td><code>'mean'</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_predictor.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>105
106
107
108
109
110
111
112
113
114
115</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">"mean"</span><span class="p">):</span>
    <span class="sd">"""Initilize duration predictor loss module.</span>

<span class="sd">    Args:</span>
<span class="sd">        offset (float, optional): Offset value to avoid nan in log domain.</span>
<span class="sd">        reduction (str): Reduction type in loss calculation.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DurationPredictorLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>outputs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of prediction durations in log domain (B, T)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>targets</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of groundtruth durations in linear domain (B, T)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Mean squared error loss value.</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code>outputs</code> is in log domain but <code>targets</code> is in linear domain.</p>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/duration_predictor.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        outputs (Tensor): Batch of prediction durations in log domain (B, T)</span>
<span class="sd">        targets (LongTensor): Batch of groundtruth durations in linear domain (B, T)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Mean squared error loss value.</span>

<span class="sd">    Note:</span>
<span class="sd">        `outputs` is in log domain but `targets` is in linear domain.</span>

<span class="sd">    """</span>
    <span class="c1"># NOTE: outputs is in log domain while targets in linear</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator">
<code>length_regulator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Length regulator related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="LengthRegulator" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator">
<code>LengthRegulator</code>
</h7>
<div class="doc doc-contents">
<p>Length regulator module for feed-forward Transformer.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="k">length</span> <span class="n">regulator</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>
<span class="n">The</span> <span class="k">length</span> <span class="n">regulator</span> <span class="n">expands</span> <span class="nb">char</span> <span class="k">or</span> <span class="n">phoneme</span><span class="o">-</span><span class="k">level</span> <span class="n">embedding</span> <span class="n">features</span> <span class="k">to</span> <span class="n">frame</span><span class="o">-</span><span class="k">level</span> <span class="k">by</span> <span class="n">repeating</span> <span class="k">each</span>
<span class="n">feature</span> <span class="n">based</span> <span class="k">on</span> <span class="n">the</span> <span class="n">corresponding</span> <span class="n">predicted</span> <span class="n">durations</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1905</span><span class="p">.</span><span class="mi">09263</span><span class="p">.</span><span class="n">pdf</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pad_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initilize length regulator module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pad_value</code></td>
<td><code>float</code></td>
<td>
<p>Value used for padding.</p>
</td>
<td><code>0.0</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/length_regulator.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>28
29
30
31
32
33
34
35
36</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pad_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="sd">"""Initilize length regulator module.</span>

<span class="sd">    Args:</span>
<span class="sd">        pad_value (float, optional): Value used for padding.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LengthRegulator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_value</span> <span class="o">=</span> <span class="n">pad_value</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of sequences of char or phoneme embeddings (B, Tmax, D).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ds</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of durations of each frame (B, T).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of input lengths (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>alpha</code></td>
<td><code>float</code></td>
<td>
<p>Alpha value to control speed of speech.</p>
</td>
<td><code>1.0</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>replicated input tensor based on durations (B, T*, D).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/fastspeech/length_regulator.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of sequences of char or phoneme embeddings (B, Tmax, D).</span>
<span class="sd">        ds (LongTensor): Batch of durations of each frame (B, T).</span>
<span class="sd">        ilens (LongTensor): Batch of input lengths (B,).</span>
<span class="sd">        alpha (float, optional): Alpha value to control speed of speech.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: replicated input tensor based on durations (B, T*, D).</span>

<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[:</span><span class="n">ilen</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">ilen</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)]</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[:</span><span class="n">ilen</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">ilen</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)]</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_repeat_one_sequence</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ds</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_value</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.initialization">
<code>initialization</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Initialization functions for RNN sequence-to-sequence models.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.lecun_normal_init_parameters">
<code class="highlight language-python">
lecun_normal_init_parameters<span class="p">(</span><span class="n">module</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.lecun_normal_init_parameters" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize parameters in the LeCun's manner.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/initialization.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">lecun_normal_init_parameters</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="sd">"""Initialize parameters in the LeCun's manner."""</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span>
        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># bias</span>
            <span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># linear weight</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">stdv</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">stdv</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
            <span class="c1"># conv weight</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]:</span>
                <span class="n">n</span> <span class="o">*=</span> <span class="n">k</span>
            <span class="n">stdv</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">stdv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.set_forget_bias_to_one">
<code class="highlight language-python">
set_forget_bias_to_one<span class="p">(</span><span class="n">bias</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.set_forget_bias_to_one" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize a bias vector in the forget gate with one.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/initialization.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>51
52
53
54
55</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">set_forget_bias_to_one</span><span class="p">(</span><span class="n">bias</span><span class="p">):</span>
    <span class="sd">"""Initialize a bias vector in the forget gate with one."""</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">n</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.uniform_init_parameters">
<code class="highlight language-python">
uniform_init_parameters<span class="p">(</span><span class="n">module</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.initialization.uniform_init_parameters" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initialize parameters with an uniform distribution.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/initialization.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>34
35
36
37
38
39
40
41
42
43
44
45
46
47
48</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">uniform_init_parameters</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="sd">"""Initialize parameters with an uniform distribution."""</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span>
        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># bias</span>
            <span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># linear weight</span>
            <span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
            <span class="c1"># conv weight</span>
            <span class="k">pass</span>  <span class="c1"># use the pytorch default</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils">
<code>nets_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Network related utility tools.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_non_pad_mask">
<code class="highlight language-python">
make_non_pad_mask<span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_non_pad_mask" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make mask tensor containing indices of non-padded part.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lengths</code></td>
<td><code>LongTensor or List</code></td>
<td>
<p>Batch of lengths (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>The reference tensor. If set, masks will be the same shape as this tensor.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>length_dim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension indicator of the above tensor. See the example.</p>
</td>
<td><code>-1</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ByteTensor</code></td>
<td>
<p>mask tensor containing indices of padded part.
            dtype=torch.uint8 in PyTorch 1.2-
            dtype=torch.bool in PyTorch 1.2+ (including 1.2)</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<p>With only lengths.</p>
<blockquote>
<blockquote>
<blockquote>
<p>lengths = [5, 3, 2]
make_non_pad_mask(lengths)
masks = [[1, 1, 1, 1 ,1],
         [1, 1, 1, 0, 0],
         [1, 1, 0, 0, 0]]</p>
</blockquote>
</blockquote>
</blockquote>
<p>With the reference tensor.</p>
<blockquote>
<blockquote>
<blockquote>
<p>xs = torch.zeros((3, 2, 4))
make_non_pad_mask(lengths, xs)
tensor([[[1, 1, 1, 1],
         [1, 1, 1, 1]],
        [[1, 1, 1, 0],
         [1, 1, 1, 0]],
        [[1, 1, 0, 0],
         [1, 1, 0, 0]]], dtype=torch.uint8)
xs = torch.zeros((3, 2, 6))
make_non_pad_mask(lengths, xs)
tensor([[[1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0]],
        [[1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0]],
        [[1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</p>
</blockquote>
</blockquote>
</blockquote>
<p>With the reference tensor and dimension indicator.</p>
<blockquote>
<blockquote>
<blockquote>
<p>xs = torch.zeros((3, 6, 6))
make_non_pad_mask(lengths, xs, 1)
tensor([[[1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [0, 0, 0, 0, 0, 0]],
        [[1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0]],
        [[1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)
make_non_pad_mask(lengths, xs, 2)
tensor([[[1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0],
         [1, 1, 1, 1, 1, 0]],
        [[1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0],
         [1, 1, 1, 0, 0, 0]],
        [[1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0],
         [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Make mask tensor containing indices of non-padded part.</span>

<span class="sd">    Args:</span>
<span class="sd">        lengths (LongTensor or List): Batch of lengths (B,).</span>
<span class="sd">        xs (Tensor, optional): The reference tensor. If set, masks will be the same shape as this tensor.</span>
<span class="sd">        length_dim (int, optional): Dimension indicator of the above tensor. See the example.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ByteTensor: mask tensor containing indices of padded part.</span>
<span class="sd">                    dtype=torch.uint8 in PyTorch 1.2-</span>
<span class="sd">                    dtype=torch.bool in PyTorch 1.2+ (including 1.2)</span>

<span class="sd">    Examples:</span>
<span class="sd">        With only lengths.</span>

<span class="sd">        &gt;&gt;&gt; lengths = [5, 3, 2]</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths)</span>
<span class="sd">        masks = [[1, 1, 1, 1 ,1],</span>
<span class="sd">                 [1, 1, 1, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0]]</span>

<span class="sd">        With the reference tensor.</span>

<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 2, 4))</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths, xs)</span>
<span class="sd">        tensor([[[1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1]],</span>
<span class="sd">                [[1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 0]],</span>
<span class="sd">                [[1, 1, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0]]], dtype=torch.uint8)</span>
<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 2, 6))</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths, xs)</span>
<span class="sd">        tensor([[[1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0]],</span>
<span class="sd">                [[1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0]],</span>
<span class="sd">                [[1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</span>

<span class="sd">        With the reference tensor and dimension indicator.</span>

<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 6, 6))</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths, xs, 1)</span>
<span class="sd">        tensor([[[1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0]],</span>
<span class="sd">                [[1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0]],</span>
<span class="sd">                [[1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths, xs, 2)</span>
<span class="sd">        tensor([[[1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 0]],</span>
<span class="sd">                [[1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 0, 0, 0]],</span>
<span class="sd">                [[1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="o">~</span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">length_dim</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_pad_mask">
<code class="highlight language-python">
make_pad_mask<span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.make_pad_mask" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make mask tensor containing indices of padded part.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lengths</code></td>
<td><code>LongTensor or List</code></td>
<td>
<p>Batch of lengths (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>The reference tensor. If set, masks will be the same shape as this tensor.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>length_dim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension indicator of the above tensor. See the example.</p>
</td>
<td><code>-1</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Mask tensor containing indices of padded part.
        dtype=torch.uint8 in PyTorch 1.2-
        dtype=torch.bool in PyTorch 1.2+ (including 1.2)</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<p>With only lengths.</p>
<blockquote>
<blockquote>
<blockquote>
<p>lengths = [5, 3, 2]
make_non_pad_mask(lengths)
masks = [[0, 0, 0, 0 ,0],
         [0, 0, 0, 1, 1],
         [0, 0, 1, 1, 1]]</p>
</blockquote>
</blockquote>
</blockquote>
<p>With the reference tensor.</p>
<blockquote>
<blockquote>
<blockquote>
<p>xs = torch.zeros((3, 2, 4))
make_pad_mask(lengths, xs)
tensor([[[0, 0, 0, 0],
         [0, 0, 0, 0]],
        [[0, 0, 0, 1],
         [0, 0, 0, 1]],
        [[0, 0, 1, 1],
         [0, 0, 1, 1]]], dtype=torch.uint8)
xs = torch.zeros((3, 2, 6))
make_pad_mask(lengths, xs)
tensor([[[0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1]],
        [[0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1]],
        [[0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</p>
</blockquote>
</blockquote>
</blockquote>
<p>With the reference tensor and dimension indicator.</p>
<blockquote>
<blockquote>
<blockquote>
<p>xs = torch.zeros((3, 6, 6))
make_pad_mask(lengths, xs, 1)
tensor([[[0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 1, 1]],
        [[0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1]],
        [[0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1],
         [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)
make_pad_mask(lengths, xs, 2)
tensor([[[0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 1]],
        [[0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1, 1]],
        [[0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Make mask tensor containing indices of padded part.</span>

<span class="sd">    Args:</span>
<span class="sd">        lengths (LongTensor or List): Batch of lengths (B,).</span>
<span class="sd">        xs (Tensor, optional): The reference tensor. If set, masks will be the same shape as this tensor.</span>
<span class="sd">        length_dim (int, optional): Dimension indicator of the above tensor. See the example.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Mask tensor containing indices of padded part.</span>
<span class="sd">                dtype=torch.uint8 in PyTorch 1.2-</span>
<span class="sd">                dtype=torch.bool in PyTorch 1.2+ (including 1.2)</span>

<span class="sd">    Examples:</span>
<span class="sd">        With only lengths.</span>

<span class="sd">        &gt;&gt;&gt; lengths = [5, 3, 2]</span>
<span class="sd">        &gt;&gt;&gt; make_non_pad_mask(lengths)</span>
<span class="sd">        masks = [[0, 0, 0, 0 ,0],</span>
<span class="sd">                 [0, 0, 0, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1]]</span>

<span class="sd">        With the reference tensor.</span>

<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 2, 4))</span>
<span class="sd">        &gt;&gt;&gt; make_pad_mask(lengths, xs)</span>
<span class="sd">        tensor([[[0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0]],</span>
<span class="sd">                [[0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 1]],</span>
<span class="sd">                [[0, 0, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1]]], dtype=torch.uint8)</span>
<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 2, 6))</span>
<span class="sd">        &gt;&gt;&gt; make_pad_mask(lengths, xs)</span>
<span class="sd">        tensor([[[0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1]],</span>
<span class="sd">                [[0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1]],</span>
<span class="sd">                [[0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</span>

<span class="sd">        With the reference tensor and dimension indicator.</span>

<span class="sd">        &gt;&gt;&gt; xs = torch.zeros((3, 6, 6))</span>
<span class="sd">        &gt;&gt;&gt; make_pad_mask(lengths, xs, 1)</span>
<span class="sd">        tensor([[[0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1]],</span>
<span class="sd">                [[0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1]],</span>
<span class="sd">                [[0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 0],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1],</span>
<span class="sd">                 [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)</span>
<span class="sd">        &gt;&gt;&gt; make_pad_mask(lengths, xs, 2)</span>
<span class="sd">        tensor([[[0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1],</span>
<span class="sd">                 [0, 0, 0, 0, 0, 1]],</span>
<span class="sd">                [[0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 0, 1, 1, 1]],</span>
<span class="sd">                [[0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1],</span>
<span class="sd">                 [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">length_dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'length_dim cannot be 0: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">length_dim</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">length_dim</span><span class="p">)</span>

    <span class="n">seq_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">seq_range_expand</span> <span class="o">=</span> <span class="n">seq_range</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span>
    <span class="n">seq_length_expand</span> <span class="o">=</span> <span class="n">seq_range_expand</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">seq_range_expand</span> <span class="o">&gt;=</span> <span class="n">seq_length_expand</span>

    <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">bs</span><span class="p">,</span> <span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">bs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">length_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">length_dim</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="n">length_dim</span>
        <span class="c1"># ind = (:, None, ..., None, :, , None, ..., None)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">length_dim</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mask</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.mask_by_length">
<code class="highlight language-python">
mask_by_length<span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.mask_by_length" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Mask tensor according to length.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input tensor (B, <code>*</code>).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>lengths</code></td>
<td><code>LongTensor or List</code></td>
<td>
<p>Batch of lengths (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>fill</code></td>
<td><code>int or float</code></td>
<td>
<p>Value to fill masked part.</p>
</td>
<td><code>0</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of masked input tensor (B, <code>*</code>).</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>x = torch.arange(5).repeat(3, 1) + 1
x
tensor([[1, 2, 3, 4, 5],
        [1, 2, 3, 4, 5],
        [1, 2, 3, 4, 5]])
lengths = [5, 3, 2]
mask_by_length(x, lengths)
tensor([[1, 2, 3, 4, 5],
        [1, 2, 3, 0, 0],
        [1, 2, 0, 0, 0]])</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">mask_by_length</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Mask tensor according to length.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of input tensor (B, `*`).</span>
<span class="sd">        lengths (LongTensor or List): Batch of lengths (B,).</span>
<span class="sd">        fill (int or float): Value to fill masked part.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of masked input tensor (B, `*`).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; x = torch.arange(5).repeat(3, 1) + 1</span>
<span class="sd">        &gt;&gt;&gt; x</span>
<span class="sd">        tensor([[1, 2, 3, 4, 5],</span>
<span class="sd">                [1, 2, 3, 4, 5],</span>
<span class="sd">                [1, 2, 3, 4, 5]])</span>
<span class="sd">        &gt;&gt;&gt; lengths = [5, 3, 2]</span>
<span class="sd">        &gt;&gt;&gt; mask_by_length(x, lengths)</span>
<span class="sd">        tensor([[1, 2, 3, 4, 5],</span>
<span class="sd">                [1, 2, 3, 0, 0],</span>
<span class="sd">                [1, 2, 0, 0, 0]])</span>

<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">fill</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lengths</span><span class="p">):</span>
        <span class="n">ret</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.pad_list">
<code class="highlight language-python">
pad_list<span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">pad_value</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.pad_list" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform padding for the list of tensors.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>List</code></td>
<td>
<p>List of Tensors [(T_1, <code>*</code>), (T_2, <code>*</code>), ..., (T_B, <code>*</code>)].</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>pad_value</code></td>
<td><code>float</code></td>
<td>
<p>Value for padding.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Padded tensor (B, Tmax, <code>*</code>).</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>x = [torch.ones(4), torch.ones(2), torch.ones(1)]
x
[tensor([1., 1., 1., 1.]), tensor([1., 1.]), tensor([1.])]
pad_list(x, 0)
tensor([[1., 1., 1., 1.],
        [1., 1., 0., 0.],
        [1., 0., 0., 0.]])</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">pad_list</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">pad_value</span><span class="p">):</span>
    <span class="sd">"""Perform padding for the list of tensors.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (List): List of Tensors [(T_1, `*`), (T_2, `*`), ..., (T_B, `*`)].</span>
<span class="sd">        pad_value (float): Value for padding.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Padded tensor (B, Tmax, `*`).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; x = [torch.ones(4), torch.ones(2), torch.ones(1)]</span>
<span class="sd">        &gt;&gt;&gt; x</span>
<span class="sd">        [tensor([1., 1., 1., 1.]), tensor([1., 1.]), tensor([1.])]</span>
<span class="sd">        &gt;&gt;&gt; pad_list(x, 0)</span>
<span class="sd">        tensor([[1., 1., 1., 1.],</span>
<span class="sd">                [1., 1., 0., 0.],</span>
<span class="sd">                [1., 0., 0., 0.]])</span>

<span class="sd">    """</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="o">*</span><span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">pad_value</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batch</span><span class="p">):</span>
        <span class="n">pad</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">pad</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.th_accuracy">
<code class="highlight language-python">
th_accuracy<span class="p">(</span><span class="n">pad_outputs</span><span class="p">,</span> <span class="n">pad_targets</span><span class="p">,</span> <span class="n">ignore_label</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.th_accuracy" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Calculate accuracy.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pad_outputs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Prediction tensors (B * Lmax, D).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>pad_targets</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Target label tensors (B, Lmax, D).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ignore_label</code></td>
<td><code>int</code></td>
<td>
<p>Ignore label id.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>float</code></td>
<td>
<p>Accuracy value (0.0 - 1.0).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">th_accuracy</span><span class="p">(</span><span class="n">pad_outputs</span><span class="p">,</span> <span class="n">pad_targets</span><span class="p">,</span> <span class="n">ignore_label</span><span class="p">):</span>
    <span class="sd">"""Calculate accuracy.</span>

<span class="sd">    Args:</span>
<span class="sd">        pad_outputs (Tensor): Prediction tensors (B * Lmax, D).</span>
<span class="sd">        pad_targets (LongTensor): Target label tensors (B, Lmax, D).</span>
<span class="sd">        ignore_label (int): Ignore label id.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Accuracy value (0.0 - 1.0).</span>

<span class="sd">    """</span>
    <span class="n">pad_pred</span> <span class="o">=</span> <span class="n">pad_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
        <span class="n">pad_targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">pad_targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pad_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">pad_targets</span> <span class="o">!=</span> <span class="n">ignore_label</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pad_pred</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">==</span> <span class="n">pad_targets</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">numerator</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">denominator</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_device">
<code class="highlight language-python">
to_device<span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_device" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Send tensor into the device of the module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>m</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Torch module.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Torch tensor.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Torch tensor located in the same place as torch module.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Send tensor into the device of the module.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (torch.nn.Module): Torch module.</span>
<span class="sd">        x (Tensor): Torch tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Torch tensor located in the same place as torch module.</span>

<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_torch_tensor">
<code class="highlight language-python">
to_torch_tensor<span class="p">(</span><span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.nets_utils.to_torch_tensor" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Change to torch.Tensor or ComplexTensor from numpy.ndarray.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code></code></td>
<td>
<p>Inputs. It should be one of numpy.ndarray, Tensor, ComplexTensor, and dict.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor or ComplexTensor</code></td>
<td>
<p>Type converted inputs.</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>xs = np.ones(3, dtype=np.float32)
xs = to_torch_tensor(xs)
tensor([1., 1., 1.])
xs = torch.ones(3, 4, 5)
assert to_torch_tensor(xs) is xs
xs = {'real': xs, 'imag': xs}
to_torch_tensor(xs)
ComplexTensor(
Real:
tensor([1., 1., 1.])
Imag;
tensor([1., 1., 1.])
)</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/nets_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">to_torch_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Change to torch.Tensor or ComplexTensor from numpy.ndarray.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Inputs. It should be one of numpy.ndarray, Tensor, ComplexTensor, and dict.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or ComplexTensor: Type converted inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; xs = np.ones(3, dtype=np.float32)</span>
<span class="sd">        &gt;&gt;&gt; xs = to_torch_tensor(xs)</span>
<span class="sd">        tensor([1., 1., 1.])</span>
<span class="sd">        &gt;&gt;&gt; xs = torch.ones(3, 4, 5)</span>
<span class="sd">        &gt;&gt;&gt; assert to_torch_tensor(xs) is xs</span>
<span class="sd">        &gt;&gt;&gt; xs = {'real': xs, 'imag': xs}</span>
<span class="sd">        &gt;&gt;&gt; to_torch_tensor(xs)</span>
<span class="sd">        ComplexTensor(</span>
<span class="sd">        Real:</span>
<span class="sd">        tensor([1., 1., 1.])</span>
<span class="sd">        Imag;</span>
<span class="sd">        tensor([1., 1., 1.])</span>
<span class="sd">        )</span>

<span class="sd">    """</span>
    <span class="c1"># If numpy, change to torch tensor</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">'c'</span><span class="p">:</span>
            <span class="c1"># Dynamically importing because torch_complex requires python3</span>
            <span class="kn">from</span> <span class="nn">torch_complex.tensor</span> <span class="kn">import</span> <span class="n">ComplexTensor</span>
            <span class="k">return</span> <span class="n">ComplexTensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># If {'real': ..., 'imag': ...}, convert to ComplexTensor</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># Dynamically importing because torch_complex requires python3</span>
        <span class="kn">from</span> <span class="nn">torch_complex.tensor</span> <span class="kn">import</span> <span class="n">ComplexTensor</span>

        <span class="k">if</span> <span class="s1">'real'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">x</span> <span class="ow">or</span> <span class="s1">'imag'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"has 'real' and 'imag' keys: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="c1"># Relative importing because of using python3 syntax</span>
        <span class="k">return</span> <span class="n">ComplexTensor</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">'real'</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="s1">'imag'</span><span class="p">])</span>

    <span class="c1"># If torch.Tensor, as it is</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"x must be numpy.ndarray, torch.Tensor or a dict like "</span>
                 <span class="s2">"{{'real': torch.Tensor, 'imag': torch.Tensor}}, "</span>
                 <span class="s2">"but got </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">torch_complex.tensor</span> <span class="kn">import</span> <span class="n">ComplexTensor</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># If PY2</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If PY3</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ComplexTensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">x</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn">
<code>rnn</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions">
<code>attentions</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Attention modules for RNN.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttAdd" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttAdd">
<code>AttAdd</code>
</h7>
<div class="doc doc-contents">
<p>Additive attention</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int eprojs: # projection-units of encoder</span>
<span class="err">:param int dunits: # units of decoder</span>
<span class="err">:param int att_dim: attention dimension</span>
<span class="err">:param bool han_mode: flag to swith on mode of hierarchical attention and not store pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttAdd.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>171
172
173
174
175
176
177
178
179
180
181
182
183</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttAdd</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttAdd.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttAdd forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: dummy (does not use)
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights (B x T_max)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttAdd forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: dummy (does not use)</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights (B x T_max)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttAdd.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>185
186
187
188
189
190</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttCov" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCov">
<code>AttCov</code>
</h7>
<div class="doc doc-contents">
<p>Coverage mechanism attention</p>
<div class="codehilite">
<pre><span></span><code><span class="n">Reference</span><span class="o">:</span> <span class="n">Get</span> <span class="n">To</span> <span class="n">The</span> <span class="n">Point</span><span class="o">:</span> <span class="n">Summarization</span> <span class="k">with</span> <span class="n">Pointer</span><span class="o">-</span><span class="n">Generator</span> <span class="n">Network</span>
   <span class="o">(</span><span class="n">https</span><span class="o">://</span><span class="n">arxiv</span><span class="o">.</span><span class="na">org</span><span class="sr">/abs/</span><span class="mf">1704.04368</span><span class="o">)</span>

<span class="o">:</span><span class="n">param</span> <span class="n">int</span> <span class="n">eprojs</span><span class="o">:</span> <span class="err">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="n">of</span> <span class="n">encoder</span>
<span class="o">:</span><span class="n">param</span> <span class="n">int</span> <span class="n">dunits</span><span class="o">:</span> <span class="err">#</span> <span class="n">units</span> <span class="n">of</span> <span class="n">decoder</span>
<span class="o">:</span><span class="n">param</span> <span class="n">int</span> <span class="n">att_dim</span><span class="o">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="o">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="o">:</span> <span class="n">flag</span> <span class="n">to</span> <span class="n">swith</span> <span class="n">on</span> <span class="n">mode</span> <span class="n">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="n">and</span> <span class="n">not</span> <span class="n">store</span> <span class="n">pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCov.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>360
361
362
363
364
365
366
367
368
369
370
371
372
373
374</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttCov</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCov.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_list</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttCov forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param list att_prev_list: list of previous attention weight
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: list of previous attention weights
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_list</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttCov forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param list att_prev_list: list of previous attention weight</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weights</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="c1"># initialize attention weight with uniform dist.</span>
    <span class="k">if</span> <span class="n">att_prev_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">att_prev_list</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()))</span>
        <span class="n">att_prev_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">att_prev_list</span> <span class="o">/</span> <span class="n">att_prev_list</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># att_prev_list: L' * [B x T] =&gt; cov_vec B x T</span>
    <span class="n">cov_vec</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">att_prev_list</span><span class="p">)</span>
    <span class="c1"># cov_vec: B x T =&gt; B x T x 1 =&gt; B x T x att_dim</span>
    <span class="n">cov_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wvec</span><span class="p">(</span><span class="n">cov_vec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">cov_vec</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_prev_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">w</span><span class="p">]</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">att_prev_list</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCov.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>376
377
378
379
380
381</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttCovLoc" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCovLoc">
<code>AttCovLoc</code>
</h7>
<div class="doc doc-contents">
<p>Coverage mechanism location aware attention</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">a</span> <span class="n">combination</span> <span class="k">of</span> <span class="n">coverage</span> <span class="k">and</span> <span class="k">location</span><span class="o">-</span><span class="n">aware</span> <span class="n">attentions</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCovLoc.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttCovLoc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aconv_chans</span> <span class="o">=</span> <span class="n">aconv_chans</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCovLoc.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_list</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttCovLoc forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param list att_prev_list: list of previous attention weight
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: list of previous attention weights
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_list</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttCovLoc forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param list att_prev_list: list of previous attention weight</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weights</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="c1"># initialize attention weight with uniform dist.</span>
    <span class="k">if</span> <span class="n">att_prev_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">att_prev_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))]</span>

    <span class="c1"># att_prev_list: L' * [B x T] =&gt; cov_vec B x T</span>
    <span class="n">cov_vec</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">att_prev_list</span><span class="p">)</span>

    <span class="c1"># cov_vec: B x T -&gt; B x 1 x 1 x T -&gt; B x C x 1 x T</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">cov_vec</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
    <span class="c1"># att_conv: utt x att_conv_chans x 1 x frame -&gt; utt x frame x att_conv_chans</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># att_conv: utt x frame x att_conv_chans -&gt; utt x frame x att_dim</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_prev_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">w</span><span class="p">]</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">att_prev_list</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttCovLoc.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>696
697
698
699
700
701</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttDot" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttDot">
<code>AttDot</code>
</h7>
<div class="doc doc-contents">
<p>Dot product attention</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int eprojs: # projection-units of encoder</span>
<span class="err">:param int dunits: # units of decoder</span>
<span class="err">:param int att_dim: attention dimension</span>
<span class="err">:param bool han_mode: flag to swith on mode of hierarchical attention and not store pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttDot.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 98
 99
100
101
102
103
104
105
106
107
108
109
110</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttDot</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttDot.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttDot forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: dummy (does not use)
:param torch.Tensor att_prev: dummy (does not use)
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weight (B x T_max)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttDot forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: dummy (does not use)</span>
<span class="sd">    :param torch.Tensor att_prev: dummy (does not use)</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weight (B x T_max)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">),</span>
                  <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># utt x frame</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttDot.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>112
113
114
115
116
117</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttForward" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForward">
<code>AttForward</code>
</h7>
<div class="doc doc-contents">
<p>Forward attention module.</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Forward attention in sequence-to-sequence acoustic modeling for speech synthesis"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1807</span><span class="p">.</span><span class="mi">06736</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForward.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1244
1245
1246
1247
1248
1249
1250
1251
1252
1253
1254
1255
1256
1257
1258</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForward.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate AttForward forward propagation.</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: attention weights of previous step
:param float scaling: scaling parameter before applying softmax
:param int last_attended_idx: index of the inputs of the last attended
:param int backward_window: backward window size in attention constraint
:param int forward_window: forward window size in attetion constraint
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights (B x T_max)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1267
1268
1269
1270
1271
1272
1273
1274
1275
1276
1277
1278
1279
1280
1281
1282
1283
1284
1285
1286
1287
1288
1289
1290
1291
1292
1293
1294
1295
1296
1297
1298
1299
1300
1301
1302
1303
1304
1305
1306
1307
1308
1309
1310
1311
1312
1313
1314
1315
1316
1317
1318
1319
1320
1321
1322
1323
1324
1325
1326
1327
1328
1329
1330
1331
1332
1333
1334
1335
1336
1337
1338</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span>
            <span class="n">scaling</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">"""Calculate AttForward forward propagation.</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: attention weights of previous step</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :param int last_attended_idx: index of the inputs of the last attended</span>
<span class="sd">    :param int backward_window: backward window size in attention constraint</span>
<span class="sd">    :param int forward_window: forward window size in attetion constraint</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights (B x T_max)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># initial attention will be [1, 0, 0, ...]</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="o">*</span><span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">att_prev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="c1"># att_prev: utt x frame -&gt; utt x 1 x 1 x frame -&gt; utt x att_conv_chans x 1 x frame</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">att_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
    <span class="c1"># att_conv: utt x att_conv_chans x 1 x frame -&gt; utt x frame x att_conv_chans</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># att_conv: utt x frame x att_conv_chans -&gt; utt x frame x att_dim</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span> <span class="o">+</span> <span class="n">att_conv</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE: consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>

    <span class="c1"># apply monotonic attention constraint (mainly for TTS)</span>
    <span class="k">if</span> <span class="n">last_attended_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">_apply_attention_constraint</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="p">,</span> <span class="n">backward_window</span><span class="p">,</span> <span class="n">forward_window</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># forward attention</span>
    <span class="n">att_prev_shift</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">att_prev</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="n">att_prev</span> <span class="o">+</span> <span class="n">att_prev_shift</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span>
    <span class="c1"># NOTE: clamp is needed to avoid nan gradient</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForward.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1260
1261
1262
1263
1264
1265</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttForwardTA" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForwardTA">
<code>AttForwardTA</code>
</h7>
<div class="doc doc-contents">
<p>Forward attention with transition agent module.</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Forward attention in sequence-to-sequence acoustic modeling for speech synthesis"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1807</span><span class="p">.</span><span class="mi">06736</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">odim</span><span class="p">:</span> <span class="k">output</span> <span class="n">dimension</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForwardTA.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">odim</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1355
1356
1357
1358
1359
1360
1361
1362
1363
1364
1365
1366
1367
1368
1369
1370
1371</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">odim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttForwardTA</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_ta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eunits</span> <span class="o">+</span> <span class="n">dunits</span> <span class="o">+</span> <span class="n">odim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eunits</span> <span class="o">=</span> <span class="n">eunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trans_agent_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForwardTA.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">out_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate AttForwardTA forward propagation.</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B, Tmax, eunits)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B, dunits)
:param torch.Tensor att_prev: attention weights of previous step
:param torch.Tensor out_prev: decoder outputs of previous step (B, odim)
:param float scaling: scaling parameter before applying softmax
:param int last_attended_idx: index of the inputs of the last attended
:param int backward_window: backward window size in attention constraint
:param int forward_window: forward window size in attetion constraint
:return: attention weighted encoder state (B, dunits)
:rtype: torch.Tensor
:return: previous attention weights (B, Tmax)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1380
1381
1382
1383
1384
1385
1386
1387
1388
1389
1390
1391
1392
1393
1394
1395
1396
1397
1398
1399
1400
1401
1402
1403
1404
1405
1406
1407
1408
1409
1410
1411
1412
1413
1414
1415
1416
1417
1418
1419
1420
1421
1422
1423
1424
1425
1426
1427
1428
1429
1430
1431
1432
1433
1434
1435
1436
1437
1438
1439
1440
1441
1442
1443
1444
1445
1446
1447
1448
1449
1450
1451
1452
1453
1454
1455
1456</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">out_prev</span><span class="p">,</span>
            <span class="n">scaling</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">"""Calculate AttForwardTA forward propagation.</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B, Tmax, eunits)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B, dunits)</span>
<span class="sd">    :param torch.Tensor att_prev: attention weights of previous step</span>
<span class="sd">    :param torch.Tensor out_prev: decoder outputs of previous step (B, odim)</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :param int last_attended_idx: index of the inputs of the last attended</span>
<span class="sd">    :param int backward_window: backward window size in attention constraint</span>
<span class="sd">    :param int forward_window: forward window size in attetion constraint</span>
<span class="sd">    :return: attention weighted encoder state (B, dunits)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights (B, Tmax)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># initial attention will be [1, 0, 0, ...]</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="o">*</span><span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">att_prev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="c1"># att_prev: utt x frame -&gt; utt x 1 x 1 x frame -&gt; utt x att_conv_chans x 1 x frame</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">att_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
    <span class="c1"># att_conv: utt x att_conv_chans x 1 x frame -&gt; utt x frame x att_conv_chans</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># att_conv: utt x frame x att_conv_chans -&gt; utt x frame x att_dim</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>

    <span class="c1"># apply monotonic attention constraint (mainly for TTS)</span>
    <span class="k">if</span> <span class="n">last_attended_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">_apply_attention_constraint</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="p">,</span> <span class="n">backward_window</span><span class="p">,</span> <span class="n">forward_window</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># forward attention</span>
    <span class="n">att_prev_shift</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">att_prev</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans_agent_prob</span> <span class="o">*</span> <span class="n">att_prev</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans_agent_prob</span><span class="p">)</span> <span class="o">*</span> <span class="n">att_prev_shift</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span>
    <span class="c1"># NOTE: clamp is needed to avoid nan gradient</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># update transition agent prob</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trans_agent_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_ta</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">c</span><span class="p">,</span> <span class="n">out_prev</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttForwardTA.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1373
1374
1375
1376
1377
1378</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trans_agent_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttLoc" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc">
<code>AttLoc</code>
</h7>
<div class="doc doc-contents">
<p>location-aware attention module.</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Attention-Based Models for Speech Recognition"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1506</span><span class="p">.</span><span class="mi">07503</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttLoc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calcualte AttLoc forward propagation.</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: previous attention weight (B x T_max)
:param float scaling: scaling parameter before applying softmax
:param torch.Tensor forward_window: forward window size when constraining attention
:param int last_attended_idx: index of the inputs of the last attended
:param int backward_window: backward window size in attention constraint
:param int forward_window: forward window size in attetion constraint
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights (B x T_max)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span>
            <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">"""Calcualte AttLoc forward propagation.</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: previous attention weight (B x T_max)</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :param torch.Tensor forward_window: forward window size when constraining attention</span>
<span class="sd">    :param int last_attended_idx: index of the inputs of the last attended</span>
<span class="sd">    :param int backward_window: backward window size in attention constraint</span>
<span class="sd">    :param int forward_window: forward window size in attetion constraint</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights (B x T_max)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="c1"># initialize attention weight with uniform dist.</span>
    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">dec_z</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dec_z</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span> <span class="o">/</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># att_prev: utt x frame -&gt; utt x 1 x 1 x frame -&gt; utt x att_conv_chans x 1 x frame</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">att_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
    <span class="c1"># att_conv: utt x att_conv_chans x 1 x frame -&gt; utt x frame x att_conv_chans</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># att_conv: utt x frame x att_conv_chans -&gt; utt x frame x att_dim</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE: consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>

    <span class="c1"># apply monotonic attention constraint (mainly for TTS)</span>
    <span class="k">if</span> <span class="n">last_attended_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">_apply_attention_constraint</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">last_attended_idx</span><span class="p">,</span> <span class="n">backward_window</span><span class="p">,</span> <span class="n">forward_window</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>272
273
274
275
276
277</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttLoc2D" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc2D">
<code>AttLoc2D</code>
</h7>
<div class="doc doc-contents">
<p>2D location-aware attention</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">an</span> <span class="n">extended</span> <span class="k">version</span> <span class="k">of</span> <span class="k">location</span> <span class="n">aware</span> <span class="n">attention</span><span class="p">.</span>
<span class="n">It</span> <span class="n">take</span> <span class="k">not</span> <span class="k">only</span> <span class="n">one</span> <span class="n">frame</span> <span class="k">before</span> <span class="n">attention</span> <span class="n">weights</span><span class="p">,</span> <span class="n">but</span> <span class="n">also</span> <span class="n">earlier</span> <span class="n">frames</span> <span class="k">into</span> <span class="n">account</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_win</span><span class="p">:</span> <span class="n">attention</span> <span class="n">window</span> <span class="k">size</span> <span class="p">(</span><span class="k">default</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc2D.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">att_win</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">att_win</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttLoc2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="n">att_win</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aconv_chans</span> <span class="o">=</span> <span class="n">aconv_chans</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_win</span> <span class="o">=</span> <span class="n">att_win</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc2D.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttLoc2D forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: previous attention weight (B x att_win x T_max)
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights (B x att_win x T_max)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttLoc2D forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: previous attention weight (B x att_win x T_max)</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights (B x att_win x T_max)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="c1"># initialize attention weight with uniform dist.</span>
    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># B * [Li x att_win]</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()))</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span> <span class="o">/</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_win</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># att_prev: B x att_win x Tmax -&gt; B x 1 x att_win x Tmax -&gt; B x C x 1 x Tmax</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">att_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># att_conv: B x C x 1 x Tmax -&gt; B x Tmax x C</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># att_conv: utt x frame x att_conv_chans -&gt; utt x frame x att_dim</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># update att_prev: B x att_win x Tmax -&gt; B x att_win+1 x Tmax -&gt; B x att_win x Tmax</span>
    <span class="n">att_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">att_prev</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">att_prev</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLoc2D.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>478
479
480
481
482
483</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttLocRec" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLocRec">
<code>AttLocRec</code>
</h7>
<div class="doc doc-contents">
<p>location-aware recurrent attention</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">an</span> <span class="n">extended</span> <span class="k">version</span> <span class="k">of</span> <span class="k">location</span> <span class="n">aware</span> <span class="n">attention</span><span class="p">.</span>
<span class="k">With</span> <span class="n">the</span> <span class="n">use</span> <span class="k">of</span> <span class="n">RNN</span><span class="p">,</span> <span class="n">it</span> <span class="n">take</span> <span class="n">the</span> <span class="n">effect</span> <span class="k">of</span> <span class="n">the</span> <span class="n">history</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">weights</span> <span class="k">into</span> <span class="n">account</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim</span><span class="p">:</span> <span class="n">attention</span> <span class="n">dimension</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_enc_h</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLocRec.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttLocRec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span> <span class="o">=</span> <span class="n">att_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLocRec.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_states</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttLocRec forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param tuple att_prev_states: previous attention weight and lstm states
                              ((B, T_max), ((B, att_dim), (B, att_dim)))
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights and lstm states (w, (hx, cx))
         ((B, T_max), ((B, att_dim), (B, att_dim)))
:rtype: tuple</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev_states</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttLocRec forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param tuple att_prev_states: previous attention weight and lstm states</span>
<span class="sd">                                  ((B, T_max), ((B, att_dim), (B, att_dim)))</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights and lstm states (w, (hx, cx))</span>
<span class="sd">             ((B, T_max), ((B, att_dim), (B, att_dim)))</span>
<span class="sd">    :rtype: tuple</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_prev_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># initialize attention weight with uniform dist.</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()))</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span> <span class="o">/</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># initialize lstm states</span>
        <span class="n">att_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>
        <span class="n">att_c</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>
        <span class="n">att_states</span> <span class="o">=</span> <span class="p">(</span><span class="n">att_h</span><span class="p">,</span> <span class="n">att_c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">att_states</span> <span class="o">=</span> <span class="n">att_prev_states</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># B x 1 x 1 x T -&gt; B x C x 1 x T</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">(</span><span class="n">att_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
    <span class="c1"># apply non-linear</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">att_conv</span><span class="p">)</span>
    <span class="c1"># B x C x 1 x T -&gt; B x C x 1 x 1 -&gt; B x C</span>
    <span class="n">att_conv</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">att_conv</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">att_h</span><span class="p">,</span> <span class="n">att_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_lstm</span><span class="p">(</span><span class="n">att_conv</span><span class="p">,</span> <span class="n">att_states</span><span class="p">)</span>

    <span class="c1"># dec_z_tiled: utt x frame x att_dim</span>
    <span class="n">dec_z_tiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dec</span><span class="p">(</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim</span><span class="p">)</span>

    <span class="c1"># dot with gvec</span>
    <span class="c1"># utt x frame x att_dim -&gt; utt x frame</span>
    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">att_h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">+</span> <span class="n">dec_z_tiled</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE consider zero padding when compute w.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
    <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># weighted sum over flames</span>
    <span class="c1"># utt x hdim</span>
    <span class="c1"># NOTE use bmm instead of sum(*)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="p">(</span><span class="n">att_h</span><span class="p">,</span> <span class="n">att_c</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttLocRec.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>584
585
586
587
588
589</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttMultiHeadAdd" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd">
<code>AttMultiHeadAdd</code>
</h7>
<div class="doc doc-contents">
<p>Multi head additive attention</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Attention is all you need"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1706</span><span class="p">.</span><span class="mi">03762</span><span class="p">)</span>

<span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span> <span class="k">using</span> <span class="n">additive</span> <span class="n">attention</span> <span class="k">for</span> <span class="k">each</span> <span class="n">head</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aheads</span><span class="p">:</span> <span class="o">#</span> <span class="n">heads</span> <span class="k">of</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_k</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">k</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_v</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">v</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_k</span> <span class="k">and</span> <span class="n">pre_compute_v</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>886
887
888
889
890
891
892
893
894
895
896
897
898
899
900
901
902
903
904
905
906
907
908
909</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttMultiHeadAdd</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">aheads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aheads</span> <span class="o">*</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aheads</span> <span class="o">=</span> <span class="n">aheads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span> <span class="o">=</span> <span class="n">att_dim_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_v</span> <span class="o">=</span> <span class="n">att_dim_v</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttMultiHeadAdd forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: dummy (does not use)
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: list of previous attention weight (B x T_max) * aheads
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>919
920
921
922
923
924
925
926
927
928
929
930
931
932
933
934
935
936
937
938
939
940
941
942
943
944
945
946
947
948
949
950
951
952
953
954
955
956
957
958
959
960
961
962
963
964
965
966
967
968
969
970
971
972
973</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">):</span>
    <span class="sd">"""AttMultiHeadAdd forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: dummy (does not use)</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pre-compute all k and v outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="n">c</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
        <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># NOTE consider zero padding when compute w.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
        <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

        <span class="c1"># weighted sum over flames</span>
        <span class="c1"># utt x hdim</span>
        <span class="c1"># NOTE use bmm instead of sum(*)</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># concat all of c</span>
    <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>911
912
913
914
915
916
917</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttMultiHeadDot" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot">
<code>AttMultiHeadDot</code>
</h7>
<div class="doc doc-contents">
<p>Multi head dot product attention</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Attention is all you need"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1706</span><span class="p">.</span><span class="mi">03762</span><span class="p">)</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aheads</span><span class="p">:</span> <span class="o">#</span> <span class="n">heads</span> <span class="k">of</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_k</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">k</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_v</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">v</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_k</span> <span class="k">and</span> <span class="n">pre_compute_v</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttMultiHeadDot</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">aheads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aheads</span> <span class="o">*</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aheads</span> <span class="o">=</span> <span class="n">aheads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span> <span class="o">=</span> <span class="n">att_dim_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_v</span> <span class="o">=</span> <span class="n">att_dim_v</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttMultiHeadDot forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: dummy (does not use)
:return: attention weighted encoder state (B x D_enc)
:rtype: torch.Tensor
:return: list of previous attention weight (B x T_max) * aheads
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>813
814
815
816
817
818
819
820
821
822
823
824
825
826
827
828
829
830
831
832
833
834
835
836
837
838
839
840
841
842
843
844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
860
861
862
863
864
865
866
867</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">):</span>
    <span class="sd">"""AttMultiHeadDot forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: dummy (does not use)</span>
<span class="sd">    :return: attention weighted encoder state (B x D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pre-compute all k and v outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">))</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="n">c</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">dec_z</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># utt x frame</span>

        <span class="c1"># NOTE consider zero padding when compute w.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
        <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

        <span class="c1"># weighted sum over flames</span>
        <span class="c1"># utt x hdim</span>
        <span class="c1"># NOTE use bmm instead of sum(*)</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># concat all of c</span>
    <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>805
806
807
808
809
810
811</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttMultiHeadLoc" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc">
<code>AttMultiHeadLoc</code>
</h7>
<div class="doc doc-contents">
<p>Multi head location based attention</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Attention is all you need"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1706</span><span class="p">.</span><span class="mi">03762</span><span class="p">)</span>

<span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span> <span class="k">using</span> <span class="k">location</span><span class="o">-</span><span class="n">aware</span> <span class="n">attention</span> <span class="k">for</span> <span class="k">each</span> <span class="n">head</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aheads</span><span class="p">:</span> <span class="o">#</span> <span class="n">heads</span> <span class="k">of</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_k</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">k</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_v</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">v</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_k</span> <span class="k">and</span> <span class="n">pre_compute_v</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 994
 995
 996
 997
 998
 999
1000
1001
1002
1003
1004
1005
1006
1007
1008
1009
1010
1011
1012
1013
1014
1015
1016
1017
1018
1019
1020
1021
1022</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttMultiHeadLoc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">aheads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">aconv_filts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aheads</span> <span class="o">*</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aheads</span> <span class="o">=</span> <span class="n">aheads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span> <span class="o">=</span> <span class="n">att_dim_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_v</span> <span class="o">=</span> <span class="n">att_dim_v</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttMultiHeadLoc forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: list of previous attention weight (B x T_max) * aheads
:param float scaling: scaling parameter before applying softmax
:return: attention weighted encoder state (B x D_enc)
:rtype: torch.Tensor
:return: list of previous attention weight (B x T_max) * aheads
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1032
1033
1034
1035
1036
1037
1038
1039
1040
1041
1042
1043
1044
1045
1046
1047
1048
1049
1050
1051
1052
1053
1054
1055
1056
1057
1058
1059
1060
1061
1062
1063
1064
1065
1066
1067
1068
1069
1070
1071
1072
1073
1074
1075
1076
1077
1078
1079
1080
1081
1082
1083
1084
1085
1086
1087
1088
1089
1090
1091
1092
1093
1094
1095
1096
1097
1098
1099</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="sd">"""AttMultiHeadLoc forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :param float scaling: scaling parameter before applying softmax</span>
<span class="sd">    :return: attention weighted encoder state (B x D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pre-compute all k and v outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
            <span class="c1"># if no bias, 0 0-pad goes 0</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">att_prev</span> <span class="o">+=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))]</span>

    <span class="n">c</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">att_prev</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">att_conv</span><span class="p">)</span>

        <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">+</span> <span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># NOTE consider zero padding when compute w.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
        <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

        <span class="c1"># weighted sum over flames</span>
        <span class="c1"># utt x hdim</span>
        <span class="c1"># NOTE use bmm instead of sum(*)</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># concat all of c</span>
    <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1024
1025
1026
1027
1028
1029
1030</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="AttMultiHeadMultiResLoc" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc">
<code>AttMultiHeadMultiResLoc</code>
</h7>
<div class="doc doc-contents">
<p>Multi head multi resolution location based attention</p>
<div class="codehilite">
<pre><span></span><code><span class="o">!!!</span> <span class="n">reference</span> <span class="ss">"Attention is all you need"</span>
    <span class="p">(</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1706</span><span class="p">.</span><span class="mi">03762</span><span class="p">)</span>

<span class="n">This</span> <span class="n">attention</span> <span class="k">is</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span> <span class="k">using</span> <span class="k">location</span><span class="o">-</span><span class="n">aware</span> <span class="n">attention</span> <span class="k">for</span> <span class="k">each</span> <span class="n">head</span><span class="p">.</span>
<span class="n">Furthermore</span><span class="p">,</span> <span class="n">it</span> <span class="n">uses</span> <span class="n">different</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">for</span> <span class="k">each</span> <span class="n">head</span><span class="p">.</span>

<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">eprojs</span><span class="p">:</span> <span class="o">#</span> <span class="n">projection</span><span class="o">-</span><span class="n">units</span> <span class="k">of</span> <span class="n">encoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">dunits</span><span class="p">:</span> <span class="o">#</span> <span class="n">units</span> <span class="k">of</span> <span class="n">decoder</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aheads</span><span class="p">:</span> <span class="o">#</span> <span class="n">heads</span> <span class="k">of</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_k</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">k</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">att_dim_v</span><span class="p">:</span> <span class="n">dimension</span> <span class="n">v</span> <span class="k">in</span> <span class="n">multi</span> <span class="n">head</span> <span class="n">attention</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_chans</span><span class="p">:</span> <span class="n">maximum</span> <span class="o">#</span> <span class="n">channels</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
    <span class="k">each</span> <span class="n">head</span> <span class="n">use</span> <span class="o">#</span><span class="n">ch</span> <span class="o">=</span> <span class="n">aconv_chans</span> <span class="o">*</span> <span class="p">(</span><span class="n">head</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">aheads</span>
    <span class="n">e</span><span class="p">.</span><span class="k">g</span><span class="p">.</span> <span class="n">aheads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="o">=</span><span class="mi">100</span> <span class="o">=&gt;</span> <span class="n">filter</span> <span class="k">size</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span>
<span class="p">:</span><span class="n">param</span> <span class="nb">int</span> <span class="n">aconv_filts</span><span class="p">:</span> <span class="n">filter</span> <span class="k">size</span> <span class="k">of</span> <span class="n">attention</span> <span class="n">convolution</span>
<span class="p">:</span><span class="n">param</span> <span class="n">bool</span> <span class="n">han_mode</span><span class="p">:</span> <span class="n">flag</span> <span class="k">to</span> <span class="n">swith</span> <span class="k">on</span> <span class="k">mode</span> <span class="k">of</span> <span class="n">hierarchical</span> <span class="n">attention</span> <span class="k">and</span> <span class="k">not</span> <span class="n">store</span> <span class="n">pre_compute_k</span> <span class="k">and</span> <span class="n">pre_compute_v</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1123
1124
1125
1126
1127
1128
1129
1130
1131
1132
1133
1134
1135
1136
1137
1138
1139
1140
1141
1142
1143
1144
1145
1146
1147
1148
1149
1150
1151
1152</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttMultiHeadMultiResLoc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">aheads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">afilts</span> <span class="o">=</span> <span class="n">aconv_filts</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">aheads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">afilts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">afilts</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aconv_chans</span><span class="p">,</span> <span class="n">att_dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">aheads</span> <span class="o">*</span> <span class="n">att_dim_v</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eprojs</span> <span class="o">=</span> <span class="n">eprojs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aheads</span> <span class="o">=</span> <span class="n">aheads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span> <span class="o">=</span> <span class="n">att_dim_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_v</span> <span class="o">=</span> <span class="n">att_dim_v</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">att_dim_k</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span> <span class="o">=</span> <span class="n">han_mode</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>AttMultiHeadMultiResLoc forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: decoder hidden state (B x D_dec)
:param torch.Tensor att_prev: list of previous attention weight (B x T_max) * aheads
:return: attention weighted encoder state (B x D_enc)
:rtype: torch.Tensor
:return: list of previous attention weight (B x T_max) * aheads
:rtype: list</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1162
1163
1164
1165
1166
1167
1168
1169
1170
1171
1172
1173
1174
1175
1176
1177
1178
1179
1180
1181
1182
1183
1184
1185
1186
1187
1188
1189
1190
1191
1192
1193
1194
1195
1196
1197
1198
1199
1200
1201
1202
1203
1204
1205
1206
1207
1208
1209
1210
1211
1212
1213
1214
1215
1216
1217
1218
1219
1220
1221
1222
1223
1224
1225
1226
1227
1228</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">):</span>
    <span class="sd">"""AttMultiHeadMultiResLoc forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: decoder hidden state (B x D_dec)</span>
<span class="sd">    :param torch.Tensor att_prev: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :return: attention weighted encoder state (B x D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: list of previous attention weight (B x T_max) * aheads</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    """</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pre-compute all k and v outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_k</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">han_mode</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># utt x frame x att_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_v</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">dec_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">enc_hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dec_z</span> <span class="o">=</span> <span class="n">dec_z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
            <span class="c1"># if no bias, 0 0-pad goes 0</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">att_prev</span> <span class="o">+=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))]</span>

    <span class="n">c</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aheads</span><span class="p">):</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_conv</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">att_prev</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">))</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="n">att_conv</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">att_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_att</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">att_conv</span><span class="p">)</span>

        <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gvec</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">+</span> <span class="n">att_conv</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_q</span><span class="p">[</span><span class="n">h</span><span class="p">](</span><span class="n">dec_z</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_dim_k</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># NOTE consider zero padding when compute w.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">))</span>
        <span class="n">e</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">))</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">*</span> <span class="n">e</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

        <span class="c1"># weighted sum over flames</span>
        <span class="c1"># utt x hdim</span>
        <span class="c1"># NOTE use bmm instead of sum(*)</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># concat all of c</span>
    <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_o</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1154
1155
1156
1157
1158
1159
1160</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_k</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_v</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="NoAtt" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.NoAtt">
<code>NoAtt</code>
</h7>
<div class="doc doc-contents">
<p>No attention</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.NoAtt.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NoAtt</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.NoAtt.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>NoAtt forward</p>
<p>:param torch.Tensor enc_hs_pad: padded encoder hidden state (B, T_max, D_enc)
:param list enc_hs_len: padded encoder hidden state length (B)
:param torch.Tensor dec_z: dummy (does not use)
:param torch.Tensor att_prev: dummy (does not use)
:return: attention weighted encoder state (B, D_enc)
:rtype: torch.Tensor
:return: previous attention weights
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_hs_pad</span><span class="p">,</span> <span class="n">enc_hs_len</span><span class="p">,</span> <span class="n">dec_z</span><span class="p">,</span> <span class="n">att_prev</span><span class="p">):</span>
    <span class="sd">"""NoAtt forward</span>

<span class="sd">    :param torch.Tensor enc_hs_pad: padded encoder hidden state (B, T_max, D_enc)</span>
<span class="sd">    :param list enc_hs_len: padded encoder hidden state length (B)</span>
<span class="sd">    :param torch.Tensor dec_z: dummy (does not use)</span>
<span class="sd">    :param torch.Tensor att_prev: dummy (does not use)</span>
<span class="sd">    :return: attention weighted encoder state (B, D_enc)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: previous attention weights</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_hs_pad</span><span class="p">)</span>
    <span class="c1"># pre-compute all h outside the decoder loop</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="n">enc_hs_pad</span>  <span class="c1"># utt x frame x hdim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># initialize attention weight with uniform dist.</span>
    <span class="k">if</span> <span class="n">att_prev</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if no bias, 0 0-pad goes 0</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">enc_hs_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att_prev</span> <span class="o">=</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">*</span> <span class="n">att_prev</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">att_prev</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.NoAtt.reset">
<code class="highlight language-python">
reset<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>reset states</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>53
54
55
56
57
58</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""reset states"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_enc_h</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="att_for()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.att_for">
<code class="highlight language-python">
att_for<span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">num_att</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Instantiates an attention module given the program arguments</p>
<p>:param Namespace args: The arguments
:param int num_att: number of attention modules (in multi-speaker case, it can be 2 or more)
:param bool han_mode: switch on/off mode of hierarchical attention network (HAN)
:rtype torch.nn.Module
:return: The attention module</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1459
1460
1461
1462
1463
1464
1465
1466
1467
1468
1469
1470
1471
1472
1473
1474
1475
1476
1477
1478
1479
1480
1481
1482
1483
1484
1485
1486
1487
1488
1489
1490
1491
1492
1493</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">att_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">num_att</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Instantiates an attention module given the program arguments</span>

<span class="sd">    :param Namespace args: The arguments</span>
<span class="sd">    :param int num_att: number of attention modules (in multi-speaker case, it can be 2 or more)</span>
<span class="sd">    :param bool han_mode: switch on/off mode of hierarchical attention network (HAN)</span>
<span class="sd">    :rtype torch.nn.Module</span>
<span class="sd">    :return: The attention module</span>
<span class="sd">    """</span>
    <span class="n">att_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="n">num_encs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"num_encs"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># use getattr to keep compatibility</span>
    <span class="n">aheads</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s1">'aheads'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">awin</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s1">'awin'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">aconv_chans</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s1">'aconv_chans'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">aconv_filts</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s1">'aconv_filts'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_att</span><span class="p">):</span>
            <span class="n">att</span> <span class="o">=</span> <span class="n">initial_att</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">atype</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">,</span> <span class="n">awin</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span>
                              <span class="n">aconv_filts</span><span class="p">)</span>
            <span class="n">att_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">num_encs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># no multi-speaker mode</span>
        <span class="k">if</span> <span class="n">han_mode</span><span class="p">:</span>
            <span class="n">att</span> <span class="o">=</span> <span class="n">initial_att</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">han_type</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">han_heads</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">han_dim</span><span class="p">,</span>
                              <span class="n">args</span><span class="o">.</span><span class="n">han_win</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">han_conv_chans</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">han_conv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">att</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">att_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">att</span> <span class="o">=</span> <span class="n">initial_att</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">atype</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">adim</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                  <span class="n">awin</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">aconv_chans</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">aconv_filts</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">att_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Number of encoders needs to be more than one. </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_encs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">att_list</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="att_to_numpy()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.att_to_numpy">
<code class="highlight language-python">
att_to_numpy<span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">att</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Converts attention weights to a numpy array given the attention</p>
<p>:param list att_ws: The attention weights
:param torch.nn.Module att: The attention
:rtype: np.ndarray
:return: The numpy array of the attention weights</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1548
1549
1550
1551
1552
1553
1554
1555
1556
1557
1558
1559
1560
1561
1562
1563
1564
1565
1566
1567
1568
1569
1570
1571
1572
1573
1574
1575
1576
1577</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">att_to_numpy</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">att</span><span class="p">):</span>
    <span class="sd">"""Converts attention weights to a numpy array given the attention</span>

<span class="sd">    :param list att_ws: The attention weights</span>
<span class="sd">    :param torch.nn.Module att: The attention</span>
<span class="sd">    :rtype: np.ndarray</span>
<span class="sd">    :return: The numpy array of the attention weights</span>
<span class="sd">    """</span>
    <span class="c1"># convert to numpy array with the shape (B, Lmax, Tmax)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="n">AttLoc2D</span><span class="p">):</span>
        <span class="c1"># att_ws =&gt; list of previous concate attentions</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">aw</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">aw</span> <span class="ow">in</span> <span class="n">att_ws</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="p">(</span><span class="n">AttCov</span><span class="p">,</span> <span class="n">AttCovLoc</span><span class="p">)):</span>
        <span class="c1"># att_ws =&gt; list of list of previous attentions</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">aw</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">aw</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">att_ws</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="n">AttLocRec</span><span class="p">):</span>
        <span class="c1"># att_ws =&gt; list of tuple of attention and hidden states</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">aw</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">aw</span> <span class="ow">in</span> <span class="n">att_ws</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="p">(</span><span class="n">AttMultiHeadDot</span><span class="p">,</span> <span class="n">AttMultiHeadAdd</span><span class="p">,</span> <span class="n">AttMultiHeadLoc</span><span class="p">,</span> <span class="n">AttMultiHeadMultiResLoc</span><span class="p">)):</span>
        <span class="c1"># att_ws =&gt; list of list of each head attention</span>
        <span class="n">n_heads</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">att_ws</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">att_ws_sorted_by_head</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_heads</span><span class="p">):</span>
            <span class="n">att_ws_head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">aw</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="k">for</span> <span class="n">aw</span> <span class="ow">in</span> <span class="n">att_ws</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">att_ws_sorted_by_head</span> <span class="o">+=</span> <span class="p">[</span><span class="n">att_ws_head</span><span class="p">]</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_ws_sorted_by_head</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># att_ws =&gt; list of attentions</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="initial_att()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.attentions.initial_att">
<code class="highlight language-python">
initial_att<span class="p">(</span><span class="n">atype</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">awin</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Instantiates a single attention module</p>
<p>:param str atype: attention type
:param int eprojs: # projection-units of encoder
:param int dunits: # units of decoder
:param int aheads: # heads of multi head attention
:param int adim: attention dimension
:param int awin: attention window size
:param int aconv_chans: # channels of attention convolution
:param int aconv_filts: filter size of attention convolution
:param bool han_mode: flag to swith on mode of hierarchical attention
:return: The attention module</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/attentions.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1496
1497
1498
1499
1500
1501
1502
1503
1504
1505
1506
1507
1508
1509
1510
1511
1512
1513
1514
1515
1516
1517
1518
1519
1520
1521
1522
1523
1524
1525
1526
1527
1528
1529
1530
1531
1532
1533
1534
1535
1536
1537
1538
1539
1540
1541
1542
1543
1544
1545</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">initial_att</span><span class="p">(</span><span class="n">atype</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">awin</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Instantiates a single attention module</span>

<span class="sd">    :param str atype: attention type</span>
<span class="sd">    :param int eprojs: # projection-units of encoder</span>
<span class="sd">    :param int dunits: # units of decoder</span>
<span class="sd">    :param int aheads: # heads of multi head attention</span>
<span class="sd">    :param int adim: attention dimension</span>
<span class="sd">    :param int awin: attention window size</span>
<span class="sd">    :param int aconv_chans: # channels of attention convolution</span>
<span class="sd">    :param int aconv_filts: filter size of attention convolution</span>
<span class="sd">    :param bool han_mode: flag to swith on mode of hierarchical attention</span>
<span class="sd">    :return: The attention module</span>
<span class="sd">    """</span>

    <span class="k">if</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'noatt'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">NoAtt</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'dot'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttDot</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'add'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttAdd</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'location'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttLoc</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                     <span class="n">adim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'location2d'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttLoc2D</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                       <span class="n">adim</span><span class="p">,</span> <span class="n">awin</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'location_recurrent'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttLocRec</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                        <span class="n">adim</span><span class="p">,</span> <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'coverage'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttCov</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'coverage_location'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttCovLoc</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span>
                        <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'multi_head_dot'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttMultiHeadDot</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                              <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'multi_head_add'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttMultiHeadAdd</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                              <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'multi_head_loc'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttMultiHeadLoc</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                              <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span>
                              <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">atype</span> <span class="o">==</span> <span class="s1">'multi_head_multi_res_loc'</span><span class="p">:</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">AttMultiHeadMultiResLoc</span><span class="p">(</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span>
                                      <span class="n">aheads</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span>
                                      <span class="n">aconv_chans</span><span class="p">,</span> <span class="n">aconv_filts</span><span class="p">,</span> <span class="n">han_mode</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">att</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders">
<code>decoders</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Decoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder">
<code>Decoder</code>
</h7>
<div class="doc doc-contents">
<p>Decoder module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int eprojs: encoder projection units</span>
<span class="err">:param int odim: dimension of outputs</span>
<span class="err">:param str dtype: gru or lstm</span>
<span class="err">:param int dlayers: decoder layers</span>
<span class="err">:param int dunits: decoder units</span>
<span class="err">:param int sos: start of sequence symbol id</span>
<span class="err">:param int eos: end of sequence symbol id</span>
<span class="err">:param torch.nn.Module att: attention module</span>
<span class="err">:param int verbose: verbose level</span>
<span class="err">:param list char_list: list of character strings</span>
<span class="err">:param ndarray labeldist: distribution of label smoothing</span>
<span class="err">:param float lsm_weight: label smoothing weight</span>
<span class="err">:param float sampling_probability: scheduled sampling probability</span>
<span class="err">:param float dropout: dropout rate</span>
<span class="err">:param float context_residual: if True, use context vector for token generation</span>
<span class="err">:param float replace_sos: use for multilingual (speech/text) translation</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">dlayers</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labeldist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lsm_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sampling_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">context_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">replace_sos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_encs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">dlayers</span><span class="p">,</span> <span class="n">dunits</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
             <span class="n">char_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labeldist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lsm_weight</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sampling_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
             <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">context_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">replace_sos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_encs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span> <span class="o">=</span> <span class="n">dlayers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">context_residual</span> <span class="o">=</span> <span class="n">context_residual</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">dunits</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">dunits</span> <span class="o">+</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dunits</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"lstm"</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">dunits</span> <span class="o">+</span> <span class="n">eprojs</span><span class="p">,</span>
                                                                                                 <span class="n">dunits</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">dunits</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"lstm"</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">dunits</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)]</span>
        <span class="c1"># NOTE: dropout is applied only for the vertical connections</span>
        <span class="c1"># see https://arxiv.org/pdf/1409.2329.pdf</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">if</span> <span class="n">context_residual</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span> <span class="o">+</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">odim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dunits</span><span class="p">,</span> <span class="n">odim</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">att</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span> <span class="o">=</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sos</span> <span class="o">=</span> <span class="n">sos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span> <span class="o">=</span> <span class="n">char_list</span>
    <span class="c1"># for label smoothing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labeldist</span> <span class="o">=</span> <span class="n">labeldist</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vlabeldist</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lsm_weight</span> <span class="o">=</span> <span class="n">lsm_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sampling_probability</span> <span class="o">=</span> <span class="n">sampling_probability</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">=</span> <span class="n">num_encs</span>

    <span class="c1"># for multilingual E2E-ST</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">replace_sos</span> <span class="o">=</span> <span class="n">replace_sos</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000000000.0</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlen</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate all of attentions</p>
<p>:param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)
                            [in multi-encoder case,
                            list of torch.Tensor, [(B, Tmax_1, D), (B, Tmax_2, D), ..., ] ]
:param torch.Tensor hlen: batch of lengths of hidden state sequences (B)
                            [in multi-encoder case, list of torch.Tensor, [(B), (B), ..., ]
:param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)
:param int strm_idx: stream index for parallel speaker attention in multi-speaker case
:param torch.Tensor lang_ids: batch of target language id tensor (B, 1)
:return: attention weights with the following shape,
    1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
    2) multi-encoder case =&gt; [(B, Lmax, Tmax1), (B, Lmax, Tmax2), ..., (B, Lmax, NumEncs)]
    3) other case =&gt; attention weights (B, Lmax, Tmax).
:rtype: float ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
781
782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803
804
805</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlen</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Calculate all of attentions</span>

<span class="sd">        :param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)</span>
<span class="sd">                                    [in multi-encoder case,</span>
<span class="sd">                                    list of torch.Tensor, [(B, Tmax_1, D), (B, Tmax_2, D), ..., ] ]</span>
<span class="sd">        :param torch.Tensor hlen: batch of lengths of hidden state sequences (B)</span>
<span class="sd">                                    [in multi-encoder case, list of torch.Tensor, [(B), (B), ..., ]</span>
<span class="sd">        :param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)</span>
<span class="sd">        :param int strm_idx: stream index for parallel speaker attention in multi-speaker case</span>
<span class="sd">        :param torch.Tensor lang_ids: batch of target language id tensor (B, 1)</span>
<span class="sd">        :return: attention weights with the following shape,</span>
<span class="sd">            1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),</span>
<span class="sd">            2) multi-encoder case =&gt; [(B, Lmax, Tmax1), (B, Lmax, Tmax2), ..., (B, Lmax, NumEncs)]</span>
<span class="sd">            3) other case =&gt; attention weights (B, Lmax, Tmax).</span>
<span class="sd">        :rtype: float ndarray</span>
<span class="sd">    """</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">hs_pad</span> <span class="o">=</span> <span class="p">[</span><span class="n">hs_pad</span><span class="p">]</span>
        <span class="n">hlen</span> <span class="o">=</span> <span class="p">[</span><span class="n">hlen</span><span class="p">]</span>

    <span class="c1"># TODO(kan-bayashi): need to make more smart way</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys_pad</span><span class="p">]</span>  <span class="c1"># parse padded ys</span>
    <span class="n">att_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">strm_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># hlen should be list of list of integer</span>
    <span class="n">hlen</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">hlen</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># prepare input and output word sequences with sos/eos IDs</span>
    <span class="n">eos</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">])</span>
    <span class="n">sos</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_sos</span><span class="p">:</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">idx</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lang_ids</span><span class="p">,</span> <span class="n">ys</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sos</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>
    <span class="n">ys_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">eos</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>

    <span class="c1"># padding for ys with -1</span>
    <span class="c1"># pys: utt x olen</span>
    <span class="n">ys_in_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>
    <span class="n">ys_out_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>

    <span class="c1"># get length info</span>
    <span class="n">olength</span> <span class="o">=</span> <span class="n">ys_out_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># initialization</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="n">c_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">z_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">att_w</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">att_w_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_c_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>  <span class="c1"># atts</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h in atts and han</span>

    <span class="c1"># pre-computation of embedding</span>
    <span class="n">eys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">ys_in_pad</span><span class="p">))</span>  <span class="c1"># utt x olen x zdim</span>

    <span class="c1"># loop for an output sequence</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">olength</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">](</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hlen</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">att_w</span><span class="p">)</span>
            <span class="n">att_ws</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att_w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">att_c_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">hs_pad</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">hlen</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">hs_pad_han</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_c_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">hlen_han</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys_in</span><span class="p">)</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">](</span><span class="n">hs_pad_han</span><span class="p">,</span> <span class="n">hlen_han</span><span class="p">,</span>
                                                                       <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                                                       <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">])</span>
            <span class="n">att_ws</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">)</span>
        <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">eys</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># utt x (zdim + hdim)</span>
        <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_forward</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># convert to numpy array with the shape (B, Lmax, Tmax)</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">att_to_numpy</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_att_ws</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ws</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">att_ws</span><span class="p">)):</span>
            <span class="n">ws</span> <span class="o">=</span> <span class="n">att_to_numpy</span><span class="p">(</span><span class="n">ws</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">_att_ws</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ws</span><span class="p">)</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="n">_att_ws</span>
    <span class="k">return</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Decoder forward</p>
<p>:param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)
                            [in multi-encoder case,
                            list of torch.Tensor, [(B, Tmax_1, D), (B, Tmax_2, D), ..., ] ]
:param torch.Tensor hlens: batch of lengths of hidden state sequences (B)
                            [in multi-encoder case, list of torch.Tensor, [(B), (B), ..., ]
:param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)
:param int strm_idx: stream index indicates the index of decoding stream.
:param torch.Tensor lang_ids: batch of target language id tensor (B, 1)
:return: attention loss value
:rtype: torch.Tensor
:return: accuracy
:rtype: float</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys_pad</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Decoder forward</span>

<span class="sd">    :param torch.Tensor hs_pad: batch of padded hidden state sequences (B, Tmax, D)</span>
<span class="sd">                                [in multi-encoder case,</span>
<span class="sd">                                list of torch.Tensor, [(B, Tmax_1, D), (B, Tmax_2, D), ..., ] ]</span>
<span class="sd">    :param torch.Tensor hlens: batch of lengths of hidden state sequences (B)</span>
<span class="sd">                                [in multi-encoder case, list of torch.Tensor, [(B), (B), ..., ]</span>
<span class="sd">    :param torch.Tensor ys_pad: batch of padded character id sequence tensor (B, Lmax)</span>
<span class="sd">    :param int strm_idx: stream index indicates the index of decoding stream.</span>
<span class="sd">    :param torch.Tensor lang_ids: batch of target language id tensor (B, 1)</span>
<span class="sd">    :return: attention loss value</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return: accuracy</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    """</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">hs_pad</span> <span class="o">=</span> <span class="p">[</span><span class="n">hs_pad</span><span class="p">]</span>
        <span class="n">hlens</span> <span class="o">=</span> <span class="p">[</span><span class="n">hlens</span><span class="p">]</span>

    <span class="c1"># TODO(kan-bayashi): need to make more smart way</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys_pad</span><span class="p">]</span>  <span class="c1"># parse padded ys</span>
    <span class="c1"># attention index for the attention module</span>
    <span class="c1"># in SPA (speaker parallel attention), att_idx is used to select attention module. In other cases, it is 0.</span>
    <span class="n">att_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">strm_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># hlens should be list of list of integer</span>
    <span class="n">hlens</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># prepare input and output word sequences with sos/eos IDs</span>
    <span class="n">eos</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">])</span>
    <span class="n">sos</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_sos</span><span class="p">:</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">idx</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lang_ids</span><span class="p">,</span> <span class="n">ys</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ys_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sos</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>
    <span class="n">ys_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">eos</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>

    <span class="c1"># padding for ys with -1</span>
    <span class="c1"># pys: utt x olen</span>
    <span class="n">ys_in_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>
    <span class="n">ys_out_pad</span> <span class="o">=</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>

    <span class="c1"># get dim, length info</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">ys_out_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">olength</span> <span class="o">=</span> <span class="n">ys_out_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">'Number of Encoder:</span><span class="si">{}</span><span class="s1">; enc</span><span class="si">{}</span><span class="s1">: input lengths: </span><span class="si">{}</span><span class="s1">.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">,</span>
                                                                                               <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' output lengths: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys_out</span><span class="p">]))</span>

    <span class="c1"># initialization</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="n">c_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">z_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">z_all</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">att_w</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">att_w_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_c_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>  <span class="c1"># atts</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h in atts and han</span>

    <span class="c1"># pre-computation of embedding</span>
    <span class="n">eys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">ys_in_pad</span><span class="p">))</span>  <span class="c1"># utt x olen x zdim</span>

    <span class="c1"># loop for an output sequence</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">olength</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">](</span><span class="n">hs_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hlens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">att_w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">att_c_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">hs_pad</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">hs_pad_han</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_c_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">hlens_han</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys_in</span><span class="p">)</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">](</span><span class="n">hs_pad_han</span><span class="p">,</span> <span class="n">hlens_han</span><span class="p">,</span>
                                                                       <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                                                       <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_probability</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">' scheduled sampling '</span><span class="p">)</span>
            <span class="n">z_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">z_all</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">z_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">z_out</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">z_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_out</span><span class="p">)))</span>
            <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">z_out</span><span class="p">,</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># utt x (zdim + hdim)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">eys</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># utt x (zdim + hdim)</span>
        <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_forward</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_residual</span><span class="p">:</span>
            <span class="n">z_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># utt x (zdim + hdim)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># utt x (zdim)</span>

    <span class="n">z_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">z_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span> <span class="o">*</span> <span class="n">olength</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute loss</span>
    <span class="n">y_all</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">z_all</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">'1.0'</span><span class="p">):</span>
        <span class="n">reduction_str</span> <span class="o">=</span> <span class="s1">'elementwise_mean'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">reduction_str</span> <span class="o">=</span> <span class="s1">'mean'</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">y_all</span><span class="p">,</span> <span class="n">ys_out_pad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                                <span class="n">ignore_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">,</span>
                                <span class="n">reduction</span><span class="o">=</span><span class="n">reduction_str</span><span class="p">)</span>
    <span class="c1"># compute perplexity</span>
    <span class="n">ppl</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="c1"># -1: eos, which is removed in the loss computation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">*=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ys_in</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">th_accuracy</span><span class="p">(</span><span class="n">y_all</span><span class="p">,</span> <span class="n">ys_out_pad</span><span class="p">,</span> <span class="n">ignore_label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'att loss:'</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)))</span>

    <span class="c1"># show predicted character sequence for debug</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">y_all</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">olength</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ys_true</span> <span class="o">=</span> <span class="n">ys_out_pad</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">),</span> <span class="n">y_true</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">ys_hat</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
                                      <span class="n">ys_true</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">MAX_DECODER_OUTPUT</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">idx_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">y_true</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">idx_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">y_true</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_id</span><span class="p">]</span>
            <span class="n">seq_hat</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idx_hat</span><span class="p">]</span>
            <span class="n">seq_true</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idx_true</span><span class="p">]</span>
            <span class="n">seq_hat</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_hat</span><span class="p">)</span>
            <span class="n">seq_true</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"groundtruth[</span><span class="si">%d</span><span class="s2">]: "</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="n">seq_true</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"prediction [</span><span class="si">%d</span><span class="s2">]: "</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="n">seq_hat</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">labeldist</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlabeldist</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vlabeldist</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labeldist</span><span class="p">))</span>
        <span class="n">loss_reg</span> <span class="o">=</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">y_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlabeldist</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys_in</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lsm_weight</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lsm_weight</span> <span class="o">*</span> <span class="n">loss_reg</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">ppl</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="init_state()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.init_state">
<code class="highlight language-python">
init_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Get an initial state for decoding (optional).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>The encoded feature tensor</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Returns: initial state</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
860
861
862
863
864</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>

    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="n">c_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
        <span class="n">z_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="c1"># TODO(karita): support strm_index for `asr_mix`</span>
    <span class="n">strm_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">att_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">strm_index</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h in atts and han</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">c_prev</span><span class="o">=</span><span class="n">c_list</span><span class="p">[:],</span> <span class="n">z_prev</span><span class="o">=</span><span class="n">z_list</span><span class="p">[:],</span> <span class="n">a_prev</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">workspace</span><span class="o">=</span><span class="p">(</span><span class="n">att_idx</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="recognize_beam()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam">
<code class="highlight language-python">
recognize_beam<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>beam search implementation</p>
<p>:param torch.Tensor h: encoder hidden state (T, eprojs)
                        [in multi-encoder case, list of torch.Tensor, [(T1, eprojs), (T2, eprojs), ...] ]
:param torch.Tensor lpz: ctc log softmax output (T, odim)
                        [in multi-encoder case, list of torch.Tensor, [(T1, odim), (T2, odim), ...] ]
:param Namespace recog_args: argument Namespace containing options
:param char_list: list of character strings
:param torch.nn.Module rnnlm: language module
:param int strm_idx: stream index for speaker parallel attention in multi-speaker case
:return: N-best decoding results
:rtype: list of dicts</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize_beam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""beam search implementation</span>

<span class="sd">    :param torch.Tensor h: encoder hidden state (T, eprojs)</span>
<span class="sd">                            [in multi-encoder case, list of torch.Tensor, [(T1, eprojs), (T2, eprojs), ...] ]</span>
<span class="sd">    :param torch.Tensor lpz: ctc log softmax output (T, odim)</span>
<span class="sd">                            [in multi-encoder case, list of torch.Tensor, [(T1, odim), (T2, odim), ...] ]</span>
<span class="sd">    :param Namespace recog_args: argument Namespace containing options</span>
<span class="sd">    :param char_list: list of character strings</span>
<span class="sd">    :param torch.nn.Module rnnlm: language module</span>
<span class="sd">    :param int strm_idx: stream index for speaker parallel attention in multi-speaker case</span>
<span class="sd">    :return: N-best decoding results</span>
<span class="sd">    :rtype: list of dicts</span>
<span class="sd">    """</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="p">]</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="p">[</span><span class="n">lpz</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">lpz</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="p">[</span><span class="n">lpz</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Number of Encoder:</span><span class="si">{}</span><span class="s1">; enc</span><span class="si">{}</span><span class="s1">: input lengths: </span><span class="si">{}</span><span class="s1">.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="n">att_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">strm_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># initialization</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="n">c_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
        <span class="n">z_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_w_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_c_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>  <span class="c1"># atts</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h in atts and han</span>

    <span class="c1"># search parms</span>
    <span class="n">beam</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">beam_size</span>
    <span class="n">penalty</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">penalty</span>
    <span class="n">ctc_weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">recog_args</span><span class="p">,</span> <span class="s2">"ctc_weight"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># for NMT</span>

    <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># weights-ctc, e.g. ctc_loss = w_1*ctc_1_loss + w_2 * ctc_2_loss + w_N * ctc_N_loss</span>
        <span class="n">weights_ctc_dec</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">weights_ctc_dec</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">weights_ctc_dec</span><span class="p">)</span>  <span class="c1"># normalize</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'ctc weights (decoding): '</span> <span class="o">+</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">weights_ctc_dec</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights_ctc_dec</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span>

    <span class="c1"># preprate sos</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_sos</span> <span class="ow">and</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">char_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; index: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; mark: '</span> <span class="o">+</span> <span class="n">char_list</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
    <span class="n">vy</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">([</span><span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)])</span>
    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># maxlen &gt;= 1</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">*</span> <span class="n">maxlen</span><span class="p">))</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">*</span> <span class="n">maxlen</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'max output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'min output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">minlen</span><span class="p">))</span>

    <span class="c1"># initialize hypothesis</span>
    <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'score'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">'yseq'</span><span class="p">:</span> <span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="s1">'c_prev'</span><span class="p">:</span> <span class="n">c_list</span><span class="p">,</span>
               <span class="s1">'z_prev'</span><span class="p">:</span> <span class="n">z_list</span><span class="p">,</span> <span class="s1">'a_prev'</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span> <span class="s1">'rnnlm_prev'</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'score'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">'yseq'</span><span class="p">:</span> <span class="p">[</span><span class="n">y</span><span class="p">],</span> <span class="s1">'c_prev'</span><span class="p">:</span> <span class="n">c_list</span><span class="p">,</span> <span class="s1">'z_prev'</span><span class="p">:</span> <span class="n">z_list</span><span class="p">,</span> <span class="s1">'a_prev'</span><span class="p">:</span> <span class="n">a</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ctc_prefix_score</span> <span class="o">=</span> <span class="p">[</span><span class="n">CTCPrefixScore</span><span class="p">(</span><span class="n">lpz</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="n">np</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                            <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
        <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctc_prefix_score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">initial_state</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
        <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span>
        <span class="k">if</span> <span class="n">ctc_weight</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># pre-pruning based on attention scores</span>
            <span class="n">ctc_beam</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">int</span><span class="p">(</span><span class="n">beam</span> <span class="o">*</span> <span class="n">CTC_SCORING_RATIO</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ctc_beam</span> <span class="o">=</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">hyps</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyp</span><span class="p">]</span>
    <span class="n">ended_hyps</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">maxlen</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'position '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="n">hyps_best_kept</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
            <span class="n">vy</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">vy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="n">ey</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">vy</span><span class="p">))</span>  <span class="c1"># utt list (1) x zdim</span>
            <span class="n">ey</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">](</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                    <span class="n">att_c_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                                                                     <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                                                                     <span class="n">hyp</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">h_han</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_c_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">](</span><span class="n">h_han</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">],</span>
                                                                           <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                                                                           <span class="n">hyp</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">])</span>
            <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ey</span><span class="p">,</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># utt(1) x (zdim + hdim)</span>
            <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_forward</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">],</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'c_prev'</span><span class="p">])</span>

            <span class="c1"># get nbest local scores and their ids</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_residual</span><span class="p">:</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">local_att_scores</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                <span class="n">rnnlm_state</span><span class="p">,</span> <span class="n">local_lm_scores</span> <span class="o">=</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">],</span> <span class="n">vy</span><span class="p">)</span>
                <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_att_scores</span> <span class="o">+</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">local_lm_scores</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_att_scores</span>

            <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
                    <span class="n">local_att_scores</span><span class="p">,</span> <span class="n">ctc_beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ctc_scores</span><span class="p">,</span> <span class="n">ctc_states</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                    <span class="n">ctc_scores</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">ctc_states</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctc_prefix_score</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span>
                        <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">],</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">local_scores</span> <span class="o">=</span> \
                    <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">ctc_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">local_att_scores</span><span class="p">[:,</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">local_scores</span> <span class="o">+=</span> <span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ctc_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                        <span class="n">local_scores</span> <span class="o">+=</span> <span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">weights_ctc_dec</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                            <span class="n">ctc_scores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                    <span class="n">local_scores</span> <span class="o">+=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">local_lm_scores</span><span class="p">[:,</span> <span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">joint_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">local_scores</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">local_best_ids</span><span class="p">[:,</span> <span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">local_best_scores</span><span class="p">,</span> <span class="n">local_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">local_scores</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">beam</span><span class="p">):</span>
                <span class="n">new_hyp</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="c1"># [:] is needed!</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">z_list</span><span class="p">[:]</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'c_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_list</span><span class="p">[:]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">att_w</span><span class="p">[:]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">][:]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+</span> <span class="n">local_best_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]))</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])]</span> <span class="o">=</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span>
                <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">local_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rnnlm_state</span>
                <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'ctc_state_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctc_states</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                                                 <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
                    <span class="n">new_hyp</span><span class="p">[</span><span class="s1">'ctc_score_prev'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctc_scores</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">joint_best_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                                                 <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
                <span class="c1"># will be (2 x beam) hyps at most</span>
                <span class="n">hyps_best_kept</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_hyp</span><span class="p">)</span>

            <span class="n">hyps_best_kept</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">hyps_best_kept</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">beam</span><span class="p">]</span>

        <span class="c1"># sort and get nbest</span>
        <span class="n">hyps</span> <span class="o">=</span> <span class="n">hyps_best_kept</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'number of pruned hypotheses: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s1">'best hypo: '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'yseq'</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span>

        <span class="c1"># add eos in the final loop to avoid that there are no ended hyps</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'adding &lt;eos&gt; in the last position in the loop'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
                <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>

        <span class="c1"># add ended hypotheses to a final list, and removed them from current hypotheses</span>
        <span class="c1"># (this will be a problem, number of hyps &lt; beam)</span>
        <span class="n">remained_hyps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">:</span>
                <span class="c1"># only store the sequence that has more than minlen outputs</span>
                <span class="c1"># also add penalty</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">minlen</span><span class="p">:</span>
                    <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">penalty</span>
                    <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>  <span class="c1"># Word LM needs to add final &lt;eos&gt; score</span>
                        <span class="n">hyp</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">+=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">final</span><span class="p">(</span>
                            <span class="n">hyp</span><span class="p">[</span><span class="s1">'rnnlm_prev'</span><span class="p">])</span>
                    <span class="n">ended_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">remained_hyps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span>

        <span class="c1"># end detection</span>
        <span class="k">if</span> <span class="n">end_detect</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">and</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'end detected at </span><span class="si">%d</span><span class="s1">'</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="n">hyps</span> <span class="o">=</span> <span class="n">remained_hyps</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'remaining hypotheses: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyps</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'no hypothesis. Finish decoding.'</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hyps</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="s1">'hypo: '</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">hyp</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'number of ended hypotheses: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">)))</span>

    <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
        <span class="n">ended_hyps</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">),</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">nbest</span><span class="p">)]</span>

    <span class="c1"># check number of hypotheses</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">'there is no N-best results, perform recognition again with smaller minlenratio.'</span><span class="p">)</span>
        <span class="c1"># should copy because Namespace will be overwritten globally</span>
        <span class="n">recog_args</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">recog_args</span><span class="p">))</span>
        <span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">recognize_beam</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">recognize_beam</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'total log probability: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'score'</span><span class="p">]))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'normalized log probability: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_hyps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'yseq'</span><span class="p">])))</span>

    <span class="c1"># remove sos</span>
    <span class="k">return</span> <span class="n">nbest_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="recognize_beam_batch()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam_batch">
<code class="highlight language-python">
recognize_beam_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">recognize_beam_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">char_list</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">normalize_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">strm_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lang_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="p">]</span>
        <span class="n">hlens</span> <span class="o">=</span> <span class="p">[</span><span class="n">hlens</span><span class="p">]</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="p">[</span><span class="n">lpz</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">lpz</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lpz</span> <span class="o">=</span> <span class="p">[</span><span class="n">lpz</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span>

    <span class="n">att_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">strm_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s1">'Number of Encoder:</span><span class="si">{}</span><span class="s1">; enc</span><span class="si">{}</span><span class="s1">: input lengths: </span><span class="si">{}</span><span class="s1">.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_by_length</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># search params</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hlens</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">beam</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">beam_size</span>
    <span class="n">penalty</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">penalty</span>
    <span class="n">ctc_weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">recog_args</span><span class="p">,</span> <span class="s2">"ctc_weight"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># for NMT</span>
    <span class="n">att_weight</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">ctc_weight</span>
    <span class="n">ctc_margin</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">recog_args</span><span class="p">,</span> <span class="s2">"ctc_window_margin"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># use getattr to keep compatibility</span>
    <span class="c1"># weights-ctc, e.g. ctc_loss = w_1*ctc_1_loss + w_2 * ctc_2_loss + w_N * ctc_N_loss</span>
    <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">weights_ctc_dec</span> <span class="o">=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">weights_ctc_dec</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">weights_ctc_dec</span><span class="p">)</span>  <span class="c1"># normalize</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'ctc weights (decoding): '</span> <span class="o">+</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">weights_ctc_dec</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights_ctc_dec</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span>

    <span class="n">n_bb</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">beam</span>
    <span class="n">pad_b</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">*</span> <span class="n">beam</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">max_hlen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)])</span>
    <span class="k">if</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="n">max_hlen</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">maxlenratio</span> <span class="o">*</span> <span class="n">max_hlen</span><span class="p">))</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">minlenratio</span> <span class="o">*</span> <span class="n">max_hlen</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'max output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'min output length: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">minlen</span><span class="p">))</span>

    <span class="c1"># initialization</span>
    <span class="n">c_prev</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>
    <span class="n">z_prev</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>
    <span class="n">vscores</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">))</span>

    <span class="n">rnnlm_state</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a_prev</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
        <span class="n">att_w_list</span><span class="p">,</span> <span class="n">ctc_scorer</span><span class="p">,</span> <span class="n">ctc_state</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a_prev</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_w_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_c_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>  <span class="c1"># atts</span>
        <span class="n">ctc_scorer</span><span class="p">,</span> <span class="n">ctc_state</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">),</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset pre-computation of h in atts and han</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_sos</span> <span class="ow">and</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; index: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">char_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">)))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; mark: '</span> <span class="o">+</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">)</span>
        <span class="n">yseq</span> <span class="o">=</span> <span class="p">[[</span><span class="n">char_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">recog_args</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">)]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_bb</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">lang_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># NOTE: used for evaluation during training</span>
        <span class="n">yseq</span> <span class="o">=</span> <span class="p">[[</span><span class="n">lang_ids</span><span class="p">[</span><span class="n">b</span> <span class="o">//</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">beam_size</span><span class="p">]]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_bb</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; index: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'&lt;sos&gt; mark: '</span> <span class="o">+</span> <span class="n">char_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">])</span>
        <span class="n">yseq</span> <span class="o">=</span> <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_bb</span><span class="p">)]</span>

    <span class="n">accum_odim_ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_bb</span><span class="p">)]</span>
    <span class="n">stop_search</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>
    <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>
    <span class="n">ended_hyps</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>

    <span class="n">exp_hlens</span> <span class="o">=</span> <span class="p">[</span><span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">beam</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">beam</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                 <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
    <span class="n">exp_hlens</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp_hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
    <span class="n">exp_h</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>
    <span class="n">exp_h</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp_h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scoring_ratio</span> <span class="o">=</span> <span class="n">CTC_SCORING_RATIO</span> <span class="k">if</span> <span class="n">att_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lpz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">ctc_scorer</span> <span class="o">=</span> <span class="p">[</span><span class="n">CTCPrefixScoreTH</span><span class="p">(</span><span class="n">lpz</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span>
                                       <span class="n">scoring_ratio</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="n">ctc_margin</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">maxlen</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">'position '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="n">vy</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_last_yseq</span><span class="p">(</span><span class="n">yseq</span><span class="p">)))</span>
        <span class="n">ey</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">vy</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">](</span><span class="n">exp_h</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">exp_hlens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">a_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">att_w_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">att_w</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">att_c_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">exp_h</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">exp_hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">a_prev</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">exp_h_han</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_c_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">](</span><span class="n">exp_h_han</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_bb</span><span class="p">,</span>
                                                                       <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">z_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                                                       <span class="n">a_prev</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">])</span>
        <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ey</span><span class="p">,</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># attention decoder</span>
        <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_forward</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">,</span> <span class="n">c_prev</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_residual</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">local_scores</span> <span class="o">=</span> <span class="n">att_weight</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># rnnlm</span>
        <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
            <span class="n">rnnlm_state</span><span class="p">,</span> <span class="n">local_lm_scores</span> <span class="o">=</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">buff_predict</span><span class="p">(</span><span class="n">rnnlm_state</span><span class="p">,</span> <span class="n">vy</span><span class="p">,</span> <span class="n">n_bb</span><span class="p">)</span>
            <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_scores</span> <span class="o">+</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">local_lm_scores</span>

        <span class="c1"># ctc</span>
        <span class="k">if</span> <span class="n">ctc_scorer</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">att_w</span> <span class="o">=</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">att_w_</span> <span class="o">=</span> <span class="n">att_w</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">att_w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ctc_state</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">local_ctc_scores</span> <span class="o">=</span> <span class="n">ctc_scorer</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">yseq</span><span class="p">,</span> <span class="n">ctc_state</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">local_scores</span><span class="p">,</span> <span class="n">att_w_</span><span class="p">)</span>
                <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_scores</span> <span class="o">+</span> <span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">weights_ctc_dec</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">local_ctc_scores</span>

        <span class="n">local_scores</span> <span class="o">=</span> <span class="n">local_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">local_scores</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>

        <span class="c1"># accumulate scores</span>
        <span class="n">eos_vscores</span> <span class="o">=</span> <span class="n">local_scores</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">]</span> <span class="o">+</span> <span class="n">vscores</span>
        <span class="n">vscores</span> <span class="o">=</span> <span class="n">vscores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>
        <span class="n">vscores</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logzero</span>
        <span class="n">vscores</span> <span class="o">=</span> <span class="p">(</span><span class="n">vscores</span> <span class="o">+</span> <span class="n">local_scores</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># global pruning</span>
        <span class="n">accum_best_scores</span><span class="p">,</span> <span class="n">accum_best_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">vscores</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">accum_odim_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">accum_best_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">accum_padded_beam_ids</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">accum_best_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span> <span class="o">+</span> <span class="n">pad_b</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="n">y_prev</span> <span class="o">=</span> <span class="n">yseq</span><span class="p">[:][:]</span>
        <span class="n">yseq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_select_list</span><span class="p">(</span><span class="n">yseq</span><span class="p">,</span> <span class="n">accum_padded_beam_ids</span><span class="p">)</span>
        <span class="n">yseq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_ids</span><span class="p">(</span><span class="n">yseq</span><span class="p">,</span> <span class="n">accum_odim_ids</span><span class="p">)</span>
        <span class="n">vscores</span> <span class="o">=</span> <span class="n">accum_best_scores</span>
        <span class="n">vidx</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">accum_padded_beam_ids</span><span class="p">))</span>

        <span class="n">a_prev</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_atts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_atts</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">_a_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">*</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="c1"># handle the case of multi-head attention</span>
                <span class="n">_a_prev</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">att_w_one</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span> <span class="k">for</span> <span class="n">att_w_one</span> <span class="ow">in</span> <span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># handle the case of location_recurrent when return is a tuple</span>
                <span class="n">_a_prev_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
                <span class="n">_h_prev_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
                <span class="n">_c_prev_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">att_w_list</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
                <span class="n">_a_prev</span> <span class="o">=</span> <span class="p">(</span><span class="n">_a_prev_</span><span class="p">,</span> <span class="p">(</span><span class="n">_h_prev_</span><span class="p">,</span> <span class="n">_c_prev_</span><span class="p">))</span>
            <span class="n">a_prev</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_a_prev</span><span class="p">)</span>
        <span class="n">z_prev</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">li</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>
        <span class="n">c_prev</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">c_list</span><span class="p">[</span><span class="n">li</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_bb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">)]</span>

        <span class="c1"># pick ended hyps</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">minlen</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">penalty_i</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">penalty</span>
            <span class="n">thr</span> <span class="o">=</span> <span class="n">accum_best_scores</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">samp_i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">stop_search</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="n">beam</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">beam_j</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">beam</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">eos_vscores</span><span class="p">[</span><span class="n">samp_i</span><span class="p">,</span> <span class="n">beam_j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thr</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]:</span>
                        <span class="n">yk</span> <span class="o">=</span> <span class="n">y_prev</span><span class="p">[</span><span class="n">k</span><span class="p">][:]</span>
                        <span class="n">yk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">yk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="n">hlens</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">samp_i</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)):</span>
                            <span class="n">_vscore</span> <span class="o">=</span> <span class="n">eos_vscores</span><span class="p">[</span><span class="n">samp_i</span><span class="p">][</span><span class="n">beam_j</span><span class="p">]</span> <span class="o">+</span> <span class="n">penalty_i</span>
                            <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
                                <span class="n">_vscore</span> <span class="o">+=</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">lm_weight</span> <span class="o">*</span> <span class="n">rnnlm</span><span class="o">.</span><span class="n">final</span><span class="p">(</span><span class="n">rnnlm_state</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
                            <span class="n">_score</span> <span class="o">=</span> <span class="n">_vscore</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                            <span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">'yseq'</span><span class="p">:</span> <span class="n">yk</span><span class="p">,</span> <span class="s1">'vscore'</span><span class="p">:</span> <span class="n">_vscore</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">:</span> <span class="n">_score</span><span class="p">})</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># end detection</span>
        <span class="n">stop_search</span> <span class="o">=</span> <span class="p">[</span><span class="n">stop_search</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]</span> <span class="ow">or</span> <span class="n">end_detect</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">samp_i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>
        <span class="n">stop_search_summary</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">stop_search</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">stop_search_summary</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">stop_search_summary</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">break</span>

        <span class="k">if</span> <span class="n">rnnlm</span><span class="p">:</span>
            <span class="n">rnnlm_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_select_lm_state</span><span class="p">(</span><span class="n">rnnlm_state</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vidx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ctc_scorer</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
                <span class="n">ctc_state</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctc_scorer</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">index_select_state</span><span class="p">(</span><span class="n">ctc_state</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">accum_best_ids</span><span class="p">)</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="n">dummy_hyps</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">'yseq'</span><span class="p">:</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">],</span> <span class="s1">'score'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)])}]</span>
    <span class="n">ended_hyps</span> <span class="o">=</span> <span class="p">[</span><span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dummy_hyps</span>
                  <span class="k">for</span> <span class="n">samp_i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">normalize_score</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">samp_i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]:</span>
                <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">'yseq'</span><span class="p">])</span>

    <span class="n">nbest_hyps</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sorted</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">],</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'score'</span><span class="p">],</span>
                         <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ended_hyps</span><span class="p">[</span><span class="n">samp_i</span><span class="p">]),</span> <span class="n">recog_args</span><span class="o">.</span><span class="n">nbest</span><span class="p">)]</span>
                  <span class="k">for</span> <span class="n">samp_i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">nbest_hyps</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="rnn_forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.rnn_forward">
<code class="highlight language-python">
rnn_forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">,</span> <span class="n">c_prev</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>102
103
104
105
106
107
108
109
110
111
112</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">rnn_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">,</span> <span class="n">c_prev</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"lstm"</span><span class="p">:</span>
        <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">ey</span><span class="p">,</span> <span class="p">(</span><span class="n">z_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
            <span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">l</span><span class="p">](</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]),</span> <span class="p">(</span><span class="n">z_prev</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_prev</span><span class="p">[</span><span class="n">l</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlayers</span><span class="p">):</span>
            <span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">z_prev</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="score()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.score">
<code class="highlight language-python">
score<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yseq</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Score new token (required).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>y</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>1D torch.int64 prefix tokens.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>state</code></td>
<td><code></code></td>
<td>
<p>Scorer state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>The encoder feature that generates ys.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tuple[torch.Tensor, Any]</code></td>
<td>
<p>Tuple of
    scores for next token that has a shape of <code>(n_vocab)</code>
    and next state for ys</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>866
867
868
869
870
871
872
873
874
875
876
877
878
879
880
881
882
883
884
885
886
887
888
889
890
891
892
893
894
895
896</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yseq</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># to support mutiple encoder asr mode, in single encoder mode, convert torch.Tensor to List of torch.Tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>

    <span class="n">att_idx</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"workspace"</span><span class="p">]</span>
    <span class="n">vy</span> <span class="o">=</span> <span class="n">yseq</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ey</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_emb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">vy</span><span class="p">))</span>  <span class="c1"># utt list (1) x zdim</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">att_idx</span><span class="p">](</span>
            <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">state</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">state</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">att_w</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># atts + han</span>
        <span class="n">att_c_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">)</span>  <span class="c1"># atts</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">):</span>
            <span class="n">att_c_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">att_w</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">state</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                                                        <span class="n">state</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">h_han</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_c_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">](</span><span class="n">h_han</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">],</span>
                                                              <span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">state</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                                                              <span class="n">state</span><span class="p">[</span><span class="s1">'a_prev'</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encs</span><span class="p">])</span>
    <span class="n">ey</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ey</span><span class="p">,</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># utt(1) x (zdim + hdim)</span>
    <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_forward</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="s1">'z_prev'</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="s1">'c_prev'</span><span class="p">])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_residual</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">att_c</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_dec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">logp</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logp</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="n">c_prev</span><span class="o">=</span><span class="n">c_list</span><span class="p">[:],</span> <span class="n">z_prev</span><span class="o">=</span><span class="n">z_list</span><span class="p">[:],</span> <span class="n">a_prev</span><span class="o">=</span><span class="n">att_w</span><span class="p">,</span> <span class="n">workspace</span><span class="o">=</span><span class="p">(</span><span class="n">att_idx</span><span class="p">,</span> <span class="n">z_list</span><span class="p">,</span> <span class="n">c_list</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="zero_state()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.Decoder.zero_state">
<code class="highlight language-python">
zero_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 99
100</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs_pad</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">hs_pad</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">hs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dunits</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="decoder_for()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.decoders.decoder_for">
<code class="highlight language-python">
decoder_for<span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">labeldist</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/decoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>899
900
901
902
903
904
905</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">decoder_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">labeldist</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dlayers</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dunits</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                   <span class="n">args</span><span class="o">.</span><span class="n">char_list</span><span class="p">,</span> <span class="n">labeldist</span><span class="p">,</span>
                   <span class="n">args</span><span class="o">.</span><span class="n">lsm_weight</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">sampling_probability</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate_decoder</span><span class="p">,</span>
                   <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"context_residual"</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>  <span class="c1"># use getattr to keep compatibility</span>
                   <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"replace_sos"</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>  <span class="c1"># use getattr to keep compatibility</span>
                   <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"num_encs"</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># use getattr to keep compatibility</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders">
<code>encoders</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Encoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.Encoder">
<code>Encoder</code>
</h7>
<div class="doc doc-contents">
<p>Encoder module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param str etype: type of encoder network</span>
<span class="err">:param int idim: number of dimensions of encoder network</span>
<span class="err">:param int elayers: number of layers of encoder network</span>
<span class="err">:param int eunits: number of lstm units of encoder network</span>
<span class="err">:param int eprojs: number of projection units of encoder network</span>
<span class="err">:param np.ndarray subsample: list of subsampling numbers</span>
<span class="err">:param float dropout: dropout rate</span>
<span class="err">:param int in_channel: number of input channels</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.Encoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">typ</span> <span class="o">=</span> <span class="n">etype</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s2">"vgg"</span><span class="p">)</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">"p"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">typ</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'lstm'</span><span class="p">,</span> <span class="s1">'gru'</span><span class="p">,</span> <span class="s1">'blstm'</span><span class="p">,</span> <span class="s1">'bgru'</span><span class="p">]:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"Error: need to specify an appropriate encoder architecture"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">etype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"vgg"</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">etype</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"p"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">VGG2L</span><span class="p">(</span><span class="n">in_channel</span><span class="p">),</span>
                                            <span class="n">RNNP</span><span class="p">(</span><span class="n">get_vgg2l_odim</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channel</span><span class="p">),</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span>
                                                 <span class="n">eprojs</span><span class="p">,</span>
                                                 <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="n">typ</span><span class="p">)])</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Use CNN-VGG + '</span> <span class="o">+</span> <span class="n">typ</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="s1">'P for encoder'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">VGG2L</span><span class="p">(</span><span class="n">in_channel</span><span class="p">),</span>
                                            <span class="n">RNN</span><span class="p">(</span><span class="n">get_vgg2l_odim</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channel</span><span class="p">),</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span>
                                                <span class="n">eprojs</span><span class="p">,</span>
                                                <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="n">typ</span><span class="p">)])</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Use CNN-VGG + '</span> <span class="o">+</span> <span class="n">typ</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="s1">' for encoder'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">etype</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"p"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
                <span class="p">[</span><span class="n">RNNP</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="n">typ</span><span class="p">)])</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">typ</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="s1">' with every-layer projection for encoder'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">RNN</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">eunits</span><span class="p">,</span> <span class="n">eprojs</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="n">typ</span><span class="p">)])</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">typ</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="s1">' without projection for encoder'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.Encoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_states</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Encoder forward</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor prev_state: batch of previous encoder hidden states (?, ...)
:return: batch of hidden state sequences (B, Tmax, eprojs)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_states</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Encoder forward</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor prev_state: batch of previous encoder hidden states (?, ...)</span>
<span class="sd">    :return: batch of hidden state sequences (B, Tmax, eprojs)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">prev_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prev_states</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">prev_states</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">)</span>

    <span class="n">current_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">module</span><span class="p">,</span> <span class="n">prev_state</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">,</span> <span class="n">prev_states</span><span class="p">):</span>
        <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_state</span><span class="o">=</span><span class="n">prev_state</span><span class="p">)</span>
        <span class="n">current_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>

    <span class="c1"># make mask to remove bias value in padded part</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_pad_mask</span><span class="p">(</span><span class="n">ilens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">current_states</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="RNN" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNN">
<code>RNN</code>
</h7>
<div class="doc doc-contents">
<p>RNN module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: dimension of inputs</span>
<span class="err">:param int elayers: number of encoder layers</span>
<span class="err">:param int cdim: number of rnn units (resulted in cdim * 2 if bidirectional)</span>
<span class="err">:param int hdim: number of final projection units</span>
<span class="err">:param float dropout: dropout rate</span>
<span class="err">:param str typ: The RNN type</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNN.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="s1">'blstm'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 98
 99
100
101
102
103
104
105
106
107
108
109</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="s2">"blstm"</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">bidir</span> <span class="o">=</span> <span class="n">typ</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"b"</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nbrnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">)</span> <span class="k">if</span> <span class="s2">"lstm"</span> <span class="ow">in</span> <span class="n">typ</span> \
        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                          <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bidir</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_last</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">cdim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hdim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_last</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">typ</span> <span class="o">=</span> <span class="n">typ</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNN.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>RNN forward</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor prev_state: batch of previous RNN states
:return: batch of hidden state sequences (B, Tmax, eprojs)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""RNN forward</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor prev_state: batch of previous RNN states</span>
<span class="sd">    :return: batch of hidden state sequences (B, Tmax, eprojs)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' input lengths: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ilens</span><span class="p">))</span>
    <span class="n">xs_pack</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nbrnn</span><span class="o">.</span><span class="n">flatten_parameters</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">prev_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbrnn</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
        <span class="c1"># We assume that when previous state is passed, it means that we're streaming the input</span>
        <span class="c1"># and therefore cannot propagate backward BRNN state (otherwise it goes in the wrong direction)</span>
        <span class="n">prev_state</span> <span class="o">=</span> <span class="n">reset_backward_rnn_state</span><span class="p">(</span><span class="n">prev_state</span><span class="p">)</span>
    <span class="n">ys</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbrnn</span><span class="p">(</span><span class="n">xs_pack</span><span class="p">,</span> <span class="n">hx</span><span class="o">=</span><span class="n">prev_state</span><span class="p">)</span>
    <span class="c1"># ys: utt list of frame x cdim x 2 (2: means bidirectional)</span>
    <span class="n">ys_pad</span><span class="p">,</span> <span class="n">ilens</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># (sum _utt frame_utt) x dim</span>
    <span class="n">projected</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l_last</span><span class="p">(</span>
        <span class="n">ys_pad</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))))</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">projected</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">states</span>  <span class="c1"># x: utt list of frame x dim</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="RNNP" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNNP">
<code>RNNP</code>
</h7>
<div class="doc doc-contents">
<p>RNN with projection layer module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: dimension of inputs</span>
<span class="err">:param int elayers: number of encoder layers</span>
<span class="err">:param int cdim: number of rnn units (resulted in cdim * 2 if bidirectional)</span>
<span class="err">:param int hdim: number of projection units</span>
<span class="err">:param np.ndarray subsample: list of subsampling numbers</span>
<span class="err">:param float dropout: dropout rate</span>
<span class="err">:param str typ: The RNN type</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNNP.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="s1">'blstm'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="s2">"blstm"</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RNNP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">bidir</span> <span class="o">=</span> <span class="n">typ</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"b"</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">elayers</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">inputdim</span> <span class="o">=</span> <span class="n">idim</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputdim</span> <span class="o">=</span> <span class="n">hdim</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">inputdim</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span>
                            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="s2">"lstm"</span> <span class="ow">in</span> <span class="n">typ</span> \
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">inputdim</span><span class="p">,</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"</span><span class="si">%s%d</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="s2">"birnn"</span> <span class="k">if</span> <span class="n">bidir</span> <span class="k">else</span> <span class="s2">"rnn"</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span> <span class="n">rnn</span><span class="p">)</span>
        <span class="c1"># bottleneck layer to merge</span>
        <span class="k">if</span> <span class="n">bidir</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"bt</span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"bt</span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">cdim</span><span class="p">,</span> <span class="n">hdim</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">elayers</span> <span class="o">=</span> <span class="n">elayers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cdim</span> <span class="o">=</span> <span class="n">cdim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="n">subsample</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">typ</span> <span class="o">=</span> <span class="n">typ</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bidir</span> <span class="o">=</span> <span class="n">bidir</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.RNNP.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>RNNP forward</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:param torch.Tensor prev_state: batch of previous RNN states
:return: batch of hidden state sequences (B, Tmax, hdim)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">prev_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""RNNP forward</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :param torch.Tensor prev_state: batch of previous RNN states</span>
<span class="sd">    :return: batch of hidden state sequences (B, Tmax, hdim)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' input lengths: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ilens</span><span class="p">))</span>
    <span class="n">elayer_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">elayers</span><span class="p">):</span>
        <span class="n">xs_pack</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">(</span><span class="s2">"birnn"</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bidir</span> <span class="k">else</span> <span class="s2">"rnn"</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">layer</span><span class="p">))</span>
        <span class="n">rnn</span><span class="o">.</span><span class="n">flatten_parameters</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">prev_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">rnn</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
            <span class="n">prev_state</span> <span class="o">=</span> <span class="n">reset_backward_rnn_state</span><span class="p">(</span><span class="n">prev_state</span><span class="p">)</span>
        <span class="n">ys</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">xs_pack</span><span class="p">,</span> <span class="n">hx</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">prev_state</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prev_state</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
        <span class="n">elayer_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="c1"># ys: utt list of frame x cdim x 2 (2: means bidirectional)</span>
        <span class="n">ys_pad</span><span class="p">,</span> <span class="n">ilens</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">sub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">[</span><span class="n">layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">sub</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ys_pad</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="p">[:,</span> <span class="p">::</span><span class="n">sub</span><span class="p">]</span>
            <span class="n">ilens</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">sub</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ilens</span><span class="p">]</span>
        <span class="c1"># (sum _utt frame_utt) x dim</span>
        <span class="n">projected</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'bt'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                            <span class="p">)(</span><span class="n">ys_pad</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">elayers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">projected</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">projected</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">elayer_states</span>  <span class="c1"># x: utt list of frame x dim</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="VGG2L" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.VGG2L">
<code>VGG2L</code>
</h7>
<div class="doc doc-contents">
<p>VGG-like module</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int in_channel: number of input channels</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.VGG2L.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>153
154
155
156
157
158
159
160
161</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">VGG2L</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># CNN layer (VGG motivated)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">in_channel</span> <span class="o">=</span> <span class="n">in_channel</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.VGG2L.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>VGG2L forward</p>
<p>:param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)
:param torch.Tensor ilens: batch of lengths of input sequences (B)
:return: batch of padded hidden state sequences (B, Tmax // 4, 128 * D // 4)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""VGG2L forward</span>

<span class="sd">    :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, D)</span>
<span class="sd">    :param torch.Tensor ilens: batch of lengths of input sequences (B)</span>
<span class="sd">    :return: batch of padded hidden state sequences (B, Tmax // 4, 128 * D // 4)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">' input lengths: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ilens</span><span class="p">))</span>

    <span class="c1"># x: utt x frame x dim</span>
    <span class="c1"># xs_pad = F.pad_sequence(xs_pad)</span>

    <span class="c1"># x: utt x 1 (input channel num) x frame x dim</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channel</span><span class="p">,</span>
                         <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channel</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># NOTE: max_pool1d ?</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1_1</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">))</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1_2</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">))</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2_1</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">))</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2_2</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">))</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">xs_pad</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ilens</span><span class="p">):</span>
        <span class="n">ilens</span> <span class="o">=</span> <span class="n">ilens</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ilens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ilens</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ilens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># x: utt_list of frame (remove zeropaded frames) x (input channel num x dim)</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">xs_pad</span> <span class="o">=</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
        <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">xs_pad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">xs_pad</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="kc">None</span>  <span class="c1"># no state in this layer</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="encoder_for()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.encoder_for">
<code class="highlight language-python">
encoder_for<span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">subsample</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Instantiates an encoder module given the program arguments</p>
<p>:param Namespace args: The arguments
:param int or List of integer idim: dimension of input, e.g. 83, or
                                    List of dimensions of inputs, e.g. [83,83]
:param List or List of List subsample: subsample factors, e.g. [1,2,2,1,1], or
                                    List of subsample factors of each encoder. e.g. [[1,2,2,1,1], [1,2,2,1,1]]
:rtype torch.nn.Module
:return: The encoder module</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encoder_for</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">subsample</span><span class="p">):</span>
    <span class="sd">"""Instantiates an encoder module given the program arguments</span>

<span class="sd">    :param Namespace args: The arguments</span>
<span class="sd">    :param int or List of integer idim: dimension of input, e.g. 83, or</span>
<span class="sd">                                        List of dimensions of inputs, e.g. [83,83]</span>
<span class="sd">    :param List or List of List subsample: subsample factors, e.g. [1,2,2,1,1], or</span>
<span class="sd">                                        List of subsample factors of each encoder. e.g. [[1,2,2,1,1], [1,2,2,1,1]]</span>
<span class="sd">    :rtype torch.nn.Module</span>
<span class="sd">    :return: The encoder module</span>
<span class="sd">    """</span>
    <span class="n">num_encs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"num_encs"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># use getattr to keep compatibility</span>
    <span class="k">if</span> <span class="n">num_encs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># compatible with single encoder asr mode</span>
        <span class="k">return</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">etype</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">num_encs</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">enc_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_encs</span><span class="p">):</span>
            <span class="n">enc</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">etype</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">idim</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">elayers</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">eunits</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">eprojs</span><span class="p">,</span> <span class="n">subsample</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                          <span class="n">args</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">enc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">enc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">enc_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Number of encoders needs to be more than one. </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_encs</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="reset_backward_rnn_state()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.rnn.encoders.reset_backward_rnn_state">
<code class="highlight language-python">
reset_backward_rnn_state<span class="p">(</span><span class="n">states</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Sets backward BRNN states to zeroes - useful in processing of sliding windows over the inputs</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/rnn/encoders.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>137
138
139
140
141
142
143
144</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset_backward_rnn_state</span><span class="p">(</span><span class="n">states</span><span class="p">):</span>
    <span class="sd">"""Sets backward BRNN states to zeroes - useful in processing of sliding windows over the inputs"""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">states</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">return</span> <span class="n">states</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming">
<code>streaming</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment">
<code>segment</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="SegmentStreamingE2E" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E">
<code>SegmentStreamingE2E</code>
</h7>
<div class="doc doc-contents">
<p>SegmentStreamingE2E constructor.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param E2E e2e: E2E ASR object</span>
<span class="err">:param recog_args: arguments for "recognize" method of E2E</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e2e</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/streaming/segment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e2e</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span> <span class="o">=</span> <span class="n">e2e</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span> <span class="o">=</span> <span class="n">recog_args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span> <span class="o">=</span> <span class="n">e2e</span><span class="o">.</span><span class="n">char_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rnnlm</span> <span class="o">=</span> <span class="n">rnnlm</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_blank_idx_in_char_list</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">blank</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_blank_idx_in_char_list</span> <span class="o">=</span> <span class="n">idx</span>
            <span class="k">break</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_subsampling_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">e2e</span><span class="o">.</span><span class="n">subsample</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_activates</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">batchsize</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> \
        <span class="s2">"SegmentStreamingE2E works only with batch size &lt;= 1"</span>
    <span class="k">assert</span> <span class="s2">"b"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">etype</span><span class="p">,</span> \
        <span class="s2">"SegmentStreamingE2E works only with uni-directional encoders"</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="accept_input()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E.accept_input">
<code class="highlight language-python">
accept_input<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Call this method each time a new batch of input is available.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/streaming/segment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">accept_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Call this method each time a new batch of input is available."""</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">ilen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">subsample_frames</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Run encoder and apply greedy search on CTC softmax output</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span>
        <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">ilen</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span>
    <span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activates</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blank_idx_in_char_list</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_activates</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># Rerun encoder with zero state at onset of detection</span>
        <span class="n">tail_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subsampling_factor</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">streaming_onset_margin</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">ilen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">subsample_frames</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span><span class="p">[</span><span class="o">-</span><span class="n">tail_len</span><span class="p">:],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])]))</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span>
            <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">ilen</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">hyp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activates</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blank_idx_in_char_list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">streaming_min_blank_dur</span><span class="p">:</span>
            <span class="n">seg_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">streaming_offset_margin</span>
            <span class="k">if</span> <span class="n">seg_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Run decoder with a detected segment</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span><span class="p">[:</span><span class="n">seg_len</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="n">lpz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span><span class="p">[:</span><span class="n">seg_len</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">batchsize</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">lpz</span> <span class="o">=</span> <span class="n">lpz</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">normalize_score</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">lpz</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">normalize_score</span> <span class="o">=</span> <span class="kc">True</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">batchsize</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">hyp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam</span><span class="p">(</span>
                        <span class="n">h</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnnlm</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">hlens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                    <span class="n">hyp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam_batch</span><span class="p">(</span>
                        <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnnlm</span><span class="p">,</span> <span class="n">normalize_score</span><span class="o">=</span><span class="n">normalize_score</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_activates</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_blank_dur</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">tail_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subsampling_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">streaming_onset_margin</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_input</span><span class="p">[</span><span class="o">-</span><span class="n">tail_len</span><span class="p">:]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">return</span> <span class="n">hyp</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window">
<code>window</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="WindowStreamingE2E" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window.WindowStreamingE2E">
<code>WindowStreamingE2E</code>
</h7>
<div class="doc doc-contents">
<p>WindowStreamingE2E constructor.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param E2E e2e: E2E ASR object</span>
<span class="err">:param recog_args: arguments for "recognize" method of E2E</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window.WindowStreamingE2E.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e2e</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/streaming/window.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e2e</span><span class="p">,</span> <span class="n">recog_args</span><span class="p">,</span> <span class="n">rnnlm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span> <span class="o">=</span> <span class="n">e2e</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span> <span class="o">=</span> <span class="n">recog_args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span> <span class="o">=</span> <span class="n">e2e</span><span class="o">.</span><span class="n">char_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rnnlm</span> <span class="o">=</span> <span class="n">rnnlm</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_offset</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_last_recognition</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">,</span> \
        <span class="s2">"WindowStreamingE2E works only with combined CTC and attention decoders."</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="accept_input()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window.WindowStreamingE2E.accept_input">
<code class="highlight language-python">
accept_input<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Call this method each time a new batch of input is available.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/streaming/window.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">accept_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Call this method each time a new batch of input is available."""</span>

    <span class="n">h</span><span class="p">,</span> <span class="n">ilen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">subsample_frames</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Streaming encoder</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span>
        <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">ilen</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_previous_encoder_recurrent_state</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="c1"># CTC posteriors for the incoming audio</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ctc_posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="decode_with_attention_offline()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.streaming.window.WindowStreamingE2E.decode_with_attention_offline">
<code class="highlight language-python">
decode_with_attention_offline<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Run the attention decoder offline.</p>
<p>Works even if the previous layers (encoder and CTC decoder) were being run in the online mode.
This method should be run after all the audio has been consumed.
This is used mostly to compare the results between offline and online implementation of the previous layers.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/streaming/window.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>65
66
67
68
69
70
71
72
73
74</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">decode_with_attention_offline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Run the attention decoder offline.</span>

<span class="sd">    Works even if the previous layers (encoder and CTC decoder) were being run in the online mode.</span>
<span class="sd">    This method should be run after all the audio has been consumed.</span>
<span class="sd">    This is used mostly to compare the results between offline and online implementation of the previous layers.</span>
<span class="sd">    """</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">lpz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_window_for_decoder</span><span class="p">(</span><span class="n">use_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e2e</span><span class="o">.</span><span class="n">dec</span><span class="o">.</span><span class="n">recognize_beam</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">lpz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recog_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_char_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnnlm</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2">
<code>tacotron2</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg">
<code>cbhg</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>CBHG related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="CBHG" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHG">
<code>CBHG</code>
</h7>
<div class="doc doc-contents">
<p>CBHG module to convert log Mel-filterbanks to linear spectrogram.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">CBHG</span> <span class="n">introduced</span> <span class="k">in</span> <span class="o">`</span><span class="n">Tacotron</span><span class="p">:</span> <span class="n">Towards</span> <span class="k">End</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="k">End</span> <span class="n">Speech</span> <span class="n">Synthesis</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>
<span class="n">The</span> <span class="n">CBHG</span> <span class="n">converts</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">log</span> <span class="n">Mel</span><span class="o">-</span><span class="n">filterbanks</span> <span class="k">into</span> <span class="n">linear</span> <span class="n">spectrogram</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">Tacotron</span><span class="p">:</span> <span class="n">Towards</span> <span class="k">End</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="k">End</span> <span class="n">Speech</span> <span class="n">Synthesis</span><span class="o">`</span><span class="p">:</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1703</span><span class="p">.</span><span class="mi">10135</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHG.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">conv_bank_layers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">conv_bank_chans</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">conv_proj_filts</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">conv_proj_chans</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">highway_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">highway_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">gru_units</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize CBHG module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>conv_bank_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of convolution bank layers.</p>
</td>
<td><code>8</code></td>
</tr>
<tr>
<td><code>conv_bank_chans</code></td>
<td><code>int</code></td>
<td>
<p>The number of channels in convolution bank.</p>
</td>
<td><code>128</code></td>
</tr>
<tr>
<td><code>conv_proj_filts</code></td>
<td><code>int</code></td>
<td>
<p>Kernel size of convolutional projection layer.</p>
</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>conv_proj_chans</code></td>
<td><code>int</code></td>
<td>
<p>The number of channels in convolutional projection layer.</p>
</td>
<td><code>256</code></td>
</tr>
<tr>
<td><code>highway_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of highway network layers.</p>
</td>
<td><code>4</code></td>
</tr>
<tr>
<td><code>highway_units</code></td>
<td><code>int</code></td>
<td>
<p>The number of highway network units.</p>
</td>
<td><code>128</code></td>
</tr>
<tr>
<td><code>gru_units</code></td>
<td><code>int</code></td>
<td>
<p>The number of GRU units (for both directions).</p>
</td>
<td><code>256</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">idim</span><span class="p">,</span>
             <span class="n">odim</span><span class="p">,</span>
             <span class="n">conv_bank_layers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
             <span class="n">conv_bank_chans</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
             <span class="n">conv_proj_filts</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
             <span class="n">conv_proj_chans</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
             <span class="n">highway_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
             <span class="n">highway_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
             <span class="n">gru_units</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
    <span class="sd">"""Initialize CBHG module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        conv_bank_layers (int, optional): The number of convolution bank layers.</span>
<span class="sd">        conv_bank_chans (int, optional): The number of channels in convolution bank.</span>
<span class="sd">        conv_proj_filts (int, optional): Kernel size of convolutional projection layer.</span>
<span class="sd">        conv_proj_chans (int, optional): The number of channels in convolutional projection layer.</span>
<span class="sd">        highway_layers (int, optional): The number of highway network layers.</span>
<span class="sd">        highway_units (int, optional): The number of highway network units.</span>
<span class="sd">        gru_units (int, optional): The number of GRU units (for both directions).</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CBHG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_layers</span> <span class="o">=</span> <span class="n">conv_bank_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_chans</span> <span class="o">=</span> <span class="n">conv_bank_chans</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_filts</span> <span class="o">=</span> <span class="n">conv_proj_filts</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_chans</span> <span class="o">=</span> <span class="n">conv_proj_chans</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">highway_layers</span> <span class="o">=</span> <span class="n">highway_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">highway_units</span> <span class="o">=</span> <span class="n">highway_units</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gru_units</span> <span class="o">=</span> <span class="n">gru_units</span>

    <span class="c1"># define 1d convolution bank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">((</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad1d</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_chans</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_chans</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())]</span>

    <span class="c1"># define max pooling (need padding for one-side to keep same length)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_pool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad1d</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># define 1d convolution projection</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projections</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_chans</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_chans</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_chans</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_chans</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idim</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_proj_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idim</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># define highway network</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">highways</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">highways</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">highway_units</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">highway_layers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">highways</span> <span class="o">+=</span> <span class="p">[</span><span class="n">HighwayNet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">highway_units</span><span class="p">)]</span>

    <span class="c1"># define bidirectional GRU</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">highway_units</span><span class="p">,</span> <span class="n">gru_units</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># define final projection</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">gru_units</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHG.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the padded sequences of inputs (B, Tmax, idim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input sequence (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of the padded sequence of outputs (B, Tmax, odim).
LongTensor: Batch of lengths of each output sequence (B,).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of the padded sequences of inputs (B, Tmax, idim).</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input sequence (B,).</span>

<span class="sd">    Return:</span>
<span class="sd">        Tensor: Batch of the padded sequence of outputs (B, Tmax, odim).</span>
<span class="sd">        LongTensor: Batch of lengths of each output sequence (B,).</span>

<span class="sd">    """</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, idim, Tmax)</span>
    <span class="n">convs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_bank_layers</span><span class="p">):</span>
        <span class="n">convs</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_bank</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">xs</span><span class="p">)]</span>
    <span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">convs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, #CH * #BANK, Tmax)</span>
    <span class="n">convs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">convs</span><span class="p">)</span>
    <span class="n">convs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projections</span><span class="p">(</span><span class="n">convs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, Tmax, idim)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">convs</span>
    <span class="c1"># + 1 for dimension adjustment layer</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">highway_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">highways</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">xs</span><span class="p">)</span>

    <span class="c1"># sort by length</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">sort_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sort_by_length</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)</span>

    <span class="c1"># total_length needs for DataParallel</span>
    <span class="c1"># (see https://github.com/pytorch/pytorch/pull/6327)</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="o">.</span><span class="n">flatten_parameters</span><span class="p">()</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">total_length</span><span class="o">=</span><span class="n">total_length</span><span class="p">)</span>

    <span class="c1"># revert sorting by length</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_revert_sort_by_length</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">sort_idx</span><span class="p">)</span>

    <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>  <span class="c1"># (B, Tmax, odim)</span>

    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHG.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Inference.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The sequences of inputs (T, idim).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>The sequence of outputs (T, odim).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>188
189
190
191
192
193
194
195
196
197
198
199
200
201
202</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Inference.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): The sequences of inputs (T, idim).</span>

<span class="sd">    Return:</span>
<span class="sd">        Tensor: The sequence of outputs (T, odim).</span>

<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="CBHGLoss" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss">
<code>CBHGLoss</code>
</h7>
<div class="doc doc-contents">
<p>Loss function module for CBHG.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize CBHG loss module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>use_masking</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to mask padded part in loss calculation.</p>
</td>
<td><code>True</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_masking</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Initialize CBHG loss module.</span>

<span class="sd">    Args:</span>
<span class="sd">        use_masking (bool): Whether to mask padded part in loss calculation.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CBHGLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span> <span class="o">=</span> <span class="n">use_masking</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">spcs</span><span class="p">,</span> <span class="n">olens</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>cbhg_outs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of CBHG outputs (B, Lmax, spc_dim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>spcs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of groundtruth of spectrogram (B, Lmax, spc_dim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>olens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of the lengths of each sequence (B,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>L1 loss value
Tensor: Mean square error loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">spcs</span><span class="p">,</span> <span class="n">olens</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        cbhg_outs (Tensor): Batch of CBHG outputs (B, Lmax, spc_dim).</span>
<span class="sd">        spcs (Tensor): Batch of groundtruth of spectrogram (B, Lmax, spc_dim).</span>
<span class="sd">        olens (LongTensor): Batch of the lengths of each sequence (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: L1 loss value</span>
<span class="sd">        Tensor: Mean square error loss value.</span>

<span class="sd">    """</span>
    <span class="c1"># perform masking for padded values</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_masking</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">olens</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">spcs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">spcs</span> <span class="o">=</span> <span class="n">spcs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">cbhg_outs</span> <span class="o">=</span> <span class="n">cbhg_outs</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

    <span class="c1"># calculate loss</span>
    <span class="n">cbhg_l1_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">spcs</span><span class="p">)</span>
    <span class="n">cbhg_mse_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">cbhg_outs</span><span class="p">,</span> <span class="n">spcs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cbhg_l1_loss</span><span class="p">,</span> <span class="n">cbhg_mse_loss</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="HighwayNet" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.HighwayNet">
<code>HighwayNet</code>
</h7>
<div class="doc doc-contents">
<p>Highway Network module.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">Highway</span> <span class="n">Network</span> <span class="n">introduced</span> <span class="k">in</span> <span class="o">`</span><span class="n">Highway</span> <span class="n">Networks</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">Highway</span> <span class="n">Networks</span><span class="o">`</span><span class="p">:</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1505</span><span class="p">.</span><span class="mi">00387</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.HighwayNet.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize Highway Network module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>222
223
224
225
226
227
228
229
230
231
232
233
234
235
236</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">):</span>
    <span class="sd">"""Initialize Highway Network module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">HighwayNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">idim</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">idim</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.cbhg.HighwayNet.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of inputs (B, ..., idim).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of outputs, which are the same shape as inputs (B, ..., idim).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/cbhg.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>238
239
240
241
242
243
244
245
246
247
248
249
250</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Batch of inputs (B, ..., idim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of outputs, which are the same shape as inputs (B, ..., idim).</span>

<span class="sd">    """</span>
    <span class="n">proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">gate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">proj</span> <span class="o">*</span> <span class="n">gate</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">gate</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder">
<code>decoder</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Tacotron2 decoder related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Decoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Decoder">
<code>Decoder</code>
</h7>
<div class="doc doc-contents">
<p>Decoder module of Spectrogram prediction network.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">decoder</span> <span class="k">of</span> <span class="n">Spectrogram</span> <span class="n">prediction</span> <span class="n">network</span> <span class="k">in</span> <span class="n">Tacotron2</span><span class="p">,</span> <span class="n">which</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span>
<span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">.</span> <span class="n">The</span> <span class="n">decoder</span> <span class="n">generates</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span>
<span class="n">features</span> <span class="k">from</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">the</span> <span class="n">hidden</span> <span class="n">states</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="p">:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1712</span><span class="p">.</span><span class="mi">05884</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Decoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">dlayers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dunits</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">prenet_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">prenet_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">postnet_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">postnet_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">postnet_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">output_activation_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cumulate_att_w</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_concate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">zoneout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize Tacotron2 decoder module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>att</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Instance of attention class.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>dlayers</code></td>
<td><code>int</code></td>
<td>
<p>The number of decoder lstm layers.</p>
</td>
<td><code>2</code></td>
</tr>
<tr>
<td><code>dunits</code></td>
<td><code>int</code></td>
<td>
<p>The number of decoder lstm units.</p>
</td>
<td><code>1024</code></td>
</tr>
<tr>
<td><code>prenet_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of prenet layers.</p>
</td>
<td><code>2</code></td>
</tr>
<tr>
<td><code>prenet_units</code></td>
<td><code>int</code></td>
<td>
<p>The number of prenet units.</p>
</td>
<td><code>256</code></td>
</tr>
<tr>
<td><code>postnet_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of postnet layers.</p>
</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>postnet_filts</code></td>
<td><code>int</code></td>
<td>
<p>The number of postnet filter size.</p>
</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>postnet_chans</code></td>
<td><code>int</code></td>
<td>
<p>The number of postnet filter channels.</p>
</td>
<td><code>512</code></td>
</tr>
<tr>
<td><code>output_activation_fn</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Activation function for outputs.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>cumulate_att_w</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to cumulate previous attention weight.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_batch_norm</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to use batch normalization.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_concate</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to concatenate encoder embedding with decoder lstm outputs.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>dropout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Dropout rate.</p>
</td>
<td><code>0.5</code></td>
</tr>
<tr>
<td><code>zoneout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Zoneout rate.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>reduction_factor</code></td>
<td><code>int</code></td>
<td>
<p>Reduction factor.</p>
</td>
<td><code>1</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span>
             <span class="n">dlayers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">dunits</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
             <span class="n">prenet_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">prenet_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
             <span class="n">postnet_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
             <span class="n">postnet_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
             <span class="n">postnet_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
             <span class="n">output_activation_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">cumulate_att_w</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">use_concate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">zoneout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Initialize Tacotron2 decoder module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        att (torch.nn.Module): Instance of attention class.</span>
<span class="sd">        dlayers (int, optional): The number of decoder lstm layers.</span>
<span class="sd">        dunits (int, optional): The number of decoder lstm units.</span>
<span class="sd">        prenet_layers (int, optional): The number of prenet layers.</span>
<span class="sd">        prenet_units (int, optional): The number of prenet units.</span>
<span class="sd">        postnet_layers (int, optional): The number of postnet layers.</span>
<span class="sd">        postnet_filts (int, optional): The number of postnet filter size.</span>
<span class="sd">        postnet_chans (int, optional): The number of postnet filter channels.</span>
<span class="sd">        output_activation_fn (torch.nn.Module, optional): Activation function for outputs.</span>
<span class="sd">        cumulate_att_w (bool, optional): Whether to cumulate previous attention weight.</span>
<span class="sd">        use_batch_norm (bool, optional): Whether to use batch normalization.</span>
<span class="sd">        use_concate (bool, optional): Whether to concatenate encoder embedding with decoder lstm outputs.</span>
<span class="sd">        dropout_rate (float, optional): Dropout rate.</span>
<span class="sd">        zoneout_rate (float, optional): Zoneout rate.</span>
<span class="sd">        reduction_factor (int, optional): Reduction factor.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># store the hyperparameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">odim</span> <span class="o">=</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">att</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="o">=</span> <span class="n">output_activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="o">=</span> <span class="n">cumulate_att_w</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_concate</span> <span class="o">=</span> <span class="n">use_concate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">reduction_factor</span>

    <span class="c1"># check attention type</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">,</span> <span class="n">AttForwardTA</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_att_extra_inputs</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_att_extra_inputs</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># define lstm network</span>
    <span class="n">prenet_units</span> <span class="o">=</span> <span class="n">prenet_units</span> <span class="k">if</span> <span class="n">prenet_layers</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">odim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">dlayers</span><span class="p">):</span>
        <span class="n">iunits</span> <span class="o">=</span> <span class="n">idim</span> <span class="o">+</span> <span class="n">prenet_units</span> <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dunits</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">iunits</span><span class="p">,</span> <span class="n">dunits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">zoneout_rate</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">lstm</span> <span class="o">=</span> <span class="n">ZoneOutCell</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">zoneout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">+=</span> <span class="p">[</span><span class="n">lstm</span><span class="p">]</span>

    <span class="c1"># define prenet</span>
    <span class="k">if</span> <span class="n">prenet_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="o">=</span> <span class="n">Prenet</span><span class="p">(</span>
            <span class="n">idim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">prenet_layers</span><span class="p">,</span>
            <span class="n">n_units</span><span class="o">=</span><span class="n">prenet_units</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># define postnet</span>
    <span class="k">if</span> <span class="n">postnet_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">=</span> <span class="n">Postnet</span><span class="p">(</span>
            <span class="n">idim</span><span class="o">=</span><span class="n">idim</span><span class="p">,</span>
            <span class="n">odim</span><span class="o">=</span><span class="n">odim</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">postnet_layers</span><span class="p">,</span>
            <span class="n">n_chans</span><span class="o">=</span><span class="n">postnet_chans</span><span class="p">,</span>
            <span class="n">n_filts</span><span class="o">=</span><span class="n">postnet_filts</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">use_batch_norm</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># define projection layers</span>
    <span class="n">iunits</span> <span class="o">=</span> <span class="n">idim</span> <span class="o">+</span> <span class="n">dunits</span> <span class="k">if</span> <span class="n">use_concate</span> <span class="k">else</span> <span class="n">dunits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">iunits</span><span class="p">,</span> <span class="n">odim</span> <span class="o">*</span> <span class="n">reduction_factor</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">iunits</span><span class="p">,</span> <span class="n">reduction_factor</span><span class="p">)</span>

    <span class="c1"># initialize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">decoder_init</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="calculate_all_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Decoder.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate all of the attention weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of padded hidden states (B, Tmax, idim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hlens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>numpy.ndarray</code></td>
<td>
<p>Batch of attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in teacher-forcing manner.</p>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Calculate all of the attention weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        hs (Tensor): Batch of the sequences of padded hidden states (B, Tmax, idim).</span>
<span class="sd">        hlens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of the sequences of padded target features (B, Lmax, odim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Batch of attention weights (B, Lmax, Tmax).</span>

<span class="sd">    Note:</span>
<span class="sd">        This computation is performed in teacher-forcing manner.</span>

<span class="sd">    """</span>
    <span class="c1"># thin out frames (B, Lmax, odim) -&gt;  (B, Lmax/r, odim)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">]</span>

    <span class="c1"># length list should be list of int</span>
    <span class="n">hlens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">hlens</span><span class="p">))</span>

    <span class="c1"># initialize hidden states of decoder</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
        <span class="n">c_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
        <span class="n">z_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">prev_out</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>

    <span class="c1"># initialize attention</span>
    <span class="n">prev_att_w</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1"># loop for an output sequence</span>
    <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_att_extra_inputs</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">,</span> <span class="n">prev_out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">)</span>
        <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="n">att_w</span><span class="p">]</span>
        <span class="n">prenet_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span><span class="p">(</span><span class="n">prev_out</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prev_out</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">att_c</span><span class="p">,</span> <span class="n">prenet_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
            <span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="n">l</span><span class="p">](</span>
                <span class="n">z_list</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]))</span>
        <span class="n">prev_out</span> <span class="o">=</span> <span class="n">y</span>  <span class="c1"># teacher forcing</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="ow">and</span> <span class="n">prev_att_w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">prev_att_w</span> <span class="o">+</span> <span class="n">att_w</span>  <span class="c1"># Note: error when use +=</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">att_w</span>

    <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, Lmax, Tmax)</span>

    <span class="k">return</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Decoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of padded hidden states (B, Tmax, idim).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hlens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of padded target features (B, Lmax, odim).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of output tensors after postnet (B, Lmax, odim).
Tensor: Batch of output tensors before postnet (B, Lmax, odim).
Tensor: Batch of logits of stop prediction (B, Lmax).
Tensor: Batch of attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in teacher-forcing manner.</p>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        hs (Tensor): Batch of the sequences of padded hidden states (B, Tmax, idim).</span>
<span class="sd">        hlens (LongTensor): Batch of lengths of each input batch (B,).</span>
<span class="sd">        ys (Tensor): Batch of the sequences of padded target features (B, Lmax, odim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of output tensors after postnet (B, Lmax, odim).</span>
<span class="sd">        Tensor: Batch of output tensors before postnet (B, Lmax, odim).</span>
<span class="sd">        Tensor: Batch of logits of stop prediction (B, Lmax).</span>
<span class="sd">        Tensor: Batch of attention weights (B, Lmax, Tmax).</span>

<span class="sd">    Note:</span>
<span class="sd">        This computation is performed in teacher-forcing manner.</span>

<span class="sd">    """</span>
    <span class="c1"># thin out frames (B, Lmax, odim) -&gt;  (B, Lmax/r, odim)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">]</span>

    <span class="c1"># length list should be list of int</span>
    <span class="n">hlens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">hlens</span><span class="p">))</span>

    <span class="c1"># initialize hidden states of decoder</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
        <span class="n">c_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
        <span class="n">z_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">prev_out</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>

    <span class="c1"># initialize attention</span>
    <span class="n">prev_att_w</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1"># loop for an output sequence</span>
    <span class="n">outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">att_ws</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_att_extra_inputs</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">,</span> <span class="n">prev_out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">hlens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">)</span>
        <span class="n">prenet_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span><span class="p">(</span><span class="n">prev_out</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prev_out</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">att_c</span><span class="p">,</span> <span class="n">prenet_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
            <span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="n">l</span><span class="p">](</span>
                <span class="n">z_list</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]))</span>
        <span class="n">zcs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">att_c</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_concate</span> <span class="k">else</span> <span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">outs</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span><span class="p">(</span><span class="n">zcs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">logits</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span><span class="p">(</span><span class="n">zcs</span><span class="p">)]</span>
        <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="n">att_w</span><span class="p">]</span>
        <span class="n">prev_out</span> <span class="o">=</span> <span class="n">y</span>  <span class="c1"># teacher forcing</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="ow">and</span> <span class="n">prev_att_w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">prev_att_w</span> <span class="o">+</span> <span class="n">att_w</span>  <span class="c1"># Note: error when use +=</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">att_w</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, Lmax)</span>
    <span class="n">before_outs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, odim, Lmax)</span>
    <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, Lmax, Tmax)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">before_outs</span> <span class="o">=</span> <span class="n">before_outs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">before_outs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, odim, Lmax)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">(</span><span class="n">before_outs</span><span class="p">)</span>  <span class="c1"># (B, odim, Lmax)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="n">before_outs</span>
    <span class="n">before_outs</span> <span class="o">=</span> <span class="n">before_outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, Lmax, odim)</span>
    <span class="n">after_outs</span> <span class="o">=</span> <span class="n">after_outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, Lmax, odim)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span>

    <span class="c1"># apply activation function for scaling</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">before_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">(</span><span class="n">before_outs</span><span class="p">)</span>
        <span class="n">after_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">(</span><span class="n">after_outs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">after_outs</span><span class="p">,</span> <span class="n">before_outs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Decoder.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">minlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">use_att_constraint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Generate the sequence of features given the sequences of characters.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>h</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input sequence of encoder hidden states (T, C).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>threshold</code></td>
<td><code>float</code></td>
<td>
<p>Threshold to stop generation.</p>
</td>
<td><code>0.5</code></td>
</tr>
<tr>
<td><code>minlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Minimum length ratio. If set to 1.0 and the length of input is 10,
the minimum length of outputs will be 10 * 1 = 10.</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>minlenratio</code></td>
<td><code>float</code></td>
<td>
<p>Minimum length ratio. If set to 10 and the length of input is 10,
the maximum length of outputs will be 10 * 10 = 100.</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>use_att_constraint</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to apply attention constraint introduced in <code>Deep Voice 3</code>_.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>backward_window</code></td>
<td><code>int</code></td>
<td>
<p>Backward window size in attention constraint.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>forward_window</code></td>
<td><code>int</code></td>
<td>
<p>Forward window size in attention constraint.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Attention weights (L, T).</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in auto-regressive manner.</p>
</div>
<p>.. _<code>Deep Voice 3</code>: https://arxiv.org/abs/1710.07654</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">minlenratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxlenratio</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>
              <span class="n">use_att_constraint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">backward_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">forward_window</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Generate the sequence of features given the sequences of characters.</span>

<span class="sd">    Args:</span>
<span class="sd">        h (Tensor): Input sequence of encoder hidden states (T, C).</span>
<span class="sd">        threshold (float, optional): Threshold to stop generation.</span>
<span class="sd">        minlenratio (float, optional): Minimum length ratio. If set to 1.0 and the length of input is 10,</span>
<span class="sd">            the minimum length of outputs will be 10 * 1 = 10.</span>
<span class="sd">        minlenratio (float, optional): Minimum length ratio. If set to 10 and the length of input is 10,</span>
<span class="sd">            the maximum length of outputs will be 10 * 10 = 100.</span>
<span class="sd">        use_att_constraint (bool): Whether to apply attention constraint introduced in `Deep Voice 3`_.</span>
<span class="sd">        backward_window (int): Backward window size in attention constraint.</span>
<span class="sd">        forward_window (int): Forward window size in attention constraint.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Output sequence of features (L, odim).</span>
<span class="sd">        Tensor: Output sequence of stop probabilities (L,).</span>
<span class="sd">        Tensor: Attention weights (L, T).</span>

<span class="sd">    Note:</span>
<span class="sd">        This computation is performed in auto-regressive manner.</span>

<span class="sd">    .. _`Deep Voice 3`: https://arxiv.org/abs/1710.07654</span>

<span class="sd">    """</span>
    <span class="c1"># setup</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">hs</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">maxlenratio</span><span class="p">)</span>
    <span class="n">minlen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">minlenratio</span><span class="p">)</span>

    <span class="c1"># initialize hidden states of decoder</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">z_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
        <span class="n">c_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
        <span class="n">z_list</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_state</span><span class="p">(</span><span class="n">hs</span><span class="p">)]</span>
    <span class="n">prev_out</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">)</span>

    <span class="c1"># initialize attention</span>
    <span class="n">prev_att_w</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1"># setup for attention constraint</span>
    <span class="k">if</span> <span class="n">use_att_constraint</span><span class="p">:</span>
        <span class="n">last_attended_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">last_attended_idx</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># loop for an output sequence</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">outs</span><span class="p">,</span> <span class="n">att_ws</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># updated index</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span>

        <span class="c1"># decoder calculation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_att_extra_inputs</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">,</span> <span class="n">prev_out</span><span class="p">,</span>
                                    <span class="n">last_attended_idx</span><span class="o">=</span><span class="n">last_attended_idx</span><span class="p">,</span>
                                    <span class="n">backward_window</span><span class="o">=</span><span class="n">backward_window</span><span class="p">,</span>
                                    <span class="n">forward_window</span><span class="o">=</span><span class="n">forward_window</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">att_c</span><span class="p">,</span> <span class="n">att_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">prev_att_w</span><span class="p">,</span>
                                    <span class="n">last_attended_idx</span><span class="o">=</span><span class="n">last_attended_idx</span><span class="p">,</span>
                                    <span class="n">backward_window</span><span class="o">=</span><span class="n">backward_window</span><span class="p">,</span>
                                    <span class="n">forward_window</span><span class="o">=</span><span class="n">forward_window</span><span class="p">)</span>

        <span class="n">att_ws</span> <span class="o">+=</span> <span class="p">[</span><span class="n">att_w</span><span class="p">]</span>
        <span class="n">prenet_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span><span class="p">(</span><span class="n">prev_out</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prev_out</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">att_c</span><span class="p">,</span> <span class="n">prenet_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)):</span>
            <span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">[</span><span class="n">l</span><span class="p">](</span>
                <span class="n">z_list</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">l</span><span class="p">]))</span>
        <span class="n">zcs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">att_c</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_concate</span> <span class="k">else</span> <span class="n">z_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">outs</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_out</span><span class="p">(</span><span class="n">zcs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">odim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>  <span class="c1"># [(1, odim, r), ...]</span>
        <span class="n">probs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_out</span><span class="p">(</span><span class="n">zcs</span><span class="p">))[</span><span class="mi">0</span><span class="p">]]</span>  <span class="c1"># [(r), ...]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prev_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">(</span><span class="n">outs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># (1, odim)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_out</span> <span class="o">=</span> <span class="n">outs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># (1, odim)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulate_att_w</span> <span class="ow">and</span> <span class="n">prev_att_w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">prev_att_w</span> <span class="o">+</span> <span class="n">att_w</span>  <span class="c1"># Note: error when use +=</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_att_w</span> <span class="o">=</span> <span class="n">att_w</span>
        <span class="k">if</span> <span class="n">use_att_constraint</span><span class="p">:</span>
            <span class="n">last_attended_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">att_w</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>

        <span class="c1"># check whether to finish generation</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">maxlen</span><span class="p">:</span>
            <span class="c1"># check mininum length</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">minlen</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (1, odim, L)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">outs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>  <span class="c1"># (1, odim, L)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">outs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (L, odim)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">att_ws</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att_ws</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">outs</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Postnet" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Postnet">
<code>Postnet</code>
</h7>
<div class="doc doc-contents">
<p>Postnet module for Spectrogram prediction network.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">Postnet</span> <span class="k">in</span> <span class="n">Spectrogram</span> <span class="n">prediction</span> <span class="n">network</span><span class="p">,</span> <span class="n">which</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span>
<span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">.</span> <span class="n">The</span> <span class="n">Postnet</span> <span class="n">predicts</span> <span class="n">refines</span> <span class="n">the</span> <span class="n">predicted</span>
<span class="n">Mel</span><span class="o">-</span><span class="n">filterbank</span> <span class="k">of</span> <span class="n">the</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">which</span> <span class="n">helps</span> <span class="k">to</span> <span class="n">compensate</span> <span class="n">the</span> <span class="n">detail</span> <span class="n">sturcture</span> <span class="k">of</span> <span class="n">spectrogram</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="p">:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1712</span><span class="p">.</span><span class="mi">05884</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Postnet.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize postnet module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>n_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of layers.</p>
</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>n_filts</code></td>
<td><code>int</code></td>
<td>
<p>The number of filter size.</p>
</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>n_units</code></td>
<td><code>int</code></td>
<td>
<p>The number of filter channels.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>use_batch_norm</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to use batch normalization..</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>dropout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Dropout rate..</p>
</td>
<td><code>0.5</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Initialize postnet module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        n_layers (int, optional): The number of layers.</span>
<span class="sd">        n_filts (int, optional): The number of filter size.</span>
<span class="sd">        n_units (int, optional): The number of filter channels.</span>
<span class="sd">        use_batch_norm (bool, optional): Whether to use batch normalization..</span>
<span class="sd">        dropout_rate (float, optional): Dropout rate..</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Postnet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">ichans</span> <span class="o">=</span> <span class="n">odim</span> <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_chans</span>
        <span class="n">ochans</span> <span class="o">=</span> <span class="n">odim</span> <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">n_chans</span>
        <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">ochans</span><span class="p">,</span> <span class="n">n_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">n_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">ochans</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">ochans</span><span class="p">,</span> <span class="n">n_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">n_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
    <span class="n">ichans</span> <span class="o">=</span> <span class="n">n_chans</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">odim</span>
    <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">n_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">n_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">odim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">n_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">n_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Postnet.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of padded input tensors (B, idim, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of padded output tensor. (B, odim, Tmax).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>195
196
197
198
199
200
201
202
203
204
205
206
207</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of the sequences of padded input tensors (B, idim, Tmax).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of padded output tensor. (B, odim, Tmax).</span>

<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">)):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postnet</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">xs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xs</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Prenet" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Prenet">
<code>Prenet</code>
</h7>
<div class="doc doc-contents">
<p>Prenet module for decoder of Spectrogram prediction network.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">Prenet</span> <span class="k">in</span> <span class="n">the</span> <span class="n">decoder</span> <span class="k">of</span> <span class="n">Spectrogram</span> <span class="n">prediction</span> <span class="n">network</span><span class="p">,</span> <span class="n">which</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span>
<span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">.</span> <span class="n">The</span> <span class="n">Prenet</span> <span class="n">preforms</span> <span class="n">nonlinear</span> <span class="k">conversion</span>
<span class="k">of</span> <span class="n">inputs</span> <span class="k">before</span> <span class="k">input</span> <span class="k">to</span> <span class="n">auto</span><span class="o">-</span><span class="n">regressive</span> <span class="n">lstm</span><span class="p">,</span> <span class="n">which</span> <span class="n">helps</span> <span class="k">to</span> <span class="n">learn</span> <span class="n">diagonal</span> <span class="n">attentions</span><span class="p">.</span>

<span class="o">!!!</span> <span class="n">note</span>
    <span class="n">This</span> <span class="n">module</span> <span class="n">alway</span> <span class="n">applies</span> <span class="n">dropout</span> <span class="n">even</span> <span class="k">in</span> <span class="n">evaluation</span><span class="p">.</span> <span class="n">See</span> <span class="n">the</span> <span class="n">detail</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span>
    <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="p">:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1712</span><span class="p">.</span><span class="mi">05884</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Prenet.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize prenet module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>idim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the inputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>odim</code></td>
<td><code>int</code></td>
<td>
<p>Dimension of the outputs.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>n_layers</code></td>
<td><code>int</code></td>
<td>
<p>The number of prenet layers.</p>
</td>
<td><code>2</code></td>
</tr>
<tr>
<td><code>n_units</code></td>
<td><code>int</code></td>
<td>
<p>The number of prenet units.</p>
</td>
<td><code>256</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="sd">"""Initialize prenet module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int): Dimension of the inputs.</span>
<span class="sd">        odim (int): Dimension of the outputs.</span>
<span class="sd">        n_layers (int, optional): The number of prenet layers.</span>
<span class="sd">        n_units (int, optional): The number of prenet units.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Prenet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">idim</span> <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenet</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_units</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.Prenet.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input tensors (B, ..., idim).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of output tensors (B, ..., odim).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>124
125
126
127
128
129
130
131
132
133
134
135
136</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Batch of input tensors (B, ..., idim).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of output tensors (B, ..., odim).</span>

<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prenet</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prenet</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="ZoneOutCell" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell">
<code>ZoneOutCell</code>
</h7>
<div class="doc doc-contents">
<p>ZoneOut Cell module.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">zoneout</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="n">Zoneout</span><span class="p">:</span> <span class="n">Regularizing</span> <span class="n">RNNs</span> <span class="k">by</span> <span class="n">Randomly</span> <span class="n">Preserving</span> <span class="n">Hidden</span> <span class="n">Activations</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>
<span class="n">This</span> <span class="n">code</span> <span class="k">is</span> <span class="n">modified</span> <span class="k">from</span> <span class="o">`</span><span class="n">eladhoffer</span><span class="o">/</span><span class="n">seq2seq</span><span class="p">.</span><span class="n">pytorch</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>

<span class="o">!!!</span> <span class="n">examples</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="n">lstm</span> <span class="o">=</span> <span class="n">ZoneOutCell</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">Zoneout</span><span class="p">:</span> <span class="n">Regularizing</span> <span class="n">RNNs</span> <span class="k">by</span> <span class="n">Randomly</span> <span class="n">Preserving</span> <span class="n">Hidden</span> <span class="n">Activations</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1606</span><span class="p">.</span><span class="mi">01305</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">eladhoffer</span><span class="o">/</span><span class="n">seq2seq</span><span class="p">.</span><span class="n">pytorch</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">eladhoffer</span><span class="o">/</span><span class="n">seq2seq</span><span class="p">.</span><span class="n">pytorch</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">zoneout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize zone out cell module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>cell</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Pytorch recurrent cell module e.g. <code>torch.nn.Module.LSTMCell</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>zoneout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Probability of zoneout from 0.0 to 1.0.</p>
</td>
<td><code>0.1</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">zoneout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="sd">"""Initialize zone out cell module.</span>

<span class="sd">    Args:</span>
<span class="sd">        cell (torch.nn.Module): Pytorch recurrent cell module e.g. `torch.nn.Module.LSTMCell`.</span>
<span class="sd">        zoneout_rate (float, optional): Probability of zoneout from 0.0 to 1.0.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ZoneOutCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">cell</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">zoneout_rate</span> <span class="o">=</span> <span class="n">zoneout_rate</span>
    <span class="k">if</span> <span class="n">zoneout_rate</span> <span class="o">&gt;</span> <span class="mf">1.0</span> <span class="ow">or</span> <span class="n">zoneout_rate</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"zoneout probability must be in the range from 0.0 to 1.0."</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>inputs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input tensor (B, input_size).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hidden</code></td>
<td><code>tuple</code></td>
<td>
<ul>
<li>Tensor: Batch of initial hidden states (B, hidden_size).</li>
<li>Tensor: Batch of initial cell states (B, hidden_size).</li>
</ul>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tuple</code></td>
<td>
<ul>
<li>Tensor: Batch of next hidden states (B, hidden_size).<ul>
<li>Tensor: Batch of next cell states (B, hidden_size).</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (Tensor): Batch of input tensor (B, input_size).</span>
<span class="sd">        hidden (tuple):</span>
<span class="sd">            - Tensor: Batch of initial hidden states (B, hidden_size).</span>
<span class="sd">            - Tensor: Batch of initial cell states (B, hidden_size).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple:</span>
<span class="sd">            - Tensor: Batch of next hidden states (B, hidden_size).</span>
<span class="sd">            - Tensor: Batch of next cell states (B, hidden_size).</span>

<span class="sd">    """</span>
    <span class="n">next_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">next_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zoneout</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">next_hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">zoneout_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">next_hidden</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="decoder_init()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.decoder.decoder_init">
<code class="highlight language-python">
decoder_init<span class="p">(</span><span class="n">m</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Initialize decoder parameters.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>16
17
18
19</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">decoder_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">"""Initialize decoder parameters."""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s1">'tanh'</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder">
<code>encoder</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Tacotron2 encoder related modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Encoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder.Encoder">
<code>Encoder</code>
</h7>
<div class="doc doc-contents">
<p>Encoder module of Spectrogram prediction network.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">encoder</span> <span class="k">of</span> <span class="n">Spectrogram</span> <span class="n">prediction</span> <span class="n">network</span> <span class="k">in</span> <span class="n">Tacotron2</span><span class="p">,</span> <span class="n">which</span> <span class="n">described</span> <span class="k">in</span> <span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span>
<span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="n">_</span><span class="p">.</span> <span class="n">This</span> <span class="k">is</span> <span class="n">the</span> <span class="n">encoder</span> <span class="n">which</span> <span class="n">converts</span> <span class="n">the</span>
<span class="n">sequence</span> <span class="k">of</span> <span class="n">characters</span> <span class="k">into</span> <span class="n">the</span> <span class="n">sequence</span> <span class="k">of</span> <span class="n">hidden</span> <span class="n">states</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="k">Natural</span> <span class="n">TTS</span> <span class="n">Synthesis</span> <span class="k">by</span> <span class="n">Conditioning</span> <span class="n">WaveNet</span> <span class="k">on</span> <span class="n">Mel</span> <span class="n">Spectrogram</span> <span class="n">Predictions</span><span class="o">`</span><span class="p">:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="k">abs</span><span class="o">/</span><span class="mi">1712</span><span class="p">.</span><span class="mi">05884</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder.Encoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">elayers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eunits</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">econv_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">econv_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">econv_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize Tacotron2 encoder module.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span>
             <span class="n">embed_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
             <span class="n">elayers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">eunits</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
             <span class="n">econv_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
             <span class="n">econv_chans</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
             <span class="n">econv_filts</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
             <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">use_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Initialize Tacotron2 encoder module.</span>

<span class="sd">    Args:</span>
<span class="sd">        idim (int) Dimension of the inputs.</span>
<span class="sd">        embed_dim (int, optional) Dimension of character embedding.</span>
<span class="sd">        elayers (int, optional) The number of encoder blstm layers.</span>
<span class="sd">        eunits (int, optional) The number of encoder blstm units.</span>
<span class="sd">        econv_layers (int, optional) The number of encoder conv layers.</span>
<span class="sd">        econv_filts (int, optional) The number of encoder conv filter size.</span>
<span class="sd">        econv_chans (int, optional) The number of encoder conv filter channels.</span>
<span class="sd">        use_batch_norm (bool, optional) Whether to use batch normalization.</span>
<span class="sd">        use_residual (bool, optional) Whether to use residual connection.</span>
<span class="sd">        dropout_rate (float, optional) Dropout rate.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># store the hyperparameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">idim</span> <span class="o">=</span> <span class="n">idim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_residual</span> <span class="o">=</span> <span class="n">use_residual</span>

    <span class="c1"># define network layer modules</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">econv_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">econv_layers</span><span class="p">):</span>
            <span class="n">ichans</span> <span class="o">=</span> <span class="n">embed_dim</span> <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">econv_chans</span>
            <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">econv_chans</span><span class="p">,</span> <span class="n">econv_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">econv_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">econv_chans</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">ichans</span><span class="p">,</span> <span class="n">econv_chans</span><span class="p">,</span> <span class="n">econv_filts</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">econv_filts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">elayers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">iunits</span> <span class="o">=</span> <span class="n">econv_chans</span> <span class="k">if</span> <span class="n">econv_layers</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
            <span class="n">iunits</span><span class="p">,</span> <span class="n">eunits</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">elayers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blstm</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># initialize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">encoder_init</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder.Encoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of the padded sequence of character ids (B, Tmax). Padded value should be 0.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ilens</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Batch of lengths of each input batch (B,).</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of the sequences of encoder states(B, Tmax, eunits).
LongTensor: Batch of lengths of each sequence (B,)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        xs (Tensor): Batch of the padded sequence of character ids (B, Tmax). Padded value should be 0.</span>
<span class="sd">        ilens (LongTensor): Batch of lengths of each input batch (B,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of the sequences of encoder states(B, Tmax, eunits).</span>
<span class="sd">        LongTensor: Batch of lengths of each sequence (B,)</span>

<span class="sd">    """</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_residual</span><span class="p">:</span>
                <span class="n">xs</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">xs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="n">l</span><span class="p">](</span><span class="n">xs</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">blstm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">xs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">ilens</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">blstm</span><span class="o">.</span><span class="n">flatten_parameters</span><span class="p">()</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blstm</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>  <span class="c1"># (B, Tmax, C)</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">hlens</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">hlens</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="inference()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder.Encoder.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Inference.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The sequeunce of character ids (T,).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>The sequences of encoder states(T, eunits).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>127
128
129
130
131
132
133
134
135
136
137
138
139
140
141</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Inference.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): The sequeunce of character ids (T,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: The sequences of encoder states(T, eunits).</span>

<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ilens</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ilens</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="encoder_init()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.tacotron2.encoder.encoder_init">
<code class="highlight language-python">
encoder_init<span class="p">(</span><span class="n">m</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Initialize encoder parameters.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/tacotron2/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>17
18
19
20</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encoder_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">"""Initialize encoder parameters."""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s1">'relu'</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer">
<code>transformer</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.add_sos_eos">
<code>add_sos_eos</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.add_sos_eos" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Unility functions for Transformer.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="add_sos_eos()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.add_sos_eos.add_sos_eos">
<code class="highlight language-python">
add_sos_eos<span class="p">(</span><span class="n">ys_pad</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">ignore_id</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Add <code>&lt;sos&gt;</code> and <code>&lt;eos&gt;</code> labels.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ys_pad</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>batch of padded target sequences (B, Lmax)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>sos</code></td>
<td><code>int</code></td>
<td>
<p>index of <code>&lt;sos&gt;</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>eos</code></td>
<td><code>int</code></td>
<td>
<p>index of <code>&lt;eos&gt;</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>ignore_id</code></td>
<td><code>int</code></td>
<td>
<p>index of padding</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.Tensor</code></td>
<td>
<p>padded tensor (B, Lmax)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/add_sos_eos.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">add_sos_eos</span><span class="p">(</span><span class="n">ys_pad</span><span class="p">,</span> <span class="n">sos</span><span class="p">,</span> <span class="n">eos</span><span class="p">,</span> <span class="n">ignore_id</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Add `&lt;sos&gt;` and `&lt;eos&gt;` labels.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        ys_pad (torch.Tensor): batch of padded target sequences (B, Lmax)</span>
<span class="sd">        sos (int): index of `&lt;sos&gt;`</span>
<span class="sd">        eos (int): index of `&lt;eos&gt;`</span>
<span class="sd">        ignore_id (int): index of padding</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: padded tensor (B, Lmax)</span>
<span class="sd">    """</span>
    <span class="kn">from</span> <span class="nn">tools.espnet_minimal</span> <span class="kn">import</span> <span class="n">pad_list</span>
    <span class="n">_sos</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">sos</span><span class="p">])</span>
    <span class="n">_eos</span> <span class="o">=</span> <span class="n">ys_pad</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">eos</span><span class="p">])</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="n">ignore_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys_pad</span><span class="p">]</span>  <span class="c1"># parse padded ys</span>
    <span class="n">ys_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">_sos</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>
    <span class="n">ys_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">_eos</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_in</span><span class="p">,</span> <span class="n">eos</span><span class="p">),</span> <span class="n">pad_list</span><span class="p">(</span><span class="n">ys_out</span><span class="p">,</span> <span class="n">ignore_id</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention">
<code>attention</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Multi-Head Attention layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="MultiHeadedAttention" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention">
<code>MultiHeadedAttention</code>
</h7>
<div class="doc doc-contents">
<p>Multi-Head Attention layer.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int n_head: the number of head s</span>
<span class="err">:param int n_feat: the number of features</span>
<span class="err">:param float dropout_rate: dropout rate</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an MultiHeadedAttention object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/attention.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>25
26
27
28
29
30
31
32
33
34
35
36
37</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="sd">"""Construct an MultiHeadedAttention object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadedAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">n_feat</span> <span class="o">%</span> <span class="n">n_head</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="c1"># We assume d_v always equals d_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">n_feat</span> <span class="o">//</span> <span class="n">n_head</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">n_head</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Compute 'Scaled Dot Product Attention'.</p>
<p>:param torch.Tensor query: (batch, time1, size)
:param torch.Tensor key: (batch, time2, size)
:param torch.Tensor value: (batch, time2, size)
:param torch.Tensor mask: (batch, time1, time2)
:param torch.nn.Dropout dropout:
:return torch.Tensor: attentined and transformed <code>value</code> (batch, time1, d_model)
     weighted by the query dot key attention (batch, head, time1, time2)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/attention.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="sd">"""Compute 'Scaled Dot Product Attention'.</span>

<span class="sd">    :param torch.Tensor query: (batch, time1, size)</span>
<span class="sd">    :param torch.Tensor key: (batch, time2, size)</span>
<span class="sd">    :param torch.Tensor value: (batch, time2, size)</span>
<span class="sd">    :param torch.Tensor mask: (batch, time1, time2)</span>
<span class="sd">    :param torch.nn.Dropout dropout:</span>
<span class="sd">    :return torch.Tensor: attentined and transformed `value` (batch, time1, d_model)</span>
<span class="sd">         weighted by the query dot key attention (batch, head, time1, time2)</span>
<span class="sd">    """</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_q</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_k</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_v</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch, head, time1, d_k)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch, head, time2, d_k)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch, head, time2, d_k)</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>  <span class="c1"># (batch, head, time1, time2)</span>
    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (batch, 1, time1, time2)</span>
        <span class="n">min_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">min_value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># (batch, head, time1, time2)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, head, time1, time2)</span>

    <span class="n">p_attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">p_attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch, head, time1, d_k)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>  <span class="c1"># (batch, time1, d_model)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch, time1, d_model)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder">
<code>decoder</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Decoder definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Decoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder.Decoder">
<code>Decoder</code>
</h7>
<div class="doc doc-contents">
<p>Transfomer decoder module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int odim: output dim</span>
<span class="err">:param int attention_dim: dimention of attention</span>
<span class="err">:param int attention_heads: the number of heads of multi head attention</span>
<span class="err">:param int linear_units: the number of units of position-wise feed forward</span>
<span class="err">:param int num_blocks: the number of decoder blocks</span>
<span class="err">:param float dropout_rate: dropout rate</span>
<span class="err">:param float attention_dropout_rate: dropout rate for attention</span>
<span class="err">:param str or torch.nn.Module input_layer: input layer type</span>
<span class="err">:param bool use_output_layer: whether to use output layer</span>
<span class="err">:param class pos_enc_class: PositionalEncoding or ScaledPositionalEncoding</span>
<span class="err">:param bool normalize_before: whether to use layer_norm before the first block</span>
<span class="err">:param bool concat_after: whether to concat attention layer's input and output</span>
<span class="err">    if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x)))</span>
<span class="err">    if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder.Decoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">attention_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">linear_units</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">num_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">self_attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">src_attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">input_layer</span><span class="o">=</span><span class="s1">'embed'</span><span class="p">,</span> <span class="n">use_output_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pos_enc_class</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">tools</span><span class="o">.</span><span class="n">espnet_minimal</span><span class="o">.</span><span class="n">nets</span><span class="o">.</span><span class="n">pytorch_backend</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">PositionalEncoding</span><span class="s1">'&gt;, normalize_before=True, concat_after=False)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an Decoder object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span>
             <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
             <span class="n">attention_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
             <span class="n">linear_units</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
             <span class="n">num_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">self_attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
             <span class="n">src_attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
             <span class="n">input_layer</span><span class="o">=</span><span class="s2">"embed"</span><span class="p">,</span>
             <span class="n">use_output_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">PositionalEncoding</span><span class="p">,</span>
             <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Construct an Decoder object."""</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">input_layer</span> <span class="o">==</span> <span class="s2">"embed"</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">),</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">input_layer</span> <span class="o">==</span> <span class="s2">"linear"</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">input_layer</span><span class="p">,</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"only `embed` or torch.nn.Module is supported."</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="k">lambda</span><span class="p">:</span> <span class="n">DecoderLayer</span><span class="p">(</span>
            <span class="n">attention_dim</span><span class="p">,</span>
            <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">attention_heads</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">self_attention_dropout_rate</span><span class="p">),</span>
            <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">attention_heads</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">src_attention_dropout_rate</span><span class="p">),</span>
            <span class="n">PositionwiseFeedForward</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">linear_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">),</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">normalize_before</span><span class="p">,</span>
            <span class="n">concat_after</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_output_layer</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">odim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder.Decoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Forward decoder.</p>
<p>:param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out) if input_layer == "embed"
                         input tensor (batch, maxlen_out, #mels) in the other cases
:param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                              dtype=torch.uint8 in PyTorch 1.2-
                              dtype=torch.bool in PyTorch 1.2+ (include 1.2)
:param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)
:param torch.Tensor memory_mask: encoded memory mask,  (batch, maxlen_in)
                                 dtype=torch.uint8 in PyTorch 1.2-
                                 dtype=torch.bool in PyTorch 1.2+ (include 1.2)
:return x: decoded token score before softmax (batch, maxlen_out, token) if use_output_layer is True,
           final block outputs (batch, maxlen_out, attention_dim) in the other cases
:rtype: torch.Tensor
:return tgt_mask: score mask before softmax (batch, maxlen_out)
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">):</span>
    <span class="sd">"""Forward decoder.</span>

<span class="sd">    :param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out) if input_layer == "embed"</span>
<span class="sd">                             input tensor (batch, maxlen_out, #mels) in the other cases</span>
<span class="sd">    :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)</span>
<span class="sd">                                  dtype=torch.uint8 in PyTorch 1.2-</span>
<span class="sd">                                  dtype=torch.bool in PyTorch 1.2+ (include 1.2)</span>
<span class="sd">    :param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)</span>
<span class="sd">    :param torch.Tensor memory_mask: encoded memory mask,  (batch, maxlen_in)</span>
<span class="sd">                                     dtype=torch.uint8 in PyTorch 1.2-</span>
<span class="sd">                                     dtype=torch.bool in PyTorch 1.2+ (include 1.2)</span>
<span class="sd">    :return x: decoded token score before softmax (batch, maxlen_out, token) if use_output_layer is True,</span>
<span class="sd">               final block outputs (batch, maxlen_out, attention_dim) in the other cases</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    :return tgt_mask: score mask before softmax (batch, maxlen_out)</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">after_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward_one_step()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder.Decoder.forward_one_step">
<code class="highlight language-python">
forward_one_step<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Forward one step.</p>
<p>:param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out)
:param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                              dtype=torch.uint8 in PyTorch 1.2-
                              dtype=torch.bool in PyTorch 1.2+ (include 1.2)
:param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)
:param List[torch.Tensor] cache: cached output list of (batch, max_time_out-1, size)
:return y, cache: NN output value and cache per <code>self.decoders</code>.
    <code>y.shape</code> is (batch, maxlen_out, token)
:rtype: Tuple[torch.Tensor, List[torch.Tensor]]</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward_one_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Forward one step.</span>

<span class="sd">    :param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out)</span>
<span class="sd">    :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)</span>
<span class="sd">                                  dtype=torch.uint8 in PyTorch 1.2-</span>
<span class="sd">                                  dtype=torch.bool in PyTorch 1.2+ (include 1.2)</span>
<span class="sd">    :param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)</span>
<span class="sd">    :param List[torch.Tensor] cache: cached output list of (batch, max_time_out-1, size)</span>
<span class="sd">    :return y, cache: NN output value and cache per `self.decoders`.</span>
<span class="sd">        `y.shape` is (batch, maxlen_out, token)</span>
<span class="sd">    :rtype: Tuple[torch.Tensor, List[torch.Tensor]]</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cache</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cache</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">)</span>
    <span class="n">new_cache</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">decoder</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
        <span class="n">new_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">after_norm</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">new_cache</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="score()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder.Decoder.score">
<code class="highlight language-python">
score<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Score.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Score."""</span>
    <span class="c1"># TODO(karita): remove this section after all ScorerInterface implements batch decoding</span>
    <span class="k">if</span> <span class="n">ys</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ys_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">logp</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_one_step</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">cache</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">state</span>

    <span class="c1"># merge states</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_state</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># transpose state of [batch, layer] into [layer, batch]</span>
        <span class="n">batch_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">state</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batch</span><span class="p">)])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>

    <span class="c1"># batch decoding</span>
    <span class="n">ys_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">logp</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_one_step</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">ys_mask</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">batch_state</span><span class="p">)</span>

    <span class="c1"># transpose state of [layer, batch] into [batch, layer]</span>
    <span class="n">state_list</span> <span class="o">=</span> <span class="p">[[</span><span class="n">state</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batch</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">logp</span><span class="p">,</span> <span class="n">state_list</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer">
<code>decoder_layer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Decoder self-attention layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="DecoderLayer" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer">
<code>DecoderLayer</code>
</h7>
<div class="doc doc-contents">
<p>Single decoder layer module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int size: input dim</span>
<span class="err">:param services.hci.speech.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention self_attn: self attention module</span>
<span class="err">:param services.hci.speech.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention src_attn: source attention module</span>
<span class="err">:param services.hci.speech.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward feed_forward:</span>
<span class="err">    feed forward layer module</span>
<span class="err">:param float dropout_rate: dropout rate</span>
<span class="err">:param bool normalize_before: whether to use layer_norm before the first block</span>
<span class="err">:param bool concat_after: whether to concat attention layer's input and output</span>
<span class="err">    if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x)))</span>
<span class="err">    if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">self_attn</span><span class="p">,</span> <span class="n">src_attn</span><span class="p">,</span> <span class="n">feed_forward</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an DecoderLayer object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder_layer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">self_attn</span><span class="p">,</span> <span class="n">src_attn</span><span class="p">,</span> <span class="n">feed_forward</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span>
             <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Construct an DecoderLayer object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">self_attn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span> <span class="o">=</span> <span class="n">src_attn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">feed_forward</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span> <span class="o">=</span> <span class="n">concat_after</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Compute decoded features.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tgt</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>decoded previous target features (batch, max_time_out, size)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>tgt_mask</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>mask for x (batch, max_time_out)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>memory</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>encoded source features (batch, max_time_in, size)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>memory_mask</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>mask for memory (batch, max_time_in)</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>cache</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>cached output (batch, max_time_out-1, size)</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/decoder_layer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Compute decoded features.</span>

<span class="sd">    Args:</span>
<span class="sd">        tgt (torch.Tensor): decoded previous target features (batch, max_time_out, size)</span>
<span class="sd">        tgt_mask (torch.Tensor): mask for x (batch, max_time_out)</span>
<span class="sd">        memory (torch.Tensor): encoded source features (batch, max_time_in, size)</span>
<span class="sd">        memory_mask (torch.Tensor): mask for memory (batch, max_time_in)</span>
<span class="sd">        cache (torch.Tensor): cached output (batch, max_time_out-1, size)</span>

<span class="sd">    """</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">tgt</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cache</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tgt_q</span> <span class="o">=</span> <span class="n">tgt</span>
        <span class="n">tgt_q_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># compute only the last frame query keeping dim: max_time_out -&gt; 1</span>
        <span class="k">assert</span> <span class="n">cache</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">tgt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tgt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> \
            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> == </span><span class="si">{</span><span class="p">(</span><span class="n">tgt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tgt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">tgt_q</span> <span class="o">=</span> <span class="n">tgt</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">residual</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="n">tgt_q_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">tgt_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tgt_q_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span><span class="p">:</span>
        <span class="n">tgt_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">tgt_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">tgt_q</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_q_mask</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear1</span><span class="p">(</span><span class="n">tgt_concat</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">tgt_q</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_q_mask</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span><span class="p">:</span>
        <span class="n">x_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear2</span><span class="p">(</span><span class="n">x_concat</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">cache</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_mask</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding">
<code>embedding</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Positonal Encoding Module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="PositionalEncoding" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.PositionalEncoding">
<code>PositionalEncoding</code>
</h7>
<div class="doc doc-contents">
<p>Positional encoding.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int d_model: embedding dim</span>
<span class="err">:param float dropout_rate: dropout rate</span>
<span class="err">:param int max_len: maximum input length</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.PositionalEncoding.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an PositionalEncoding object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>37
38
39
40
41
42
43
44
45</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
    <span class="sd">"""Construct an PositionalEncoding object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">xscale</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">extend_pe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_register_load_state_dict_pre_hook</span><span class="p">(</span><span class="n">_pre_hook</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="extend_pe()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.PositionalEncoding.extend_pe">
<code class="highlight language-python">
extend_pe<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Reset the positional encodings.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>47
48
49
50
51
52
53
54
55
56
57
58
59
60
61</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">extend_pe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Reset the positional encodings."""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span>
    <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span>
                         <span class="o">-</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
    <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.PositionalEncoding.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Add positional encoding.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input. Its shape is (batch, time, ...)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.Tensor</code></td>
<td>
<p>Encoded tensor. Its shape is (batch, time, ...)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>63
64
65
66
67
68
69
70
71
72
73
74
75</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="sd">"""Add positional encoding.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input. Its shape is (batch, time, ...)</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)</span>

<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">extend_pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xscale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="ScaledPositionalEncoding" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding">
<code>ScaledPositionalEncoding</code>
</h7>
<div class="doc doc-contents">
<p>Scaled positional encoding module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">See also: Sec. 3.2  https://arxiv.org/pdf/1809.08895.pdf</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize class.</p>
<p>:param int d_model: embedding dim
:param float dropout_rate: dropout rate
:param int max_len: maximum input length</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>85
86
87
88
89
90
91
92
93
94</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
    <span class="sd">"""Initialize class.</span>

<span class="sd">    :param int d_model: embedding dim</span>
<span class="sd">    :param float dropout_rate: dropout rate</span>
<span class="sd">    :param int max_len: maximum input length</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Add positional encoding.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>Input. Its shape is (batch, time, ...)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.Tensor</code></td>
<td>
<p>Encoded tensor. Its shape is (batch, time, ...)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>100
101
102
103
104
105
106
107
108
109
110
111
112</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Add positional encoding.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input. Its shape is (batch, time, ...)</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)</span>

<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">extend_pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="reset_parameters()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.reset_parameters">
<code class="highlight language-python">
reset_parameters<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Reset parameters.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/embedding.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>96
97
98</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Reset parameters."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder">
<code>encoder</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Encoder definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Encoder" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder.Encoder">
<code>Encoder</code>
</h7>
<div class="doc doc-contents">
<p>Transformer encoder module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: input dim</span>
<span class="err">:param int attention_dim: dimention of attention</span>
<span class="err">:param int attention_heads: the number of heads of multi head attention</span>
<span class="err">:param int linear_units: the number of units of position-wise feed forward</span>
<span class="err">:param int num_blocks: the number of decoder blocks</span>
<span class="err">:param float dropout_rate: dropout rate</span>
<span class="err">:param float attention_dropout_rate: dropout rate in attention</span>
<span class="err">:param float positional_dropout_rate: dropout rate after adding positional encoding</span>
<span class="err">:param str or torch.nn.Module input_layer: input layer type</span>
<span class="err">:param class pos_enc_class: PositionalEncoding or ScaledPositionalEncoding</span>
<span class="err">:param bool normalize_before: whether to use layer_norm before the first block</span>
<span class="err">:param bool concat_after: whether to concat attention layer's input and output</span>
<span class="err">    if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x)))</span>
<span class="err">    if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</span>
<span class="err">:param str positionwise_layer_type: linear of conv1d</span>
<span class="err">:param int positionwise_conv_kernel_size: kernel size of positionwise conv1d layer</span>
<span class="err">:param int padding_idx: padding_idx for input_layer=embed</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder.Encoder.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">attention_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">linear_units</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">num_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">input_layer</span><span class="o">=</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="n">pos_enc_class</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">tools</span><span class="o">.</span><span class="n">espnet_minimal</span><span class="o">.</span><span class="n">nets</span><span class="o">.</span><span class="n">pytorch_backend</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">PositionalEncoding</span><span class="s1">'&gt;, normalize_before=True, concat_after=False, positionwise_layer_type='</span><span class="n">linear</span><span class="s1">', positionwise_conv_kernel_size=1, padding_idx=-1)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an Encoder object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span>
             <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
             <span class="n">attention_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
             <span class="n">linear_units</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
             <span class="n">num_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">positional_dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">attention_dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
             <span class="n">input_layer</span><span class="o">=</span><span class="s2">"conv2d"</span><span class="p">,</span>
             <span class="n">pos_enc_class</span><span class="o">=</span><span class="n">PositionalEncoding</span><span class="p">,</span>
             <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">positionwise_layer_type</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span>
             <span class="n">positionwise_conv_kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">padding_idx</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Construct an Encoder object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">input_layer</span> <span class="o">==</span> <span class="s2">"linear"</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">input_layer</span> <span class="o">==</span> <span class="s2">"conv2d"</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">Conv2dSubsampling</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">input_layer</span> <span class="o">==</span> <span class="s2">"embed"</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">),</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">input_layer</span><span class="p">,</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">input_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">pos_enc_class</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">positional_dropout_rate</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"unknown input_layer: "</span> <span class="o">+</span> <span class="n">input_layer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>
    <span class="k">if</span> <span class="n">positionwise_layer_type</span> <span class="o">==</span> <span class="s2">"linear"</span><span class="p">:</span>
        <span class="n">positionwise_layer</span> <span class="o">=</span> <span class="n">PositionwiseFeedForward</span>
        <span class="n">positionwise_layer_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">linear_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">positionwise_layer_type</span> <span class="o">==</span> <span class="s2">"conv1d"</span><span class="p">:</span>
        <span class="n">positionwise_layer</span> <span class="o">=</span> <span class="n">MultiLayeredConv1d</span>
        <span class="n">positionwise_layer_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">linear_units</span><span class="p">,</span> <span class="n">positionwise_conv_kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">positionwise_layer_type</span> <span class="o">==</span> <span class="s2">"conv1d-linear"</span><span class="p">:</span>
        <span class="n">positionwise_layer</span> <span class="o">=</span> <span class="n">Conv1dLinear</span>
        <span class="n">positionwise_layer_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">linear_units</span><span class="p">,</span> <span class="n">positionwise_conv_kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Support only linear or conv1d."</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="k">lambda</span><span class="p">:</span> <span class="n">EncoderLayer</span><span class="p">(</span>
            <span class="n">attention_dim</span><span class="p">,</span>
            <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">attention_heads</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">attention_dropout_rate</span><span class="p">),</span>
            <span class="n">positionwise_layer</span><span class="p">(</span><span class="o">*</span><span class="n">positionwise_layer_args</span><span class="p">),</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">normalize_before</span><span class="p">,</span>
            <span class="n">concat_after</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder.Encoder.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Embed positions in tensor.</p>
<p>:param torch.Tensor xs: input tensor
:param torch.Tensor masks: input mask
:return: position embedded tensor and mask
:rtype Tuple[torch.Tensor, torch.Tensor]:</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/encoder.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">masks</span><span class="p">):</span>
    <span class="sd">"""Embed positions in tensor.</span>

<span class="sd">    :param torch.Tensor xs: input tensor</span>
<span class="sd">    :param torch.Tensor masks: input mask</span>
<span class="sd">    :return: position embedded tensor and mask</span>
<span class="sd">    :rtype Tuple[torch.Tensor, torch.Tensor]:</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">,</span> <span class="n">Conv2dSubsampling</span><span class="p">):</span>
        <span class="n">xs</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">after_norm</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">masks</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer">
<code>encoder_layer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Encoder self-attention layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="EncoderLayer" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer">
<code>EncoderLayer</code>
</h7>
<div class="doc doc-contents">
<p>Encoder layer module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int size: input dim</span>
<span class="err">:param services.hci.speech.espnet_minimal.nets.pytorch_backend.transformer.attention.MultiHeadedAttention self_attn: self attention module</span>
<span class="err">:param services.hci.speech.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward feed_forward:</span>
<span class="err">    feed forward module</span>
<span class="err">:param float dropout_rate: dropout rate</span>
<span class="err">:param bool normalize_before: whether to use layer_norm before the first block</span>
<span class="err">:param bool concat_after: whether to concat attention layer's input and output</span>
<span class="err">    if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x)))</span>
<span class="err">    if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">self_attn</span><span class="p">,</span> <span class="n">feed_forward</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an EncoderLayer object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/encoder_layer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">self_attn</span><span class="p">,</span> <span class="n">feed_forward</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span>
             <span class="n">normalize_before</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">concat_after</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Construct an EncoderLayer object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">self_attn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">feed_forward</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span> <span class="o">=</span> <span class="n">concat_after</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Compute encoded features.</p>
<p>:param torch.Tensor x: encoded source features (batch, max_time_in, size)
:param torch.Tensor mask: mask for x (batch, max_time_in)
:rtype: Tuple[torch.Tensor, torch.Tensor]</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/encoder_layer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="sd">"""Compute encoded features.</span>

<span class="sd">    :param torch.Tensor x: encoded source features (batch, max_time_in, size)</span>
<span class="sd">    :param torch.Tensor mask: mask for x (batch, max_time_in)</span>
<span class="sd">    :rtype: Tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">    """</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_after</span><span class="p">:</span>
        <span class="n">x_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_linear</span><span class="p">(</span><span class="n">x_concat</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_before</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.initializer">
<code>initializer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.initializer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Parameter initialization.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="initialize()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.initializer.initialize">
<code class="highlight language-python">
initialize<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">init_type</span><span class="o">=</span><span class="s1">'pytorch'</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Initialize Transformer module.</p>
<p>:param torch.nn.Module model: transformer instance
:param str init_type: initialization type</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/initializer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">init_type</span><span class="o">=</span><span class="s2">"pytorch"</span><span class="p">):</span>
    <span class="sd">"""Initialize Transformer module.</span>

<span class="sd">    :param torch.nn.Module model: transformer instance</span>
<span class="sd">    :param str init_type: initialization type</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">init_type</span> <span class="o">==</span> <span class="s2">"pytorch"</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># weight init</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">init_type</span> <span class="o">==</span> <span class="s2">"xavier_uniform"</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">init_type</span> <span class="o">==</span> <span class="s2">"xavier_normal"</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">init_type</span> <span class="o">==</span> <span class="s2">"kaiming_uniform"</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">init_type</span> <span class="o">==</span> <span class="s2">"kaiming_normal"</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Unknown initialization: "</span> <span class="o">+</span> <span class="n">init_type</span><span class="p">)</span>
    <span class="c1"># bias init</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="c1"># reset some modules with default init</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">)):</span>
            <span class="n">m</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss">
<code>label_smoothing_loss</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Label smoothing module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="LabelSmoothingLoss" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss">
<code>LabelSmoothingLoss</code>
</h7>
<div class="doc doc-contents">
<p>Label-smoothing loss.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int size: the number of class</span>
<span class="err">:param int padding_idx: ignored class id</span>
<span class="err">:param float smoothing: smoothing rate (0.0 means the conventional CE)</span>
<span class="err">:param bool normalize_length: normalize loss by sequence length if True</span>
<span class="err">:param torch.nn.Module criterion: loss function to be smoothed</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">smoothing</span><span class="p">,</span> <span class="n">normalize_length</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="n">KLDivLoss</span><span class="p">())</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an LabelSmoothingLoss object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/label_smoothing_loss.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>23
24
25
26
27
28
29
30
31
32</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">smoothing</span><span class="p">,</span> <span class="n">normalize_length</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">reduce</span><span class="o">=</span><span class="kc">False</span><span class="p">)):</span>
    <span class="sd">"""Construct an LabelSmoothingLoss object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LabelSmoothingLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">smoothing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">=</span> <span class="n">smoothing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">true_dist</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize_length</span> <span class="o">=</span> <span class="n">normalize_length</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Compute loss between x and target.</p>
<p>:param torch.Tensor x: prediction (batch, seqlen, class)
:param torch.Tensor target: target signal masked with self.padding_id (batch, seqlen)
:return: scalar float value
:rtype torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/label_smoothing_loss.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="sd">"""Compute loss between x and target.</span>

<span class="sd">    :param torch.Tensor x: prediction (batch, seqlen, class)</span>
<span class="sd">    :param torch.Tensor target: target signal masked with self.padding_id (batch, seqlen)</span>
<span class="sd">    :return: scalar float value</span>
<span class="sd">    :rtype torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">true_dist</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">true_dist</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">ignore</span> <span class="o">=</span> <span class="n">target</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>  <span class="c1"># (B,)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="o">-</span> <span class="n">ignore</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">ignore</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># avoid -1 index</span>
        <span class="n">true_dist</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span><span class="p">)</span>
    <span class="n">kl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">true_dist</span><span class="p">)</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">total</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_length</span> <span class="k">else</span> <span class="n">batch_size</span>
    <span class="k">return</span> <span class="n">kl</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">ignore</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">denom</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm">
<code>layer_norm</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Layer normalization module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="LayerNorm" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm.LayerNorm">
<code>LayerNorm</code>
</h7>
<div class="doc doc-contents">
<p>Layer normalization module.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int nout: output dim size</span>
<span class="err">:param int dim: dimension to be normalized</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm.LayerNorm.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nout</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an LayerNorm object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/layer_norm.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>19
20
21
22</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nout</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Construct an LayerNorm object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">nout</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.layer_norm.LayerNorm.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Apply layer normalization.</p>
<p>:param torch.Tensor x: input tensor
:return: layer normalized tensor
:rtype torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/layer_norm.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>24
25
26
27
28
29
30
31
32
33</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Apply layer normalization.</span>

<span class="sd">    :param torch.Tensor x: input tensor</span>
<span class="sd">    :return: layer normalized tensor</span>
<span class="sd">    :rtype torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask">
<code>mask</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Mask module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="subsequent_mask()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask.subsequent_mask">
<code class="highlight language-python">
subsequent_mask<span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Create mask for subsequent steps (1, size, size).</p>
<p>:param int size: size of mask
:param str device: "cpu" or "cuda" or torch.Tensor.device
:param torch.dtype dtype: result dtype
:rtype: torch.Tensor</p>
<blockquote>
<blockquote>
<blockquote>
<p>subsequent_mask(3)
[[1, 0, 0],
 [1, 1, 0],
 [1, 1, 1]]</p>
</blockquote>
</blockquote>
</blockquote>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/mask.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>16
17
18
19
20
21
22
23
24
25
26
27
28
29</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">subsequent_mask</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">datatype</span><span class="p">):</span>
    <span class="sd">"""Create mask for subsequent steps (1, size, size).</span>

<span class="sd">    :param int size: size of mask</span>
<span class="sd">    :param str device: "cpu" or "cuda" or torch.Tensor.device</span>
<span class="sd">    :param torch.dtype dtype: result dtype</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    &gt;&gt;&gt; subsequent_mask(3)</span>
<span class="sd">    [[1, 0, 0],</span>
<span class="sd">     [1, 1, 0],</span>
<span class="sd">     [1, 1, 1]]</span>
<span class="sd">    """</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">ret</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="target_mask()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.mask.target_mask">
<code class="highlight language-python">
target_mask<span class="p">(</span><span class="n">ys_in_pad</span><span class="p">,</span> <span class="n">ignore_id</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Create mask for decoder self-attention.</p>
<p>:param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)
:param int ignore_id: index of padding
:param torch.dtype dtype: result dtype
:rtype: torch.Tensor</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/mask.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>32
33
34
35
36
37
38
39
40
41
42</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">target_mask</span><span class="p">(</span><span class="n">ys_in_pad</span><span class="p">,</span> <span class="n">ignore_id</span><span class="p">):</span>
    <span class="sd">"""Create mask for decoder self-attention.</span>

<span class="sd">    :param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)</span>
<span class="sd">    :param int ignore_id: index of padding</span>
<span class="sd">    :param torch.dtype dtype: result dtype</span>
<span class="sd">    :rtype: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="n">ys_mask</span> <span class="o">=</span> <span class="n">ys_in_pad</span> <span class="o">!=</span> <span class="n">ignore_id</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">ys_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">ys_mask</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ys_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">m</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv">
<code>multi_layer_conv</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Layer modules for FFT block in FastSpeech (Feed-forward Transformer).</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Conv1dLinear" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear">
<code>Conv1dLinear</code>
</h7>
<div class="doc doc-contents">
<p>Conv1D + Linear for Transformer block.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">A variant of MultiLayeredConv1d, which replaces second conv-layer to linear.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize Conv1dLinear module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>in_chans</code></td>
<td><code>int</code></td>
<td>
<p>Number of input channels.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hidden_chans</code></td>
<td><code>int</code></td>
<td>
<p>Number of hidden channels.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>kernel_size</code></td>
<td><code>int</code></td>
<td>
<p>Kernel size of conv1d.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>dropout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Dropout rate.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/multi_layer_conv.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>61
62
63
64
65
66
67
68
69
70
71
72
73
74
75</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="sd">"""Initialize Conv1dLinear module.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_chans (int): Number of input channels.</span>
<span class="sd">        hidden_chans (int): Number of hidden channels.</span>
<span class="sd">        kernel_size (int): Kernel size of conv1d.</span>
<span class="sd">        dropout_rate (float): Dropout rate.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv1dLinear</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_chans</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input tensors (B, ..., in_chans).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of output tensors (B, ..., hidden_chans).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/multi_layer_conv.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>77
78
79
80
81
82
83
84
85
86
87
88</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Batch of input tensors (B, ..., in_chans).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of output tensors (B, ..., hidden_chans).</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="MultiLayeredConv1d" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d">
<code>MultiLayeredConv1d</code>
</h7>
<div class="doc doc-contents">
<p>Multi-layered conv1d for Transformer block.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">This</span> <span class="k">is</span> <span class="n">a</span> <span class="n">module</span> <span class="k">of</span> <span class="n">multi</span><span class="o">-</span><span class="n">leyered</span> <span class="n">conv1d</span> <span class="n">designed</span> <span class="k">to</span> <span class="k">replace</span> <span class="n">positionwise</span> <span class="n">feed</span><span class="o">-</span><span class="k">forward</span> <span class="n">network</span>
<span class="k">in</span> <span class="n">Transforner</span> <span class="n">block</span><span class="p">,</span> <span class="n">which</span> <span class="k">is</span> <span class="n">introduced</span> <span class="k">in</span> <span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="n">_</span><span class="p">.</span>

<span class="p">..</span> <span class="n">_</span><span class="o">`</span><span class="n">FastSpeech</span><span class="p">:</span> <span class="n">Fast</span><span class="p">,</span> <span class="n">Robust</span> <span class="k">and</span> <span class="n">Controllable</span> <span class="nb">Text</span> <span class="k">to</span> <span class="n">Speech</span><span class="o">`</span><span class="p">:</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pdf</span><span class="o">/</span><span class="mi">1905</span><span class="p">.</span><span class="mi">09263</span><span class="p">.</span><span class="n">pdf</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Initialize MultiLayeredConv1d module.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>in_chans</code></td>
<td><code>int</code></td>
<td>
<p>Number of input channels.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hidden_chans</code></td>
<td><code>int</code></td>
<td>
<p>Number of hidden channels.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>kernel_size</code></td>
<td><code>int</code></td>
<td>
<p>Kernel size of conv1d.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>dropout_rate</code></td>
<td><code>float</code></td>
<td>
<p>Dropout rate.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/multi_layer_conv.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="sd">"""Initialize MultiLayeredConv1d module.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_chans (int): Number of input channels.</span>
<span class="sd">        hidden_chans (int): Number of hidden channels.</span>
<span class="sd">        kernel_size (int): Kernel size of conv1d.</span>
<span class="sd">        dropout_rate (float): Dropout rate.</span>

<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MultiLayeredConv1d</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">hidden_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hidden_chans</span><span class="p">,</span> <span class="n">in_chans</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Batch of input tensors (B, ..., in_chans).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Batch of output tensors (B, ..., hidden_chans).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/multi_layer_conv.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>40
41
42
43
44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Batch of input tensors (B, ..., in_chans).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Batch of output tensors (B, ..., hidden_chans).</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer">
<code>optimizer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Optimizer module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="NoamOpt" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt">
<code>NoamOpt</code>
</h7>
<div class="doc doc-contents">
<p>Optim wrapper that implements rate.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h8 class="doc doc-heading" data-toc-label="param_groups" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.param_groups">
<code class="highlight">
param_groups        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Return param_groups.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_size</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">warmup</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an NoamOpt object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>15
16
17
18
19
20
21
22</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_size</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">warmup</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="sd">"""Construct an NoamOpt object."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">warmup</span> <span class="o">=</span> <span class="n">warmup</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model_size</span> <span class="o">=</span> <span class="n">model_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="load_state_dict()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.load_state_dict">
<code class="highlight language-python">
load_state_dict<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Load state_dict.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>60
61
62
63
64
65
66</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
    <span class="sd">"""Load state_dict."""</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">"optimizer"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">"optimizer"</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="rate()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.rate">
<code class="highlight language-python">
rate<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Implement <code>lrate</code> above.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>38
39
40
41
42
43</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Implement `lrate` above."""</span>
    <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_size</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> \
           <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">step</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">step</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="state_dict()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.state_dict">
<code class="highlight language-python">
state_dict<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Return state_dict.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>49
50
51
52
53
54
55
56
57
58</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Return state_dict."""</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">"_step"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">,</span>
        <span class="s2">"warmup"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup</span><span class="p">,</span>
        <span class="s2">"factor"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span><span class="p">,</span>
        <span class="s2">"model_size"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_size</span><span class="p">,</span>
        <span class="s2">"_rate"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">,</span>
        <span class="s2">"optimizer"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="p">}</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="step()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.step">
<code class="highlight language-python">
step<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Update parameters and rate.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>29
30
31
32
33
34
35
36</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Update parameters and rate."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rate</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">p</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span> <span class="o">=</span> <span class="n">rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="zero_grad()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.NoamOpt.zero_grad">
<code class="highlight language-python">
zero_grad<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Reset gradient.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>45
46
47</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Reset gradient."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="get_std_opt()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.optimizer.get_std_opt">
<code class="highlight language-python">
get_std_opt<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup</span><span class="p">,</span> <span class="n">factor</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Get standard NoamOpt.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/optimizer.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>69
70
71
72</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_std_opt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup</span><span class="p">,</span> <span class="n">factor</span><span class="p">):</span>
    <span class="sd">"""Get standard NoamOpt."""</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">NoamOpt</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">warmup</span><span class="p">,</span> <span class="n">base</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot">
<code>plot</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="PlotAttentionReport" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.PlotAttentionReport">
<code>PlotAttentionReport</code>
</h7>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__call__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.PlotAttentionReport.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>70
71
72
73</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">):</span>
    <span class="n">attn_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_attention_weights</span><span class="p">()</span>
    <span class="n">suffix</span> <span class="o">=</span> <span class="s2">"ep.{.updater.epoch}.png"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plotfn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outdir</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">savefig</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="get_attention_weights()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.PlotAttentionReport.get_attention_weights">
<code class="highlight language-python">
get_attention_weights<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>75
76
77
78
79
80
81</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">converter</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_vis_fn</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">att_ws</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_vis_fn</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">att_ws</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="log_attentions()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.PlotAttentionReport.log_attentions">
<code class="highlight language-python">
log_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>83
84
85
86
87
88
89
90</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">log_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">log_fig</span><span class="p">(</span><span class="n">plot</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">basename</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">add_figure</span><span class="p">(</span><span class="n">basename</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span> <span class="n">plot</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>

    <span class="n">attn_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_attention_weights</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plotfn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outdir</span><span class="p">,</span> <span class="s2">""</span><span class="p">,</span> <span class="n">log_fig</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="plotfn()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.PlotAttentionReport.plotfn">
<code class="highlight language-python">
plotfn<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>67
68</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">plotfn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">plot_multi_head_attention</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="plot_multi_head_attention()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.plot_multi_head_attention">
<code class="highlight language-python">
plot_multi_head_attention<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="n">outdir</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">'png'</span><span class="p">,</span> <span class="n">savefn</span><span class="o">=&lt;</span><span class="n">function</span> <span class="n">savefig</span> <span class="n">at</span> <span class="mh">0x7fe3c583ee50</span><span class="o">&gt;</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Plot multi head attentions</p>
<p>:param dict data: utts info from json file
:param dict[str, torch.Tensor] attn_dict: multi head attention dict.
    values should be torch.Tensor (head, input_length, output_length)
:param str outdir: dir to save fig
:param str suffix: filename suffix including image type (e.g., png)
:param savefn: function to save</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">plot_multi_head_attention</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attn_dict</span><span class="p">,</span> <span class="n">outdir</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s2">"png"</span><span class="p">,</span> <span class="n">savefn</span><span class="o">=</span><span class="n">savefig</span><span class="p">):</span>
    <span class="sd">"""Plot multi head attentions</span>

<span class="sd">    :param dict data: utts info from json file</span>
<span class="sd">    :param dict[str, torch.Tensor] attn_dict: multi head attention dict.</span>
<span class="sd">        values should be torch.Tensor (head, input_length, output_length)</span>
<span class="sd">    :param str outdir: dir to save fig</span>
<span class="sd">    :param str suffix: filename suffix including image type (e.g., png)</span>
<span class="sd">    :param savefn: function to save</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">att_ws</span> <span class="ow">in</span> <span class="n">attn_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">att_w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">att_ws</span><span class="p">):</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="s2">"</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">outdir</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="p">,</span> <span class="n">suffix</span><span class="p">)</span>
            <span class="n">dec_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s1">'output'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">enc_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s1">'input'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="s2">"encoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">att_w</span> <span class="o">=</span> <span class="n">att_w</span><span class="p">[:,</span> <span class="p">:</span><span class="n">enc_len</span><span class="p">,</span> <span class="p">:</span><span class="n">enc_len</span><span class="p">]</span>
            <span class="k">elif</span> <span class="s2">"decoder"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">"self"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">att_w</span> <span class="o">=</span> <span class="n">att_w</span><span class="p">[:,</span> <span class="p">:</span><span class="n">dec_len</span><span class="p">,</span> <span class="p">:</span><span class="n">dec_len</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">att_w</span> <span class="o">=</span> <span class="n">att_w</span><span class="p">[:,</span> <span class="p">:</span><span class="n">dec_len</span><span class="p">,</span> <span class="p">:</span><span class="n">enc_len</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"unknown name for shaping attention"</span><span class="p">)</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">_plot_and_save_attention</span><span class="p">(</span><span class="n">att_w</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
            <span class="n">savefn</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="savefig()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.plot.savefig">
<code class="highlight language-python">
savefig<span class="p">(</span><span class="n">plot</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/plot.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>32
33
34</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">savefig</span><span class="p">(</span><span class="n">plot</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward">
<code>positionwise_feed_forward</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Positionwise feed forward layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="PositionwiseFeedForward" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward">
<code>PositionwiseFeedForward</code>
</h7>
<div class="doc doc-contents">
<p>Positionwise feed forward layer.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: input dimenstion</span>
<span class="err">:param int hidden_units: number of hidden units</span>
<span class="err">:param float dropout_rate: dropout rate</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an PositionwiseFeedForward object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/positionwise_feed_forward.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>21
22
23
24
25
26</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="sd">"""Construct an PositionwiseFeedForward object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PositionwiseFeedForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">idim</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">idim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Forward funciton.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/positionwise_feed_forward.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>28
29
30</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Forward funciton."""</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat">
<code>repeat</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Repeat the same layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="MultiSequential" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat.MultiSequential">
<code>MultiSequential</code>
</h7>
<div class="doc doc-contents">
<p>Multi-input multi-output torch.nn.Sequential.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat.MultiSequential.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Repeat.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/repeat.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>15
16
17
18
19</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Repeat."""</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">args</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h7 class="doc doc-heading" data-toc-label="repeat()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.repeat.repeat">
<code class="highlight language-python">
repeat<span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Repeat module N times.</p>
<p>:param int N: repeat time
:param function fn: function to generate module
:return: repeated modules
:rtype: MultiSequential</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/repeat.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>22
23
24
25
26
27
28
29
30</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">"""Repeat module N times.</span>

<span class="sd">    :param int N: repeat time</span>
<span class="sd">    :param function fn: function to generate module</span>
<span class="sd">    :return: repeated modules</span>
<span class="sd">    :rtype: MultiSequential</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">MultiSequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">fn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)])</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling">
<code>subsampling</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Subsampling layer definition.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h7 class="doc doc-heading" data-toc-label="Conv2dSubsampling" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling">
<code>Conv2dSubsampling</code>
</h7>
<div class="doc doc-contents">
<p>Convolutional 2D subsampling (to 1/4 length).</p>
<div class="codehilite">
<pre><span></span><code><span class="err">:param int idim: input dim</span>
<span class="err">:param int odim: output dim</span>
<span class="err">:param flaot dropout_rate: dropout rate</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h8>
<div class="doc doc-contents">
<p>Construct an Conv2dSubsampling object.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/subsampling.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>23
24
25
26
27
28
29
30
31
32
33
34
35</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="sd">"""Construct an Conv2dSubsampling object."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv2dSubsampling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">odim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">odim</span> <span class="o">*</span> <span class="p">(((</span><span class="n">idim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">odim</span><span class="p">),</span>
        <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">odim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h8 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_mask</span><span class="p">)</span> </code>
</h8>
<div class="doc doc-contents">
<p>Subsample x.</p>
<p>:param torch.Tensor x: input tensor
:param torch.Tensor x_mask: input mask
:return: subsampled x and mask
:rtype Tuple[torch.Tensor, torch.Tensor]</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/transformer/subsampling.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>37
38
39
40
41
42
43
44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_mask</span><span class="p">):</span>
    <span class="sd">"""Subsample x.</span>

<span class="sd">    :param torch.Tensor x: input tensor</span>
<span class="sd">    :param torch.Tensor x_mask: input mask</span>
<span class="sd">    :return: subsampled x and mask</span>
<span class="sd">    :rtype Tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (b, c, t, f)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">c</span> <span class="o">*</span> <span class="n">f</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">x_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_mask</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span><span class="mi">2</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet">
<code>wavenet</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>This code is based on https://github.com/kan-bayashi/PytorchWaveNetVocoder.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d">
<code>CausalConv1d</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>1D dilated causal convolution.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 99
100
101
102
103
104
105
106
107</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CausalConv1d</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dilation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                          <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.CausalConv1d.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input tensor with the shape (B, in_channels, T).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Tensor with the shape (B, out_channels, T)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>109
110
111
112
113
114
115
116
117
118
119
120
121
122</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Input tensor with the shape (B, in_channels, T).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Tensor with the shape (B, out_channels, T)</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot">
<code>OneHot</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Convert to one-hot vector.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    depth (int): Dimension of one-hot vector.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>75
76
77</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">OneHot</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.OneHot.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>LongTensor</code></td>
<td>
<p>long tensor variable with the shape  (B, T)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>float tensor variable with the shape (B, depth, T)</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>79
80
81
82
83
84
85
86
87
88
89
90
91
92
93</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (LongTensor): long tensor variable with the shape  (B, T)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: float tensor variable with the shape (B, depth, T)</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x_onehot</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">x_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling">
<code>UpSampling</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Upsampling layer with deconvolution.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    upsampling_factor (int): Upsampling factor.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">upsampling_factor</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>133
134
135
136
137
138
139
140</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">upsampling_factor</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">UpSampling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span> <span class="o">=</span> <span class="n">upsampling_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                                   <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span><span class="p">),</span>
                                   <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span><span class="p">),</span>
                                   <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.UpSampling.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>Input tensor with the shape  (B, C, T)</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Tensor with the shape (B, C, T') where T' = T * upsampling_factor.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>142
143
144
145
146
147
148
149
150
151
152
153
154</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): Input tensor with the shape  (B, C, T)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Tensor with the shape (B, C, T') where T' = T * upsampling_factor.</span>

<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># B x 1 x C x T</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># B x 1 x C x T'</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet">
<code>WaveNet</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Conditional wavenet.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    n_quantize (int): Number of quantization.</span>
<span class="err">    n_aux (int): Number of aux feature dimension.</span>
<span class="err">    n_resch (int): Number of filter channels for residual block.</span>
<span class="err">    n_skipch (int): Number of filter channels for skip connection.</span>
<span class="err">    dilation_depth (int): Number of dilation depth (e.g. if set 10, max dilation = 2^(10-1)).</span>
<span class="err">    dilation_repeat (int): Number of dilation repeat.</span>
<span class="err">    kernel_size (int): Filter size of dilated causal convolution.</span>
<span class="err">    upsampling_factor (int): Upsampling factor.</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_quantize</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_aux</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">n_resch</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_skipch</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dilation_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dilation_repeat</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">upsampling_factor</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_quantize</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_aux</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">n_resch</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_skipch</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
             <span class="n">dilation_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dilation_repeat</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">upsampling_factor</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">WaveNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_aux</span> <span class="o">=</span> <span class="n">n_aux</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_quantize</span> <span class="o">=</span> <span class="n">n_quantize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span> <span class="o">=</span> <span class="n">n_resch</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_skipch</span> <span class="o">=</span> <span class="n">n_skipch</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation_depth</span> <span class="o">=</span> <span class="n">dilation_depth</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation_repeat</span> <span class="o">=</span> <span class="n">dilation_repeat</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span> <span class="o">=</span> <span class="n">upsampling_factor</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation_depth</span><span class="p">)]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation_repeat</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">receptive_field</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># for preprocessing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">OneHot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_quantize</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">CausalConv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_quantize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upsampling</span> <span class="o">=</span> <span class="n">UpSampling</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span><span class="p">)</span>

    <span class="c1"># for residual blocks</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dil_sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dil_tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">skip_1x1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">res_1x1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dil_sigmoid</span> <span class="o">+=</span> <span class="p">[</span><span class="n">CausalConv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">d</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dil_tanh</span> <span class="o">+=</span> <span class="p">[</span><span class="n">CausalConv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">d</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_sigmoid</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_aux</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_tanh</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_aux</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_1x1</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_skipch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_1x1</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_resch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># for postprocessing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_post_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_skipch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_skipch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_post_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_skipch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantize</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="forward()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Calculate forward propagation.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Quantized input waveform tensor with the shape  (B, T).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>h</code></td>
<td><code>Tensor</code></td>
<td>
<p>Auxiliary feature tensor with the shape  (B, n_aux, T).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Logits with the shape (B, T, n_quantize).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="sd">"""Calculate forward propagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (LongTensor): Quantized input waveform tensor with the shape  (B, T).</span>
<span class="sd">        h (Tensor): Auxiliary feature tensor with the shape  (B, n_aux, T).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Logits with the shape (B, T, n_quantize).</span>

<span class="sd">    """</span>
    <span class="c1"># preprocess</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="c1"># residual block</span>
    <span class="n">skip_connections</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="p">)):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">skip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residual_forward</span><span class="p">(</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">skip_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
        <span class="n">skip_connections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">skip</span><span class="p">)</span>

    <span class="c1"># skip-connection part</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">skip_connections</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="generate()" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.WaveNet.generate">
<code class="highlight language-python">
generate<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'sampling'</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Generate a waveform with fast genration algorithm.</p>
<p>This generation based on <code>Fast WaveNet Generation Algorithm</code>_.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>LongTensor</code></td>
<td>
<p>Initial waveform tensor with the shape  (T,).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>h</code></td>
<td><code>Tensor</code></td>
<td>
<p>Auxiliary feature tensor with the shape  (n_samples + T, n_aux).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>n_samples</code></td>
<td><code>int</code></td>
<td>
<p>Number of samples to be generated.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>interval</code></td>
<td><code>int</code></td>
<td>
<p>Log interval.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>mode</code></td>
<td><code>str</code></td>
<td>
<p>"sampling" or "argmax".</p>
</td>
<td><code>'sampling'</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ndarray</code></td>
<td>
<p>Generated quantized waveform (n_samples).</p>
</td>
</tr>
</tbody>
</table>
<p>.. _<code>Fast WaveNet Generation Algorithm</code>: https://arxiv.org/abs/1611.09482</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"sampling"</span><span class="p">):</span>
    <span class="sd">"""Generate a waveform with fast genration algorithm.</span>

<span class="sd">    This generation based on `Fast WaveNet Generation Algorithm`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (LongTensor): Initial waveform tensor with the shape  (T,).</span>
<span class="sd">        h (Tensor): Auxiliary feature tensor with the shape  (n_samples + T, n_aux).</span>
<span class="sd">        n_samples (int): Number of samples to be generated.</span>
<span class="sd">        interval (int, optional): Log interval.</span>
<span class="sd">        mode (str, optional): "sampling" or "argmax".</span>

<span class="sd">    Return:</span>
<span class="sd">        ndarray: Generated quantized waveform (n_samples).</span>

<span class="sd">    .. _`Fast WaveNet Generation Algorithm`: https://arxiv.org/abs/1611.09482</span>

<span class="sd">    """</span>
    <span class="c1"># reshape inputs</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_aux</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># perform upsampling</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling_factor</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsampling</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="c1"># padding for shortage</span>
    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s2">"replicate"</span><span class="p">)</span>

    <span class="c1"># padding if the length less than</span>
    <span class="n">n_pad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">receptive_field</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_pad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">n_pad</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">"constant"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantize</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">(</span><span class="n">n_pad</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">"replicate"</span><span class="p">)</span>

    <span class="c1"># prepare buffer</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">h_</span> <span class="o">=</span> <span class="n">h</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">output_buffer</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="p">):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residual_forward</span><span class="p">(</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">h_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">skip_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">buffer_size</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">buffer_size</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">buffer_size</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># generate</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">h_</span> <span class="o">=</span> <span class="n">h</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">samples</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_aux</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output_buffer_next</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">skip_connections</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">skip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_residual_forward</span><span class="p">(</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">h_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dil_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_sigmoid</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_1x1_tanh</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">skip_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_1x1</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">output_buffer</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">output</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">output_buffer_next</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">buffer_size</span><span class="p">[</span><span class="n">l</span><span class="p">]:])</span>
            <span class="n">skip_connections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">skip</span><span class="p">)</span>

        <span class="c1"># update buffer</span>
        <span class="n">output_buffer</span> <span class="o">=</span> <span class="n">output_buffer_next</span>

        <span class="c1"># get predicted sample</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">skip_connections</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess</span><span class="p">(</span><span class="n">output</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">"sampling"</span><span class="p">:</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">"argmax"</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"mode should be sampling or argmax"</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">sample</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># show progress</span>
        <span class="k">if</span> <span class="n">interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">elapsed_time_per_sample</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="n">interval</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> estimated time = </span><span class="si">%.3f</span><span class="s2"> sec (</span><span class="si">%.3f</span><span class="s2"> sec / sample)"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">elapsed_time_per_sample</span><span class="p">,</span> <span class="n">elapsed_time_per_sample</span><span class="p">))</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="n">n_samples</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.decode_mu_law">
<code class="highlight language-python">
decode_mu_law<span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.decode_mu_law" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform mu-law decoding.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>ndarray</code></td>
<td>
<p>Quantized audio signal with the range from 0 to mu - 1.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>mu</code></td>
<td><code>int</code></td>
<td>
<p>Quantized level.</p>
</td>
<td><code>256</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ndarray</code></td>
<td>
<p>Audio signal with the range from -1 to 1.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>34
35
36
37
38
39
40
41
42
43
44
45
46
47
48</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">decode_mu_law</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
    <span class="sd">"""Perform mu-law decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (ndarray): Quantized audio signal with the range from 0 to mu - 1.</span>
<span class="sd">        mu (int): Quantized level.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Audio signal with the range from -1 to 1.</span>

<span class="sd">    """</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">mu</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">fx</span><span class="p">)</span> <span class="o">/</span> <span class="n">mu</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">mu</span><span class="p">)</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">fx</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.encode_mu_law">
<code class="highlight language-python">
encode_mu_law<span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.encode_mu_law" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Perform mu-law encoding.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>ndarray</code></td>
<td>
<p>Audio signal with the range from -1 to 1.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>mu</code></td>
<td><code>int</code></td>
<td>
<p>Quantized level.</p>
</td>
<td><code>256</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ndarray</code></td>
<td>
<p>Quantized audio signal with the range from 0 to mu - 1.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">encode_mu_law</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
    <span class="sd">"""Perform mu-law encoding.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (ndarray): Audio signal with the range from -1 to 1.</span>
<span class="sd">        mu (int): Quantized level.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Quantized audio signal with the range from 0 to mu - 1.</span>

<span class="sd">    """</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">mu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">fx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">mu</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.initialize">
<code class="highlight language-python">
initialize<span class="p">(</span><span class="n">m</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.pytorch_backend.wavenet.initialize" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initilize conv layers with xavier.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>m</code></td>
<td><code>torch.nn.Module</code></td>
<td>
<p>Torch module.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/pytorch_backend/wavenet.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>51
52
53
54
55
56
57
58
59
60
61
62
63
64</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">"""Initilize conv layers with xavier.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (torch.nn.Module): Torch module.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface">
<code>scorer_interface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>Scorer interface module.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface">
<code>BatchScorerInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Batch scorer interface.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface.score">
<code class="highlight language-python">
score<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.BatchScorerInterface.score" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score new token batch (required).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ys</code></td>
<td><code>Tensor</code></td>
<td>
<p>torch.int64 prefix tokens (n_batch, ylen).</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>states</code></td>
<td><code>List[Any]</code></td>
<td>
<p>Scorer states for prefix tokens.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>xs</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoder feature that generates ys (n_batch, xlen, n_feat).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[torch.Tensor, List[Any]]</code></td>
<td>
<p>tuple[torch.Tensor, List[Any]]: Tuple of
    batchfied scores for next token with shape of <code>(n_batch, n_vocab)</code>
    and next state list for ys.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>84
85
86
87
88
89
90
91
92
93
94
95
96
97
98</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">states</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">xs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]:</span>
    <span class="sd">"""Score new token batch (required).</span>

<span class="sd">    Args:</span>
<span class="sd">        ys (torch.Tensor): torch.int64 prefix tokens (n_batch, ylen).</span>
<span class="sd">        states (List[Any]): Scorer states for prefix tokens.</span>
<span class="sd">        xs (torch.Tensor): The encoder feature that generates ys (n_batch, xlen, n_feat).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[torch.Tensor, List[Any]]: Tuple of</span>
<span class="sd">            batchfied scores for next token with shape of `(n_batch, n_vocab)`</span>
<span class="sd">            and next state list for ys.</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface">
<code>PartialScorerInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Partial scorer interface for beam search.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">The</span> <span class="k">partial</span> <span class="n">scorer</span> <span class="n">performs</span> <span class="n">scoring</span> <span class="k">when</span> <span class="n">non</span><span class="o">-</span><span class="k">partial</span> <span class="n">scorer</span> <span class="n">finished</span> <span class="n">scoring</span><span class="p">,</span>
<span class="k">and</span> <span class="n">recieves</span> <span class="n">pre</span><span class="o">-</span><span class="n">pruned</span> <span class="k">next</span> <span class="n">tokens</span> <span class="k">to</span> <span class="n">score</span> <span class="n">because</span> <span class="n">it</span> <span class="k">is</span> <span class="n">too</span> <span class="n">heavy</span> <span class="k">to</span> <span class="n">score</span>
<span class="k">all</span> <span class="n">the</span> <span class="n">tokens</span><span class="p">.</span>

<span class="o">!!!</span> <span class="n">examples</span>
     <span class="o">*</span> <span class="k">Prefix</span> <span class="k">search</span> <span class="k">for</span> <span class="n">connectionist</span><span class="o">-</span><span class="n">temporal</span><span class="o">-</span><span class="n">classification</span> <span class="n">models</span>
         <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">scorers</span><span class="p">.</span><span class="n">ctc</span><span class="p">.</span><span class="n">CTCPrefixScorer</span><span class="o">`</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface.score_partial">
<code class="highlight language-python">
score_partial<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">next_tokens</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.PartialScorerInterface.score_partial" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score new token (required).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>y</code></td>
<td><code>Tensor</code></td>
<td>
<p>1D prefix token</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>next_tokens</code></td>
<td><code>Tensor</code></td>
<td>
<p>torch.int64 next token to score</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>state</code></td>
<td><code>Any</code></td>
<td>
<p>decoder state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoder feature that generates ys</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[torch.Tensor, Any]</code></td>
<td>
<p>tuple[torch.Tensor, Any]: Tuple of a score tensor for y that has a shape <code>(len(next_tokens),)</code>
    and next state for ys</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score_partial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">next_tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> \
        <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="sd">"""Score new token (required).</span>

<span class="sd">    Args:</span>
<span class="sd">        y (torch.Tensor): 1D prefix token</span>
<span class="sd">        next_tokens (torch.Tensor): torch.int64 next token to score</span>
<span class="sd">        state: decoder state for prefix tokens</span>
<span class="sd">        x (torch.Tensor): The encoder feature that generates ys</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[torch.Tensor, Any]: Tuple of a score tensor for y that has a shape `(len(next_tokens),)`</span>
<span class="sd">            and next state for ys</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface">
<code>ScorerInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Scorer interface for beam search.</p>
<div class="codehilite">
<pre><span></span><code><span class="n">The</span> <span class="n">scorer</span> <span class="n">performs</span> <span class="n">scoring</span> <span class="k">of</span> <span class="n">the</span> <span class="k">all</span> <span class="n">tokens</span> <span class="k">in</span> <span class="n">vocabulary</span><span class="p">.</span>

<span class="o">!!!</span> <span class="n">examples</span>
    <span class="o">*</span> <span class="k">Search</span> <span class="n">heuristics</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">scorers</span><span class="p">.</span><span class="n">length_bonus</span><span class="p">.</span><span class="n">LengthBonus</span><span class="o">`</span>
    <span class="o">*</span> <span class="n">Decoder</span> <span class="n">networks</span> <span class="k">of</span> <span class="n">the</span> <span class="n">sequence</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="n">sequence</span> <span class="n">models</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">pytorch_backend</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">Decoder</span><span class="o">`</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">pytorch_backend</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">rnn</span><span class="p">.</span><span class="n">decoders</span><span class="p">.</span><span class="n">Decoder</span><span class="o">`</span>
    <span class="o">*</span> <span class="n">Neural</span> <span class="k">language</span> <span class="n">models</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">pytorch_backend</span><span class="p">.</span><span class="n">lm</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">TransformerLM</span><span class="o">`</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">pytorch_backend</span><span class="p">.</span><span class="n">lm</span><span class="p">.</span><span class="k">default</span><span class="p">.</span><span class="n">DefaultRNNLM</span><span class="o">`</span>
        <span class="o">*</span> <span class="p">:</span><span class="k">class</span><span class="p">:</span><span class="o">`</span><span class="n">services</span><span class="p">.</span><span class="n">hci</span><span class="p">.</span><span class="n">speech</span><span class="p">.</span><span class="n">espnet_minimal</span><span class="p">.</span><span class="n">nets</span><span class="p">.</span><span class="n">pytorch_backend</span><span class="p">.</span><span class="n">lm</span><span class="p">.</span><span class="n">seq_rnn</span><span class="p">.</span><span class="n">SequentialRNNLM</span><span class="o">`</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.final_score">
<code class="highlight language-python">
final_score<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.final_score" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score eos (optional).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>state</code></td>
<td><code>Any</code></td>
<td>
<p>Scorer state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>float</code></td>
<td>
<p>float: final score</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>68
69
70
71
72
73
74
75
76
77
78</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">final_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Score eos (optional).</span>

<span class="sd">    Args:</span>
<span class="sd">        state: Scorer state for prefix tokens</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: final score</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="mf">0.0</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.init_state">
<code class="highlight language-python">
init_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.init_state" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Get an initial state for decoding (optional).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoded feature tensor</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Returns: initial state</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>28
29
30
31
32
33
34
35
36
37</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">"""Get an initial state for decoding (optional).</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The encoded feature tensor</span>

<span class="sd">    Returns: initial state</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.score">
<code class="highlight language-python">
score<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.score" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Score new token (required).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>y</code></td>
<td><code>Tensor</code></td>
<td>
<p>1D torch.int64 prefix tokens.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>state</code></td>
<td><code>Any</code></td>
<td>
<p>Scorer state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoder feature that generates ys.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[torch.Tensor, Any]</code></td>
<td>
<p>tuple[torch.Tensor, Any]: Tuple of
    scores for next token that has a shape of <code>(n_vocab)</code>
    and next state for ys</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>52
53
54
55
56
57
58
59
60
61
62
63
64
65
66</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="sd">"""Score new token (required).</span>

<span class="sd">    Args:</span>
<span class="sd">        y (torch.Tensor): 1D torch.int64 prefix tokens.</span>
<span class="sd">        state: Scorer state for prefix tokens</span>
<span class="sd">        x (torch.Tensor): The encoder feature that generates ys.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[torch.Tensor, Any]: Tuple of</span>
<span class="sd">            scores for next token that has a shape of `(n_vocab)`</span>
<span class="sd">            and next state for ys</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.select_state">
<code class="highlight language-python">
select_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorer_interface.ScorerInterface.select_state" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Select state with relative ids in the main beam search.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>state</code></td>
<td><code>Any</code></td>
<td>
<p>Decoder state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>i</code></td>
<td><code>int</code></td>
<td>
<p>Index to select a state in the main beam search</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Any</code></td>
<td>
<p>state: pruned state</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorer_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>39
40
41
42
43
44
45
46
47
48
49
50</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">select_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">"""Select state with relative ids in the main beam search.</span>

<span class="sd">    Args:</span>
<span class="sd">        state: Decoder state for prefix tokens</span>
<span class="sd">        i (int): Index to select a state in the main beam search</span>

<span class="sd">    Returns:</span>
<span class="sd">        state: pruned state</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorers">
<code>scorers</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorers" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorers.ctc">
<code>ctc</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorers.ctc" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>ScorerInterface implementation for CTC.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer">
<code>CTCPrefixScorer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Decoder interface wrapper for CTCPrefixScore.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctc</span><span class="p">,</span> <span class="n">eos</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Initialize class.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ctc</code></td>
<td><code>Module</code></td>
<td>
<p>The CTC implementaiton. For example, :class:<code>services.hci.speech.espnet_minimal.nets.pytorch_backend.ctc.CTC</code></p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>eos</code></td>
<td><code>int</code></td>
<td>
<p>The end-of-sequence id.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorers/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>13
14
15
16
17
18
19
20
21
22
23</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctc</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">"""Initialize class.</span>

<span class="sd">    Args:</span>
<span class="sd">        ctc (torch.nn.Module): The CTC implementaiton. For example, :class:`services.hci.speech.espnet_minimal.nets.pytorch_backend.ctc.CTC`</span>
<span class="sd">        eos (int): The end-of-sequence id.</span>

<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span> <span class="o">=</span> <span class="n">ctc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">impl</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="init_state()" id="adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer.init_state">
<code class="highlight language-python">
init_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Get an initial state for decoding.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Tensor</code></td>
<td>
<p>The encoded feature tensor</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Returns: initial state</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorers/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>25
26
27
28
29
30
31
32
33
34
35
36
37</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="sd">"""Get an initial state for decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The encoded feature tensor</span>

<span class="sd">    Returns: initial state</span>

<span class="sd">    """</span>
    <span class="n">logp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="c1"># TODO(karita): use CTCPrefixScoreTH</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">impl</span> <span class="o">=</span> <span class="n">CTCPrefixScore</span><span class="p">(</span><span class="n">logp</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">,</span> <span class="n">np</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">impl</span><span class="o">.</span><span class="n">initial_state</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="score_partial()" id="adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer.score_partial">
<code class="highlight language-python">
score_partial<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Score new token.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>y</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>1D prefix token</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>next_tokens</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>torch.int64 next token to score</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>state</code></td>
<td><code></code></td>
<td>
<p>decoder state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>2D encoder feature that generates ys</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tuple[torch.Tensor, Any]</code></td>
<td>
<p>Tuple of a score tensor for y that has a shape <code>(len(next_tokens),)</code>
    and next state for ys</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorers/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">score_partial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Score new token.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (torch.Tensor): 1D prefix token</span>
<span class="sd">        next_tokens (torch.Tensor): torch.int64 next token to score</span>
<span class="sd">        state: decoder state for prefix tokens</span>
<span class="sd">        x (torch.Tensor): 2D encoder feature that generates ys</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[torch.Tensor, Any]: Tuple of a score tensor for y that has a shape `(len(next_tokens),)`</span>
<span class="sd">            and next state for ys</span>

<span class="sd">    """</span>
    <span class="n">prev_score</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">presub_score</span><span class="p">,</span> <span class="n">new_st</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">ids</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">tscore</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">presub_score</span> <span class="o">-</span> <span class="n">prev_score</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tscore</span><span class="p">,</span> <span class="p">(</span><span class="n">presub_score</span><span class="p">,</span> <span class="n">new_st</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="select_state()" id="adviser.tools.espnet_minimal.nets.scorers.ctc.CTCPrefixScorer.select_state">
<code class="highlight language-python">
select_state<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Select state with relative ids in the main beam search.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>state</code></td>
<td><code></code></td>
<td>
<p>Decoder state for prefix tokens</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>i</code></td>
<td><code>int</code></td>
<td>
<p>Index to select a state in the main beam search</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>state</code></td>
<td>
<p>pruned state</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/scorers/ctc.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>39
40
41
42
43
44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">select_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="sd">"""Select state with relative ids in the main beam search.</span>

<span class="sd">    Args:</span>
<span class="sd">        state: Decoder state for prefix tokens</span>
<span class="sd">        i (int): Index to select a state in the main beam search</span>

<span class="sd">    Returns:</span>
<span class="sd">        state: pruned state</span>

<span class="sd">    """</span>
    <span class="n">sc</span><span class="p">,</span> <span class="n">st</span> <span class="o">=</span> <span class="n">state</span>
    <span class="k">return</span> <span class="n">sc</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">st</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface">
<code>tts_interface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>TTS Interface realted modules.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface">
<code>TTSInterface</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>TTS Interface for ESPnet model implementation.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.base_plot_keys">
<code class="highlight">
base_plot_keys        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.base_plot_keys" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Return base key names to plot during training.</p>
<p>The keys should match what <code>chainer.reporter</code> reports.
if you add the key <code>loss</code>, the reporter will report <code>main/loss</code> and <code>validation/main/loss</code> values.
also <code>loss.png</code> will be created as a figure visulizing <code>main/loss</code> and <code>validation/main/loss</code> values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>list[str]</code></td>
<td>
<p>Base keys to plot during training.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Initilize TTS module.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>19
20
21</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Initilize TTS module."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reporter</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.add_arguments">
<code class="highlight language-python">
add_arguments<span class="p">(</span><span class="n">parser</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.add_arguments" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Add model specific argments to parser.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="sd">"""Add model specific argments to parser."""</span>
    <span class="k">return</span> <span class="n">parser</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.calculate_all_attentions">
<code class="highlight language-python">
calculate_all_attentions<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.calculate_all_attentions" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Calculate TTS attention weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td><code></code></td>
<td>
<p>Batch of attention weights (B, Lmax, Tmax).</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>43
44
45
46
47
48
49
50</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">calculate_all_attentions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate TTS attention weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        Tensor: Batch of attention weights (B, Lmax, Tmax).</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"calculate_all_attentions method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.forward">
<code class="highlight language-python">
forward<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.forward" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Calculate TTS forward propagation.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>Loss value.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>23
24
25
26
27
28
29
30</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Calculate TTS forward propagation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Loss value.</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"forward method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.inference">
<code class="highlight language-python">
inference<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.inference" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Generate the sequence of features given the sequences of characters.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tensor</code></td>
<td>
<p>The sequence of generated features (L, odim).
Tensor: The sequence of stop probabilities (L,).
Tensor: The sequence of attention weights (L, T).</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>32
33
34
35
36
37
38
39
40
41</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Generate the sequence of features given the sequences of characters.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: The sequence of generated features (L, odim).</span>
<span class="sd">        Tensor: The sequence of stop probabilities (L,).</span>
<span class="sd">        Tensor: The sequence of attention weights (L, T).</span>

<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"inference method is not implemented"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.load_pretrained_model">
<code class="highlight language-python">
load_pretrained_model<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.nets.tts_interface.TTSInterface.load_pretrained_model" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Load pretrained model parameters.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/nets/tts_interface.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>52
53
54</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">load_pretrained_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
    <span class="sd">"""Load pretrained model parameters."""</span>
    <span class="n">torch_load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h3 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils">
<code>utils</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.check_kwargs">
<code>check_kwargs</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.check_kwargs" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.check_kwargs.check_kwargs">
<code class="highlight language-python">
check_kwargs<span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.check_kwargs.check_kwargs" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>check kwargs are valid for func</p>
<p>If kwargs are invalid, raise TypeError as same as python default
:param function func: function to be validated
:param dict kwargs: keyword arguments for func
:param str name: name used in TypeError (default is func name)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/check_kwargs.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">check_kwargs</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""check kwargs are valid for func</span>

<span class="sd">    If kwargs are invalid, raise TypeError as same as python default</span>
<span class="sd">    :param function func: function to be validated</span>
<span class="sd">    :param dict kwargs: keyword arguments for func</span>
<span class="sd">    :param str name: name used in TypeError (default is func name)</span>
<span class="sd">    """</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">func</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">return</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">() got an unexpected keyword argument '</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers">
<code>cli_readers</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader">
<code>HDF5Reader</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>69
70
71
72
73
74
75
76
77
78</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">rspecifier</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Give "rspecifier" such as "ark:some.ark: </span><span class="si">{}</span><span class="s1">"'</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rspecifier</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rspecifier</span> <span class="o">=</span> <span class="n">rspecifier</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rspecifier</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'ark'</span><span class="p">,</span> <span class="s1">'scp'</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Must be scp or ark: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span> <span class="o">=</span> <span class="n">return_shape</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.HDF5Reader.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span> <span class="o">==</span> <span class="s1">'scp'</span><span class="p">:</span>
        <span class="n">hdf5_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s1">'scp file for hdf5 should be like: '</span>
                        <span class="s1">'"uttid filepath.h5:key": </span><span class="si">{}</span><span class="s1">(</span><span class="si">{}</span><span class="s1">)'</span>
                            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">))</span>
                <span class="n">path</span><span class="p">,</span> <span class="n">h5_key</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="n">hdf5_file</span> <span class="o">=</span> <span class="n">hdf5_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">hdf5_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">hdf5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                            <span class="s1">'Error when loading </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
                        <span class="k">raise</span>
                    <span class="n">hdf5_dict</span><span class="p">[</span><span class="n">path</span><span class="p">]</span> <span class="o">=</span> <span class="n">hdf5_file</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">hdf5_file</span><span class="p">[</span><span class="n">h5_key</span><span class="p">]</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">'Error when loading </span><span class="si">{}</span><span class="s1"> with key=</span><span class="si">{}</span><span class="s1">'</span>
                                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">h5_key</span><span class="p">))</span>
                    <span class="k">raise</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="p">[()]</span>

        <span class="c1"># Closing all files</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">hdf5_dict</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">hdf5_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">==</span> <span class="s1">'-'</span><span class="p">:</span>
            <span class="c1"># Required h5py&gt;=2.9</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span>
        <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="n">f</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="n">f</span><span class="p">[</span><span class="n">key</span><span class="p">][()]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader">
<code>KaldiReader</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">segments</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>54
55
56
57</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">segments</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rspecifier</span> <span class="o">=</span> <span class="n">rspecifier</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span> <span class="o">=</span> <span class="n">return_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">segments</span> <span class="o">=</span> <span class="n">segments</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.KaldiReader.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>59
60
61
62
63
64
65</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">kaldiio</span><span class="o">.</span><span class="n">ReadHelper</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">segments</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">segments</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="n">array</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader">
<code>SoundHDF5Reader</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>138
139
140
141
142
143
144
145</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">rspecifier</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Give "rspecifier" such as "ark:some.ark: </span><span class="si">{}</span><span class="s1">"'</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">rspecifier</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'ark'</span><span class="p">,</span> <span class="s1">'scp'</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Must be scp or ark: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span> <span class="o">=</span> <span class="n">return_shape</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundHDF5Reader.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span> <span class="o">==</span> <span class="s1">'scp'</span><span class="p">:</span>
        <span class="n">hdf5_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s1">'scp file for hdf5 should be like: '</span>
                        <span class="s1">'"uttid filepath.h5:key": </span><span class="si">{}</span><span class="s1">(</span><span class="si">{}</span><span class="s1">)'</span>
                            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">))</span>
                <span class="n">path</span><span class="p">,</span> <span class="n">h5_key</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="n">hdf5_file</span> <span class="o">=</span> <span class="n">hdf5_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">hdf5_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">hdf5_file</span> <span class="o">=</span> <span class="n">SoundHDF5File</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                            <span class="s1">'Error when loading </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
                        <span class="k">raise</span>
                    <span class="n">hdf5_dict</span><span class="p">[</span><span class="n">path</span><span class="p">]</span> <span class="o">=</span> <span class="n">hdf5_file</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">hdf5_file</span><span class="p">[</span><span class="n">h5_key</span><span class="p">]</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">'Error when loading </span><span class="si">{}</span><span class="s1"> with key=</span><span class="si">{}</span><span class="s1">'</span>
                                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">h5_key</span><span class="p">))</span>
                    <span class="k">raise</span>

                <span class="c1"># Change Tuple[ndarray, int] -&gt; Tuple[int, ndarray]</span>
                <span class="c1"># (soundfile style -&gt; scipy style)</span>
                <span class="n">array</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">data</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                    <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="n">array</span><span class="p">)</span>

        <span class="c1"># Closing all files</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">hdf5_dict</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">hdf5_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">==</span> <span class="s1">'-'</span><span class="p">:</span>
            <span class="c1"># Required h5py&gt;=2.9</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="ow">in</span> <span class="n">SoundHDF5File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundReader">
<code>SoundReader</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>205
206
207
208
209
210
211
212
213</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">rspecifier</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Give "rspecifier" such as "scp:some.scp: </span><span class="si">{}</span><span class="s1">"'</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">rspecifier</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span> <span class="o">!=</span> <span class="s1">'scp'</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Only supporting "scp" for sound file: </span><span class="si">{}</span><span class="s1">'</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ark_or_scp</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span> <span class="o">=</span> <span class="n">return_shape</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.SoundReader.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>215
216
217
218
219
220
221
222
223
224
225</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">sound_file_path</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Assume PCM16</span>
            <span class="n">array</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">soundfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">sound_file_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int16'</span><span class="p">)</span>
            <span class="c1"># Change Tuple[ndarray, int] -&gt; Tuple[int, ndarray]</span>
            <span class="c1"># (soundfile style -&gt; scipy style)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_shape</span><span class="p">:</span>
                <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="n">array</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_readers.file_reader_helper">
<code class="highlight language-python">
file_reader_helper<span class="p">(</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">filetype</span><span class="o">=</span><span class="s1">'mat'</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">segments</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_readers.file_reader_helper" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Read uttid and array in kaldi style</p>
<p>This function might be a bit confusing as "ark" is used
for HDF5 to imitate "kaldi-rspecifier".</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>rspecifier</code></td>
<td><code>str</code></td>
<td>
<p>Give as "ark:feats.ark" or "scp:feats.scp"</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>filetype</code></td>
<td><code>str</code></td>
<td>
<p>"mat" is kaldi-martix, "hdf5": HDF5</p>
</td>
<td><code>'mat'</code></td>
</tr>
<tr>
<td><code>return_shape</code></td>
<td><code>bool</code></td>
<td>
<p>Return the shape of the matrix,
instead of the matrix. This can reduce IO cost for HDF5.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Generator[Tuple[str, np.ndarray], None, None]</code></td>
<td></td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<p>Read from kaldi-matrix ark file:</p>
<blockquote>
<blockquote>
<blockquote>
<p>for u, array in file_reader_helper('ark:feats.ark', 'mat'):
...     array</p>
</blockquote>
</blockquote>
</blockquote>
<p>Read from HDF5 file:</p>
<blockquote>
<blockquote>
<blockquote>
<p>for u, array in file_reader_helper('ark:feats.h5', 'hdf5'):
...     array</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_readers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">file_reader_helper</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filetype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">'mat'</span><span class="p">,</span>
                       <span class="n">return_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                       <span class="n">segments</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Read uttid and array in kaldi style</span>

<span class="sd">    This function might be a bit confusing as "ark" is used</span>
<span class="sd">    for HDF5 to imitate "kaldi-rspecifier".</span>

<span class="sd">    Args:</span>
<span class="sd">        rspecifier: Give as "ark:feats.ark" or "scp:feats.scp"</span>
<span class="sd">        filetype: "mat" is kaldi-martix, "hdf5": HDF5</span>
<span class="sd">        return_shape: Return the shape of the matrix,</span>
<span class="sd">            instead of the matrix. This can reduce IO cost for HDF5.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Generator[Tuple[str, np.ndarray], None, None]:</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read from kaldi-matrix ark file:</span>

<span class="sd">        &gt;&gt;&gt; for u, array in file_reader_helper('ark:feats.ark', 'mat'):</span>
<span class="sd">        ...     array</span>

<span class="sd">        Read from HDF5 file:</span>

<span class="sd">        &gt;&gt;&gt; for u, array in file_reader_helper('ark:feats.h5', 'hdf5'):</span>
<span class="sd">        ...     array</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'mat'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">KaldiReader</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="n">return_shape</span><span class="p">,</span>
                           <span class="n">segments</span><span class="o">=</span><span class="n">segments</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'hdf5'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">HDF5Reader</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="n">return_shape</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'sound.hdf5'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SoundHDF5Reader</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="n">return_shape</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'sound'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SoundReader</span><span class="p">(</span><span class="n">rspecifier</span><span class="p">,</span> <span class="n">return_shape</span><span class="o">=</span><span class="n">return_shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'filetype=</span><span class="si">{</span><span class="n">filetype</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_utils">
<code>cli_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_utils" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_utils.assert_scipy_wav_style">
<code class="highlight language-python">
assert_scipy_wav_style<span class="p">(</span><span class="n">value</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_utils.assert_scipy_wav_style" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>33
34
35
36
37
38</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">assert_scipy_wav_style</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">is_scipy_wav_style</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> \
        <span class="s1">'Must be Tuple[int, numpy.ndarray], but got </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
            <span class="k">else</span> <span class="s1">'</span><span class="si">{}</span><span class="s1">[</span><span class="si">{}</span><span class="s1">]'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
                                 <span class="s1">', '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">value</span><span class="p">)))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_utils.get_commandline_args">
<code class="highlight language-python">
get_commandline_args<span class="p">()</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_utils.get_commandline_args" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>13
14
15
16
17
18
19
20
21
22
23</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_commandline_args</span><span class="p">():</span>
    <span class="n">extra_chars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">';'</span><span class="p">,</span> <span class="s1">'&amp;'</span><span class="p">,</span> <span class="s1">'('</span><span class="p">,</span> <span class="s1">')'</span><span class="p">,</span> <span class="s1">'|'</span><span class="p">,</span> <span class="s1">'^'</span><span class="p">,</span> <span class="s1">'&lt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'?'</span><span class="p">,</span> <span class="s1">'*'</span><span class="p">,</span>
                   <span class="s1">'['</span><span class="p">,</span> <span class="s1">']'</span><span class="p">,</span> <span class="s1">'$'</span><span class="p">,</span> <span class="s1">'`'</span><span class="p">,</span> <span class="s1">'"'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\\</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'!'</span><span class="p">,</span> <span class="s1">'{'</span><span class="p">,</span> <span class="s1">'}'</span><span class="p">]</span>

    <span class="c1"># Escape the extra characters for shell</span>
    <span class="n">argv</span> <span class="o">=</span> <span class="p">[</span><span class="n">arg</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\'</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\'\\\'\'</span><span class="s1">'</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">arg</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">extra_chars</span><span class="p">)</span>
            <span class="k">else</span> <span class="s1">'</span><span class="se">\'</span><span class="s1">'</span> <span class="o">+</span> <span class="n">arg</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\'</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\'\\\'\'</span><span class="s1">'</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\'</span><span class="s1">'</span>
            <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">sys</span><span class="o">.</span><span class="n">executable</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">argv</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_utils.is_scipy_wav_style">
<code class="highlight language-python">
is_scipy_wav_style<span class="p">(</span><span class="n">value</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_utils.is_scipy_wav_style" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>26
27
28
29
30</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">is_scipy_wav_style</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="c1"># If Tuple[int, numpy.ndarray] or not</span>
    <span class="k">return</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_utils.strtobool">
<code class="highlight language-python">
strtobool<span class="p">(</span><span class="n">x</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_utils.strtobool" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 8
 9
10</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">strtobool</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># distutils.util.strtobool returns integer, but it's confusing,</span>
    <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">dist_strtobool</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers">
<code>cli_writers</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter">
<code>BaseWriter</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__enter__">
<code class="highlight language-python">
__enter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__enter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>77
78</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__exit__">
<code class="highlight language-python">
__exit__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__exit__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>80
81</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>74
75</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.close">
<code class="highlight language-python">
close<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.BaseWriter.close" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer">
<code>HDF5Writer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>HDF5Writer</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! examples</span>
<span class="err">    &gt;&gt;&gt; with HDF5Writer('ark:out.h5', compress=True) as f:</span>
<span class="err">    ...     f['key'] = array</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">spec_dict</span> <span class="o">=</span> <span class="n">parse_wspecifier</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">spec_dict</span><span class="p">[</span><span class="s1">'ark'</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">compress</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'compression'</span><span class="p">:</span> <span class="s1">'gzip'</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">spec_dict</span><span class="p">[</span><span class="s1">'ark'</span><span class="p">],</span> <span class="s1">'w'</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">'scp'</span> <span class="ow">in</span> <span class="n">spec_dict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">spec_dict</span><span class="p">[</span><span class="s1">'scp'</span><span class="p">],</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">write_num_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="n">get_num_frames_writer</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.HDF5Writer.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>190
191
192
193
194
195
196</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter">
<code>KaldiWriter</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compression_method</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>124
125
126
127
128
129
130
131
132
133
134
135</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">compression_method</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">compress</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">kaldiio</span><span class="o">.</span><span class="n">WriteHelper</span><span class="p">(</span>
            <span class="n">wspecifier</span><span class="p">,</span> <span class="n">compression_method</span><span class="o">=</span><span class="n">compression_method</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">kaldiio</span><span class="o">.</span><span class="n">WriteHelper</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">write_num_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="n">get_num_frames_writer</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.KaldiWriter.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>137
138
139
140</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer">
<code>SoundHDF5Writer</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>SoundHDF5Writer</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! examples</span>
<span class="err">    &gt;&gt;&gt; fs = 16000</span>
<span class="err">    &gt;&gt;&gt; with SoundHDF5Writer('ark:out.h5') as f:</span>
<span class="err">    ...     f['key'] = fs, array</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pcm_format</span><span class="o">=</span><span class="s1">'wav'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>208
209
210
211
212
213
214
215
216
217
218
219
220
221</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pcm_format</span><span class="o">=</span><span class="s1">'wav'</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pcm_format</span> <span class="o">=</span> <span class="n">pcm_format</span>
    <span class="n">spec_dict</span> <span class="o">=</span> <span class="n">parse_wspecifier</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">spec_dict</span><span class="p">[</span><span class="s1">'ark'</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SoundHDF5File</span><span class="p">(</span><span class="n">spec_dict</span><span class="p">[</span><span class="s1">'ark'</span><span class="p">],</span> <span class="s1">'w'</span><span class="p">,</span>
                                <span class="nb">format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pcm_format</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">'scp'</span> <span class="ow">in</span> <span class="n">spec_dict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">spec_dict</span><span class="p">[</span><span class="s1">'scp'</span><span class="p">],</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">write_num_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="n">get_num_frames_writer</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundHDF5Writer.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>223
224
225
226
227
228
229
230
231
232
233</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">assert_scipy_wav_style</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="c1"># Change Tuple[int, ndarray] -&gt; Tuple[ndarray, int]</span>
    <span class="c1"># (scipy style -&gt; soundfile style)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter">
<code>SoundWriter</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>SoundWriter</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! examples</span>
<span class="err">    &gt;&gt;&gt; fs = 16000</span>
<span class="err">    &gt;&gt;&gt; with SoundWriter('ark,scp:outdir,out.scp') as f:</span>
<span class="err">    ...     f['key'] = fs, array</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pcm_format</span><span class="o">=</span><span class="s1">'wav'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pcm_format</span><span class="o">=</span><span class="s1">'wav'</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pcm_format</span> <span class="o">=</span> <span class="n">pcm_format</span>
    <span class="n">spec_dict</span> <span class="o">=</span> <span class="n">parse_wspecifier</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">)</span>
    <span class="c1"># e.g. ark,scp:dirname,wav.scp</span>
    <span class="c1"># -&gt; The wave files are found in dirname/*.wav</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dirname</span> <span class="o">=</span> <span class="n">spec_dict</span><span class="p">[</span><span class="s1">'ark'</span><span class="p">]</span>
    <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="s1">'scp'</span> <span class="ow">in</span> <span class="n">spec_dict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">spec_dict</span><span class="p">[</span><span class="s1">'scp'</span><span class="p">],</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">write_num_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="n">get_num_frames_writer</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.SoundWriter.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>263
264
265
266
267
268
269
270
271
272</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">assert_scipy_wav_style</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="n">rate</span><span class="p">,</span> <span class="n">signal</span> <span class="o">=</span> <span class="n">value</span>
    <span class="n">wavfile</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s1">'.'</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pcm_format</span><span class="p">)</span>
    <span class="n">soundfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">wavfile</span><span class="p">,</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int16</span><span class="p">),</span> <span class="n">rate</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_scp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">wavfile</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer_nframe</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.file_writer_helper">
<code class="highlight language-python">
file_writer_helper<span class="p">(</span><span class="n">wspecifier</span><span class="p">,</span> <span class="n">filetype</span><span class="o">=</span><span class="s1">'mat'</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compression_method</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pcm_format</span><span class="o">=</span><span class="s1">'wav'</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.file_writer_helper" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Write matrices in kaldi style</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>wspecifier</code></td>
<td><code>str</code></td>
<td>
<p>e.g. ark,scp:out.ark,out.scp</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>filetype</code></td>
<td><code>str</code></td>
<td>
<p>"mat" is kaldi-martix, "hdf5": HDF5</p>
</td>
<td><code>'mat'</code></td>
</tr>
<tr>
<td><code>write_num_frames</code></td>
<td><code>str</code></td>
<td>
<p>e.g. 'ark,t:num_frames.txt'</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>compress</code></td>
<td><code>bool</code></td>
<td>
<p>Compress or not</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>compression_method</code></td>
<td><code>int</code></td>
<td>
<p>Specify compression level</p>
</td>
<td><code>2</code></td>
</tr>
</tbody>
</table>
<p>Write in kaldi-matrix-ark with "kaldi-scp" file:</p>
<blockquote>
<blockquote>
<blockquote>
<p>with file_writer_helper('ark,scp:out.ark,out.scp') as f:
    f['uttid'] = array</p>
</blockquote>
</blockquote>
</blockquote>
<p>This "scp" has the following format:</p>
<div class="codehilite">
<pre><span></span><code><span class="err">uttidA out.ark:1234</span>
<span class="err">uttidB out.ark:2222</span>
</code></pre>
</div>
<p>where, 1234 and 2222 points the strating byte address of the matrix.
(For detail, see official documentation of Kaldi)</p>
<p>Write in HDF5 with "scp" file:</p>
<blockquote>
<blockquote>
<blockquote>
<p>with file_writer_helper('ark,scp:out.h5,out.scp', 'hdf5') as f:
    f['uttid'] = array</p>
</blockquote>
</blockquote>
</blockquote>
<p>This "scp" file is created as:</p>
<div class="codehilite">
<pre><span></span><code><span class="err">uttidA out.h5:uttidA</span>
<span class="err">uttidB out.h5:uttidB</span>
</code></pre>
</div>
<p>HDF5 can be, unlike "kaldi-ark", accessed to any keys,
so originally "scp" is not required for random-reading.
Nevertheless we create "scp" for HDF5 because it is useful
for some use-case. e.g. Concatenation, Splitting.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">file_writer_helper</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filetype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">'mat'</span><span class="p">,</span>
                       <span class="n">write_num_frames</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">compress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                       <span class="n">compression_method</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                       <span class="n">pcm_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">'wav'</span><span class="p">):</span>
    <span class="sd">"""Write matrices in kaldi style</span>

<span class="sd">    Args:</span>
<span class="sd">        wspecifier: e.g. ark,scp:out.ark,out.scp</span>
<span class="sd">        filetype: "mat" is kaldi-martix, "hdf5": HDF5</span>
<span class="sd">        write_num_frames: e.g. 'ark,t:num_frames.txt'</span>
<span class="sd">        compress: Compress or not</span>
<span class="sd">        compression_method: Specify compression level</span>

<span class="sd">    Write in kaldi-matrix-ark with "kaldi-scp" file:</span>

<span class="sd">    &gt;&gt;&gt; with file_writer_helper('ark,scp:out.ark,out.scp') as f:</span>
<span class="sd">    &gt;&gt;&gt;     f['uttid'] = array</span>

<span class="sd">    This "scp" has the following format:</span>

<span class="sd">        uttidA out.ark:1234</span>
<span class="sd">        uttidB out.ark:2222</span>

<span class="sd">    where, 1234 and 2222 points the strating byte address of the matrix.</span>
<span class="sd">    (For detail, see official documentation of Kaldi)</span>

<span class="sd">    Write in HDF5 with "scp" file:</span>

<span class="sd">    &gt;&gt;&gt; with file_writer_helper('ark,scp:out.h5,out.scp', 'hdf5') as f:</span>
<span class="sd">    &gt;&gt;&gt;     f['uttid'] = array</span>

<span class="sd">    This "scp" file is created as:</span>

<span class="sd">        uttidA out.h5:uttidA</span>
<span class="sd">        uttidB out.h5:uttidB</span>

<span class="sd">    HDF5 can be, unlike "kaldi-ark", accessed to any keys,</span>
<span class="sd">    so originally "scp" is not required for random-reading.</span>
<span class="sd">    Nevertheless we create "scp" for HDF5 because it is useful</span>
<span class="sd">    for some use-case. e.g. Concatenation, Splitting.</span>

<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'mat'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">KaldiWriter</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="n">write_num_frames</span><span class="p">,</span>
                           <span class="n">compress</span><span class="o">=</span><span class="n">compress</span><span class="p">,</span>
                           <span class="n">compression_method</span><span class="o">=</span><span class="n">compression_method</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'hdf5'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">HDF5Writer</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="n">write_num_frames</span><span class="p">,</span>
                          <span class="n">compress</span><span class="o">=</span><span class="n">compress</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'sound.hdf5'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SoundHDF5Writer</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="n">write_num_frames</span><span class="p">,</span>
                               <span class="n">pcm_format</span><span class="o">=</span><span class="n">pcm_format</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s1">'sound'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SoundWriter</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">,</span> <span class="n">write_num_frames</span><span class="o">=</span><span class="n">write_num_frames</span><span class="p">,</span>
                           <span class="n">pcm_format</span><span class="o">=</span><span class="n">pcm_format</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'filetype=</span><span class="si">{</span><span class="n">filetype</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.get_num_frames_writer">
<code class="highlight language-python">
get_num_frames_writer<span class="p">(</span><span class="n">write_num_frames</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.get_num_frames_writer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>get_num_frames_writer</p>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>get_num_frames_writer('ark,t:num_frames.txt')</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_num_frames_writer</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">"""get_num_frames_writer</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; get_num_frames_writer('ark,t:num_frames.txt')</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">write_num_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">write_num_frames</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Must include ":", write_num_frames=</span><span class="si">{}</span><span class="s1">'</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">write_num_frames</span><span class="p">))</span>

        <span class="n">nframes_type</span><span class="p">,</span> <span class="n">nframes_file</span> <span class="o">=</span> <span class="n">write_num_frames</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nframes_type</span> <span class="o">!=</span> <span class="s1">'ark,t'</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">'Only supporting text mode. '</span>
                <span class="s1">'e.g. --write-num-frames=ark,t:foo.txt :'</span>
                <span class="s1">'</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nframes_type</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">open</span><span class="p">(</span><span class="n">nframes_file</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.cli_writers.parse_wspecifier">
<code class="highlight language-python">
parse_wspecifier<span class="p">(</span><span class="n">wspecifier</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.cli_writers.parse_wspecifier" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Parse wspecifier to dict</p>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>parse_wspecifier('ark,scp:out.ark,out.scp')
{'ark': 'out.ark', 'scp': 'out.scp'}</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/cli_writers.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">parse_wspecifier</span><span class="p">(</span><span class="n">wspecifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="sd">"""Parse wspecifier to dict</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; parse_wspecifier('ark,scp:out.ark,out.scp')</span>
<span class="sd">        {'ark': 'out.ark', 'scp': 'out.scp'}</span>

<span class="sd">    """</span>
    <span class="n">ark_scp</span><span class="p">,</span> <span class="n">filepath</span> <span class="o">=</span> <span class="n">wspecifier</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ark_scp</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'ark'</span><span class="p">,</span> <span class="s1">'scp,ark'</span><span class="p">,</span> <span class="s1">'ark,scp'</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">'</span><span class="si">{}</span><span class="s1"> is not allowed: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ark_scp</span><span class="p">,</span> <span class="n">wspecifier</span><span class="p">))</span>
    <span class="n">ark_scps</span> <span class="o">=</span> <span class="n">ark_scp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)</span>
    <span class="n">filepaths</span> <span class="o">=</span> <span class="n">filepath</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ark_scps</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">filepaths</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">'Mismatch: </span><span class="si">{}</span><span class="s1"> and </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ark_scp</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
    <span class="n">spec_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">ark_scps</span><span class="p">,</span> <span class="n">filepaths</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">spec_dict</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset">
<code>dataset</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>This module contains pytorch dataset and dataloader implementation for chainer training.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader">
<code>ChainerDataLoader</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Pytorch dataloader in chainer style.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    all args for torch.utils.data.dataloader.Dataloader</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.epoch_detail">
<code class="highlight">
epoch_detail        </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.epoch_detail" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Epoch_detail required by chainer.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Init function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""Init function."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">'dataset'</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Implement iter function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>68
69
70
71</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Implement iter function."""</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">batch</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.finalize">
<code class="highlight language-python">
finalize<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.finalize" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Implement finalize function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>90
91
92</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Implement finalize function."""</span>
    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.next">
<code class="highlight language-python">
next<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.next" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Implement next function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>53
54
55
56
57
58
59
60
61
62
63
64
65
66</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Implement next function."""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">ret</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.serialize">
<code class="highlight language-python">
serialize<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">serializer</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.serialize" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Serialize and deserialize function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>78
79
80
81
82
83</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">serialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">serializer</span><span class="p">):</span>
    <span class="sd">"""Serialize and deserialize function."""</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">serializer</span><span class="p">(</span><span class="s1">'epoch'</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">)</span>
    <span class="n">current_position</span> <span class="o">=</span> <span class="n">serializer</span><span class="p">(</span><span class="s1">'current_position'</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_position</span> <span class="o">=</span> <span class="n">current_position</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.start_shuffle">
<code class="highlight language-python">
start_shuffle<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.ChainerDataLoader.start_shuffle" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Shuffle function for sortagrad.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>85
86
87
88</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">start_shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Shuffle function for sortagrad."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">'shuffle'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.TransformDataset">
<code>TransformDataset</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Transform Dataset for pytorch backend.</p>
<div class="codehilite">
<pre><span></span><code><span class="err">!!! args</span>
<span class="err">    data: list object from make_batchset</span>
<span class="err">    transfrom: transform function</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__getitem__">
<code class="highlight language-python">
__getitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__getitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>[] operator.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>31
32
33</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="sd">"""[] operator."""</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Init function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>21
22
23
24
25</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">transform</span><span class="p">):</span>
    <span class="sd">"""Init function."""</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TransformDataset</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__len__">
<code class="highlight language-python">
__len__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dataset.TransformDataset.__len__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Len function.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dataset.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>27
28
29</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Len function."""</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.deterministic_utils">
<code>deterministic_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.deterministic_utils" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_chainer">
<code class="highlight language-python">
set_deterministic_chainer<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_chainer" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Ensures chainer produces deterministic results depending on the program arguments</p>
<p>:param Namespace args: The program arguments</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/deterministic_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">set_deterministic_chainer</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Ensures chainer produces deterministic results depending on the program arguments</span>

<span class="sd">    :param Namespace args: The program arguments</span>
<span class="sd">    """</span>
    <span class="c1"># seed setting (chainer seed may not need it)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'CHAINER_SEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'chainer seed = '</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'CHAINER_SEED'</span><span class="p">])</span>

    <span class="c1"># debug mode setting</span>
    <span class="c1"># 0 would be fastest, but 1 seems to be reasonable</span>
    <span class="c1"># considering reproducibility</span>
    <span class="c1"># remove type check</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">debugmode</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">type_check</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'chainer type check is disabled'</span><span class="p">)</span>
    <span class="c1"># use deterministic computation or not</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">debugmode</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cudnn_deterministic</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'chainer cudnn deterministic is disabled'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cudnn_deterministic</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_pytorch">
<code class="highlight language-python">
set_deterministic_pytorch<span class="p">(</span><span class="n">args</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.deterministic_utils.set_deterministic_pytorch" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Ensures pytorch produces deterministic results depending on the program arguments</p>
<p>:param Namespace args: The program arguments</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/deterministic_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">set_deterministic_pytorch</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">"""Ensures pytorch produces deterministic results depending on the program arguments</span>

<span class="sd">    :param Namespace args: The program arguments</span>
<span class="sd">    """</span>
    <span class="c1"># seed setting</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># debug mode setting</span>
    <span class="c1"># 0 would be fastest, but 1 seems to be reasonable</span>
    <span class="c1"># considering reproducibility</span>
    <span class="c1"># remove type check</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># https://github.com/pytorch/pytorch/issues/6351</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">debugmode</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">type_check</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'torch type check is disabled'</span><span class="p">)</span>
    <span class="c1"># use deterministic computation or not</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">debugmode</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'torch cudnn deterministic is disabled'</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dynamic_import">
<code>dynamic_import</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dynamic_import" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.dynamic_import.dynamic_import">
<code class="highlight language-python">
dynamic_import<span class="p">(</span><span class="n">import_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="p">{})</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.dynamic_import.dynamic_import" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>dynamic import module and class</p>
<p>:param str import_path: syntax 'module_name:class_name'
    e.g., 'services.hci.speech.espnet_minimal.transform.add_deltas:AddDeltas'
:param dict alias: shortcut for registered class
:return: imported class</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/dynamic_import.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">dynamic_import</span><span class="p">(</span><span class="n">import_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="nb">dict</span><span class="p">()):</span>
    <span class="sd">"""dynamic import module and class</span>

<span class="sd">    :param str import_path: syntax 'module_name:class_name'</span>
<span class="sd">        e.g., 'services.hci.speech.espnet_minimal.transform.add_deltas:AddDeltas'</span>
<span class="sd">    :param dict alias: shortcut for registered class</span>
<span class="sd">    :return: imported class</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">import_path</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">alias</span> <span class="ow">and</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">import_path</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">'import_path should be one of </span><span class="si">{}</span><span class="s1"> or '</span>
            <span class="s1">'include ":", e.g. "services.hci.speech.espnet_minimal.transform.add_deltas:AddDeltas" : '</span>
            <span class="s1">'</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">alias</span><span class="p">),</span> <span class="n">import_path</span><span class="p">))</span>
    <span class="k">if</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">import_path</span><span class="p">:</span>
        <span class="n">import_path</span> <span class="o">=</span> <span class="n">alias</span><span class="p">[</span><span class="n">import_path</span><span class="p">]</span>

    <span class="n">module_name</span><span class="p">,</span> <span class="n">objname</span> <span class="o">=</span> <span class="n">import_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">module_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">objname</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.fill_missing_args">
<code>fill_missing_args</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.fill_missing_args" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.fill_missing_args.fill_missing_args">
<code class="highlight language-python">
fill_missing_args<span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">add_arguments</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.fill_missing_args.fill_missing_args" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Fill missing arguments in args.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>args</code></td>
<td><code>Namespace or None</code></td>
<td>
<p>Namesapce containing hyperparameters.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>add_arguments</code></td>
<td><code>function</code></td>
<td>
<p>Function to add arguments.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Namespace</code></td>
<td>
<p>Arguments whose missing ones are filled with default value.</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition examples">
<p class="admonition-title">Examples</p>
<blockquote>
<blockquote>
<blockquote>
<p>from argparse import Namespace
from services.hci.speech.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2 import Tacotron2
args = Namespace()
fill_missing_args(args, Tacotron2.add_arguments_fn)
Namespace(aconv_chans=32, aconv_filts=15, adim=512, atype='location', ...)</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/fill_missing_args.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">fill_missing_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">add_arguments</span><span class="p">):</span>
    <span class="sd">"""Fill missing arguments in args.</span>

<span class="sd">    Args:</span>
<span class="sd">        args (Namespace or None): Namesapce containing hyperparameters.</span>
<span class="sd">        add_arguments (function): Function to add arguments.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Namespace: Arguments whose missing ones are filled with default value.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from argparse import Namespace</span>
<span class="sd">        &gt;&gt;&gt; from services.hci.speech.espnet_minimal.nets.pytorch_backend.e2e_tts_tacotron2 import Tacotron2</span>
<span class="sd">        &gt;&gt;&gt; args = Namespace()</span>
<span class="sd">        &gt;&gt;&gt; fill_missing_args(args, Tacotron2.add_arguments_fn)</span>
<span class="sd">        Namespace(aconv_chans=32, aconv_filts=15, adim=512, atype='location', ...)</span>

<span class="sd">    """</span>
    <span class="c1"># check argument type</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="ow">or</span> <span class="n">args</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">callable</span><span class="p">(</span><span class="n">add_arguments</span><span class="p">)</span>

    <span class="c1"># get default arguments</span>
    <span class="n">default_args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">add_arguments</span><span class="p">(</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">())</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

    <span class="c1"># convert to dict</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">default_args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">default_args</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">default_args</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"attribute </span><span class="se">\"</span><span class="si">%s</span><span class="se">\"</span><span class="s2"> does not exist. use default </span><span class="si">%s</span><span class="s2">."</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
            <span class="n">args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="c1"># Note from Florian:</span>
            <span class="c1"># I believe this is where the wrong</span>
            <span class="c1"># arguments are introduced... no idea</span>
            <span class="c1"># however where the arguments we actually</span>
            <span class="c1"># load go missing.</span>

    <span class="k">return</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils">
<code>io_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets">
<code>LoadInputsAndTargets</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Create a mini-batch from a list of dicts</p>
<div class="codehilite">
<pre><span></span><code><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">batch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">('utt1',</span>
<span class="n">...           dict(input=[dict(feat='some.ark:123',</span>
<span class="n">...                            filetype='mat',</span>
<span class="n">...                            name='input1',</span>
<span class="n">...                            shape=[100, 80</span><span class="o">]</span><span class="p">)</span><span class="err">]</span><span class="p">,</span><span class="w"></span>
<span class="p">...</span><span class="w">                </span><span class="k">output</span><span class="o">=[</span><span class="n">dict(tokenid='1 2 3 4',</span>
<span class="n">...                             name='target1',</span>
<span class="n">...                             shape=[4, 31</span><span class="o">]</span><span class="p">)</span><span class="err">]]</span><span class="p">))</span><span class="w"></span>
<span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LoadInputsAndTargets</span><span class="p">()</span><span class="w"></span>
<span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">feat</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="w"></span>

<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="w"> </span><span class="nl">mode</span><span class="p">:</span><span class="w"> </span><span class="n">Specify</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="n">mode</span><span class="p">,</span><span class="w"> </span><span class="ss">"asr"</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="ss">"tts"</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="w"> </span><span class="nl">preprocess_conf</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="k">path</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">json</span><span class="w"> </span><span class="k">file</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">pre</span><span class="o">-</span><span class="n">processing</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="nl">load_input</span><span class="p">:</span><span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="k">False</span><span class="p">,</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="k">data</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="nl">load_output</span><span class="p">:</span><span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="k">False</span><span class="p">,</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">output</span><span class="w"> </span><span class="k">data</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="nl">sort_in_input_length</span><span class="p">:</span><span class="w"> </span><span class="n">Sort</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">mini</span><span class="o">-</span><span class="n">batch</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">descending</span><span class="w"> </span><span class="k">order</span><span class="w"></span>
<span class="w">    </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">length</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="nl">use_speaker_embedding</span><span class="p">:</span><span class="w"> </span><span class="n">Used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">tts</span><span class="w"> </span><span class="n">mode</span><span class="w"> </span><span class="k">only</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="nl">use_second_target</span><span class="p">:</span><span class="w"> </span><span class="n">Used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">tts</span><span class="w"> </span><span class="n">mode</span><span class="w"> </span><span class="k">only</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">dict</span><span class="w"> </span><span class="nl">preprocess_args</span><span class="p">:</span><span class="w"> </span><span class="k">Set</span><span class="w"> </span><span class="ow">some</span><span class="w"> </span><span class="n">optional</span><span class="w"> </span><span class="n">arguments</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">preprocessing</span><span class="w"></span>
<span class="err">:</span><span class="nl">param</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">dict</span><span class="o">]</span><span class="w"> </span><span class="nl">preprocess_args</span><span class="p">:</span><span class="w"> </span><span class="n">Used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">tts</span><span class="w"> </span><span class="n">mode</span><span class="w"> </span><span class="k">only</span><span class="w"></span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__call__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Function to load inputs and targets from list of dicts</p>
<p>:param List[Tuple[str, dict]] batch: list of dict which is subset of
    loaded data.json
:return: list of input token id sequences [(L_1), (L_2), ..., (L_B)]
:return: list of input feature sequences
    [(T_1, D), (T_2, D), ..., (T_B, D)]
:rtype: list of float ndarray
:return: list of target token id sequences [(L_1), (L_2), ..., (L_B)]
:rtype: list of int ndarray</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="sd">"""Function to load inputs and targets from list of dicts</span>

<span class="sd">    :param List[Tuple[str, dict]] batch: list of dict which is subset of</span>
<span class="sd">        loaded data.json</span>
<span class="sd">    :return: list of input token id sequences [(L_1), (L_2), ..., (L_B)]</span>
<span class="sd">    :return: list of input feature sequences</span>
<span class="sd">        [(T_1, D), (T_2, D), ..., (T_B, D)]</span>
<span class="sd">    :rtype: list of float ndarray</span>
<span class="sd">    :return: list of target token id sequences [(L_1), (L_2), ..., (L_B)]</span>
<span class="sd">    :rtype: list of int ndarray</span>

<span class="sd">    """</span>
    <span class="n">x_feats_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>  <span class="c1"># OrderedDict[str, List[np.ndarray]]</span>
    <span class="n">y_feats_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>  <span class="c1"># OrderedDict[str, List[np.ndarray]]</span>
    <span class="n">uttid_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List[str]</span>

    <span class="k">for</span> <span class="n">uttid</span><span class="p">,</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">uttid_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">uttid</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_input</span><span class="p">:</span>
            <span class="c1"># Note(kamo): This for-loop is for multiple inputs</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'input'</span><span class="p">]):</span>
                <span class="c1"># {"input":</span>
                <span class="c1">#  [{"feat": "some/path.h5:F01_050C0101_PED_REAL",</span>
                <span class="c1">#    "filetype": "hdf5",</span>
                <span class="c1">#    "name": "input1", ...}], ...}</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_from_loader</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="o">=</span><span class="n">inp</span><span class="p">[</span><span class="s1">'feat'</span><span class="p">],</span>
                    <span class="n">filetype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'filetype'</span><span class="p">,</span> <span class="s1">'mat'</span><span class="p">))</span>
                <span class="n">x_feats_dict</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="s1">'name'</span><span class="p">],</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># FIXME(kamo): Dirty way to load only speaker_embedding without the other inputs</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'tts'</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_speaker_embedding</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'input'</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'input'</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_from_loader</span><span class="p">(</span>
                        <span class="n">filepath</span><span class="o">=</span><span class="n">inp</span><span class="p">[</span><span class="s1">'feat'</span><span class="p">],</span>
                        <span class="n">filetype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'filetype'</span><span class="p">,</span> <span class="s1">'mat'</span><span class="p">))</span>
                <span class="n">x_feats_dict</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="s1">'name'</span><span class="p">],</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_output</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'mt'</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">info</span><span class="p">[</span><span class="s1">'output'</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s1">'tokenid'</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
                <span class="n">x_feats_dict</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'output'</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s1">'name'</span><span class="p">],</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'output'</span><span class="p">]):</span>
                <span class="k">if</span> <span class="s1">'tokenid'</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">:</span>
                    <span class="c1"># ======= Legacy format for output =======</span>
                    <span class="c1"># {"output": [{"tokenid": "1 2 3 4"}])</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">inp</span><span class="p">[</span><span class="s1">'tokenid'</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># ======= New format =======</span>
                    <span class="c1"># {"input":</span>
                    <span class="c1">#  [{"feat": "some/path.h5:F01_050C0101_PED_REAL",</span>
                    <span class="c1">#    "filetype": "hdf5",</span>
                    <span class="c1">#    "name": "target1", ...}], ...}</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_from_loader</span><span class="p">(</span>
                        <span class="n">filepath</span><span class="o">=</span><span class="n">inp</span><span class="p">[</span><span class="s1">'feat'</span><span class="p">],</span>
                        <span class="n">filetype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'filetype'</span><span class="p">,</span> <span class="s1">'mat'</span><span class="p">))</span>

                <span class="n">y_feats_dict</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="s1">'name'</span><span class="p">],</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'asr'</span><span class="p">:</span>
        <span class="n">return_batch</span><span class="p">,</span> <span class="n">uttid_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_batch_asr</span><span class="p">(</span>
            <span class="n">x_feats_dict</span><span class="p">,</span> <span class="n">y_feats_dict</span><span class="p">,</span> <span class="n">uttid_list</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'tts'</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">eos</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'output'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">return_batch</span><span class="p">,</span> <span class="n">uttid_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_batch_tts</span><span class="p">(</span>
            <span class="n">x_feats_dict</span><span class="p">,</span> <span class="n">y_feats_dict</span><span class="p">,</span> <span class="n">uttid_list</span><span class="p">,</span> <span class="n">eos</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'mt'</span><span class="p">:</span>
        <span class="n">return_batch</span><span class="p">,</span> <span class="n">uttid_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_batch_mt</span><span class="p">(</span>
            <span class="n">x_feats_dict</span><span class="p">,</span> <span class="n">y_feats_dict</span><span class="p">,</span> <span class="n">uttid_list</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Apply pre-processing all input features</span>
        <span class="k">for</span> <span class="n">x_name</span> <span class="ow">in</span> <span class="n">return_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">x_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"input"</span><span class="p">):</span>
                <span class="n">return_batch</span><span class="p">[</span><span class="n">x_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span>
                    <span class="n">return_batch</span><span class="p">[</span><span class="n">x_name</span><span class="p">],</span> <span class="n">uttid_list</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">preprocess_args</span><span class="p">)</span>

    <span class="c1"># Doesn't return the names now.</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">return_batch</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'asr'</span><span class="p">,</span> <span class="n">preprocess_conf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">load_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">load_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sort_in_input_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_speaker_embedding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_second_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">preprocess_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_all_data_on_mem</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.LoadInputsAndTargets.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'asr'</span><span class="p">,</span>
             <span class="n">preprocess_conf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">load_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">load_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">sort_in_input_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">use_speaker_embedding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">use_second_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">preprocess_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">keep_all_data_on_mem</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loaders</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'asr'</span><span class="p">,</span> <span class="s1">'tts'</span><span class="p">,</span> <span class="s1">'mt'</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">'Only asr or tts are allowed: mode=</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">preprocess_conf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="n">Transformation</span><span class="p">(</span><span class="n">preprocess_conf</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s1">'[Experimental feature] Some preprocessing will be done '</span>
            <span class="s1">'for the mini-batch creation using </span><span class="si">{}</span><span class="s1">'</span>
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># If conf doesn't exist, this function don't touch anything.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">use_second_target</span> <span class="ow">and</span> <span class="n">use_speaker_embedding</span> <span class="ow">and</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">'tts'</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Choose one of "use_second_target" and '</span>
                         <span class="s1">'"use_speaker_embedding "'</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">use_second_target</span> <span class="ow">or</span> <span class="n">use_speaker_embedding</span><span class="p">)</span> <span class="ow">and</span> <span class="n">mode</span> <span class="o">!=</span> <span class="s1">'tts'</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s1">'"use_second_target" and "use_speaker_embedding" is '</span>
            <span class="s1">'used only for tts mode'</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_output</span> <span class="o">=</span> <span class="n">load_output</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_input</span> <span class="o">=</span> <span class="n">load_input</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sort_in_input_length</span> <span class="o">=</span> <span class="n">sort_in_input_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_speaker_embedding</span> <span class="o">=</span> <span class="n">use_speaker_embedding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_second_target</span> <span class="o">=</span> <span class="n">use_second_target</span>
    <span class="k">if</span> <span class="n">preprocess_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">preprocess_args</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">preprocess_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">preprocess_args</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">keep_all_data_on_mem</span> <span class="o">=</span> <span class="n">keep_all_data_on_mem</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File">
<code>SoundHDF5File</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Collecting sound files to a HDF5 file</p>
<div class="codehilite">
<pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">f</span> <span class="o">=</span> <span class="n">SoundHDF5File</span><span class="p">(</span><span class="s1">'a.flac.h5'</span><span class="p">,</span> <span class="k">mode</span><span class="o">=</span><span class="s1">'a'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">int16</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f</span><span class="p">[</span><span class="s1">'id'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="nb">array</span><span class="p">,</span> <span class="mi">16000</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">array</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">'id'</span><span class="p">]</span>


<span class="p">:</span><span class="n">param</span><span class="p">:</span> <span class="n">str</span> <span class="n">filepath</span><span class="p">:</span>
<span class="p">:</span><span class="n">param</span><span class="p">:</span> <span class="n">str</span> <span class="k">mode</span><span class="p">:</span>
<span class="p">:</span><span class="n">param</span><span class="p">:</span> <span class="n">str</span> <span class="n">format</span><span class="p">:</span> <span class="n">The</span> <span class="k">type</span> <span class="n">used</span> <span class="k">when</span> <span class="n">saving</span> <span class="n">wav</span><span class="p">.</span> <span class="n">flac</span><span class="p">,</span> <span class="n">nist</span><span class="p">,</span> <span class="n">htk</span><span class="p">,</span> <span class="n">etc</span><span class="p">.</span>
<span class="p">:</span><span class="n">param</span><span class="p">:</span> <span class="n">str</span> <span class="n">dtype</span><span class="p">:</span>
</code></pre>
</div>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__contains__">
<code class="highlight language-python">
__contains__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__contains__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>536
537</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__enter__">
<code class="highlight language-python">
__enter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__enter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>542
543</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__exit__">
<code class="highlight language-python">
__exit__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__exit__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>545
546</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__getitem__">
<code class="highlight language-python">
__getitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__getitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>516
517
518
519
520</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">[</span><span class="n">key</span><span class="p">][()]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
    <span class="n">array</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">soundfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">array</span><span class="p">,</span> <span class="n">rate</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r+'</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int16'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__init__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r+'</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int16'</span><span class="p">,</span>
             <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">filepath</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># filepath = a.flac.h5 -&gt; format = flac</span>
        <span class="n">second_ext</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filepath</span><span class="p">)[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
        <span class="nb">format</span> <span class="o">=</span> <span class="n">second_ext</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">if</span> <span class="nb">format</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">soundfile</span><span class="o">.</span><span class="n">available_formats</span><span class="p">():</span>
            <span class="c1"># If not found, flac is selected</span>
            <span class="nb">format</span> <span class="o">=</span> <span class="s1">'flac'</span>

    <span class="c1"># This format affects only saving</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">format</span> <span class="o">=</span> <span class="nb">format</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__iter__">
<code class="highlight language-python">
__iter__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__iter__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>533
534</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__len__">
<code class="highlight language-python">
__len__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__len__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>539
540</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__repr__">
<code class="highlight language-python">
__repr__<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__repr__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>502
503
504</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">'&lt;SoundHDF5 file "</span><span class="si">{}</span><span class="s1">" (mode </span><span class="si">{}</span><span class="s1">, format </span><span class="si">{}</span><span class="s1">, type </span><span class="si">{}</span><span class="s1">)&gt;'</span> \
        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">format</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__setitem__">
<code class="highlight language-python">
__setitem__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.__setitem__" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>513
514</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.close">
<code class="highlight language-python">
close<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.close" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>548
549</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.create_dataset">
<code class="highlight language-python">
create_dataset<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.create_dataset" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>506
507
508
509
510
511</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">array</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">soundfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                             <span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()),</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.items">
<code class="highlight language-python">
items<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.items" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>529
530
531</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.keys">
<code class="highlight language-python">
keys<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.keys" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>522
523</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.values">
<code class="highlight language-python">
values<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.io_utils.SoundHDF5File.values" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/io_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>525
526
527</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment">
<code>spec_augment</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<p>This implementation is modified from https://github.com/zcaceres/spec_augment</p>
<p>MIT License</p>
<p>Copyright (c) 2019 Zach Caceres</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETjjHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.apply_interpolation">
<code class="highlight language-python">
apply_interpolation<span class="p">(</span><span class="n">query_points</span><span class="p">,</span> <span class="n">train_points</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.apply_interpolation" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Apply polyharmonic interpolation model to data.</p>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<p>Given coefficients w and v for the interpolation model, we evaluate
interpolated function values at query_points.</p>
</div>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>query_points</code></td>
<td><code></code></td>
<td>
<p><code>[b, m, d]</code> x values to evaluate the interpolation at</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>train_points</code></td>
<td><code></code></td>
<td>
<p><code>[b, n, d]</code> x values that act as the interpolation centers
( the c variables in the wikipedia article)
w: <code>[b, n, k]</code> weights on each interpolation center
v: <code>[b, d, k]</code> weights on each input dimension</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>order</code></td>
<td><code></code></td>
<td>
<p>order of the interpolation</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code></code></td>
<td>
<p>Polyharmonic interpolation evaluated at points defined in query_points.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">apply_interpolation</span><span class="p">(</span><span class="n">query_points</span><span class="p">,</span> <span class="n">train_points</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
    <span class="sd">"""Apply polyharmonic interpolation model to data.</span>

<span class="sd">    Notes:</span>
<span class="sd">        Given coefficients w and v for the interpolation model, we evaluate</span>
<span class="sd">        interpolated function values at query_points.</span>

<span class="sd">    Args:</span>
<span class="sd">        query_points: `[b, m, d]` x values to evaluate the interpolation at</span>
<span class="sd">        train_points: `[b, n, d]` x values that act as the interpolation centers</span>
<span class="sd">            ( the c variables in the wikipedia article)</span>
<span class="sd">            w: `[b, n, k]` weights on each interpolation center</span>
<span class="sd">            v: `[b, d, k]` weights on each input dimension</span>
<span class="sd">        order: order of the interpolation</span>

<span class="sd">    Returns:</span>
<span class="sd">        Polyharmonic interpolation evaluated at points defined in query_points.</span>
<span class="sd">    """</span>
    <span class="n">query_points</span> <span class="o">=</span> <span class="n">query_points</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># First, compute the contribution from the rbf term.</span>
    <span class="n">pairwise_dists</span> <span class="o">=</span> <span class="n">cross_squared_distance_matrix</span><span class="p">(</span><span class="n">query_points</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">train_points</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">phi_pairwise_dists</span> <span class="o">=</span> <span class="n">phi</span><span class="p">(</span><span class="n">pairwise_dists</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

    <span class="n">rbf_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">phi_pairwise_dists</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

    <span class="c1"># Then, compute the contribution from the linear term.</span>
    <span class="c1"># Pad query_points with ones, for the bias term in the linear model.</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">query_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">query_points_pad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span>
        <span class="n">query_points</span><span class="p">,</span>
        <span class="n">ones</span>
    <span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">linear_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_points_pad</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">rbf_term</span> <span class="o">+</span> <span class="n">linear_term</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.create_dense_flows">
<code class="highlight language-python">
create_dense_flows<span class="p">(</span><span class="n">flattened_flows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.create_dense_flows" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>180
181
182</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">create_dense_flows</span><span class="p">(</span><span class="n">flattened_flows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">):</span>
    <span class="c1"># possibly .view</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_flows</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.cross_squared_distance_matrix">
<code class="highlight language-python">
cross_squared_distance_matrix<span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.cross_squared_distance_matrix" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Pairwise squared distance between two (batch) matrices' rows (2nd dim).</p>
<p>Computes the pairwise distances between rows of x and rows of y</p>
<p>x: [batch_size, n, d] float <code>Tensor</code>
y: [batch_size, m, d] float <code>Tensor</code></p>
<p>squared_dists: [batch_size, n, m] float <code>Tensor</code>, where
squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">cross_squared_distance_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">"""Pairwise squared distance between two (batch) matrices' rows (2nd dim).</span>

<span class="sd">        Computes the pairwise distances between rows of x and rows of y</span>
<span class="sd">        Args:</span>
<span class="sd">        x: [batch_size, n, d] float `Tensor`</span>
<span class="sd">        y: [batch_size, m, d] float `Tensor`</span>
<span class="sd">        Returns:</span>
<span class="sd">        squared_dists: [batch_size, n, m] float `Tensor`, where</span>
<span class="sd">        squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2</span>
<span class="sd">    """</span>
    <span class="n">x_norm_squared</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">y_norm_squared</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="n">x_y_transpose</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># squared_dists[b,i,j] = ||x_bi - y_bj||^2 = x_bi'x_bi- 2x_bi'x_bj + x_bj'x_bj</span>
    <span class="n">squared_dists</span> <span class="o">=</span> <span class="n">x_norm_squared</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_y_transpose</span> <span class="o">+</span> <span class="n">y_norm_squared</span>

    <span class="k">return</span> <span class="n">squared_dists</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.dense_image_warp">
<code class="highlight language-python">
dense_image_warp<span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">flow</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.dense_image_warp" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Image warping using per-pixel flow vectors.</p>
<p>Apply a non-linear warp to the image, where the warp is specified by a dense
flow field of offset vectors that define the correspondences of pixel values
in the output image back to locations in the  source image. Specifically, the
pixel value at output[b, j, i, c] is
images[b, j - flow[b, j, i, 0], i - flow[b, j, i, 1], c].
The locations specified by this formula do not necessarily map to an int
index. Therefore, the pixel value is obtained by bilinear
interpolation of the 4 nearest pixels around
(b, j - flow[b, j, i, 0], i - flow[b, j, i, 1]). For locations outside
of the image, we use the nearest pixel values at the image boundary.</p>
<p>image: 4-D float <code>Tensor</code> with shape <code>[batch, height, width, channels]</code>.
flow: A 4-D float <code>Tensor</code> with shape <code>[batch, height, width, 2]</code>.
name: A name for the operation (optional).
Note that image and flow can be of type tf.half, tf.float32, or tf.float64,
and do not necessarily have to be the same type.</p>
<p>A 4-D float <code>Tensor</code> with shape<code>[batch, height, width, channels]</code>
and same type as input image.</p>
<p>ValueError: if height &lt; 2 or width &lt; 2 or the inputs have the wrong number
of dimensions.</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">dense_image_warp</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">flow</span><span class="p">):</span>
    <span class="sd">"""Image warping using per-pixel flow vectors.</span>

<span class="sd">    Apply a non-linear warp to the image, where the warp is specified by a dense</span>
<span class="sd">    flow field of offset vectors that define the correspondences of pixel values</span>
<span class="sd">    in the output image back to locations in the  source image. Specifically, the</span>
<span class="sd">    pixel value at output[b, j, i, c] is</span>
<span class="sd">    images[b, j - flow[b, j, i, 0], i - flow[b, j, i, 1], c].</span>
<span class="sd">    The locations specified by this formula do not necessarily map to an int</span>
<span class="sd">    index. Therefore, the pixel value is obtained by bilinear</span>
<span class="sd">    interpolation of the 4 nearest pixels around</span>
<span class="sd">    (b, j - flow[b, j, i, 0], i - flow[b, j, i, 1]). For locations outside</span>
<span class="sd">    of the image, we use the nearest pixel values at the image boundary.</span>
<span class="sd">    Args:</span>
<span class="sd">    image: 4-D float `Tensor` with shape `[batch, height, width, channels]`.</span>
<span class="sd">    flow: A 4-D float `Tensor` with shape `[batch, height, width, 2]`.</span>
<span class="sd">    name: A name for the operation (optional).</span>
<span class="sd">    Note that image and flow can be of type tf.half, tf.float32, or tf.float64,</span>
<span class="sd">    and do not necessarily have to be the same type.</span>
<span class="sd">    Returns:</span>
<span class="sd">    A 4-D float `Tensor` with shape`[batch, height, width, channels]`</span>
<span class="sd">    and same type as input image.</span>
<span class="sd">    Raises:</span>
<span class="sd">    ValueError: if height &lt; 2 or width &lt; 2 or the inputs have the wrong number</span>
<span class="sd">    of dimensions.</span>
<span class="sd">    """</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># add a single channel dimension to image tensor</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">device</span>

    <span class="c1"># The flow is defined on the image grid. Turn the flow into a list of query</span>
    <span class="c1"># points in the grid space.</span>
    <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

    <span class="n">stacked_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">grid_y</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="n">batched_grid</span> <span class="o">=</span> <span class="n">stacked_grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">query_points_on_grid</span> <span class="o">=</span> <span class="n">batched_grid</span> <span class="o">-</span> <span class="n">flow</span>
    <span class="n">query_points_flattened</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">query_points_on_grid</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="c1"># Compute values at the query points, then reshape the result back to the</span>
    <span class="c1"># image grid.</span>
    <span class="n">interpolated</span> <span class="o">=</span> <span class="n">interpolate_bilinear</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">query_points_flattened</span><span class="p">)</span>
    <span class="n">interpolated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">interpolated</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">interpolated</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.flatten_grid_locations">
<code class="highlight language-python">
flatten_grid_locations<span class="p">(</span><span class="n">grid_locations</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.flatten_grid_locations" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>169
170</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">flatten_grid_locations</span><span class="p">(</span><span class="n">grid_locations</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid_locations</span><span class="p">,</span> <span class="p">[</span><span class="n">image_height</span> <span class="o">*</span> <span class="n">image_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.freq_mask">
<code class="highlight language-python">
freq_mask<span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.freq_mask" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Frequency masking</p>
<p>:param torch.Tensor spec: input tensor with shape (T, dim)
:param int F: maximum width of each mask
:param int num_masks: number of masks
:param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">freq_mask</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Frequency masking</span>

<span class="sd">    :param torch.Tensor spec: input tensor with shape (T, dim)</span>
<span class="sd">    :param int F: maximum width of each mask</span>
<span class="sd">    :param int num_masks: number of masks</span>
<span class="sd">    :param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</span>
<span class="sd">    """</span>
    <span class="n">cloned</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">num_mel_channels</span> <span class="o">=</span> <span class="n">cloned</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_masks</span><span class="p">):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
        <span class="n">f_zero</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_mel_channels</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span>

        <span class="c1"># avoids randrange error if values are equal and range is empty</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">f_zero</span> <span class="o">==</span> <span class="n">f_zero</span> <span class="o">+</span> <span class="n">f</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">cloned</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">mask_end</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="n">f_zero</span><span class="p">,</span> <span class="n">f_zero</span> <span class="o">+</span> <span class="n">f</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">replace_with_zero</span><span class="p">):</span>
            <span class="n">cloned</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="n">f_zero</span><span class="p">:</span><span class="n">mask_end</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cloned</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="n">f_zero</span><span class="p">:</span><span class="n">mask_end</span><span class="p">]</span> <span class="o">=</span> <span class="n">cloned</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">cloned</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.get_flat_grid_locations">
<code class="highlight language-python">
get_flat_grid_locations<span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_flat_grid_locations" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>173
174
175
176
177</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_flat_grid_locations</span><span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">y_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">image_height</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y_grid</span><span class="p">,</span> <span class="n">x_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">y_range</span><span class="p">,</span> <span class="n">x_range</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">y_grid</span><span class="p">,</span> <span class="n">x_grid</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">image_height</span> <span class="o">*</span> <span class="n">image_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.get_grid_locations">
<code class="highlight language-python">
get_grid_locations<span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.get_grid_locations" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>162
163
164
165
166</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_grid_locations</span><span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">y_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">image_height</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y_grid</span><span class="p">,</span> <span class="n">x_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">y_range</span><span class="p">,</span> <span class="n">x_range</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">y_grid</span><span class="p">,</span> <span class="n">x_grid</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.interpolate_bilinear">
<code class="highlight language-python">
interpolate_bilinear<span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">query_points</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'interpolate_bilinear'</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">'ij'</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_bilinear" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Similar to Matlab's interp2 function.</p>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<p>Finds values for query points on a grid using bilinear interpolation.</p>
</div>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>grid</code></td>
<td><code></code></td>
<td>
<p>a 4-D float <code>Tensor</code> of shape <code>[batch, height, width, channels]</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>query_points</code></td>
<td><code></code></td>
<td>
<p>a 3-D float <code>Tensor</code> of N points with shape <code>[batch, N, 2]</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>name</code></td>
<td><code></code></td>
<td>
<p>a name for the operation (optional).</p>
</td>
<td><code>'interpolate_bilinear'</code></td>
</tr>
<tr>
<td><code>indexing</code></td>
<td><code></code></td>
<td>
<p>whether the query points are specified as row and column (ij),
or Cartesian coordinates (xy).</p>
</td>
<td><code>'ij'</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>values</code></td>
<td>
<p>a 3-D <code>Tensor</code> with shape <code>[batch, N, channels]</code></p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>if the indexing mode is invalid, or if the shape of the inputs</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">interpolate_bilinear</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span>
                         <span class="n">query_points</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="s1">'interpolate_bilinear'</span><span class="p">,</span>
                         <span class="n">indexing</span><span class="o">=</span><span class="s1">'ij'</span><span class="p">):</span>
    <span class="sd">"""Similar to Matlab's interp2 function.</span>

<span class="sd">    Notes:</span>
<span class="sd">        Finds values for query points on a grid using bilinear interpolation.</span>

<span class="sd">    Args:</span>
<span class="sd">        grid: a 4-D float `Tensor` of shape `[batch, height, width, channels]`.</span>
<span class="sd">        query_points: a 3-D float `Tensor` of N points with shape `[batch, N, 2]`.</span>
<span class="sd">        name: a name for the operation (optional).</span>
<span class="sd">        indexing: whether the query points are specified as row and column (ij),</span>
<span class="sd">            or Cartesian coordinates (xy).</span>

<span class="sd">    Returns:</span>
<span class="sd">        values: a 3-D `Tensor` with shape `[batch, N, channels]`</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if the indexing mode is invalid, or if the shape of the inputs</span>
<span class="sd">        invalid.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">indexing</span> <span class="o">!=</span> <span class="s1">'ij'</span> <span class="ow">and</span> <span class="n">indexing</span> <span class="o">!=</span> <span class="s1">'xy'</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Indexing mode must be </span><span class="se">\'</span><span class="s1">ij</span><span class="se">\'</span><span class="s1"> or </span><span class="se">\'</span><span class="s1">xy</span><span class="se">\'</span><span class="s1">'</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">'Grid must be 4 dimensional. Received size: '</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span><span class="p">]</span>
    <span class="n">query_type</span> <span class="o">=</span> <span class="n">query_points</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">grid_type</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">grid_device</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">device</span>

    <span class="n">num_queries</span> <span class="o">=</span> <span class="n">query_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">floors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ceils</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">index_order</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">indexing</span> <span class="o">==</span> <span class="s1">'ij'</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">unstacked_query_points</span> <span class="o">=</span> <span class="n">query_points</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">index_order</span><span class="p">:</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">unstacked_query_points</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

        <span class="n">size_in_indexing_dimension</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># max_floor is size_in_indexing_dimension - 2 so that max_floor + 1</span>
        <span class="c1"># is still a valid index into the grid.</span>
        <span class="n">max_floor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">size_in_indexing_dimension</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">query_type</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span>
        <span class="n">min_floor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">query_type</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span>
        <span class="n">maxx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">min_floor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">queries</span><span class="p">))</span>
        <span class="n">floor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">maxx</span><span class="p">,</span> <span class="n">max_floor</span><span class="p">)</span>
        <span class="n">int_floor</span> <span class="o">=</span> <span class="n">floor</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">floors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">int_floor</span><span class="p">)</span>
        <span class="n">ceil</span> <span class="o">=</span> <span class="n">int_floor</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">ceils</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ceil</span><span class="p">)</span>

        <span class="c1"># alpha has the same type as the grid, as we will directly use alpha</span>
        <span class="c1"># when taking linear combinations of pixel values from the image.</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="n">queries</span> <span class="o">-</span> <span class="n">floor</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">grid_type</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span>
        <span class="n">min_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">grid_type</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span>
        <span class="n">max_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">grid_type</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">min_alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">),</span> <span class="n">max_alpha</span><span class="p">)</span>

        <span class="c1"># Expand alpha to [b, n, 1] so we can use broadcasting</span>
        <span class="c1"># (since the alpha values don't depend on the channel).</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

    <span class="n">flattened_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span><span class="p">])</span>
    <span class="n">batch_offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">grid_device</span><span class="p">)</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1"># This wraps array_ops.gather. We reshape the image data such that the</span>
    <span class="c1"># batch, y, and x coordinates are pulled into the first dimension.</span>
    <span class="c1"># Then we gather. Finally, we reshape the output back. It's possible this</span>
    <span class="c1"># code would be made simpler by using array_ops.gather_nd.</span>
    <span class="k">def</span> <span class="nf">gather</span><span class="p">(</span><span class="n">y_coords</span><span class="p">,</span> <span class="n">x_coords</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">linear_coordinates</span> <span class="o">=</span> <span class="n">batch_offsets</span> <span class="o">+</span> <span class="n">y_coords</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">x_coords</span>
        <span class="n">gathered_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">flattened_grid</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">linear_coordinates</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">gathered_values</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="n">channels</span><span class="p">])</span>

    <span class="c1"># grab the pixel values in the 4 corners around each query point</span>
    <span class="n">top_left</span> <span class="o">=</span> <span class="n">gather</span><span class="p">(</span><span class="n">floors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">floors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'top_left'</span><span class="p">)</span>
    <span class="n">top_right</span> <span class="o">=</span> <span class="n">gather</span><span class="p">(</span><span class="n">floors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ceils</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'top_right'</span><span class="p">)</span>
    <span class="n">bottom_left</span> <span class="o">=</span> <span class="n">gather</span><span class="p">(</span><span class="n">ceils</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">floors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'bottom_left'</span><span class="p">)</span>
    <span class="n">bottom_right</span> <span class="o">=</span> <span class="n">gather</span><span class="p">(</span><span class="n">ceils</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ceils</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'bottom_right'</span><span class="p">)</span>

    <span class="n">interp_top</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">top_right</span> <span class="o">-</span> <span class="n">top_left</span><span class="p">)</span> <span class="o">+</span> <span class="n">top_left</span>
    <span class="n">interp_bottom</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">bottom_right</span> <span class="o">-</span> <span class="n">bottom_left</span><span class="p">)</span> <span class="o">+</span> <span class="n">bottom_left</span>
    <span class="n">interp</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">interp_bottom</span> <span class="o">-</span> <span class="n">interp_top</span><span class="p">)</span> <span class="o">+</span> <span class="n">interp_top</span>

    <span class="k">return</span> <span class="n">interp</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.interpolate_spline">
<code class="highlight language-python">
interpolate_spline<span class="p">(</span><span class="n">train_points</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">query_points</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.interpolate_spline" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>185
186
187
188
189
190
191</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">interpolate_spline</span><span class="p">(</span><span class="n">train_points</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">query_points</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="p">):</span>
    <span class="c1"># First, fit the spline to the observed data.</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">solve_interpolation</span><span class="p">(</span><span class="n">train_points</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="p">)</span>
    <span class="c1"># Then, evaluate the spline at the query locations.</span>
    <span class="n">query_values</span> <span class="o">=</span> <span class="n">apply_interpolation</span><span class="p">(</span><span class="n">query_points</span><span class="p">,</span> <span class="n">train_points</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">query_values</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.phi">
<code class="highlight language-python">
phi<span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.phi" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Coordinate-wise nonlinearity used to define the order of the interpolation.</p>
<p>See https://en.wikipedia.org/wiki/Polyharmonic_spline for the definition.</p>
<p>r: input op
order: interpolation order</p>
<p>phi_k evaluated coordinate-wise on r, for k = r</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">phi</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
    <span class="sd">"""Coordinate-wise nonlinearity used to define the order of the interpolation.</span>

<span class="sd">    See https://en.wikipedia.org/wiki/Polyharmonic_spline for the definition.</span>
<span class="sd">    Args:</span>
<span class="sd">    r: input op</span>
<span class="sd">    order: interpolation order</span>
<span class="sd">    Returns:</span>
<span class="sd">    phi_k evaluated coordinate-wise on r, for k = r</span>
<span class="sd">    """</span>
    <span class="n">EPSILON</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">r</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># using EPSILON prevents log(0), sqrt0), etc.</span>
    <span class="c1"># sqrt(0) is well-defined, but its gradient is not</span>
    <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">EPSILON</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>
    <span class="k">elif</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">r</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">EPSILON</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">EPSILON</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">order</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">EPSILON</span><span class="p">)</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">order</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">EPSILON</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">order</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.solve_interpolation">
<code class="highlight language-python">
solve_interpolation<span class="p">(</span><span class="n">train_points</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.solve_interpolation" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">solve_interpolation</span><span class="p">(</span><span class="n">train_points</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">train_points</span><span class="o">.</span><span class="n">device</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">train_points</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">train_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">c</span> <span class="o">=</span> <span class="n">train_points</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">train_values</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="n">matrix_a</span> <span class="o">=</span> <span class="n">phi</span><span class="p">(</span><span class="n">cross_squared_distance_matrix</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">),</span> <span class="n">order</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [b, n, n]</span>

    <span class="c1"># Append ones to the feature values for the bias term in the linear model.</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">train_points</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">matrix_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">ones</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># [b, n, d + 1]</span>

    <span class="c1"># [b, n + d + 1, n]</span>
    <span class="n">left_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">matrix_a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">matrix_b</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">num_b_cols</span> <span class="o">=</span> <span class="n">matrix_b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># d + 1</span>

    <span class="c1"># In Tensorflow, zeros are used here. Pytorch solve fails with zeros for some reason we don't understand.</span>
    <span class="c1"># So instead we use very tiny randn values (variance of one, zero mean) on one side of our multiplication.</span>
    <span class="n">lhs_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">num_b_cols</span><span class="p">,</span> <span class="n">num_b_cols</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e10</span>
    <span class="n">right_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">matrix_b</span><span class="p">,</span> <span class="n">lhs_zeros</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [b, n + d + 1, d + 1]</span>
    <span class="n">lhs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">left_block</span><span class="p">,</span> <span class="n">right_block</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># [b, n + d + 1, n + d + 1]</span>

    <span class="n">rhs_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">train_points</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">rhs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">f</span><span class="p">,</span> <span class="n">rhs_zeros</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [b, n + d + 1, k]</span>

    <span class="c1"># Then, solve the linear system and unpack the results.</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">LU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gesv</span><span class="p">(</span><span class="n">rhs</span><span class="p">,</span> <span class="n">lhs</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:,</span> <span class="p">:]</span>

    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">v</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.sparse_image_warp">
<code class="highlight language-python">
sparse_image_warp<span class="p">(</span><span class="n">img_tensor</span><span class="p">,</span> <span class="n">source_control_point_locations</span><span class="p">,</span> <span class="n">dest_control_point_locations</span><span class="p">,</span> <span class="n">interpolation_order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">regularization_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">num_boundaries_points</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.sparse_image_warp" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">sparse_image_warp</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">,</span>
                      <span class="n">source_control_point_locations</span><span class="p">,</span>
                      <span class="n">dest_control_point_locations</span><span class="p">,</span>
                      <span class="n">interpolation_order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">regularization_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                      <span class="n">num_boundaries_points</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">img_tensor</span><span class="o">.</span><span class="n">device</span>
    <span class="n">control_point_flows</span> <span class="o">=</span> <span class="n">dest_control_point_locations</span> <span class="o">-</span> <span class="n">source_control_point_locations</span>

    <span class="n">batch_size</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">=</span> <span class="n">img_tensor</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">flattened_grid_locations</span> <span class="o">=</span> <span class="n">get_flat_grid_locations</span><span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="n">flattened_flows</span> <span class="o">=</span> <span class="n">interpolate_spline</span><span class="p">(</span>
        <span class="n">dest_control_point_locations</span><span class="p">,</span>
        <span class="n">control_point_flows</span><span class="p">,</span>
        <span class="n">flattened_grid_locations</span><span class="p">,</span>
        <span class="n">interpolation_order</span><span class="p">,</span>
        <span class="n">regularization_weight</span><span class="p">)</span>

    <span class="n">dense_flows</span> <span class="o">=</span> <span class="n">create_dense_flows</span><span class="p">(</span><span class="n">flattened_flows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">)</span>

    <span class="n">warped_image</span> <span class="o">=</span> <span class="n">dense_image_warp</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">,</span> <span class="n">dense_flows</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">warped_image</span><span class="p">,</span> <span class="n">dense_flows</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.specaug">
<code class="highlight language-python">
specaug<span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">num_freq_masks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_time_masks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.specaug" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>SpecAugment</p>
<div class="admonition reference">
<p class="admonition-title">SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</p>
<p>(https://arxiv.org/pdf/1904.08779.pdf)</p>
</div>
<p>This implementation modified from https://github.com/zcaceres/spec_augment</p>
<p>:param torch.Tensor spec: input tensor with the shape (T, dim)
:param int W: time warp parameter
:param int F: maximum width of each freq mask
:param int T: maximum width of each time mask
:param int num_freq_masks: number of frequency masks
:param int num_time_masks: number of time masks
:param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">specaug</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">num_freq_masks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_time_masks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""SpecAugment</span>

<span class="sd">    Reference: SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</span>
<span class="sd">        (https://arxiv.org/pdf/1904.08779.pdf)</span>

<span class="sd">    This implementation modified from https://github.com/zcaceres/spec_augment</span>

<span class="sd">    :param torch.Tensor spec: input tensor with the shape (T, dim)</span>
<span class="sd">    :param int W: time warp parameter</span>
<span class="sd">    :param int F: maximum width of each freq mask</span>
<span class="sd">    :param int T: maximum width of each time mask</span>
<span class="sd">    :param int num_freq_masks: number of frequency masks</span>
<span class="sd">    :param int num_time_masks: number of time masks</span>
<span class="sd">    :param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">time_mask</span><span class="p">(</span>
        <span class="n">freq_mask</span><span class="p">(</span><span class="n">time_warp</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">),</span>
                  <span class="n">F</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="n">num_freq_masks</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="n">replace_with_zero</span><span class="p">),</span>
        <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="n">num_time_masks</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="n">replace_with_zero</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.time_mask">
<code class="highlight language-python">
time_mask<span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_mask" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Time masking</p>
<p>:param torch.Tensor spec: input tensor with shape (T, dim)
:param int T: maximum width of each mask
:param int num_masks: number of masks
:param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">time_mask</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">num_masks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">replace_with_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Time masking</span>

<span class="sd">    :param torch.Tensor spec: input tensor with shape (T, dim)</span>
<span class="sd">    :param int T: maximum width of each mask</span>
<span class="sd">    :param int num_masks: number of masks</span>
<span class="sd">    :param bool replace_with_zero: if True, masked parts will be filled with 0, if False, filled with mean</span>
<span class="sd">    """</span>
    <span class="n">cloned</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">len_spectro</span> <span class="o">=</span> <span class="n">cloned</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_masks</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
        <span class="n">t_zero</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len_spectro</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># avoids randrange error if values are equal and range is empty</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">t_zero</span> <span class="o">==</span> <span class="n">t_zero</span> <span class="o">+</span> <span class="n">t</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">cloned</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">mask_end</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="n">t_zero</span><span class="p">,</span> <span class="n">t_zero</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">replace_with_zero</span><span class="p">):</span>
            <span class="n">cloned</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">t_zero</span><span class="p">:</span><span class="n">mask_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cloned</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">t_zero</span><span class="p">:</span><span class="n">mask_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">cloned</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">cloned</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.spec_augment.time_warp">
<code class="highlight language-python">
time_warp<span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.spec_augment.time_warp" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<p>Time warping</p>
<p>:param torch.Tensor spec: input tensor with shape (T, dim)
:param int W: time warp parameter</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/spec_augment.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">time_warp</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">"""Time warping</span>

<span class="sd">    :param torch.Tensor spec: input tensor with shape (T, dim)</span>
<span class="sd">    :param int W: time warp parameter</span>
<span class="sd">    """</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">spec_len</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">num_rows</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">device</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">num_rows</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">horizontal_line_at_ctr</span> <span class="o">=</span> <span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="n">y</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">horizontal_line_at_ctr</span><span class="p">)</span> <span class="o">==</span> <span class="n">spec_len</span>

    <span class="n">point_to_warp</span> <span class="o">=</span> <span class="n">horizontal_line_at_ctr</span><span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">spec_len</span> <span class="o">-</span> <span class="n">W</span><span class="p">)]</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">point_to_warp</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>

    <span class="c1"># Uniform distribution from (0,W) with chance to be up to W negative</span>
    <span class="n">dist_to_warp</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="n">src_pts</span><span class="p">,</span> <span class="n">dest_pts</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="n">point_to_warp</span><span class="p">,</span> <span class="n">y</span><span class="p">]]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                         <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="n">point_to_warp</span> <span class="o">+</span> <span class="n">dist_to_warp</span><span class="p">,</span> <span class="n">y</span><span class="p">]]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
    <span class="n">warped_spectro</span><span class="p">,</span> <span class="n">dense_flows</span> <span class="o">=</span> <span class="n">sparse_image_warp</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">src_pts</span><span class="p">,</span> <span class="n">dest_pts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">warped_spectro</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h4 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training">
<code>training</code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training" title="Permanent link">¶</a></h4>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy">
<code>batchfy</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_bin">
<code class="highlight language-python">
batchfy_by_bin<span class="p">(</span><span class="n">sorted_data</span><span class="p">,</span> <span class="n">batch_bins</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ikey</span><span class="o">=</span><span class="s1">'input'</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s1">'output'</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_bin" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make variably sized batch set, which maximizes the number of bins up to <code>batch_bins</code>.</p>
<p>:param Dict[str, Dict[str, Any]] sorted_data: dictionary loaded from data.json
:param int batch_bins: Maximum frames of a batch
:param int num_batches: # number of batches to use (for debug)
:param int min_batch_size: minimum batch size (for multi-gpu)
:param int test: Return only every <code>test</code> batches
:param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</p>
<p>:param str ikey: key to access input (for ASR ikey="input", for TTS ikey="output".)
:param str okey: key to access output (for ASR okey="output". for TTS okey="input".)</p>
<p>:return: List[Tuple[str, Dict[str, List[Dict[str, Any]]]] list of batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/batchfy.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batchfy_by_bin</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">,</span> <span class="n">batch_bins</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">ikey</span><span class="o">=</span><span class="s2">"input"</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s2">"output"</span><span class="p">):</span>
    <span class="sd">"""Make variably sized batch set, which maximizes the number of bins up to `batch_bins`.</span>

<span class="sd">    :param Dict[str, Dict[str, Any]] sorted_data: dictionary loaded from data.json</span>
<span class="sd">    :param int batch_bins: Maximum frames of a batch</span>
<span class="sd">    :param int num_batches: # number of batches to use (for debug)</span>
<span class="sd">    :param int min_batch_size: minimum batch size (for multi-gpu)</span>
<span class="sd">    :param int test: Return only every `test` batches</span>
<span class="sd">    :param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</span>

<span class="sd">    :param str ikey: key to access input (for ASR ikey="input", for TTS ikey="output".)</span>
<span class="sd">    :param str okey: key to access output (for ASR okey="output". for TTS okey="input".)</span>

<span class="sd">    :return: List[Tuple[str, Dict[str, List[Dict[str, Any]]]] list of batches</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">batch_bins</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"invalid batch_bins=</span><span class="si">{</span><span class="n">batch_bins</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)</span>
    <span class="n">idim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">ikey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">odim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">okey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'# utts: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)))</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Dynamic batch size depending on size of samples</span>
        <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">next_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_olen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">next_size</span> <span class="o">&lt;</span> <span class="n">batch_bins</span> <span class="ow">and</span> <span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">:</span>
            <span class="n">ilen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">ikey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">idim</span>
            <span class="n">olen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">okey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">odim</span>
            <span class="k">if</span> <span class="n">olen</span> <span class="o">&gt;</span> <span class="n">max_olen</span><span class="p">:</span>
                <span class="n">max_olen</span> <span class="o">=</span> <span class="n">olen</span>
            <span class="n">next_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_olen</span> <span class="o">+</span> <span class="n">ilen</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_size</span> <span class="o">&lt;=</span> <span class="n">batch_bins</span><span class="p">:</span>
                <span class="n">b</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">next_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Can't fit one sample in batch_bins (</span><span class="si">{</span><span class="n">batch_bins</span><span class="si">}</span><span class="s2">): Please increase the value"</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">start</span> <span class="o">+</span> <span class="nb">max</span><span class="p">(</span><span class="n">min_batch_size</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">minibatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="c1"># Check for min_batch_size and fixes the batches if needed</span>
        <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">min_batch_size</span><span class="p">:</span>
            <span class="n">missing</span> <span class="o">=</span> <span class="n">min_batch_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span> <span class="o">-</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">):</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][:</span><span class="n">missing</span><span class="p">])</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">missing</span><span class="p">:]</span>
                <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">end</span> <span class="o">==</span> <span class="n">length</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">num_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[:</span><span class="n">num_batches</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">minibatches</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" batches containing from "</span> <span class="o">+</span>
                 <span class="nb">str</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" to "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" samples "</span> <span class="o">+</span>
                 <span class="s2">"(avg "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span> <span class="o">+</span> <span class="s2">" samples)."</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">minibatches</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_frame">
<code class="highlight language-python">
batchfy_by_frame<span class="p">(</span><span class="n">sorted_data</span><span class="p">,</span> <span class="n">max_frames_in</span><span class="p">,</span> <span class="n">max_frames_out</span><span class="p">,</span> <span class="n">max_frames_inout</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ikey</span><span class="o">=</span><span class="s1">'input'</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s1">'output'</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_frame" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make variably sized batch set, which maximizes the number of frames to max_batch_frame.</p>
<p>:param Dict[str, Dict[str, Any]] sorteddata: dictionary loaded from data.json
:param int max_frames_in: Maximum input frames of a batch
:param int max_frames_out: Maximum output frames of a batch
:param int max_frames_inout: Maximum input+output frames of a batch
:param int num_batches: # number of batches to use (for debug)
:param int min_batch_size: minimum batch size (for multi-gpu)
:param int test: Return only every <code>test</code> batches
:param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</p>
<p>:param str ikey: key to access input (for ASR ikey="input", for TTS ikey="output".)
:param str okey: key to access output (for ASR okey="output". for TTS okey="input".)</p>
<p>:return: List[Tuple[str, Dict[str, List[Dict[str, Any]]]] list of batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/batchfy.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batchfy_by_frame</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">,</span> <span class="n">max_frames_in</span><span class="p">,</span> <span class="n">max_frames_out</span><span class="p">,</span> <span class="n">max_frames_inout</span><span class="p">,</span>
                     <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">ikey</span><span class="o">=</span><span class="s2">"input"</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s2">"output"</span><span class="p">):</span>
    <span class="sd">"""Make variably sized batch set, which maximizes the number of frames to max_batch_frame.</span>

<span class="sd">    :param Dict[str, Dict[str, Any]] sorteddata: dictionary loaded from data.json</span>
<span class="sd">    :param int max_frames_in: Maximum input frames of a batch</span>
<span class="sd">    :param int max_frames_out: Maximum output frames of a batch</span>
<span class="sd">    :param int max_frames_inout: Maximum input+output frames of a batch</span>
<span class="sd">    :param int num_batches: # number of batches to use (for debug)</span>
<span class="sd">    :param int min_batch_size: minimum batch size (for multi-gpu)</span>
<span class="sd">    :param int test: Return only every `test` batches</span>
<span class="sd">    :param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</span>

<span class="sd">    :param str ikey: key to access input (for ASR ikey="input", for TTS ikey="output".)</span>
<span class="sd">    :param str okey: key to access output (for ASR okey="output". for TTS okey="input".)</span>

<span class="sd">    :return: List[Tuple[str, Dict[str, List[Dict[str, Any]]]] list of batches</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">max_frames_in</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">max_frames_out</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">max_frames_inout</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"At least, one of `--batch-frames-in`, `--batch-frames-out` or `--batch-frames-inout` should be &gt; 0"</span><span class="p">)</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">end</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">end</span> <span class="o">!=</span> <span class="n">length</span><span class="p">:</span>
        <span class="c1"># Dynamic batch size depending on size of samples</span>
        <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_olen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_ilen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">:</span>
            <span class="n">ilen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">ikey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">ilen</span> <span class="o">&gt;</span> <span class="n">max_frames_in</span> <span class="ow">and</span> <span class="n">max_frames_in</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Can't fit one sample in --batch-frames-in (</span><span class="si">{</span><span class="n">max_frames_in</span><span class="si">}</span><span class="s2">): Please increase the value"</span><span class="p">)</span>
            <span class="n">olen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">okey</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">olen</span> <span class="o">&gt;</span> <span class="n">max_frames_out</span> <span class="ow">and</span> <span class="n">max_frames_out</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Can't fit one sample in --batch-frames-out (</span><span class="si">{</span><span class="n">max_frames_out</span><span class="si">}</span><span class="s2">): Please increase the value"</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ilen</span> <span class="o">+</span> <span class="n">olen</span> <span class="o">&gt;</span> <span class="n">max_frames_inout</span> <span class="ow">and</span> <span class="n">max_frames_inout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Can't fit one sample in --batch-frames-out (</span><span class="si">{</span><span class="n">max_frames_inout</span><span class="si">}</span><span class="s2">): Please increase the value"</span><span class="p">)</span>
            <span class="n">max_olen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_olen</span><span class="p">,</span> <span class="n">olen</span><span class="p">)</span>
            <span class="n">max_ilen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_ilen</span><span class="p">,</span> <span class="n">ilen</span><span class="p">)</span>
            <span class="n">in_ok</span> <span class="o">=</span> <span class="n">max_ilen</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_frames_in</span> <span class="ow">or</span> <span class="n">max_frames_in</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="n">out_ok</span> <span class="o">=</span> <span class="n">max_olen</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_frames_out</span> <span class="ow">or</span> <span class="n">max_frames_out</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="n">inout_ok</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_ilen</span> <span class="o">+</span> <span class="n">max_olen</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_frames_inout</span> <span class="ow">or</span> <span class="n">max_frames_inout</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">in_ok</span> <span class="ow">and</span> <span class="n">out_ok</span> <span class="ow">and</span> <span class="n">inout_ok</span><span class="p">:</span>
                <span class="c1"># add more seq in the minibatch</span>
                <span class="n">b</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># no more seq in the minibatch</span>
                <span class="k">break</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">start</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">minibatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="c1"># Check for min_batch_size and fixes the batches if needed</span>
        <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">min_batch_size</span><span class="p">:</span>
            <span class="n">missing</span> <span class="o">=</span> <span class="n">min_batch_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span> <span class="o">-</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">):</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][:</span><span class="n">missing</span><span class="p">])</span>
                <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">missing</span><span class="p">:]</span>
                <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
    <span class="k">if</span> <span class="n">num_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[:</span><span class="n">num_batches</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">minibatches</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" batches containing from "</span> <span class="o">+</span>
                 <span class="nb">str</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" to "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span> <span class="o">+</span> <span class="s2">" samples"</span> <span class="o">+</span>
                 <span class="s2">"(avg "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span> <span class="o">+</span> <span class="s2">" samples)."</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">minibatches</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_seq">
<code class="highlight language-python">
batchfy_by_seq<span class="p">(</span><span class="n">sorted_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_length_in</span><span class="p">,</span> <span class="n">max_length_out</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ikey</span><span class="o">=</span><span class="s1">'input'</span><span class="p">,</span> <span class="n">iaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s1">'output'</span><span class="p">,</span> <span class="n">oaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_by_seq" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make batch set from json dictionary</p>
<p>:param Dict[str, Dict[str, Any]] sorted_data: dictionary loaded from data.json
:param int batch_size: batch size
:param int max_length_in: maximum length of input to decide adaptive batch size
:param int max_length_out: maximum length of output to decide adaptive batch size
:param int min_batch_size: mininum batch size (for multi-gpu)
:param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</p>
<p>:param str ikey: key to access input (for ASR ikey="input", for TTS, MT ikey="output".)
:param int iaxis: dimension to access input (for ASR, TTS iaxis=0, for MT iaxis="1".)
:param str okey: key to access output (for ASR, MT okey="output". for TTS okey="input".)
:param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0, reserved for future research,
                  -1 means all axis.)</p>
<p>:return: List[List[Tuple[str, dict]]] list of batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/batchfy.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batchfy_by_seq</span><span class="p">(</span>
        <span class="n">sorted_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_length_in</span><span class="p">,</span> <span class="n">max_length_out</span><span class="p">,</span>
        <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ikey</span><span class="o">=</span><span class="s2">"input"</span><span class="p">,</span> <span class="n">iaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="s2">"output"</span><span class="p">,</span> <span class="n">oaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Make batch set from json dictionary</span>

<span class="sd">    :param Dict[str, Dict[str, Any]] sorted_data: dictionary loaded from data.json</span>
<span class="sd">    :param int batch_size: batch size</span>
<span class="sd">    :param int max_length_in: maximum length of input to decide adaptive batch size</span>
<span class="sd">    :param int max_length_out: maximum length of output to decide adaptive batch size</span>
<span class="sd">    :param int min_batch_size: mininum batch size (for multi-gpu)</span>
<span class="sd">    :param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</span>

<span class="sd">    :param str ikey: key to access input (for ASR ikey="input", for TTS, MT ikey="output".)</span>
<span class="sd">    :param int iaxis: dimension to access input (for ASR, TTS iaxis=0, for MT iaxis="1".)</span>
<span class="sd">    :param str okey: key to access output (for ASR, MT okey="output". for TTS okey="input".)</span>
<span class="sd">    :param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0, reserved for future research,</span>
<span class="sd">                      -1 means all axis.)</span>

<span class="sd">    :return: List[List[Tuple[str, dict]]] list of batches</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Invalid batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># check #utts is more than min_batch_size</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_batch_size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"#utts(</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)</span><span class="si">}</span><span class="s2">) is less than min_batch_size(</span><span class="si">{</span><span class="n">min_batch_size</span><span class="si">}</span><span class="s2">)."</span><span class="p">)</span>

    <span class="c1"># make list of minibatches</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span><span class="p">]</span>
        <span class="n">ilen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="n">ikey</span><span class="p">][</span><span class="n">iaxis</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">olen</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="n">okey</span><span class="p">][</span><span class="n">oaxis</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">oaxis</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">max</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">info</span><span class="p">[</span><span class="n">okey</span><span class="p">]))</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ilen</span> <span class="o">/</span> <span class="n">max_length_in</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">olen</span> <span class="o">/</span> <span class="n">max_length_out</span><span class="p">))</span>
        <span class="c1"># change batchsize depending on the input and output length</span>
        <span class="c1"># if ilen = 1000 and max_length_in = 800</span>
        <span class="c1"># then b = batchsize / 2</span>
        <span class="c1"># and max(min_batches, .) avoids batchsize = 0</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">min_batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">factor</span><span class="p">)))</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">),</span> <span class="n">start</span> <span class="o">+</span> <span class="n">bs</span><span class="p">)</span>
        <span class="n">minibatch</span> <span class="o">=</span> <span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>

        <span class="c1"># check each batch is more than minimum batchsize</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_batch_size</span><span class="p">:</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">min_batch_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span> <span class="o">%</span> <span class="n">min_batch_size</span>
            <span class="n">additional_minibatch</span> <span class="o">=</span> <span class="p">[</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">mod</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
                <span class="n">additional_minibatch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">additional_minibatch</span><span class="p">)</span>
        <span class="n">minibatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">end</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>

    <span class="c1"># batch: List[List[Tuple[str, dict]]]</span>
    <span class="k">return</span> <span class="n">minibatches</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_shuffle">
<code class="highlight language-python">
batchfy_shuffle<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">shortest_first</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy.batchfy_shuffle" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/batchfy.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">batchfy_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">shortest_first</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">random</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'use shuffled batch.'</span><span class="p">)</span>
    <span class="n">sorted_data</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'# utts: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)))</span>
    <span class="c1"># make list of minibatches</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">),</span> <span class="n">start</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># check each batch is more than minimum batchsize</span>
        <span class="n">minibatch</span> <span class="o">=</span> <span class="n">sorted_data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_batch_size</span><span class="p">:</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">min_batch_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span> <span class="o">%</span> <span class="n">min_batch_size</span>
            <span class="n">additional_minibatch</span> <span class="o">=</span> <span class="p">[</span><span class="n">sorted_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">mod</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">shortest_first</span><span class="p">:</span>
                <span class="n">additional_minibatch</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">additional_minibatch</span><span class="p">)</span>
        <span class="n">minibatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">end</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>

    <span class="c1"># for debugging</span>
    <span class="k">if</span> <span class="n">num_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatches</span><span class="p">[:</span><span class="n">num_batches</span><span class="p">]</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'# minibatches: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">minibatches</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">minibatches</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.batchfy.make_batchset">
<code class="highlight language-python">
make_batchset<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_length_in</span><span class="o">=</span><span class="n">inf</span><span class="p">,</span> <span class="n">max_length_out</span><span class="o">=</span><span class="n">inf</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_sort_key</span><span class="o">=</span><span class="s1">'input'</span><span class="p">,</span> <span class="n">swap_io</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span> <span class="n">batch_bins</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_in</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_out</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_inout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">iaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">oaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.batchfy.make_batchset" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Make batch set from json dictionary</p>
<p>if utts have "category" value,</p>
<div class="codehilite">
<pre><span></span><code><span class="err">&gt;&gt;&gt; data = {'utt1': {'category': 'A', 'input': ...},</span>
<span class="err">...         'utt2': {'category': 'B', 'input': ...},</span>
<span class="err">...         'utt3': {'category': 'B', 'input': ...},</span>
<span class="err">...         'utt4': {'category': 'A', 'input': ...}}</span>
<span class="err">&gt;&gt;&gt; make_batchset(data, batchsize=2, ...)</span>
<span class="err">[[('utt1', ...), ('utt4', ...)], [('utt2', ...), ('utt3': ...)]]</span>
</code></pre>
</div>
<p>Note that if any utts doesn't have "category",
perform as same as batchfy_by_{count}</p>
<p>:param Dict[str, Dict[str, Any]] data: dictionary loaded from data.json
:param int batch_size: maximum number of sequences in a minibatch.
:param int batch_bins: maximum number of bins (frames x dim) in a minibatch.
:param int batch_frames_in:  maximum number of input frames in a minibatch.
:param int batch_frames_out: maximum number of output frames in a minibatch.
:param int batch_frames_out: maximum number of input+output frames in a minibatch.
:param str count: strategy to count maximum size of batch.
    For choices, see services.hci.speech.espnet_minimal.asr.batchfy.BATCH_COUNT_CHOICES</p>
<p>:param int max_length_in: maximum length of input to decide adaptive batch size
:param int max_length_out: maximum length of output to decide adaptive batch size
:param int num_batches: # number of batches to use (for debug)
:param int min_batch_size: minimum batch size (for multi-gpu)
:param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse
    :return: List[List[Tuple[str, dict]]] list of batches
:param str batch_sort_key: how to sort data before creating minibatches ["input", "output", "shuffle"]
:param bool swap_io: if True, use "input" as output and "output" as input in <code>data</code> dict
:param bool mt: if True, use 0-axis of "output" as output and 1-axis of "output" as input in <code>data</code> dict
:param int iaxis: dimension to access input (for ASR, TTS iaxis=0, for MT iaxis="1".)
:param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0, reserved for future research,
                  -1 means all axis.)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/batchfy.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">make_batchset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_length_in</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">),</span> <span class="n">max_length_out</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">),</span>
                  <span class="n">num_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shortest_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_sort_key</span><span class="o">=</span><span class="s2">"input"</span><span class="p">,</span>
                  <span class="n">swap_io</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">,</span>
                  <span class="n">batch_bins</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_in</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_out</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_frames_inout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="n">iaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">oaxis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Make batch set from json dictionary</span>

<span class="sd">    if utts have "category" value,</span>

<span class="sd">        &gt;&gt;&gt; data = {'utt1': {'category': 'A', 'input': ...},</span>
<span class="sd">        ...         'utt2': {'category': 'B', 'input': ...},</span>
<span class="sd">        ...         'utt3': {'category': 'B', 'input': ...},</span>
<span class="sd">        ...         'utt4': {'category': 'A', 'input': ...}}</span>
<span class="sd">        &gt;&gt;&gt; make_batchset(data, batchsize=2, ...)</span>
<span class="sd">        [[('utt1', ...), ('utt4', ...)], [('utt2', ...), ('utt3': ...)]]</span>

<span class="sd">    Note that if any utts doesn't have "category",</span>
<span class="sd">    perform as same as batchfy_by_{count}</span>

<span class="sd">    :param Dict[str, Dict[str, Any]] data: dictionary loaded from data.json</span>
<span class="sd">    :param int batch_size: maximum number of sequences in a minibatch.</span>
<span class="sd">    :param int batch_bins: maximum number of bins (frames x dim) in a minibatch.</span>
<span class="sd">    :param int batch_frames_in:  maximum number of input frames in a minibatch.</span>
<span class="sd">    :param int batch_frames_out: maximum number of output frames in a minibatch.</span>
<span class="sd">    :param int batch_frames_out: maximum number of input+output frames in a minibatch.</span>
<span class="sd">    :param str count: strategy to count maximum size of batch.</span>
<span class="sd">        For choices, see services.hci.speech.espnet_minimal.asr.batchfy.BATCH_COUNT_CHOICES</span>

<span class="sd">    :param int max_length_in: maximum length of input to decide adaptive batch size</span>
<span class="sd">    :param int max_length_out: maximum length of output to decide adaptive batch size</span>
<span class="sd">    :param int num_batches: # number of batches to use (for debug)</span>
<span class="sd">    :param int min_batch_size: minimum batch size (for multi-gpu)</span>
<span class="sd">    :param bool shortest_first: Sort from batch with shortest samples to longest if true, otherwise reverse</span>
<span class="sd">        :return: List[List[Tuple[str, dict]]] list of batches</span>
<span class="sd">    :param str batch_sort_key: how to sort data before creating minibatches ["input", "output", "shuffle"]</span>
<span class="sd">    :param bool swap_io: if True, use "input" as output and "output" as input in `data` dict</span>
<span class="sd">    :param bool mt: if True, use 0-axis of "output" as output and 1-axis of "output" as input in `data` dict</span>
<span class="sd">    :param int iaxis: dimension to access input (for ASR, TTS iaxis=0, for MT iaxis="1".)</span>
<span class="sd">    :param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0, reserved for future research,</span>
<span class="sd">                      -1 means all axis.)</span>
<span class="sd">    """</span>

    <span class="c1"># check args</span>
    <span class="k">if</span> <span class="n">count</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">BATCH_COUNT_CHOICES</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"arg 'count' (</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">) should be one of </span><span class="si">{</span><span class="n">BATCH_COUNT_CHOICES</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch_sort_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">BATCH_SORT_KEY_CHOICES</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"arg 'batch_sort_key' (</span><span class="si">{</span><span class="n">batch_sort_key</span><span class="si">}</span><span class="s2">) should be one of </span><span class="si">{</span><span class="n">BATCH_SORT_KEY_CHOICES</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># TODO(karita): remove this by creating converter from ASR to TTS json format</span>
    <span class="n">batch_sort_axis</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">swap_io</span><span class="p">:</span>
        <span class="c1"># for TTS</span>
        <span class="n">ikey</span> <span class="o">=</span> <span class="s2">"output"</span>
        <span class="n">okey</span> <span class="o">=</span> <span class="s2">"input"</span>
        <span class="k">if</span> <span class="n">batch_sort_key</span> <span class="o">==</span> <span class="s2">"input"</span><span class="p">:</span>
            <span class="n">batch_sort_key</span> <span class="o">=</span> <span class="s2">"output"</span>
        <span class="k">elif</span> <span class="n">batch_sort_key</span> <span class="o">==</span> <span class="s2">"output"</span><span class="p">:</span>
            <span class="n">batch_sort_key</span> <span class="o">=</span> <span class="s2">"input"</span>
    <span class="k">elif</span> <span class="n">mt</span><span class="p">:</span>
        <span class="c1"># for MT</span>
        <span class="n">ikey</span> <span class="o">=</span> <span class="s2">"output"</span>
        <span class="n">okey</span> <span class="o">=</span> <span class="s2">"output"</span>
        <span class="n">batch_sort_key</span> <span class="o">=</span> <span class="s2">"output"</span>
        <span class="n">batch_sort_axis</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">iaxis</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">oaxis</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># NOTE: input is json['output'][1] and output is json['output'][0]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ikey</span> <span class="o">=</span> <span class="s2">"input"</span>
        <span class="n">okey</span> <span class="o">=</span> <span class="s2">"output"</span>

    <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="s2">"auto"</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="s2">"seq"</span>
        <span class="k">elif</span> <span class="n">batch_bins</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="s2">"bin"</span>
        <span class="k">elif</span> <span class="n">batch_frames_in</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">batch_frames_out</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">batch_frames_inout</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="s2">"frame"</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cannot detect `count` manually set one of </span><span class="si">{</span><span class="n">BATCH_COUNT_CHOICES</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"count is auto detected as </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">count</span> <span class="o">!=</span> <span class="s2">"seq"</span> <span class="ow">and</span> <span class="n">batch_sort_key</span> <span class="o">==</span> <span class="s2">"shuffle"</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"batch_sort_key=shuffle is only available if batch_count=seq"</span><span class="p">)</span>

    <span class="n">category2data</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Dict[str, dict]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">category2data</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'category'</span><span class="p">),</span> <span class="p">{})[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="n">batches_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List[List[List[Tuple[str, dict]]]]</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">category2data</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">batch_sort_key</span> <span class="o">==</span> <span class="s1">'shuffle'</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batchfy_shuffle</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">shortest_first</span><span class="p">)</span>
            <span class="n">batches_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># sort it by input lengths (long to short)</span>
        <span class="n">sorted_data</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">data</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">batch_sort_key</span><span class="p">][</span><span class="n">batch_sort_axis</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="ow">not</span> <span class="n">shortest_first</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'# utts: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="s2">"seq"</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batchfy_by_seq</span><span class="p">(</span>
                <span class="n">sorted_data</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">max_length_in</span><span class="o">=</span><span class="n">max_length_in</span><span class="p">,</span>
                <span class="n">max_length_out</span><span class="o">=</span><span class="n">max_length_out</span><span class="p">,</span>
                <span class="n">min_batch_size</span><span class="o">=</span><span class="n">min_batch_size</span><span class="p">,</span>
                <span class="n">shortest_first</span><span class="o">=</span><span class="n">shortest_first</span><span class="p">,</span>
                <span class="n">ikey</span><span class="o">=</span><span class="n">ikey</span><span class="p">,</span> <span class="n">iaxis</span><span class="o">=</span><span class="n">iaxis</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="n">okey</span><span class="p">,</span> <span class="n">oaxis</span><span class="o">=</span><span class="n">oaxis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="s2">"bin"</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batchfy_by_bin</span><span class="p">(</span>
                <span class="n">sorted_data</span><span class="p">,</span>
                <span class="n">batch_bins</span><span class="o">=</span><span class="n">batch_bins</span><span class="p">,</span>
                <span class="n">min_batch_size</span><span class="o">=</span><span class="n">min_batch_size</span><span class="p">,</span>
                <span class="n">shortest_first</span><span class="o">=</span><span class="n">shortest_first</span><span class="p">,</span>
                <span class="n">ikey</span><span class="o">=</span><span class="n">ikey</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="n">okey</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="s2">"frame"</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batchfy_by_frame</span><span class="p">(</span>
                <span class="n">sorted_data</span><span class="p">,</span>
                <span class="n">max_frames_in</span><span class="o">=</span><span class="n">batch_frames_in</span><span class="p">,</span>
                <span class="n">max_frames_out</span><span class="o">=</span><span class="n">batch_frames_out</span><span class="p">,</span>
                <span class="n">max_frames_inout</span><span class="o">=</span><span class="n">batch_frames_inout</span><span class="p">,</span>
                <span class="n">min_batch_size</span><span class="o">=</span><span class="n">min_batch_size</span><span class="p">,</span>
                <span class="n">shortest_first</span><span class="o">=</span><span class="n">shortest_first</span><span class="p">,</span>
                <span class="n">ikey</span><span class="o">=</span><span class="n">ikey</span><span class="p">,</span> <span class="n">okey</span><span class="o">=</span><span class="n">okey</span><span class="p">)</span>
        <span class="n">batches_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="n">batches_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Concat list. This way is faster than "sum(batch_list, [])"</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">batches_list</span><span class="p">))</span>

    <span class="c1"># for debugging</span>
    <span class="k">if</span> <span class="n">num_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="p">[:</span><span class="n">num_batches</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'# minibatches: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)))</span>

    <span class="c1"># batch: List[List[Tuple[str, dict]]]</span>
    <span class="k">return</span> <span class="n">batches</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.evaluator">
<code>evaluator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.evaluator" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.evaluator.BaseEvaluator">
<code>BaseEvaluator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.evaluator.BaseEvaluator" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Base Evaluator in ESPnet</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__call__()" id="adviser.tools.espnet_minimal.utils.training.evaluator.BaseEvaluator.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/evaluator.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 9
10
11
12
13
14
15
16
17
18</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># force tensorboard to report evaluation log</span>
            <span class="n">tb_logger</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">get_extension</span><span class="p">(</span><span class="n">TensorboardLogger</span><span class="o">.</span><span class="n">default_name</span><span class="p">)</span>
            <span class="n">tb_logger</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="n">ret</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.iterators">
<code>iterators</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.iterators" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler">
<code>ShufflingEnabler</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>An extension enabling shuffling on an Iterator</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__call__()" id="adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Calls the enabler on the given iterator</p>
<p>:param trainer: The iterator</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>20
21
22
23
24
25
26
27
28</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">):</span>
    <span class="sd">"""Calls the enabler on the given iterator</span>

<span class="sd">    :param trainer: The iterator</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterators</span><span class="p">:</span>
            <span class="n">iterator</span><span class="o">.</span><span class="n">start_shuffle</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.utils.training.iterators.ShufflingEnabler.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterators</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Inits the ShufflingEnabler</p>
<p>:param list[Iterator] iterators: The iterators to enable shuffling on</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterators</span><span class="p">):</span>
    <span class="sd">"""Inits the ShufflingEnabler</span>

<span class="sd">    :param list[Iterator] iterators: The iterators to enable shuffling on</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iterators</span> <span class="o">=</span> <span class="n">iterators</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator">
<code>ToggleableShufflingMultiprocessIterator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>A MultiprocessIterator that can have its shuffling property activated during training</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_processes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_prefetch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shared_mem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxtasksperchild</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Init the iterator</p>
<p>:param torch.nn.Tensor dataset: The dataset to take batches from
:param int batch_size: The batch size
:param bool repeat: Whether to repeat batches or not (enables multiple epochs)
:param bool shuffle: Whether to shuffle the order of the batches
:param int n_processes: How many processes to use
:param int n_prefetch: The number of prefetch to use
:param int shared_mem: How many memory to share between processes
:param int maxtasksperchild: Maximum number of tasks per child</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_processes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_prefetch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shared_mem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">maxtasksperchild</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="sd">"""Init the iterator</span>

<span class="sd">    :param torch.nn.Tensor dataset: The dataset to take batches from</span>
<span class="sd">    :param int batch_size: The batch size</span>
<span class="sd">    :param bool repeat: Whether to repeat batches or not (enables multiple epochs)</span>
<span class="sd">    :param bool shuffle: Whether to shuffle the order of the batches</span>
<span class="sd">    :param int n_processes: How many processes to use</span>
<span class="sd">    :param int n_prefetch: The number of prefetch to use</span>
<span class="sd">    :param int shared_mem: How many memory to share between processes</span>
<span class="sd">    :param int maxtasksperchild: Maximum number of tasks per child</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ToggleableShufflingMultiprocessIterator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                                  <span class="n">repeat</span><span class="o">=</span><span class="n">repeat</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                                                                  <span class="n">n_processes</span><span class="o">=</span><span class="n">n_processes</span><span class="p">,</span>
                                                                  <span class="n">n_prefetch</span><span class="o">=</span><span class="n">n_prefetch</span><span class="p">,</span> <span class="n">shared_mem</span><span class="o">=</span><span class="n">shared_mem</span><span class="p">,</span>
                                                                  <span class="n">maxtasksperchild</span><span class="o">=</span><span class="n">maxtasksperchild</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="start_shuffle()" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingMultiprocessIterator.start_shuffle">
<code class="highlight language-python">
start_shuffle<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Starts shuffling (or reshuffles) the batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>76
77
78
79
80
81
82
83
84</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">start_shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Starts shuffling (or reshuffles) the batches"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">_version</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">order_sampler</span> <span class="o">=</span> <span class="n">ShuffleOrderSampler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">order_sampler</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_set_prefetch_state</span><span class="p">()</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator">
<code>ToggleableShufflingSerialIterator</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>A SerialIterator that can have its shuffling property activated during training</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Init the Iterator</p>
<p>:param torch.nn.Tensor dataset: The dataset to take batches from
:param int batch_size: The batch size
:param bool repeat: Whether to repeat data (allow multiple epochs)
:param bool shuffle: Whether to shuffle the batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>34
35
36
37
38
39
40
41
42</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Init the Iterator</span>

<span class="sd">    :param torch.nn.Tensor dataset: The dataset to take batches from</span>
<span class="sd">    :param int batch_size: The batch size</span>
<span class="sd">    :param bool repeat: Whether to repeat data (allow multiple epochs)</span>
<span class="sd">    :param bool shuffle: Whether to shuffle the batches</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ToggleableShufflingSerialIterator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="start_shuffle()" id="adviser.tools.espnet_minimal.utils.training.iterators.ToggleableShufflingSerialIterator.start_shuffle">
<code class="highlight language-python">
start_shuffle<span class="p">(</span><span class="bp">self</span><span class="p">)</span> </code>
</h7>
<div class="doc doc-contents">
<p>Starts shuffling (or reshuffles) the batches</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/iterators.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>44
45
46
47
48
49
50
51</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">start_shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Starts shuffling (or reshuffles) the batches"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shuffle</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">_version</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">order_sampler</span> <span class="o">=</span> <span class="n">ShuffleOrderSampler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">order_sampler</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.tensorboard_logger">
<code>tensorboard_logger</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger">
<code>TensorboardLogger</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>A tensorboard logger extension</p>
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__call__()" id="adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Updates the events file with the new values</p>
<p>:param trainer: The trainer</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/tensorboard_logger.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">):</span>
    <span class="sd">"""Updates the events file with the new values</span>

<span class="sd">    :param trainer: The trainer</span>
<span class="sd">    """</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">observation</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">observation</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_entries</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entries</span><span class="p">):</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">'cupy'</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)):</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="s1">'cupy'</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">k</span><span class="p">)):</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_att_reporter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">get_iterator</span><span class="p">(</span><span class="s1">'main'</span><span class="p">)</span><span class="o">.</span><span class="n">epoch</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">get_iterator</span><span class="p">(</span><span class="s1">'main'</span><span class="p">)</span><span class="o">.</span><span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_att_reporter</span><span class="o">.</span><span class="n">log_attentions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_logger</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h7 class="doc doc-heading" data-toc-label="__init__()" id="adviser.tools.espnet_minimal.utils.training.tensorboard_logger.TensorboardLogger.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="n">att_reporter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">entries</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h7>
<div class="doc doc-contents">
<p>Init the extension</p>
<p>:param SummaryWriter logger: The logger to use
:param PlotAttentionReporter att_reporter: The (optional) PlotAttentionReporter
:param entries: The entries to watch
:param int epoch: The starting epoch</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/tensorboard_logger.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 9
10
11
12
13
14
15
16
17
18
19
20</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="n">att_reporter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">entries</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">"""Init the extension</span>

<span class="sd">    :param SummaryWriter logger: The logger to use</span>
<span class="sd">    :param PlotAttentionReporter att_reporter: The (optional) PlotAttentionReporter</span>
<span class="sd">    :param entries: The entries to watch</span>
<span class="sd">    :param int epoch: The starting epoch</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_entries</span> <span class="o">=</span> <span class="n">entries</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_att_reporter</span> <span class="o">=</span> <span class="n">att_reporter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_logger</span> <span class="o">=</span> <span class="n">logger</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h5 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.train_utils">
<code>train_utils</code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.train_utils" title="Permanent link">¶</a></h5>
<div class="doc doc-contents">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.train_utils.check_early_stop">
<code class="highlight language-python">
check_early_stop<span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.train_utils.check_early_stop" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Checks if the training was stopped by an early stopping trigger and warns the user if it's the case</p>
<p>:param trainer: The trainer used for training
:param epochs: The maximum number of epochs</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/train_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 6
 7
 8
 9
10
11
12
13
14
15</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">check_early_stop</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="sd">"""Checks if the training was stopped by an early stopping trigger and warns the user if it's the case</span>

<span class="sd">    :param trainer: The trainer used for training</span>
<span class="sd">    :param epochs: The maximum number of epochs</span>
<span class="sd">    """</span>
    <span class="n">end_epoch</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">get_iterator</span><span class="p">(</span><span class="s1">'main'</span><span class="p">)</span><span class="o">.</span><span class="n">epoch</span>
    <span class="k">if</span> <span class="n">end_epoch</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Hit early stop at epoch "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
            <span class="n">end_epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">You can change the patience or set it to 0 to run all epochs"</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h6 class="doc doc-heading" id="adviser.tools.espnet_minimal.utils.training.train_utils.set_early_stop">
<code class="highlight language-python">
set_early_stop<span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#adviser.tools.espnet_minimal.utils.training.train_utils.set_early_stop" title="Permanent link">¶</a></h6>
<div class="doc doc-contents">
<p>Sets the early stop trigger given the program arguments</p>
<p>:param trainer: The trainer used for training
:param args: The program arguments
:param is_lm: If the trainer is for a LM (epoch instead of epochs)</p>
<details class="quote">
<summary>Source code in <code>adviser/tools/espnet_minimal/utils/training/train_utils.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">set_early_stop</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">"""Sets the early stop trigger given the program arguments</span>

<span class="sd">    :param trainer: The trainer used for training</span>
<span class="sd">    :param args: The program arguments</span>
<span class="sd">    :param is_lm: If the trainer is for a LM (epoch instead of epochs)</span>
<span class="sd">    """</span>
    <span class="n">patience</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">patience</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">early_stop_criterion</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epoch</span> <span class="k">if</span> <span class="n">is_lm</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s1">'max'</span> <span class="k">if</span> <span class="s1">'acc'</span> <span class="ow">in</span> <span class="n">criterion</span> <span class="k">else</span> <span class="s1">'min'</span>
    <span class="k">if</span> <span class="n">patience</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">stop_trigger</span> <span class="o">=</span> <span class="n">chainer</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">triggers</span><span class="o">.</span><span class="n">EarlyStoppingTrigger</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
                                                                              <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
                                                                              <span class="n">patients</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
                                                                              <span class="n">max_trigger</span><span class="o">=</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="s1">'epoch'</span><span class="p">))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav aria-label="Footer" class="md-footer-nav__inner md-grid">
<a class="md-footer-nav__link md-footer-nav__link--prev" href="../utils/" rel="prev" title="Utils">
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Utils
              </div>
</div>
</a>
<a class="md-footer-nav__link md-footer-nav__link--next" href="../../tutorials/introduction/" rel="next" title="Introduction">
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                Introduction
              </div>
</div>
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
          Material for MkDocs
        </a>
</div>
</div>
</div>
</footer>
</div>
<script src="../../assets/javascripts/vendor.83fe6e3c.min.js"></script>
<script src="../../assets/javascripts/bundle.7e1cb91c.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
<script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.37585f48.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
</body>
</html>