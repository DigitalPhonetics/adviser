{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Introduction We present ADVISER - an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision) and socially-engaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The Python based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research. Guiding Principles Modularity In contrast to a traditional (rather static) pipeline approach which adheres to a fixed order of information flow, Adviser is implemented in an asynchronous way, using the publish-subscribe software pattern. This allows for parallel information flow which facilitates the combination of multiple modalities as well as the integration of additional modules. For each module in a classic dialog system (NLU, BST, dialog policy and NLG), we provide a handcrafted baseline module, additionally we provide a reinforcement learning based implementation for the policy. These can be used to quickly assemble a working dialog system or as implementation guidelines for custom modules. Additionally, because all modules inherit from the same abstract class, technical users can also easily write their own implementations or combinations of modules. Flexibility The publish-subscribe pattern allows great flexibility in terms of structure and scope of the dialog system. Users can easily realize anything from a simple text-based pipeline system to a full-fledged multimodal, multi-domain dialog system. Further, distributed systems are possible. Services are location-transparent and may thus be distributed across multiple machines. The central dialog system discovers local and remote services and provides synchronization guarantees for dialog initialization and termination. This is useful for resource-heavy tasks such as speech synthesis. Transparency We provide a utility to draw the dialog graph, showing the information flow between services and any inconsistencies in publish/subscribe connections. Todo Graphen einf\u00fcgen? User-friendly at different levels technical users have the full flexibility to explore and extend the back-end; non-technical users can use the provided code base for building systems; students from different disciplines could easily learn the concepts and explore human machine interaction. Support You can ask questions by sending emails to adviser-support@ims.uni-stuttgart.de . You can also post bug reports and feature requests in GitHub issues. How To Cite If you use or reimplement any of this source code, please cite the following paper: Todo Update reference @InProceedings { title = {ADVISER: A Toolkit for DevelopingMulti-modal,Multi-domainandSocially-engagedConversational Agents } , author = {Daniel Ortega and Dirk V{\\\"{a}}th and Gianna Weber and Lindsey Vanderlyn and Maximilian Schmidt and Moritz V{\\\"{o}}lkel and Zorica Karacevic and Ngoc Thang Vu}, booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019) - System Demonstrations}, publisher = {Association for Computational Linguistics}, location = {Seattle, Washington, USA}, year = {2020} } License Adviser is published under the GNU GPL 3 license.","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#introduction","text":"We present ADVISER - an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision) and socially-engaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The Python based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.","title":"Introduction"},{"location":"#guiding-principles","text":"","title":"Guiding Principles"},{"location":"#modularity","text":"In contrast to a traditional (rather static) pipeline approach which adheres to a fixed order of information flow, Adviser is implemented in an asynchronous way, using the publish-subscribe software pattern. This allows for parallel information flow which facilitates the combination of multiple modalities as well as the integration of additional modules. For each module in a classic dialog system (NLU, BST, dialog policy and NLG), we provide a handcrafted baseline module, additionally we provide a reinforcement learning based implementation for the policy. These can be used to quickly assemble a working dialog system or as implementation guidelines for custom modules. Additionally, because all modules inherit from the same abstract class, technical users can also easily write their own implementations or combinations of modules.","title":"Modularity"},{"location":"#flexibility","text":"The publish-subscribe pattern allows great flexibility in terms of structure and scope of the dialog system. Users can easily realize anything from a simple text-based pipeline system to a full-fledged multimodal, multi-domain dialog system. Further, distributed systems are possible. Services are location-transparent and may thus be distributed across multiple machines. The central dialog system discovers local and remote services and provides synchronization guarantees for dialog initialization and termination. This is useful for resource-heavy tasks such as speech synthesis.","title":"Flexibility"},{"location":"#transparency","text":"We provide a utility to draw the dialog graph, showing the information flow between services and any inconsistencies in publish/subscribe connections. Todo Graphen einf\u00fcgen?","title":"Transparency"},{"location":"#user-friendly-at-different-levels","text":"technical users have the full flexibility to explore and extend the back-end; non-technical users can use the provided code base for building systems; students from different disciplines could easily learn the concepts and explore human machine interaction.","title":"User-friendly at different levels"},{"location":"#support","text":"You can ask questions by sending emails to adviser-support@ims.uni-stuttgart.de . You can also post bug reports and feature requests in GitHub issues.","title":"Support"},{"location":"#how-to-cite","text":"If you use or reimplement any of this source code, please cite the following paper: Todo Update reference @InProceedings { title = {ADVISER: A Toolkit for DevelopingMulti-modal,Multi-domainandSocially-engagedConversational Agents } , author = {Daniel Ortega and Dirk V{\\\"{a}}th and Gianna Weber and Lindsey Vanderlyn and Maximilian Schmidt and Moritz V{\\\"{o}}lkel and Zorica Karacevic and Ngoc Thang Vu}, booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019) - System Demonstrations}, publisher = {Association for Computational Linguistics}, location = {Seattle, Washington, USA}, year = {2020} }","title":"How To Cite"},{"location":"#license","text":"Adviser is published under the GNU GPL 3 license.","title":"License"},{"location":"faq/","text":"FAQ Todo Add missing members Daniel Ortega Dirk V\u00e4th Gianna Weber Lindsey Vanderlyn Maximilian Schmidt Moritz V\u00f6lkel Zorica Kacarevic Ngoc Thang Vu How shall I cite ADvISER Todo Add links Please see here. Who can I contact in case of problems or questions? You can ask questions by sending emails to adviser-support@ims.uni-stuttgart.de You can also post bug reports and feature requests (only) in GitHub issues. Make sure to read our guidelines first. Can I contribute to the project? Todo Add links You can post bug reports and feature requests in GitHub issues. You can find the code to ADvISER in our Git repository. Information about the download can be found here. Todo Update/Add image _images/sds.png Which User Actions and System Actions are currently supported by the system? User Actions Inform : User informs the system about a constraint/entity name NegativeInform : User informs the system they do not want a particular value Request : User asks the system for information about an entity Hello : User issues a greeting Bye : User says bye; this ends the dialog Thanks : User says thanks Affirm : User agrees with the last system confirm request Deny : User disagrees with the last system confirm request RequestAlternatives : User asks for an alternative offer from the system Ack : User likes the system's proposed offer Bad : User input could not be recognized SelectDomain : User has provided a domain keyword System Actions Welcome : Issue system greeting InformByName : Propose an entity to the user InformByAlternatives : Propose an alternate entity if the user isn't satisfied with the first Request : Ask for more information from the user Confirm : Ask the user to confirm a proposed value for a slot Select : Provide the user with 2 or 3 options and ask the user to select the correct one RequestMore : Ask the user if there is anything else the system can provide Bad : If the system could not understand the user Bye : Say goodbye What Emotions and Engagements are currently supported by the system? User Emotions happy angry neutral User Engagement high low Todo Update domains ADvISER currently supports the following domains: IMS Lecturers Providing information about lecturers teaching at the IMS (for privacy reasons, our database includes fictive information about lecturers and related contact information, however, it serves as an example for a real-world application). IMS Courses Providing information about courses offered at the IMS, e.g. course content, requirements, or locational information. Todo Add link Please see here.","title":"FAQ"},{"location":"faq/#faq","text":"Todo Add missing members Daniel Ortega Dirk V\u00e4th Gianna Weber Lindsey Vanderlyn Maximilian Schmidt Moritz V\u00f6lkel Zorica Kacarevic Ngoc Thang Vu","title":"FAQ"},{"location":"faq/#how-shall-i-cite-adviser","text":"Todo Add links Please see here. Who can I contact in case of problems or questions? You can ask questions by sending emails to adviser-support@ims.uni-stuttgart.de You can also post bug reports and feature requests (only) in GitHub issues. Make sure to read our guidelines first.","title":"How shall I cite ADvISER"},{"location":"faq/#can-i-contribute-to-the-project","text":"Todo Add links You can post bug reports and feature requests in GitHub issues. You can find the code to ADvISER in our Git repository. Information about the download can be found here. Todo Update/Add image _images/sds.png","title":"Can I contribute to the project?"},{"location":"faq/#which-user-actions-and-system-actions-are-currently-supported-by-the-system","text":"","title":"Which User Actions and System Actions are currently supported by the system?"},{"location":"faq/#user-actions","text":"Inform : User informs the system about a constraint/entity name NegativeInform : User informs the system they do not want a particular value Request : User asks the system for information about an entity Hello : User issues a greeting Bye : User says bye; this ends the dialog Thanks : User says thanks Affirm : User agrees with the last system confirm request Deny : User disagrees with the last system confirm request RequestAlternatives : User asks for an alternative offer from the system Ack : User likes the system's proposed offer Bad : User input could not be recognized SelectDomain : User has provided a domain keyword","title":"User Actions"},{"location":"faq/#system-actions","text":"Welcome : Issue system greeting InformByName : Propose an entity to the user InformByAlternatives : Propose an alternate entity if the user isn't satisfied with the first Request : Ask for more information from the user Confirm : Ask the user to confirm a proposed value for a slot Select : Provide the user with 2 or 3 options and ask the user to select the correct one RequestMore : Ask the user if there is anything else the system can provide Bad : If the system could not understand the user Bye : Say goodbye","title":"System Actions"},{"location":"faq/#what-emotions-and-engagements-are-currently-supported-by-the-system","text":"","title":"What Emotions and Engagements are currently supported by the system?"},{"location":"faq/#user-emotions","text":"happy angry neutral","title":"User Emotions"},{"location":"faq/#user-engagement","text":"high low Todo Update domains ADvISER currently supports the following domains: IMS Lecturers Providing information about lecturers teaching at the IMS (for privacy reasons, our database includes fictive information about lecturers and related contact information, however, it serves as an example for a real-world application). IMS Courses Providing information about courses offered at the IMS, e.g. course content, requirements, or locational information. Todo Add link Please see here.","title":"User Engagement"},{"location":"getting-started/","text":"Getting Started Installing the Adviser Toolkit Get the code and follow the install instructions. Testing Your Installation Open a terminal Activate your virtual environment for Adviser (as created in the install instructions) Navigate to the adviser folder containing the run_chat.py file Execute python run_chat.py mensa This will start a new dialog with a domain about the food plan of the University of Stuttgart's dining hall Try chatting with the system e.g. type something like What's the vegetarian main dish today In case you encounter any errors, try to make sure your setup is correct. If the problem persists, feel free to write an email to support , providing the full stack trace and, if possible, the dialog turn history. Creating and Running Your Own Dialog System To setup your own text-based dialog system (in this example, for a domain about lecturer information from the IMS Institute at the Unviersity of Stuttgart), it's as simple as creating a new file in the 'adviser' folder (where the run_chat.py file is located), naming it e.g. mydiasys.py , and adding the following content: import sys import os from typing import List from utils.domain.jsonlookupdomain import JSONLookupDomain from services.service import Service , PublishSubscribe , DialogSystem from services.domain_tracker import DomainTracker from services.nlu.nlu import HandcraftedNLU from services.nlg.nlg import HandcraftedNLG from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.hci import ConsoleInput , ConsoleOutput from utils.logger import DiasysLogger , LogLevel # create modules lecturers_domain = JSONLookupDomain ( 'ImsLecturers' ) nlu = HandcraftedNLU ( domain = lecturers_domain ) bst = HandcraftedBST ( domain = lecturers_domain ) policy = HandcraftedPolicy ( domain = lecturers_domain ) nlg = HandcraftedNLG ( domain = lecturers_domain ) d_tracker = DomainTracker ( domains = [ lecturers_domain ]) # Input modules (just allow access to terminal for text based dialog) user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" ) logger = DiasysLogger ( console_log_lvl = LogLevel . DIALOGS ) ds = DialogSystem ( services = [ d_tracker , user_in , user_out , nlu , bst , policy , nlg ], debug_logger = logger ) error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_inconsistencies () ds . draw_system_graph ( name = \"testgraph\" ) # start dialog for _ in range ( 1 ): ds . run_dialog ({ 'gen_user_utterance' : \"\" }) ds . shutdown () To run this code, execute python mydiasys.py . You can try e.g. utterances like I want information about a Digital Phoentics lecturer and continue the dialog from there.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#installing-the-adviser-toolkit","text":"Get the code and follow the install instructions.","title":"Installing the Adviser Toolkit"},{"location":"getting-started/#testing-your-installation","text":"Open a terminal Activate your virtual environment for Adviser (as created in the install instructions) Navigate to the adviser folder containing the run_chat.py file Execute python run_chat.py mensa This will start a new dialog with a domain about the food plan of the University of Stuttgart's dining hall Try chatting with the system e.g. type something like What's the vegetarian main dish today In case you encounter any errors, try to make sure your setup is correct. If the problem persists, feel free to write an email to support , providing the full stack trace and, if possible, the dialog turn history.","title":"Testing Your Installation"},{"location":"getting-started/#creating-and-running-your-own-dialog-system","text":"To setup your own text-based dialog system (in this example, for a domain about lecturer information from the IMS Institute at the Unviersity of Stuttgart), it's as simple as creating a new file in the 'adviser' folder (where the run_chat.py file is located), naming it e.g. mydiasys.py , and adding the following content: import sys import os from typing import List from utils.domain.jsonlookupdomain import JSONLookupDomain from services.service import Service , PublishSubscribe , DialogSystem from services.domain_tracker import DomainTracker from services.nlu.nlu import HandcraftedNLU from services.nlg.nlg import HandcraftedNLG from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.hci import ConsoleInput , ConsoleOutput from utils.logger import DiasysLogger , LogLevel # create modules lecturers_domain = JSONLookupDomain ( 'ImsLecturers' ) nlu = HandcraftedNLU ( domain = lecturers_domain ) bst = HandcraftedBST ( domain = lecturers_domain ) policy = HandcraftedPolicy ( domain = lecturers_domain ) nlg = HandcraftedNLG ( domain = lecturers_domain ) d_tracker = DomainTracker ( domains = [ lecturers_domain ]) # Input modules (just allow access to terminal for text based dialog) user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" ) logger = DiasysLogger ( console_log_lvl = LogLevel . DIALOGS ) ds = DialogSystem ( services = [ d_tracker , user_in , user_out , nlu , bst , policy , nlg ], debug_logger = logger ) error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_inconsistencies () ds . draw_system_graph ( name = \"testgraph\" ) # start dialog for _ in range ( 1 ): ds . run_dialog ({ 'gen_user_utterance' : \"\" }) ds . shutdown () To run this code, execute python mydiasys.py . You can try e.g. utterances like I want information about a Digital Phoentics lecturer and continue the dialog from there.","title":"Creating and Running Your Own Dialog System"},{"location":"api/examples/","text":"Examples adviser.examples special Modules adviser.examples.qa special Modules adviser.examples.qa.worldknowledge special Modules adviser.examples.qa.worldknowledge.domain Classes adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain Question answering domain for the world knowledge domain. !!! attributes artificial_id_counter (int): pseudo identifier for each entry name_lex (Dict[str->str]): lexicon for matching topic's names to their KG entity Methods adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.__init__ ( self ) special Calls super class' constructor and loads name lexicon Source code in adviser/examples/qa/worldknowledge/domain.py 38 39 40 41 42 def __init__ ( self ): \"\"\"Calls super class' constructor and loads name lexicon\"\"\" LookupDomain . __init__ ( self , 'CSQA' , 'World Knowledge' ) self . artificial_id_counter = 1 self . name_lex = self . _init_name_lexicon () adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f1659292fd0 > ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required Source code in adviser/examples/qa/worldknowledge/domain.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints \"\"\" assert 'relation' in constraints assert 'topic' in constraints assert 'direction' in constraints topics = self . _find_topic_entities ( constraints [ 'topic' ]) if not topics : return [] answers = [] for topic_id , topic_label in topics : answer_ids = [] if constraints [ 'direction' ] == 'out' : answer_ids = self . _perform_out_query ( constraints [ 'relation' ], topic_id ) for answer_id in answer_ids : answers . append ({ 'subject' : topic_label , 'predicate' : constraints [ 'relation' ], 'object' : answer_id }) self . artificial_id_counter += 1 else : answer_ids = self . _perform_in_query ( constraints [ 'relation' ], topic_id ) for answer_id in answer_ids : answers . append ({ 'subject' : answer_id , 'predicate' : constraints [ 'relation' ], 'object' : topic_label }) self . artificial_id_counter += 1 return answers adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/qa/worldknowledge/domain.py 126 127 128 129 130 131 132 133 134 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" raise BaseException ( 'should not be called' ) adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_domain_name ( self ) Return the domain name of the current ontology. Returns: Type Description object Source code in adviser/examples/qa/worldknowledge/domain.py 136 137 def get_domain_name ( self ): return \"qa\" adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/examples/qa/worldknowledge/domain.py 147 148 149 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'relation' , 'topic' , 'direction' ] adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_mandatory_slots ( self ) Returns a list of all mandatory slots. Source code in adviser/examples/qa/worldknowledge/domain.py 151 152 153 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'relation' , 'topic' , 'direction' ] adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/qa/worldknowledge/domain.py 155 156 157 158 159 160 161 162 163 164 165 166 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" # 'assert False, \"this method should not be called\"' raise BaseException ( 'should not be called' ) adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_primary_key ( self ) Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/qa/worldknowledge/domain.py 168 169 170 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id' adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/examples/qa/worldknowledge/domain.py 139 140 141 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'subject' , 'predicate' , 'object' , 'object_type' ] adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/examples/qa/worldknowledge/domain.py 143 144 145 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'relation' , 'topic' , 'direction' ] adviser.examples.qa.worldknowledge.multinlg Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.examples.qa.worldknowledge.multinlg.MultiNLG Extension of the handcrafted NLG by allowing multiple system acts. This change is necessary for QA, since the policy publishes multiple system acts. adviser.examples.qa.worldknowledge.neuralmodels special Modules adviser.examples.qa.worldknowledge.neuralmodels.director Classes adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier Neural network for predicting the relation's direction (outgoing or incoming). The model uses a question encoder to classify the question as one of the two classes \"outgoing\" or \"incoming\" . !!! attributes hidden_dim ( int ): Size of the Bi_LSTM 's hidden layer out_dim (int): Size of the output layer (here: 2) diminisher (nn.Module): Fine-tuning embedding layer, good for reducing Bi-LSTM' s size lstm ( nn . Module ): Bi - LSTM for encoding a question hidden2tag ( nn . Module ): Output layer Methods adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier.__init__ ( self , emb_dim , lstm_out_dim , num_classes ) special Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required lstm_out_dim int Output size of the Bi-LSTM required num_classes int Size of the output layer (in this context, always 2) required Source code in adviser/examples/qa/worldknowledge/neuralmodels/director.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , emb_dim : int , lstm_out_dim : int , num_classes : int ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer lstm_out_dim: Output size of the Bi-LSTM num_classes: Size of the output layer (in this context, always 2) \"\"\" super ( Classifier , self ) . __init__ () self . hidden_dim = lstm_out_dim self . out_dim = num_classes self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm = nn . LSTM ( emb_dim , lstm_out_dim , bidirectional = True ) self . hidden2tag = nn . Linear ( lstm_out_dim * 2 , self . out_dim ) adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier.forward ( self , embeds ) Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities of the two classes \"incoming\" and \"outgoing\" Source code in adviser/examples/qa/worldknowledge/neuralmodels/director.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities of the two classes \"incoming\" and \"outgoing\" \"\"\" embeds = self . diminisher ( embeds ) lstm_out , _ = self . lstm ( embeds ) tag_space = self . hidden2tag ( lstm_out [ 0 ]) tag_scores = F . log_softmax ( tag_space , dim = 1 ) return tag_scores adviser.examples.qa.worldknowledge.neuralmodels.simpledot Classes adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot Neural network for predicting the relation of a question. The simple dot approach compares a question with each possible relation candidate by taking the ( simple ) dot product between the encoded question and every encoded relation . !!! attributes softmax ( bool ): whether or not the scores should be converted to probabilities hidden ( int ): size of the hidden layer relations_tensor ( torch . autograd . Variable ): embeddings for all relation descriptions diminisher ( nn . Module ): Fine - tuning embedding layer , good for reducing Bi - LSTMs ' size lstm_question ( nn . Module ): Bi - LSTM for encoding a question lstm_relation ( nn . Module ): Bi - LSTM for encoding a relation Methods adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot.__init__ ( self , emb_dim , hidden_dim , softmax = True ) special Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required hidden_dim int Output size of the Bi-LSTM required softmax bool Whether or not a softmax is applied on the output layer True Source code in adviser/examples/qa/worldknowledge/neuralmodels/simpledot.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , emb_dim : int , hidden_dim : int , softmax : bool = True ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer hidden_dim: Output size of the Bi-LSTM softmax: Whether or not a softmax is applied on the output layer \"\"\" super ( SimpleDot , self ) . __init__ () self . softmax = softmax self . hidden = hidden_dim self . relations_tensor = self . _initialise_relations_tensor () self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm_question = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True ) self . lstm_relation = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True ) adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot.forward ( self , embeds ) Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities for the relation classes Source code in adviser/examples/qa/worldknowledge/neuralmodels/simpledot.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities for the relation classes \"\"\" embeds = self . diminisher ( embeds ) relations_embeds = self . diminisher ( self . relations_tensor ) question_out , _ = self . lstm_question ( embeds ) # T_Q x B x H relation_out , _ = self . lstm_relation ( relations_embeds ) # T_R x R x H last_question_out = question_out [ 0 ][:, self . hidden :] # B x H last_relation_out = relation_out [ 0 ][:, self . hidden :] # R x H # relation prediction matrix = last_relation_out . repeat ( last_question_out . size ( 0 ), 1 , 1 ) # B x R x H vector = last_question_out rel_scores = torch . bmm ( matrix , vector . unsqueeze ( 2 )) . squeeze () if self . softmax : rel_scores = F . log_softmax ( rel_scores , dim = 1 ) return rel_scores adviser.examples.qa.worldknowledge.neuralmodels.tagger Classes adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger Neural network for predicting the topic entities. The model uses a question encoder and classifies each token using the BIO tag set . !!! attributes hidden_dim ( int ): Size of the Bi_LSTM 's hidden layer diminisher (nn.Module): Fine-tuning embedding layer, good for reducing Bi-LSTM' s size lstm ( nn . Module ): Bi - LSTM hidden2label ( nn . Module ): Output layer Methods adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger.__init__ ( self , emb_dim , hidden_dim ) special Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required hidden_dim int Hidden layer size of the Bi-LSTM required Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , emb_dim : int , hidden_dim : int ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer hidden_dim: Hidden layer size of the Bi-LSTM \"\"\" super ( Tagger , self ) . __init__ () self . hidden_dim = hidden_dim self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True ) self . hidden2label = nn . Linear ( hidden_dim * 2 , len ( TAGS )) adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger.forward ( self , embeds ) Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities of each BIO tag for all tokens Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities of each BIO tag for all tokens \"\"\" embeds = self . diminisher ( embeds ) lstm_out , _ = self . lstm ( embeds ) label_space = self . hidden2label ( lstm_out [ 1 :]) label_scores = F . log_softmax ( label_space , dim = 2 ) return label_scores Functions adviser.examples.qa.worldknowledge.neuralmodels.tagger.extract_entities ( tokens , tag_idxs ) Extracts entities using the predicted BIO tags for each token Parameters: Name Type Description Default tokens List[str] question's tokens required tag_idxs List[int] index of the BIO tag for each token in the question required Returns: Type Description List[List[str]] List of entities, i.e. list of connected tokens Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def extract_entities ( tokens : List [ str ], tag_idxs : List [ int ]) -> List [ List [ str ]]: \"\"\"Extracts entities using the predicted BIO tags for each token Arguments: tokens: question's tokens tag_idxs: index of the BIO tag for each token in the question Returns: List of entities, i.e. list of connected tokens \"\"\" entities = [] curr_entity = [] tags = [ TAGS [ tag_idx ] for tag_idx in tag_idxs ] for i , ( token , tag ) in enumerate ( zip ( tokens , tags )): if tag == 'I' : curr_entity . append ( token ) continue else : if curr_entity : entities . append ( curr_entity ) curr_entity = [] if tag == 'B' : curr_entity . append ( token ) if curr_entity : entities . append ( curr_entity ) return entities adviser.examples.qa.worldknowledge.policyqa Classes adviser.examples.qa.worldknowledge.policyqa.QaPolicy Policy module for question answering. Provides a simple rule - based policy for question answering . The QA module assumes that the user acts contain information about relation , topic entities and relation direction . Adequate answers are looked up in the knowledge and published . The difference to the default HandcraftedPolicy is that no BST is needed and that multiple system acts can be published . adviser.examples.qa.worldknowledge.semanticparser Classes adviser.examples.qa.worldknowledge.semanticparser.QuestionParser Semantic parsing module for question answering !!! attributes device ( torch . device ) : PyTorch device object , either CPU or GPU nn_relation ( nn . Module ) : neural network for relation prediction nn_entity ( nn . Module ) : neural network for topic entity prediction nn_direction ( nn . Module ) : neural network for relation direction prediction tags ( List [ str ] ) : relation tags max_seq_len ( int ) : maximum number of tokens per question embedding_creator ( BertEmbedding ) : object creating BERT embeddings Methods adviser.examples.qa.worldknowledge.semanticparser.QuestionParser.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > , device = 'cpu' ) special Creates neural networks for semantic parsing and other required utils Parameters: Name Type Description Default domain LookupDomain the QA domain required logger DiasysLogger the logger <DiasysLogger adviser (NOTSET)> device str PyTorch device name 'cpu' Source code in adviser/examples/qa/worldknowledge/semanticparser.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def __init__ ( self , domain : LookupDomain , \\ logger : DiasysLogger = DiasysLogger (), device : str = 'cpu' ): \"\"\"Creates neural networks for semantic parsing and other required utils Args: domain: the QA domain logger: the logger device: PyTorch device name \"\"\" Service . __init__ ( self , domain = domain , debug_logger = logger ) self . device = torch . device ( device ) self . nn_relation = self . _load_relation_model () self . nn_entity = self . _load_entity_model () self . nn_direction = self . _load_direction_model () self . tags = self . _load_tag_set () self . max_seq_len = 40 self . embedding_creator = BertEmbedding ( max_seq_length = self . max_seq_len ) adviser.examples.webapi special Modules adviser.examples.webapi.mensa special Modules adviser.examples.webapi.mensa.domain Classes adviser.examples.webapi.mensa.domain.MensaDomain Domain for the Mensa API !!! attributes parser ( MensaParser ) : HTML file parser for dynamically building a pseudo database last_results ( List [ dict ] ) : Current results which the user might request info about Methods adviser.examples.webapi.mensa.domain.MensaDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15ce013450 > ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15ce013450> Source code in adviser/examples/webapi/mensa/domain.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" if 'day' in constraints : meals = self . parser . get_meals ( constraints [ 'day' ]) results = [ meal . as_dict () for meal in meals ] for slot in constraints : if slot == 'day' : continue results = [ candidate for candidate in results if candidate [ slot ] == constraints [ slot ]] for i , result in enumerate ( results ): result [ 'artificial_id' ] = i + 1 if list ( requested_slots ): cleaned_results = [{ slot : result_dict [ slot ] for slot in requested_slots } for result_dict in results ] else : cleaned_results = results self . last_results = results return cleaned_results else : return [] adviser.examples.webapi.mensa.domain.MensaDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/webapi/mensa/domain.py 75 76 77 78 79 80 81 82 83 84 85 def find_info_about_entity ( self , entity_id : str , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" result = { slot : self . last_results [ int ( entity_id ) - 1 ][ slot ] for slot in requested_slots } result [ 'artificial_id' ] = entity_id return [ result ] adviser.examples.webapi.mensa.domain.MensaDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/examples/webapi/mensa/domain.py 95 96 97 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'day' , 'type' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ] adviser.examples.webapi.mensa.domain.MensaDomain.get_mandatory_slots ( self ) Returns a list of all mandatory slots. Source code in adviser/examples/webapi/mensa/domain.py 99 100 101 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'day' ] adviser.examples.webapi.mensa.domain.MensaDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/webapi/mensa/domain.py 103 104 105 106 107 108 109 110 111 112 113 114 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" assert slot in SLOT_VALUES return SLOT_VALUES [ slot ] adviser.examples.webapi.mensa.domain.MensaDomain.get_primary_key ( self ) Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/webapi/mensa/domain.py 116 117 118 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id' adviser.examples.webapi.mensa.domain.MensaDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/examples/webapi/mensa/domain.py 87 88 89 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'name' , 'type' , 'price' , 'allergens' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ] adviser.examples.webapi.mensa.domain.MensaDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/examples/webapi/mensa/domain.py 91 92 93 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'day' , 'type' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ] adviser.examples.webapi.mensa.nlu Classes adviser.examples.webapi.mensa.nlu.MensaNLU Adapted handcrafted NLU for the mensa domain. The default handcrafted NLU is adapted to automatically add the user act request(name). This is necessary because the name is not the primary key, i.e. it is not printed by default once an element is found. To force the Policy to automatically inform about the name, too, a request for the name is added in each turn. adviser.examples.webapi.mensa.parser Classes adviser.examples.webapi.mensa.parser.Allergen This enum provides the allergens used in the mensa menu. adviser.examples.webapi.mensa.parser.DishType This enum provides the dish types used in the mensa menu. Methods adviser.examples.webapi.mensa.parser.DishType.from_website_name ( website_name ) staticmethod Converts the type as listed on the website into the type used in the dialog system. Parameters: Name Type Description Default website_name str The name as used in the response to the POST request. required Returns: Type Description DishType The corresponding enum member. Source code in adviser/examples/webapi/mensa/parser.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @staticmethod def from_website_name ( website_name : str ) -> 'DishType' : \"\"\"Converts the type as listed on the website into the type used in the dialog system. Args: website_name: The name as used in the response to the POST request. Returns: The corresponding enum member. \"\"\" if website_name == 'STARTER' : return DishType . Starter elif website_name == 'BUFFET' : return DishType . Buffet elif website_name == 'MAIN DISH' : return DishType . MainDish elif website_name == 'SIDE DISH' : return DishType . SideDish elif website_name == 'DESSERT' : return DishType . Dessert adviser.examples.webapi.mensa.parser.Location This enum provides the possible mensa locations. adviser.examples.webapi.mensa.parser.Meal Methods adviser.examples.webapi.mensa.parser.Meal.__init__ ( self , name , day , prices , price_quantity , allergens , vegan , vegetarian , fish , pork , dish_type ) special The class for a meal consisting of a name and several properties (slot-value pairs). Parameters: Name Type Description Default name str The name of the meal. required day str The day on which the meal is offered. required prices Tuple[float] The price for students and guests. required price_quantity str The unit for which the price is valid. required allergens List[adviser.examples.webapi.mensa.parser.Allergen] The allergens of this meal. required vegan bool Whether the meal is vegan or not. required vegetarian bool Whether the meal is vegetarian or not. required fish bool Whether the meal contains fish or not. required pork bool Whether the meal contains pork or not. required dish_type DishType The type of the dish. (Starter, Buffet, Main Dish, Side Dish or Buffet) required Source code in adviser/examples/webapi/mensa/parser.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __init__ ( self , name : str , day : str , prices : Tuple [ float ], price_quantity : str , \\ allergens : List [ Allergen ], vegan : bool , vegetarian : bool , fish : bool , pork : bool , \\ dish_type : DishType ): \"\"\"The class for a meal consisting of a name and several properties (slot-value pairs). Args: name: The name of the meal. day: The day on which the meal is offered. prices: The price for students and guests. price_quantity: The unit for which the price is valid. allergens: The allergens of this meal. vegan: Whether the meal is vegan or not. vegetarian: Whether the meal is vegetarian or not. fish: Whether the meal contains fish or not. pork: Whether the meal contains pork or not. dish_type: The type of the dish. (Starter, Buffet, Main Dish, Side Dish or Buffet) \"\"\" self . name = name self . day = day self . prices = prices self . price_quantity = price_quantity self . allergens = allergens self . vegan = vegan self . vegetarian = vegetarian self . fish = fish self . pork = pork self . dish_type = dish_type adviser.examples.webapi.mensa.parser.Meal.__repr__ ( self ) special The string representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 162 163 164 165 def __repr__ ( self ) -> str : \"\"\"The string representation of the meal.\"\"\" return str ( self ) adviser.examples.webapi.mensa.parser.Meal.__str__ ( self ) special The string representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 154 155 156 157 158 159 160 def __str__ ( self ) -> str : \"\"\"The string representation of the meal.\"\"\" return ( f \"Meal(name= { self . name } , day= { self . day } , prices= { self . prices } , \\ price_quantity= { self . price_quantity } , \" f \"allergens= { self . allergens } , vegan= { self . vegan } , vegetarian= { self . vegetarian } , \" f \"fish= { self . fish } , pork= { self . pork } , dish_type= { self . dish_type } )\" ) adviser.examples.webapi.mensa.parser.Meal.as_dict ( self ) A dict representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def as_dict ( self ) -> Dict [ str , str ]: \"\"\"A dict representation of the meal.\"\"\" return { 'name' : self . name , 'day' : self . day , 'type' : self . dish_type . value , 'price' : str ( self . prices [ 0 ]), 'allergens' : ', ' . join ([ allergen . value for allergen in self . allergens ]) if \\ self . allergens is not None else 'none' , 'vegan' : str ( self . vegan ) . lower (), 'vegetarian' : str ( self . vegetarian ) . lower (), 'fish' : str ( self . fish ) . lower (), 'pork' : str ( self . pork ) . lower () } adviser.examples.webapi.mensa.parser.MensaParser Methods adviser.examples.webapi.mensa.parser.MensaParser.__init__ ( self , cache = True ) special The class to issue post requests and parse the response. Will also take care of caching the parser's results. Parameters: Name Type Description Default cache bool Whether to cache results or not. True Source code in adviser/examples/webapi/mensa/parser.py 169 170 171 172 173 174 175 176 177 178 179 180 181 def __init__ ( self , cache : bool = True ): \"\"\" The class to issue post requests and parse the response. Will also take care of caching the parser's results. Args: cache (bool): Whether to cache results or not. \"\"\" #: dict of str: storgae to cache parsed meals self . storage = {} self . cache = cache adviser.examples.webapi.mensa.parser.MensaParser.get_meals ( self , date , use_cache = True ) Gets the meals for a specified day by either looking them up in the cache or by issuing and parsing a post request . Args : date ( str ): The date for which the data will be returned . Can be a string in the format 'Y-m-d' or one of today , tomorrow and monday - sunday . use_cache ( bool ): If False will always query the server instead of using the cache . Returns: Type Description List[adviser.examples.webapi.mensa.parser.Meal] :obj: list of Meal: List of meals for specified date Source code in adviser/examples/webapi/mensa/parser.py 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 def get_meals ( self , date : str , use_cache : bool = True ) -> List [ Meal ]: \"\"\" Gets the meals for a specified day by either looking them up in the cache or by issuing and parsing a post request. Args: date (str): The date for which the data will be returned. Can be a string in the format 'Y-m-d' or one of today, tomorrow and monday-sunday. use_cache (bool): If False will always query the server instead of using the cache. Returns: :obj:`list` of Meal: List of meals for specified date \"\"\" date = self . _parse_date ( date ) if use_cache and date . date () in self . storage : # NOTE data could be deprecated return self . storage [ date . date ()] else : # issue request to server return self . _parse ( date ) adviser.examples.webapi.mensa.parser.ParseDateError This exception is raised when the date cannot be parsed. adviser.examples.webapi.weather special Modules adviser.examples.webapi.weather.domain Classes adviser.examples.webapi.weather.domain.WeatherDomain Domain for the Weather API. !!! attributes last_results ( List [ dict ] ) : Current results which the user might request info about Methods adviser.examples.webapi.weather.domain.WeatherDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15cd589c90 > ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15cd589c90> Source code in adviser/examples/webapi/weather/domain.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" if 'location' in constraints and 'date' in constraints : forecast = self . _query ( constraints [ 'location' ], constraints [ 'date' ]) if forecast is None : return [] temperature = int ( ' %.0f ' % ( float ( forecast [ 'main' ][ 'temp' ]) - 273.15 )) description = forecast [ 'weather' ][ 0 ][ 'description' ] result_dict = { 'artificial_id' : str ( len ( self . last_results )), 'temperature' : temperature , 'description' : description , 'location' : constraints [ 'location' ], 'date' : constraints [ 'date' ], } if any ( True for _ in requested_slots ): cleaned_result_dict = { slot : result_dict [ slot ] for slot in requested_slots } else : cleaned_result_dict = result_dict self . last_results . append ( cleaned_result_dict ) return [ cleaned_result_dict ] else : return [] adviser.examples.webapi.weather.domain.WeatherDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/webapi/weather/domain.py 76 77 78 79 80 81 82 83 84 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" return [ self . last_results [ int ( entity_id )]] adviser.examples.webapi.weather.domain.WeatherDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/examples/webapi/weather/domain.py 94 95 96 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'location' , 'date' ] adviser.examples.webapi.weather.domain.WeatherDomain.get_mandatory_slots ( self ) Returns a list of all mandatory slots. Source code in adviser/examples/webapi/weather/domain.py 98 99 100 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'location' , 'date' ] adviser.examples.webapi.weather.domain.WeatherDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/webapi/weather/domain.py 102 103 104 105 106 107 108 109 110 111 112 113 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" raise BaseException ( 'all slots in this domain do not have a fixed set of ' 'values, so this method should never be called' ) adviser.examples.webapi.weather.domain.WeatherDomain.get_primary_key ( self ) Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/webapi/weather/domain.py 115 116 117 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id' adviser.examples.webapi.weather.domain.WeatherDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/examples/webapi/weather/domain.py 86 87 88 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'temperature' , 'description' ] adviser.examples.webapi.weather.domain.WeatherDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/examples/webapi/weather/domain.py 90 91 92 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'location' , 'date' ] adviser.examples.webapi.weather.nlg Classes adviser.examples.webapi.weather.nlg.WeatherNLG Simple NLG for the weather domain adviser.examples.webapi.weather.nlu Classes adviser.examples.webapi.weather.nlu.WeatherNLU Very simple NLU for the weather domain.","title":"Examples"},{"location":"api/examples/#examples","text":"","title":"Examples"},{"location":"api/examples/#adviser.examples","text":"","title":"examples"},{"location":"api/examples/#modules","text":"","title":"Modules"},{"location":"api/examples/#adviser.examples.qa","text":"","title":"qa"},{"location":"api/examples/#modules_1","text":"","title":"Modules"},{"location":"api/examples/#adviser.examples.qa.worldknowledge","text":"Modules adviser.examples.qa.worldknowledge.domain Classes adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain Question answering domain for the world knowledge domain. !!! attributes artificial_id_counter (int): pseudo identifier for each entry name_lex (Dict[str->str]): lexicon for matching topic's names to their KG entity","title":"worldknowledge"},{"location":"api/examples/#methods","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.__init__","text":"Calls super class' constructor and loads name lexicon Source code in adviser/examples/qa/worldknowledge/domain.py 38 39 40 41 42 def __init__ ( self ): \"\"\"Calls super class' constructor and loads name lexicon\"\"\" LookupDomain . __init__ ( self , 'CSQA' , 'World Knowledge' ) self . artificial_id_counter = 1 self . name_lex = self . _init_name_lexicon ()","title":"__init__()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.find_entities","text":"Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required Source code in adviser/examples/qa/worldknowledge/domain.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints \"\"\" assert 'relation' in constraints assert 'topic' in constraints assert 'direction' in constraints topics = self . _find_topic_entities ( constraints [ 'topic' ]) if not topics : return [] answers = [] for topic_id , topic_label in topics : answer_ids = [] if constraints [ 'direction' ] == 'out' : answer_ids = self . _perform_out_query ( constraints [ 'relation' ], topic_id ) for answer_id in answer_ids : answers . append ({ 'subject' : topic_label , 'predicate' : constraints [ 'relation' ], 'object' : answer_id }) self . artificial_id_counter += 1 else : answer_ids = self . _perform_in_query ( constraints [ 'relation' ], topic_id ) for answer_id in answer_ids : answers . append ({ 'subject' : answer_id , 'predicate' : constraints [ 'relation' ], 'object' : topic_label }) self . artificial_id_counter += 1 return answers","title":"find_entities()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.find_info_about_entity","text":"Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/qa/worldknowledge/domain.py 126 127 128 129 130 131 132 133 134 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" raise BaseException ( 'should not be called' )","title":"find_info_about_entity()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_domain_name","text":"Return the domain name of the current ontology. Returns: Type Description object Source code in adviser/examples/qa/worldknowledge/domain.py 136 137 def get_domain_name ( self ): return \"qa\"","title":"get_domain_name()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_informable_slots","text":"Returns a list of all informable slots. Source code in adviser/examples/qa/worldknowledge/domain.py 147 148 149 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'relation' , 'topic' , 'direction' ]","title":"get_informable_slots()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_mandatory_slots","text":"Returns a list of all mandatory slots. Source code in adviser/examples/qa/worldknowledge/domain.py 151 152 153 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'relation' , 'topic' , 'direction' ]","title":"get_mandatory_slots()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_possible_values","text":"Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/qa/worldknowledge/domain.py 155 156 157 158 159 160 161 162 163 164 165 166 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" # 'assert False, \"this method should not be called\"' raise BaseException ( 'should not be called' )","title":"get_possible_values()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_primary_key","text":"Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/qa/worldknowledge/domain.py 168 169 170 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id'","title":"get_primary_key()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_requestable_slots","text":"Returns a list of all slots requestable by the user. Source code in adviser/examples/qa/worldknowledge/domain.py 139 140 141 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'subject' , 'predicate' , 'object' , 'object_type' ]","title":"get_requestable_slots()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.domain.WorldKnowledgeDomain.get_system_requestable_slots","text":"Returns a list of all slots requestable by the system. Source code in adviser/examples/qa/worldknowledge/domain.py 143 144 145 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'relation' , 'topic' , 'direction' ] adviser.examples.qa.worldknowledge.multinlg Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.examples.qa.worldknowledge.multinlg.MultiNLG Extension of the handcrafted NLG by allowing multiple system acts. This change is necessary for QA, since the policy publishes multiple system acts. adviser.examples.qa.worldknowledge.neuralmodels special Modules adviser.examples.qa.worldknowledge.neuralmodels.director","title":"get_system_requestable_slots()"},{"location":"api/examples/#classes","text":"","title":"Classes"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier","text":"Neural network for predicting the relation's direction (outgoing or incoming). The model uses a question encoder to classify the question as one of the two classes \"outgoing\" or \"incoming\" . !!! attributes hidden_dim ( int ): Size of the Bi_LSTM 's hidden layer out_dim (int): Size of the output layer (here: 2) diminisher (nn.Module): Fine-tuning embedding layer, good for reducing Bi-LSTM' s size lstm ( nn . Module ): Bi - LSTM for encoding a question hidden2tag ( nn . Module ): Output layer","title":"Classifier"},{"location":"api/examples/#methods_1","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier.__init__","text":"Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required lstm_out_dim int Output size of the Bi-LSTM required num_classes int Size of the output layer (in this context, always 2) required Source code in adviser/examples/qa/worldknowledge/neuralmodels/director.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , emb_dim : int , lstm_out_dim : int , num_classes : int ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer lstm_out_dim: Output size of the Bi-LSTM num_classes: Size of the output layer (in this context, always 2) \"\"\" super ( Classifier , self ) . __init__ () self . hidden_dim = lstm_out_dim self . out_dim = num_classes self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm = nn . LSTM ( emb_dim , lstm_out_dim , bidirectional = True ) self . hidden2tag = nn . Linear ( lstm_out_dim * 2 , self . out_dim )","title":"__init__()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.director.Classifier.forward","text":"Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities of the two classes \"incoming\" and \"outgoing\" Source code in adviser/examples/qa/worldknowledge/neuralmodels/director.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities of the two classes \"incoming\" and \"outgoing\" \"\"\" embeds = self . diminisher ( embeds ) lstm_out , _ = self . lstm ( embeds ) tag_space = self . hidden2tag ( lstm_out [ 0 ]) tag_scores = F . log_softmax ( tag_space , dim = 1 ) return tag_scores adviser.examples.qa.worldknowledge.neuralmodels.simpledot","title":"forward()"},{"location":"api/examples/#classes_1","text":"","title":"Classes"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot","text":"Neural network for predicting the relation of a question. The simple dot approach compares a question with each possible relation candidate by taking the ( simple ) dot product between the encoded question and every encoded relation . !!! attributes softmax ( bool ): whether or not the scores should be converted to probabilities hidden ( int ): size of the hidden layer relations_tensor ( torch . autograd . Variable ): embeddings for all relation descriptions diminisher ( nn . Module ): Fine - tuning embedding layer , good for reducing Bi - LSTMs ' size lstm_question ( nn . Module ): Bi - LSTM for encoding a question lstm_relation ( nn . Module ): Bi - LSTM for encoding a relation","title":"SimpleDot"},{"location":"api/examples/#methods_2","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot.__init__","text":"Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required hidden_dim int Output size of the Bi-LSTM required softmax bool Whether or not a softmax is applied on the output layer True Source code in adviser/examples/qa/worldknowledge/neuralmodels/simpledot.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , emb_dim : int , hidden_dim : int , softmax : bool = True ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer hidden_dim: Output size of the Bi-LSTM softmax: Whether or not a softmax is applied on the output layer \"\"\" super ( SimpleDot , self ) . __init__ () self . softmax = softmax self . hidden = hidden_dim self . relations_tensor = self . _initialise_relations_tensor () self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm_question = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True ) self . lstm_relation = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True )","title":"__init__()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.simpledot.SimpleDot.forward","text":"Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities for the relation classes Source code in adviser/examples/qa/worldknowledge/neuralmodels/simpledot.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities for the relation classes \"\"\" embeds = self . diminisher ( embeds ) relations_embeds = self . diminisher ( self . relations_tensor ) question_out , _ = self . lstm_question ( embeds ) # T_Q x B x H relation_out , _ = self . lstm_relation ( relations_embeds ) # T_R x R x H last_question_out = question_out [ 0 ][:, self . hidden :] # B x H last_relation_out = relation_out [ 0 ][:, self . hidden :] # R x H # relation prediction matrix = last_relation_out . repeat ( last_question_out . size ( 0 ), 1 , 1 ) # B x R x H vector = last_question_out rel_scores = torch . bmm ( matrix , vector . unsqueeze ( 2 )) . squeeze () if self . softmax : rel_scores = F . log_softmax ( rel_scores , dim = 1 ) return rel_scores adviser.examples.qa.worldknowledge.neuralmodels.tagger","title":"forward()"},{"location":"api/examples/#classes_2","text":"","title":"Classes"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger","text":"Neural network for predicting the topic entities. The model uses a question encoder and classifies each token using the BIO tag set . !!! attributes hidden_dim ( int ): Size of the Bi_LSTM 's hidden layer diminisher (nn.Module): Fine-tuning embedding layer, good for reducing Bi-LSTM' s size lstm ( nn . Module ): Bi - LSTM hidden2label ( nn . Module ): Output layer","title":"Tagger"},{"location":"api/examples/#methods_3","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger.__init__","text":"Initialises all required elements of the neural network. Parameters: Name Type Description Default emb_dim int Output size of the fine-tuning embedding layer required hidden_dim int Hidden layer size of the Bi-LSTM required Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , emb_dim : int , hidden_dim : int ): \"\"\"Initialises all required elements of the neural network. Args: emb_dim: Output size of the fine-tuning embedding layer hidden_dim: Hidden layer size of the Bi-LSTM \"\"\" super ( Tagger , self ) . __init__ () self . hidden_dim = hidden_dim self . diminisher = nn . Linear ( 768 , emb_dim ) self . lstm = nn . LSTM ( emb_dim , hidden_dim , bidirectional = True ) self . hidden2label = nn . Linear ( hidden_dim * 2 , len ( TAGS ))","title":"__init__()"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.tagger.Tagger.forward","text":"Application of the neural network on a given input question. Parameters: Name Type Description Default embeds Tensor Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| required Returns: Type Description Tensor Probabilities of each BIO tag for all tokens Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def forward ( self , embeds : torch . Tensor ) -> torch . Tensor : \"\"\"Application of the neural network on a given input question. Args: embeds: Tensor containing the embeddings of shape |Token| x |Batch| x |Embedding Size| Returns: Probabilities of each BIO tag for all tokens \"\"\" embeds = self . diminisher ( embeds ) lstm_out , _ = self . lstm ( embeds ) label_space = self . hidden2label ( lstm_out [ 1 :]) label_scores = F . log_softmax ( label_space , dim = 2 ) return label_scores","title":"forward()"},{"location":"api/examples/#functions","text":"","title":"Functions"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.neuralmodels.tagger.extract_entities","text":"Extracts entities using the predicted BIO tags for each token Parameters: Name Type Description Default tokens List[str] question's tokens required tag_idxs List[int] index of the BIO tag for each token in the question required Returns: Type Description List[List[str]] List of entities, i.e. list of connected tokens Source code in adviser/examples/qa/worldknowledge/neuralmodels/tagger.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def extract_entities ( tokens : List [ str ], tag_idxs : List [ int ]) -> List [ List [ str ]]: \"\"\"Extracts entities using the predicted BIO tags for each token Arguments: tokens: question's tokens tag_idxs: index of the BIO tag for each token in the question Returns: List of entities, i.e. list of connected tokens \"\"\" entities = [] curr_entity = [] tags = [ TAGS [ tag_idx ] for tag_idx in tag_idxs ] for i , ( token , tag ) in enumerate ( zip ( tokens , tags )): if tag == 'I' : curr_entity . append ( token ) continue else : if curr_entity : entities . append ( curr_entity ) curr_entity = [] if tag == 'B' : curr_entity . append ( token ) if curr_entity : entities . append ( curr_entity ) return entities adviser.examples.qa.worldknowledge.policyqa Classes adviser.examples.qa.worldknowledge.policyqa.QaPolicy Policy module for question answering. Provides a simple rule - based policy for question answering . The QA module assumes that the user acts contain information about relation , topic entities and relation direction . Adequate answers are looked up in the knowledge and published . The difference to the default HandcraftedPolicy is that no BST is needed and that multiple system acts can be published . adviser.examples.qa.worldknowledge.semanticparser Classes adviser.examples.qa.worldknowledge.semanticparser.QuestionParser Semantic parsing module for question answering !!! attributes device ( torch . device ) : PyTorch device object , either CPU or GPU nn_relation ( nn . Module ) : neural network for relation prediction nn_entity ( nn . Module ) : neural network for topic entity prediction nn_direction ( nn . Module ) : neural network for relation direction prediction tags ( List [ str ] ) : relation tags max_seq_len ( int ) : maximum number of tokens per question embedding_creator ( BertEmbedding ) : object creating BERT embeddings","title":"extract_entities()"},{"location":"api/examples/#methods_4","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.qa.worldknowledge.semanticparser.QuestionParser.__init__","text":"Creates neural networks for semantic parsing and other required utils Parameters: Name Type Description Default domain LookupDomain the QA domain required logger DiasysLogger the logger <DiasysLogger adviser (NOTSET)> device str PyTorch device name 'cpu' Source code in adviser/examples/qa/worldknowledge/semanticparser.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def __init__ ( self , domain : LookupDomain , \\ logger : DiasysLogger = DiasysLogger (), device : str = 'cpu' ): \"\"\"Creates neural networks for semantic parsing and other required utils Args: domain: the QA domain logger: the logger device: PyTorch device name \"\"\" Service . __init__ ( self , domain = domain , debug_logger = logger ) self . device = torch . device ( device ) self . nn_relation = self . _load_relation_model () self . nn_entity = self . _load_entity_model () self . nn_direction = self . _load_direction_model () self . tags = self . _load_tag_set () self . max_seq_len = 40 self . embedding_creator = BertEmbedding ( max_seq_length = self . max_seq_len )","title":"__init__()"},{"location":"api/examples/#adviser.examples.webapi","text":"","title":"webapi"},{"location":"api/examples/#modules_2","text":"","title":"Modules"},{"location":"api/examples/#adviser.examples.webapi.mensa","text":"Modules adviser.examples.webapi.mensa.domain Classes adviser.examples.webapi.mensa.domain.MensaDomain Domain for the Mensa API !!! attributes parser ( MensaParser ) : HTML file parser for dynamically building a pseudo database last_results ( List [ dict ] ) : Current results which the user might request info about","title":"mensa"},{"location":"api/examples/#methods_5","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.find_entities","text":"Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15ce013450> Source code in adviser/examples/webapi/mensa/domain.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" if 'day' in constraints : meals = self . parser . get_meals ( constraints [ 'day' ]) results = [ meal . as_dict () for meal in meals ] for slot in constraints : if slot == 'day' : continue results = [ candidate for candidate in results if candidate [ slot ] == constraints [ slot ]] for i , result in enumerate ( results ): result [ 'artificial_id' ] = i + 1 if list ( requested_slots ): cleaned_results = [{ slot : result_dict [ slot ] for slot in requested_slots } for result_dict in results ] else : cleaned_results = results self . last_results = results return cleaned_results else : return []","title":"find_entities()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.find_info_about_entity","text":"Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/webapi/mensa/domain.py 75 76 77 78 79 80 81 82 83 84 85 def find_info_about_entity ( self , entity_id : str , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" result = { slot : self . last_results [ int ( entity_id ) - 1 ][ slot ] for slot in requested_slots } result [ 'artificial_id' ] = entity_id return [ result ]","title":"find_info_about_entity()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_informable_slots","text":"Returns a list of all informable slots. Source code in adviser/examples/webapi/mensa/domain.py 95 96 97 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'day' , 'type' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ]","title":"get_informable_slots()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_mandatory_slots","text":"Returns a list of all mandatory slots. Source code in adviser/examples/webapi/mensa/domain.py 99 100 101 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'day' ]","title":"get_mandatory_slots()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_possible_values","text":"Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/webapi/mensa/domain.py 103 104 105 106 107 108 109 110 111 112 113 114 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" assert slot in SLOT_VALUES return SLOT_VALUES [ slot ]","title":"get_possible_values()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_primary_key","text":"Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/webapi/mensa/domain.py 116 117 118 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id'","title":"get_primary_key()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_requestable_slots","text":"Returns a list of all slots requestable by the user. Source code in adviser/examples/webapi/mensa/domain.py 87 88 89 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'name' , 'type' , 'price' , 'allergens' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ]","title":"get_requestable_slots()"},{"location":"api/examples/#adviser.examples.webapi.mensa.domain.MensaDomain.get_system_requestable_slots","text":"Returns a list of all slots requestable by the system. Source code in adviser/examples/webapi/mensa/domain.py 91 92 93 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'day' , 'type' , 'vegan' , 'vegetarian' , 'fish' , 'pork' ] adviser.examples.webapi.mensa.nlu Classes adviser.examples.webapi.mensa.nlu.MensaNLU Adapted handcrafted NLU for the mensa domain. The default handcrafted NLU is adapted to automatically add the user act request(name). This is necessary because the name is not the primary key, i.e. it is not printed by default once an element is found. To force the Policy to automatically inform about the name, too, a request for the name is added in each turn. adviser.examples.webapi.mensa.parser Classes adviser.examples.webapi.mensa.parser.Allergen This enum provides the allergens used in the mensa menu. adviser.examples.webapi.mensa.parser.DishType This enum provides the dish types used in the mensa menu.","title":"get_system_requestable_slots()"},{"location":"api/examples/#methods_6","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.DishType.from_website_name","text":"Converts the type as listed on the website into the type used in the dialog system. Parameters: Name Type Description Default website_name str The name as used in the response to the POST request. required Returns: Type Description DishType The corresponding enum member. Source code in adviser/examples/webapi/mensa/parser.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @staticmethod def from_website_name ( website_name : str ) -> 'DishType' : \"\"\"Converts the type as listed on the website into the type used in the dialog system. Args: website_name: The name as used in the response to the POST request. Returns: The corresponding enum member. \"\"\" if website_name == 'STARTER' : return DishType . Starter elif website_name == 'BUFFET' : return DishType . Buffet elif website_name == 'MAIN DISH' : return DishType . MainDish elif website_name == 'SIDE DISH' : return DishType . SideDish elif website_name == 'DESSERT' : return DishType . Dessert adviser.examples.webapi.mensa.parser.Location This enum provides the possible mensa locations. adviser.examples.webapi.mensa.parser.Meal","title":"from_website_name()"},{"location":"api/examples/#methods_7","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.Meal.__init__","text":"The class for a meal consisting of a name and several properties (slot-value pairs). Parameters: Name Type Description Default name str The name of the meal. required day str The day on which the meal is offered. required prices Tuple[float] The price for students and guests. required price_quantity str The unit for which the price is valid. required allergens List[adviser.examples.webapi.mensa.parser.Allergen] The allergens of this meal. required vegan bool Whether the meal is vegan or not. required vegetarian bool Whether the meal is vegetarian or not. required fish bool Whether the meal contains fish or not. required pork bool Whether the meal contains pork or not. required dish_type DishType The type of the dish. (Starter, Buffet, Main Dish, Side Dish or Buffet) required Source code in adviser/examples/webapi/mensa/parser.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __init__ ( self , name : str , day : str , prices : Tuple [ float ], price_quantity : str , \\ allergens : List [ Allergen ], vegan : bool , vegetarian : bool , fish : bool , pork : bool , \\ dish_type : DishType ): \"\"\"The class for a meal consisting of a name and several properties (slot-value pairs). Args: name: The name of the meal. day: The day on which the meal is offered. prices: The price for students and guests. price_quantity: The unit for which the price is valid. allergens: The allergens of this meal. vegan: Whether the meal is vegan or not. vegetarian: Whether the meal is vegetarian or not. fish: Whether the meal contains fish or not. pork: Whether the meal contains pork or not. dish_type: The type of the dish. (Starter, Buffet, Main Dish, Side Dish or Buffet) \"\"\" self . name = name self . day = day self . prices = prices self . price_quantity = price_quantity self . allergens = allergens self . vegan = vegan self . vegetarian = vegetarian self . fish = fish self . pork = pork self . dish_type = dish_type","title":"__init__()"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.Meal.__repr__","text":"The string representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 162 163 164 165 def __repr__ ( self ) -> str : \"\"\"The string representation of the meal.\"\"\" return str ( self )","title":"__repr__()"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.Meal.__str__","text":"The string representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 154 155 156 157 158 159 160 def __str__ ( self ) -> str : \"\"\"The string representation of the meal.\"\"\" return ( f \"Meal(name= { self . name } , day= { self . day } , prices= { self . prices } , \\ price_quantity= { self . price_quantity } , \" f \"allergens= { self . allergens } , vegan= { self . vegan } , vegetarian= { self . vegetarian } , \" f \"fish= { self . fish } , pork= { self . pork } , dish_type= { self . dish_type } )\" )","title":"__str__()"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.Meal.as_dict","text":"A dict representation of the meal. Source code in adviser/examples/webapi/mensa/parser.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def as_dict ( self ) -> Dict [ str , str ]: \"\"\"A dict representation of the meal.\"\"\" return { 'name' : self . name , 'day' : self . day , 'type' : self . dish_type . value , 'price' : str ( self . prices [ 0 ]), 'allergens' : ', ' . join ([ allergen . value for allergen in self . allergens ]) if \\ self . allergens is not None else 'none' , 'vegan' : str ( self . vegan ) . lower (), 'vegetarian' : str ( self . vegetarian ) . lower (), 'fish' : str ( self . fish ) . lower (), 'pork' : str ( self . pork ) . lower () } adviser.examples.webapi.mensa.parser.MensaParser","title":"as_dict()"},{"location":"api/examples/#methods_8","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.MensaParser.__init__","text":"The class to issue post requests and parse the response. Will also take care of caching the parser's results. Parameters: Name Type Description Default cache bool Whether to cache results or not. True Source code in adviser/examples/webapi/mensa/parser.py 169 170 171 172 173 174 175 176 177 178 179 180 181 def __init__ ( self , cache : bool = True ): \"\"\" The class to issue post requests and parse the response. Will also take care of caching the parser's results. Args: cache (bool): Whether to cache results or not. \"\"\" #: dict of str: storgae to cache parsed meals self . storage = {} self . cache = cache","title":"__init__()"},{"location":"api/examples/#adviser.examples.webapi.mensa.parser.MensaParser.get_meals","text":"Gets the meals for a specified day by either looking them up in the cache or by issuing and parsing a post request . Args : date ( str ): The date for which the data will be returned . Can be a string in the format 'Y-m-d' or one of today , tomorrow and monday - sunday . use_cache ( bool ): If False will always query the server instead of using the cache . Returns: Type Description List[adviser.examples.webapi.mensa.parser.Meal] :obj: list of Meal: List of meals for specified date Source code in adviser/examples/webapi/mensa/parser.py 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 def get_meals ( self , date : str , use_cache : bool = True ) -> List [ Meal ]: \"\"\" Gets the meals for a specified day by either looking them up in the cache or by issuing and parsing a post request. Args: date (str): The date for which the data will be returned. Can be a string in the format 'Y-m-d' or one of today, tomorrow and monday-sunday. use_cache (bool): If False will always query the server instead of using the cache. Returns: :obj:`list` of Meal: List of meals for specified date \"\"\" date = self . _parse_date ( date ) if use_cache and date . date () in self . storage : # NOTE data could be deprecated return self . storage [ date . date ()] else : # issue request to server return self . _parse ( date ) adviser.examples.webapi.mensa.parser.ParseDateError This exception is raised when the date cannot be parsed.","title":"get_meals()"},{"location":"api/examples/#adviser.examples.webapi.weather","text":"Modules adviser.examples.webapi.weather.domain Classes adviser.examples.webapi.weather.domain.WeatherDomain Domain for the Weather API. !!! attributes last_results ( List [ dict ] ) : Current results which the user might request info about","title":"weather"},{"location":"api/examples/#methods_9","text":"","title":"Methods"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.find_entities","text":"Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15cd589c90> Source code in adviser/examples/webapi/weather/domain.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" if 'location' in constraints and 'date' in constraints : forecast = self . _query ( constraints [ 'location' ], constraints [ 'date' ]) if forecast is None : return [] temperature = int ( ' %.0f ' % ( float ( forecast [ 'main' ][ 'temp' ]) - 273.15 )) description = forecast [ 'weather' ][ 0 ][ 'description' ] result_dict = { 'artificial_id' : str ( len ( self . last_results )), 'temperature' : temperature , 'description' : description , 'location' : constraints [ 'location' ], 'date' : constraints [ 'date' ], } if any ( True for _ in requested_slots ): cleaned_result_dict = { slot : result_dict [ slot ] for slot in requested_slots } else : cleaned_result_dict = result_dict self . last_results . append ( cleaned_result_dict ) return [ cleaned_result_dict ] else : return []","title":"find_entities()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.find_info_about_entity","text":"Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/examples/webapi/weather/domain.py 76 77 78 79 80 81 82 83 84 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" return [ self . last_results [ int ( entity_id )]]","title":"find_info_about_entity()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_informable_slots","text":"Returns a list of all informable slots. Source code in adviser/examples/webapi/weather/domain.py 94 95 96 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return [ 'location' , 'date' ]","title":"get_informable_slots()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_mandatory_slots","text":"Returns a list of all mandatory slots. Source code in adviser/examples/webapi/weather/domain.py 98 99 100 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" return [ 'location' , 'date' ]","title":"get_mandatory_slots()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_possible_values","text":"Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/examples/webapi/weather/domain.py 102 103 104 105 106 107 108 109 110 111 112 113 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" raise BaseException ( 'all slots in this domain do not have a fixed set of ' 'values, so this method should never be called' )","title":"get_possible_values()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_primary_key","text":"Returns the slot name that will be used as the 'name' of an entry Source code in adviser/examples/webapi/weather/domain.py 115 116 117 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" return 'artificial_id'","title":"get_primary_key()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_requestable_slots","text":"Returns a list of all slots requestable by the user. Source code in adviser/examples/webapi/weather/domain.py 86 87 88 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return [ 'temperature' , 'description' ]","title":"get_requestable_slots()"},{"location":"api/examples/#adviser.examples.webapi.weather.domain.WeatherDomain.get_system_requestable_slots","text":"Returns a list of all slots requestable by the system. Source code in adviser/examples/webapi/weather/domain.py 90 91 92 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return [ 'location' , 'date' ] adviser.examples.webapi.weather.nlg Classes adviser.examples.webapi.weather.nlg.WeatherNLG Simple NLG for the weather domain adviser.examples.webapi.weather.nlu Classes adviser.examples.webapi.weather.nlu.WeatherNLU Very simple NLU for the weather domain.","title":"get_system_requestable_slots()"},{"location":"api/resources/","text":"Resources adviser.resources special","title":"Resources"},{"location":"api/resources/#resources","text":"","title":"Resources"},{"location":"api/resources/#adviser.resources","text":"","title":"resources"},{"location":"api/services/","text":"Services adviser.services special Modules adviser.services.backchannel special Modules adviser.services.backchannel.acoustic_backchanneller Classes adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller AcousticBackchanneller predicts a backchannel given the last user utterance. The model can predict: No backchannel (0), Assessment (1), Continuer (2) The backchannel realization is added in the NLG module. Methods adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller.load_model ( self ) The PyTorch Backchannel model is instantiated and the pretrained parameters are loaded. Source code in adviser/services/backchannel/acoustic_backchanneller.py 48 49 50 51 52 53 54 55 56 def load_model ( self ): \"\"\" The PyTorch Backchannel model is instantiated and the pretrained parameters are loaded. Returns: \"\"\" self . model = PytorchAcousticBackchanneler () self . model . load_state_dict ( torch . load ( self . trained_model_path )) self . model . eval () adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller.split_input_data ( self , mfcc_features ) Preprocess and segmentation of MFCC features of the user's speech. Segmentation is done every 150ms without overlapping. Parameters: Name Type Description Default mfcc_features numpy.array mffcc features of users speech required Returns: Type Description new_data (list) segmented mfcc features Source code in adviser/services/backchannel/acoustic_backchanneller.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def split_input_data ( self , mfcc_features ): \"\"\" Preprocess and segmentation of MFCC features of the user's speech. Segmentation is done every 150ms without overlapping. Args: mfcc_features (numpy.array): mffcc features of users speech Returns: new_data (list): segmented mfcc features \"\"\" input_height = 150 # this stands for 150ms input_length = mfcc_features . shape [ 0 ] zero_shape = list ( mfcc_features . shape ) zero_shape [ 0 ] = input_height ranges = list ( reversed ([ idx for idx in range ( input_length - 1 , 0 , - input_height )])) new_data = [] for r in ranges : if r < input_height : zero_data = np . zeros ( zero_shape ) zero_data [ - r :, :] = mfcc_features [: r , :] new_data . append ( zero_data ) else : new_data . append ( mfcc_features [ r - input_height : r , :]) return ( new_data ) adviser.services.backchannel.PytorchAcousticBackchanneler Classes adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler Class for defining the Deep Backchannel model in PyTorch Methods adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler.__init__ ( self , parameters = [], load_params = False ) special Defines the elements/layers of the neural network as well as loads the pretrained parameters The model is constituted by two parallel CNNs followed by a concatenation, a FFN and a softmax layer. Parameters: Name Type Description Default parameters list list of pre-trained parameters to be used for prediction [] load_params bool Bool to signal if params should be loaded False Source code in adviser/services/backchannel/PytorchAcousticBackchanneler.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , parameters : list = [], load_params : bool = False ): \"\"\" Defines the elements/layers of the neural network as well as loads the pretrained parameters The model is constituted by two parallel CNNs followed by a concatenation, a FFN and a softmax layer. Args: parameters (list): list of pre-trained parameters to be used for prediction load_params (bool): Bool to signal if params should be loaded \"\"\" super ( PytorchAcousticBackchanneler , self ) . __init__ () # First CNN cnn = nn . Conv2d ( in_channels = 1 , out_channels = 16 , kernel_size = ( 11 , 13 ), stride = ( 3 , 1 )) if load_params : weights = np . transpose ( parameters [ 0 ][ 0 ], ( 3 , 2 , 0 , 1 )) cnn . weight = torch . nn . Parameter ( torch . tensor ( weights ) . float ()) cnn . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 0 ][ 1 ]) . float ()) self . cnn1 = nn . Sequential ( cnn , nn . ReLU (), nn . MaxPool2d (( 23 , 1 )) ) # Second CNN cnn = nn . Conv2d ( in_channels = 1 , out_channels = 16 , kernel_size = ( 12 , 13 ), stride = ( 3 , 1 )) if load_params : weights = np . transpose ( parameters [ 1 ][ 0 ], ( 3 , 2 , 0 , 1 )) cnn . weight = torch . nn . Parameter ( torch . tensor ( weights ) . float ()) cnn . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 1 ][ 1 ]) . float ()) self . cnn2 = nn . Sequential ( cnn , nn . ReLU (), nn . MaxPool2d (( 23 , 1 )) ) # Linear layer self . linear1 = nn . Linear ( in_features = 64 , out_features = 100 ) if load_params : self . linear1 . weight = torch . nn . Parameter ( torch . tensor ( parameters [ 2 ][ 0 ] . T ) . float ()) self . linear1 . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 2 ][ 1 ]) . float ()) self . relu = nn . ReLU () self . dropout = nn . Dropout ( 0.5 ) # Softmax self . linear2 = nn . Linear ( in_features = 100 , out_features = 3 ) if load_params : self . linear2 . weight = torch . nn . Parameter ( torch . tensor ( parameters [ 3 ][ 0 ] . T ) . float ()) self . linear2 . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 3 ][ 1 ]) . float ()) self . softmax = nn . Softmax ( dim = 1 ) adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler.forward ( self , feat_inputs ) PyTorch forward method used for training and prediction. It defines the interaction between layers. Parameters: Name Type Description Default feat_inputs numpy array It contains the network's input. required Returns: Type Description out (torch.tensor) Network's output Source code in adviser/services/backchannel/PytorchAcousticBackchanneler.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def forward ( self , feat_inputs ): \"\"\" PyTorch forward method used for training and prediction. It defines the interaction between layers. Args: feat_inputs (numpy array): It contains the network's input. Returns: out (torch.tensor): Network's output \"\"\" feat_inputs = torch . tensor ( feat_inputs ) . float () feat_inputs = feat_inputs . unsqueeze ( 1 ) cnn_1 = self . cnn1 ( feat_inputs ) cnn_1 = cnn_1 . flatten ( 1 ) cnn_2 = self . cnn2 ( feat_inputs ) . flatten ( 1 ) out = torch . cat (( cnn_1 , cnn_2 ), 1 ) out = self . linear1 ( out ) out = self . relu ( out ) out = self . dropout ( out ) out = self . linear2 ( out ) out = self . softmax ( out ) return out adviser.services.bst special Modules adviser.services.bst.bst Classes adviser.services.bst.bst.HandcraftedBST A rule-based approach to belief state tracking. Methods adviser.services.bst.bst.HandcraftedBST.dialog_start ( self ) Restets the belief state so it is ready for a new dialog Returns: Type Description (dict) a dictionary with a single entry where the key is 'beliefstate'and the value is a new BeliefState object Source code in adviser/services/bst/bst.py 69 70 71 72 73 74 75 76 77 78 def dialog_start ( self ): \"\"\" Restets the belief state so it is ready for a new dialog Returns: (dict): a dictionary with a single entry where the key is 'beliefstate'and the value is a new BeliefState object \"\"\" # initialize belief state self . bs = BeliefState ( self . domain ) adviser.services.domain_tracker special Modules adviser.services.domain_tracker.domain_tracker The console module provides ADVISER services for tracking current domain Classes adviser.services.domain_tracker.domain_tracker.DomainTracker Responsible for selecting which domain should be active at a given time. Current implmentation uses keywords to switch domains. Methods adviser.services.domain_tracker.domain_tracker.DomainTracker.dialog_start ( self ) Resets the domain tracker for the start of a new dialog Source code in adviser/services/domain_tracker/domain_tracker.py 40 41 42 43 44 45 def dialog_start ( self ): \"\"\" Resets the domain tracker for the start of a new dialog \"\"\" self . turn = 0 self . current_domain = None adviser.services.domain_tracker.domain_tracker.DomainTracker.domains_to_str ( self ) Method to create the greeting on the first turn, grammatically joins the names of possible domains into a string Returns: Type Description (str) String representing a list of all domain names the system can talk about Source code in adviser/services/domain_tracker/domain_tracker.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def domains_to_str ( self ): \"\"\" Method to create the greeting on the first turn, grammatically joins the names of possible domains into a string Returns: (str): String representing a list of all domain names the system can talk about \"\"\" if len ( self . domains ) == 1 : return self . domains [ 0 ] . get_display_name () elif len ( self . domains ) == 2 : return \" and \" . join ([ d . get_display_name () for d in self . domains ]) else : return \", \" . join ([ d . get_display_name () for d in self . domains ][: - 1 ]) + f \", and { self . domains [ - 1 ] . get_display_name () } \" adviser.services.emotion special Modules adviser.services.emotion.EmotionRecognition Emotion recognition module. Classes adviser.services.emotion.EmotionRecognition.EmotionRecognition Emotion recognition module. This module receives acoustic features, loads pretrained models and outputs predictions of emotional states. It can easily be extended/adapted to use different models and facial features in addition. Methods adviser.services.emotion.EmotionRecognition.EmotionRecognition.__init__ ( self ) special Emotion recognition module. On initialization all necessary models are loaded. Source code in adviser/services/emotion/EmotionRecognition.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self ): \"\"\" Emotion recognition module. On initialization all necessary models are loaded. \"\"\" Service . __init__ ( self ) self . emotion_dir = os . path . dirname ( os . path . abspath ( __file__ )) self . model_path = os . path . abspath ( os . path . join ( self . emotion_dir , \"..\" , \"..\" , \"resources\" , \"models\" , \"emotion\" ) ) def load_args ( emo_representation ): arg_dict = pickle . load ( open ( os . path . join ( self . model_path , f ' { emo_representation } _args.pkl' ), 'rb' ) ) return arg_dict def load_model ( emo_representation , arg_dict ): ARGS = arg_dict [ 'args' ] model = cnn ( kernel_size = ( ARGS . height , arg_dict [ 'D_in' ]), D_out = arg_dict [ 'D_out' ], args = ARGS ) model . load_state_dict ( torch . load ( os . path . join ( self . model_path , f ' { emo_representation } _model_params.pt' ), map_location = torch . device ( 'cpu' ) ) ) model . eval () return model self . emo_representations = [ 'category' , 'arousal' , 'valence' ] self . models = {} self . args = {} for emo_representation in self . emo_representations : self . args [ emo_representation ] = load_args ( emo_representation ) self . models [ emo_representation ] = load_model ( emo_representation , self . args [ emo_representation ] ) self . arousal_mapping = { 0 : 'low' , 1 : 'medium' , 2 : 'high' } self . valence_mapping = { 0 : 'negative' , 1 : 'neutral' , 2 : 'positive' } self . category_mapping = { 0 : EmotionType . Angry , 1 : EmotionType . Happy , 2 : EmotionType . Neutral , 3 : EmotionType . Sad } adviser.services.engagement special Modules adviser.services.engagement.engagement_tracker Classes adviser.services.engagement.engagement_tracker.EngagementTracker Start feature extraction with OpenFace. Requires OpenFace to be installed - instructions can be found in tool/openface.txt Methods adviser.services.engagement.engagement_tracker.EngagementTracker.__init__ ( self , domain = '' , camera_id = 0 , openface_port = 6004 , delay = 2 , identifier = None ) special Parameters: Name Type Description Default camera_id int index of the camera you want to use (if you only have one camera: 0) 0 Source code in adviser/services/engagement/engagement_tracker.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , domain = \"\" , camera_id : int = 0 , openface_port : int = 6004 , delay : int = 2 , identifier = None ): \"\"\" Args: camera_id: index of the camera you want to use (if you only have one camera: 0) \"\"\" Service . __init__ ( self , domain = \"\" , identifier = identifier ) self . camera_id = camera_id self . openface_port = openface_port self . openface_running = False self . threshold = delay # provide number of seconds as parameter, one second = 15 frames ctx = Context . instance () self . openface_endpoint = ctx . socket ( zmq . PAIR ) self . openface_endpoint . bind ( f \"tcp://127.0.0.1: { self . openface_port } \" ) startExtraction = f \" { os . path . join ( get_root_dir (), 'tools/OpenFace/build/bin/FaceLandmarkVidZMQ' ) } -device { self . camera_id } -port 6004\" # todo config open face port self . p_openface = subprocess . Popen ( startExtraction . split (), stdout = subprocess . PIPE ) # start OpenFace self . extracting = False self . extractor_thread = None adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_end ( self ) This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/engagement/engagement_tracker.py 145 146 147 148 149 def dialog_end ( self ): # Set openface to non-publishing mode and wait until it is ready self . openface_endpoint . send ( bytes ( f \"OPENFACE_END\" , encoding = \"ascii\" )) if self . extractor_thread : self . extractor_thread . join () adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_exit ( self ) This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. Source code in adviser/services/engagement/engagement_tracker.py 151 152 153 def dialog_exit ( self ): # close openface process self . p_openface . kill () adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/engagement/engagement_tracker.py 69 70 71 72 73 74 75 76 77 78 79 80 def dialog_start ( self ): # Set openface to publishing mode and wait until it is ready self . openface_endpoint . send ( bytes ( f \"OPENFACE_START\" , encoding = \"ascii\" )) self . extracting = False while not self . extracting : msg = self . openface_endpoint . recv () # receive started signal msg = msg . decode ( \"utf-8\" ) if msg == \"OPENFACE_STARTED\" : print ( \"START EXTRACTION\" ) self . extracting = True self . extractor_thread = Thread ( target = self . publish_gaze_directions ) self . extractor_thread . start () adviser.services.engagement.engagement_tracker.EngagementTracker.publish_gaze_directions ( self ) Meant to be used in a thread. Runs an inifinte loop polling features from OpenFace library, parsing them and extracting engagement features. Calls yield_gaze_direction to publish the polled and processed engagement features. Source code in adviser/services/engagement/engagement_tracker.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def publish_gaze_directions ( self ): \"\"\" Meant to be used in a thread. Runs an inifinte loop polling features from OpenFace library, parsing them and extracting engagement features. Calls `yield_gaze_direction` to publish the polled and processed engagement features. \"\"\" x_coordinates = [] y_coordinates = [] norm = 0.0 # center point of screen; should be close(r) to 0 looking = True while self . extracting : req = self . openface_endpoint . send ( bytes ( f \"OPENFACE_PULL\" , encoding = \"ascii\" )) msg = self . openface_endpoint . recv () try : msg = msg . decode ( \"utf-8\" ) if msg == \"OPENFACE_ENDED\" : self . extracting = False msg_data = json . loads ( msg ) gaze_x = msg_data [ \"gaze\" ][ \"angle\" ][ \"x\" ] gaze_y = msg_data [ \"gaze\" ][ \"angle\" ][ \"y\" ] gaze_x = sqrt ( gaze_x ** 2 ) # gaze_angle_x (left-right movement), square + root is done to yield only positive values gaze_y = sqrt ( gaze_y ** 2 ) # gaze_angle_y (up-down movement) x_coordinates . append ( gaze_x ) y_coordinates . append ( gaze_y ) current = ( len ( x_coordinates )) - 1 if current > self . threshold : previous_x = mean ( x_coordinates [ current - ( self . threshold + 1 ): current ]) # obtain the average of previous frames previous_y = mean ( y_coordinates [ current - ( self . threshold + 1 ): current ]) difference_x = sqrt (( norm - previous_x ) ** 2 ) # compare current frame to average of previous frames difference_y = sqrt (( norm - previous_y ) ** 2 ) # print(difference_x, difference_y) if difference_x < 0.15 and difference_y < 0.15 : # check whether difference between current and previous frames exceeds certain threshold (regulates tolerance/strictness) if looking != True : looking = True self . yield_gaze_direction ( engagement = EngagementType . High , gaze_direction = ( gaze_x , gaze_y )) else : if looking != False : looking = False self . yield_gaze_direction ( engagement = EngagementType . Low , gaze_direction = ( gaze_x , gaze_y )) except : # import traceback # traceback.print_exc() pass adviser.services.hci special Modules adviser.services.hci.console The console module provides ADVISER modules that access the console for input and output. Classes adviser.services.hci.console.ConsoleInput Gets the user utterance from the console. Waits for the built-in input function to return a non-empty text. Methods adviser.services.hci.console.ConsoleInput.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/hci/console.py 48 49 def dialog_start ( self ): self . interaction_count = 0 adviser.services.hci.console.ConsoleOutput Writes the system utterance to the console. adviser.services.hci.gui Classes adviser.services.hci.gui.GUIServer Service for the React-based Web-UI. Run this as a remote service: * run this file seperately, will start the GUI Server * run the dialog system in another python instance, add a RemoteService with identifier GUIServer adviser.services.hci.speech special Modules adviser.services.hci.speech.cleaners This file is derived from https://github.com/keithito/tacotron. Functions adviser.services.hci.speech.cleaners.basic_cleaners ( text ) Basic pipeline that lowercases and collapses whitespace without transliteration. Source code in adviser/services/hci/speech/cleaners.py 208 209 210 211 212 def basic_cleaners ( text ): \"\"\"Basic pipeline that lowercases and collapses whitespace without transliteration.\"\"\" text = lowercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.custom_english_cleaners ( text ) Custom pipeline for English text, including number and abbreviation expansion. Source code in adviser/services/hci/speech/cleaners.py 254 255 256 257 258 259 260 261 262 263 264 265 266 def custom_english_cleaners ( text ): \"\"\"Custom pipeline for English text, including number and abbreviation expansion.\"\"\" text = convert_to_ascii ( text ) text = expand_email ( text ) text = expand_acronym ( text ) text = lowercase ( text ) text = expand_numbers ( text ) text = expand_abbreviations ( text ) text = expand_symbols ( text ) text = remove_unnecessary_symbols ( text ) text = uppercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.english_cleaners ( text ) Pipeline for English text, including number and abbreviation expansion. Source code in adviser/services/hci/speech/cleaners.py 223 224 225 226 227 228 229 230 def english_cleaners ( text ): \"\"\"Pipeline for English text, including number and abbreviation expansion.\"\"\" text = convert_to_ascii ( text ) text = lowercase ( text ) text = expand_numbers ( text ) text = expand_abbreviations ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.expand_abbreviations ( text ) Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 137 138 139 140 141 142 143 144 145 def expand_abbreviations ( text ): \"\"\" Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for regex , replacement in _abbreviations : text = re . sub ( regex , replacement , text ) return text adviser.services.hci.speech.cleaners.expand_acronym ( text ) Preprocesses a text to turn acronyms into forms that the TTS can pronounce properly text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 171 172 173 174 175 176 177 178 179 def expand_acronym ( text ): \"\"\" Preprocesses a text to turn acronyms into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for word , replacement in _acronym : text = re . sub ( word , replacement , text ) return text adviser.services.hci.speech.cleaners.normalize_numbers ( text ) Normalizes numbers in an utterance as preparation for TTS text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def normalize_numbers ( text ): \"\"\" Normalizes numbers in an utterance as preparation for TTS text (string): Text to be preprocessed \"\"\" text = re . sub ( _comma_number_re , _remove_commas , text ) text = re . sub ( _pounds_re , r '\\1 pounds' , text ) text = re . sub ( _dollars_re , _expand_dollars , text ) text = re . sub ( _decimal_number_re , _expand_decimal_point , text ) text = re . sub ( _ordinal_re , _expand_ordinal , text ) text = re . sub ( _ID_number_re , _expand_ID_number , text ) text = re . sub ( _number_re , _expand_number , text ) return text adviser.services.hci.speech.cleaners.transliteration_cleaners ( text ) Pipeline for non-English text that transliterates to ASCII. Source code in adviser/services/hci/speech/cleaners.py 215 216 217 218 219 220 def transliteration_cleaners ( text ): \"\"\"Pipeline for non-English text that transliterates to ASCII.\"\"\" text = convert_to_ascii ( text ) text = lowercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.FeatureExtractor Feature extraction with openSMILE. This module provides a feature extractor which uses the openSMILE toolkit to extract features from raw audio. The user utterance which is represented as a numpy array in-memory needs to be written to a temporary file first, so that openSMILE can read it. Classes adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor SpeechFeatureExtractor calls openSMILE to extract features from audio. Note : openSMILE will be downloaded & compiled to tools / opensmile if not found there . Methods adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.__init__ ( self ) special SpeechFeatureExtractor. The following things are setup on initialization: * directory for temporary audio files * path to openSMILE config files * path to openSMILE executable Source code in adviser/services/hci/speech/FeatureExtractor.py 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self ): \"\"\" SpeechFeatureExtractor. The following things are setup on initialization: * directory for temporary audio files * path to openSMILE config files * path to openSMILE executable \"\"\" Service . __init__ ( self ) self . speech_out_dir = os . path . join ( \"resources\" , \"tmp_audio_and_features\" ) self . cfg_dir = os . path . join ( \"resources\" , \"opensmile_config\" ) self . openSmile_path = get_opensmile_executable_path () adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.extract_wav_file_features ( self , features , new_audio_file ) Extracting acoustic features using openSMILE. Parameters: Name Type Description Default features str path to openSMILE's feature config required new_audio_file str path to audio file required Returns: Type Description numpy.ndarray extracted features for the audio file Source code in adviser/services/hci/speech/FeatureExtractor.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def extract_wav_file_features ( self , features , new_audio_file ): \"\"\"Extracting acoustic features using openSMILE. Args: features (str): path to openSMILE's feature config new_audio_file (str): path to audio file Returns: numpy.ndarray: extracted features for the audio file \"\"\" output_file = new_audio_file + '.csv' config_file = os . path . join ( self . cfg_dir , features + \".conf\" ) f = open ( os . devnull , 'w' ) try : # OpenSMILE command to extract features # SMILExtract -C <configfile> -I <input_file> \u2212O <output_file> command = ' ' . join ([ self . openSmile_path , '-C' , config_file , '-I' , new_audio_file , '-csvoutput' , output_file , '-headercsv' , '0' , '-timestampcsv' , '0' , '-instname' , '0' ]) subprocess . call ( command , stdout = f , stderr = f , shell = True ) return self . preprocess_csv ( output_file ) except OSError as err : print ( command ) print ( \"OS error: {0} \" . format ( err )) adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.preprocess_csv ( self , csv_file ) Get features from csv file and normalize them if necessary. openSMILE feature are written to temporary csv file. This function reads them into a numpy array, removes instance names and could do a normalization step if needed. This is not implemented right now. Parameters: Name Type Description Default csv_file str path to csv file required Returns: Type Description numpy.ndarray raw feature values Source code in adviser/services/hci/speech/FeatureExtractor.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def preprocess_csv ( self , csv_file ): \"\"\"Get features from csv file and normalize them if necessary. openSMILE feature are written to temporary csv file. This function reads them into a numpy array, removes instance names and could do a normalization step if needed. This is not implemented right now. Args: csv_file (str): path to csv file Returns: numpy.ndarray: raw feature values \"\"\" feats = np . genfromtxt ( csv_file , delimiter = ';' ) if len ( feats . shape ) == 1 : # reshape one-dimensional features, e.g. gemaps feats = feats . reshape ( 1 , - 1 ) # take everything except first column which is the instance name feats = feats [:, 1 :] # StandardScaler normalizes feats to zero mean and unit variance # for frame-wise LLDs, it will standardize across frames # for gemaps (or functionals in general), it's not possible to scale # ideal setup: fit StandardScaler on training set across samples # and apply it with .transform() to new samples # scaler = preprocessing.StandardScaler() self . remove_file ( csv_file ) return feats adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.remove_file ( self , file_name ) Remove specified file. Parameters: Name Type Description Default file_name str full path of file which shall be removed required Source code in adviser/services/hci/speech/FeatureExtractor.py 94 95 96 97 98 99 100 101 102 103 104 def remove_file ( self , file_name ): \"\"\" Remove specified file. Args: file_name (str): full path of file which shall be removed \"\"\" try : os . remove ( file_name ) except FileNotFoundError as error : self . logger . error ( error ) raise ( error ) adviser.services.hci.speech.speech_utility Utility for the emotion recognition script that needs the utterance a s file Functions adviser.services.hci.speech.speech_utility.delete_file ( filepath ) Deletes the file at the given path to clean up the audio file once it's not needed anymore. This is why unique filenames are important. filepath (string): path to the file that is to be deleted Source code in adviser/services/hci/speech/speech_utility.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def delete_file ( filepath ): \"\"\" Deletes the file at the given path to clean up the audio file once it's not needed anymore. This is why unique filenames are important. filepath (string): path to the file that is to be deleted \"\"\" if os . path . exists ( filepath ): os . remove ( filepath ) else : print ( \"The file cannot be deleted, as it was not found. \" \"Please check the provided path for errors: \\n {} \" . format ( filepath )) adviser.services.hci.speech.speech_utility.sound_array_to_file ( filepath , sampling_rate , sound_as_array ) Saves the recording of the recorder to a file Turns the audio from the recorder service into a wav file for processing with opensmile c++ scripts filepath (string): full path, including filename and .wav suffix at an arbitrary location. Careful: python takes paths as relative to the main script. The name should be unique, to ensure files don't get mixed up if there are multiple calls in short time and one file might get overwriteen or deleted before it's done being processed. sampling_rate (int): the sampling rate of the audio, as published by the recorder sound_as_array (np.array): the audio in form of an array as published by the recorder Source code in adviser/services/hci/speech/speech_utility.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def sound_array_to_file ( filepath , sampling_rate , sound_as_array ): \"\"\" Saves the recording of the recorder to a file Turns the audio from the recorder service into a wav file for processing with opensmile c++ scripts filepath (string): full path, including filename and .wav suffix at an arbitrary location. Careful: python takes paths as relative to the main script. The name should be unique, to ensure files don't get mixed up if there are multiple calls in short time and one file might get overwriteen or deleted before it's done being processed. sampling_rate (int): the sampling rate of the audio, as published by the recorder sound_as_array (np.array): the audio in form of an array as published by the recorder \"\"\" librosa . output . write_wav ( filepath , sound_as_array , sampling_rate ) adviser.services.hci.speech.SpeechInputDecoder Classes adviser.services.hci.speech.SpeechInputDecoder.SpeechInputDecoder Methods adviser.services.hci.speech.SpeechInputDecoder.SpeechInputDecoder.__init__ ( self , domain = '' , identifier = None , conversation_log_dir = None , use_cuda = False ) special Transforms spoken input from the user to text for further processing. Parameters: Name Type Description Default domain Domain Needed for Service, but has no meaning here '' identifier string Needed for Service None conversation_log_dir str If this is provided, logfiles will be placed by this Service into the specified directory. None use_cuda boolean Whether or not to run the computations on a GPU False Source code in adviser/services/hci/speech/SpeechInputDecoder.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , domain : Domain = \"\" , identifier = None , conversation_log_dir : str = None , use_cuda = False ): \"\"\" Transforms spoken input from the user to text for further processing. Args: domain (Domain): Needed for Service, but has no meaning here identifier (string): Needed for Service conversation_log_dir (string): If this is provided, logfiles will be placed by this Service into the specified directory. use_cuda (boolean): Whether or not to run the computations on a GPU \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir # load model model_dir = os . path . join ( get_root_dir (), \"resources\" , \"models\" , \"speech\" , \"multi_en_20190916\" ) self . model , conf = load_trained_model ( os . path . join ( model_dir , \"model.bin\" )) self . vocab = conf . char_list # setup beam search self . bs = BeamSearch ( scorers = self . model . scorers (), weights = { \"decoder\" : 1.0 , \"ctc\" : 0.0 }, sos = self . model . sos , eos = self . model . eos , beam_size = 4 , vocab_size = len ( self . vocab ), pre_beam_score_key = \"decoder\" ) self . bs . __class__ = BatchBeamSearch # choose hardware to run on if use_cuda : self . device = \"cuda\" else : self . device = \"cpu\" self . model . to ( self . device ) self . bs . to ( self . device ) # change from training mode to eval mode self . model . eval () self . bs . eval () # scale and offset for feature normalization # follows https://github.com/kaldi-asr/kaldi/blob/33255ed224500f55c8387f1e4fa40e08b73ff48a/src/transform/cmvn.cc#L92-L111 norm = torch . load ( os . path . join ( model_dir , \"cmvn.bin\" )) count = norm [ 0 ][ - 1 ] mean = norm [ 0 ][: - 1 ] / count var = ( norm [ 1 ][: - 1 ] / count ) - mean * mean self . scale = 1.0 / torch . sqrt ( var ) self . offset = - ( mean * self . scale ) adviser.services.hci.speech.SpeechInputFeatureExtractor Classes adviser.services.hci.speech.SpeechInputFeatureExtractor.SpeechInputFeatureExtractor Methods adviser.services.hci.speech.SpeechInputFeatureExtractor.SpeechInputFeatureExtractor.__init__ ( self , domain = '' ) special Given a sound, this service extracts features and passes them on to the decoder for ASR Parameters: Name Type Description Default domain Domain Needed for Service, no meaning here '' Source code in adviser/services/hci/speech/SpeechInputFeatureExtractor.py 32 33 34 35 36 37 38 39 def __init__ ( self , domain : Domain = \"\" ): \"\"\" Given a sound, this service extracts features and passes them on to the decoder for ASR Args: domain (Domain): Needed for Service, no meaning here \"\"\" Service . __init__ ( self , domain = domain ) adviser.services.hci.speech.SpeechOutputGenerator Classes adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator Methods adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator.__init__ ( self , domain = '' , identifier = None , use_cuda = False , sub_topic_domains = {}) special Text To Speech Module that reads out the system utterance. Parameters: Name Type Description Default domain Domain Needed for Service, no meaning here '' identifier str Needed for Service None use_cuda boolean Whether or not to perform computations on GPU. Highly recommended if available False sub_topic_domains Dict[str, str] Needed for Service TODO: (<-- is it really or can we get rid of it?) {} Source code in adviser/services/hci/speech/SpeechOutputGenerator.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , domain : Domain = \"\" , identifier : str = None , use_cuda = False , sub_topic_domains : Dict [ str , str ] = {}): \"\"\" Text To Speech Module that reads out the system utterance. Args: domain (Domain): Needed for Service, no meaning here identifier (string): Needed for Service use_cuda (boolean): Whether or not to perform computations on GPU. Highly recommended if available sub_topic_domains: Needed for Service TODO: (<-- is it really or can we get rid of it?) \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier , sub_topic_domains = sub_topic_domains ) self . models_directory = os . path . join ( get_root_dir (), \"resources\" , \"models\" , \"speech\" ) # The following lines can be changed to incorporate different models. # This is the only thing that needs to be changed for that, everything else should be dynamic. self . transcription_type = \"phn\" self . dict_path = os . path . join ( self . models_directory , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"data\" , \"lang_1phn\" , \"train_no_dev_units.txt\" ) self . model_path = os . path . join ( self . models_directory , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"exp\" , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"results\" , \"model.last1.avg.best\" ) self . vocoder_path = os . path . join ( self . models_directory , \"ljspeech.parallel_wavegan.v1\" , \"checkpoint-400000steps.pkl\" ) self . vocoder_conf = os . path . join ( self . models_directory , \"ljspeech.parallel_wavegan.v1\" , \"config.yml\" ) # define device to run the synthesis on if use_cuda : self . device = torch . device ( \"cuda\" ) else : self . device = torch . device ( \"cpu\" ) # define end to end TTS model self . input_dimensions , self . output_dimensions , self . train_args = get_model_conf ( self . model_path ) model_class = dynamic_import . dynamic_import ( self . train_args . model_module ) model = model_class ( self . input_dimensions , self . output_dimensions , self . train_args ) torch_load ( self . model_path , model ) self . model = model . eval () . to ( self . device ) self . inference_args = Namespace ( ** { \"threshold\" : 0.5 , \"minlenratio\" : 0.0 , \"maxlenratio\" : 10.0 }) # define neural vocoder with open ( self . vocoder_conf ) as vocoder_config_file : self . config = yaml . load ( vocoder_config_file , Loader = yaml . Loader ) vocoder = ParallelWaveGANGenerator ( ** self . config [ \"generator_params\" ]) vocoder . load_state_dict ( torch . load ( self . vocoder_path , map_location = \"cpu\" )[ \"model\" ][ \"generator\" ]) vocoder . remove_weight_norm () self . vocoder = vocoder . eval () . to ( self . device ) with open ( self . dict_path ) as dictionary_file : lines = dictionary_file . readlines () lines = [ line . replace ( \" \\n \" , \"\" ) . split ( \" \" ) for line in lines ] self . char_to_id = { c : int ( i ) for c , i in lines } self . g2p = G2p () # download the pretrained Punkt tokenizer from NLTK. This is done only # the first time the code is executed on a machine, if it has been done # before, this line will be skipped and output a warning. We will probably # redirect warnings into a file rather than std_err in the future, since # there's also a lot of pytorch warnings going on etc. nltk . download ( 'punkt' , quiet = True ) adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator.preprocess_text_input ( self , text ) Clean the text and then convert it to id sequence. Parameters: Name Type Description Default text string The text to preprocess required Source code in adviser/services/hci/speech/SpeechOutputGenerator.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def preprocess_text_input ( self , text ): \"\"\" Clean the text and then convert it to id sequence. Args: text (string): The text to preprocess \"\"\" text = custom_english_cleaners ( text ) # cleans the text if self . transcription_type == \"phn\" : # depending on the model type, different preprocessing is needed. text = filter ( lambda s : s != \" \" , self . g2p ( text )) text = \" \" . join ( text ) char_sequence = text . split ( \" \" ) else : char_sequence = list ( text ) id_sequence = [] for c in char_sequence : if c . isspace (): id_sequence += [ self . char_to_id [ \"<space>\" ]] elif c not in self . char_to_id . keys (): id_sequence += [ self . char_to_id [ \"<unk>\" ]] else : id_sequence += [ self . char_to_id [ c ]] id_sequence += [ self . input_dimensions - 1 ] # <eos> return torch . LongTensor ( id_sequence ) . view ( - 1 ) . to ( self . device ) adviser.services.hci.speech.SpeechOutputPlayer Classes adviser.services.hci.speech.SpeechOutputPlayer.SpeechOutputPlayer Methods adviser.services.hci.speech.SpeechOutputPlayer.SpeechOutputPlayer.__init__ ( self , domain = '' , conversation_log_dir = None , identifier = None ) special Service that plays the system utterance as sound Parameters: Name Type Description Default domain Domain Needed for Service, but has no meaning here '' conversation_log_dir str If this is provided it will create log files in the specified directory. None identifier str Needed for Service. None Source code in adviser/services/hci/speech/SpeechOutputPlayer.py 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , domain : Domain = \"\" , conversation_log_dir : str = None , identifier : str = None ): \"\"\" Service that plays the system utterance as sound Args: domain (Domain): Needed for Service, but has no meaning here conversation_log_dir (string): If this is provided it will create log files in the specified directory. identifier (string): Needed for Service. \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir self . interaction_count = 0 adviser.services.hci.speech.SpeechRecorder Classes adviser.services.hci.speech.SpeechRecorder.SpeechRecorder Methods adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.__init__ ( self , domain = '' , conversation_log_dir = None , enable_plotting = False , threshold = 8000 , voice_privacy = False , identifier = None ) special A service that can record a microphone upon a key pressing event and publish the result as an array. The end of the utterance is detected automatically, also the voice can be masked to alleviate privacy issues. Parameters: Name Type Description Default domain Union[str, utils.domain.domain.Domain] I don't know why this is here. Service needs it, but it means nothing in this context. '' conversation_log_dir str If this parameter is given, log files of the conversation will be created in this directory None enable_plotting bool If this is set to True, the recorder is no longer real time able and thus the recordings don't work properly. This is just to be used to tune the threshold for the end of utterance detection, not during deployment. False threshold int The threshold below which the assumption of the end of utterance detection is silence 8000 voice_privacy bool Whether or not to enable the masking of the users voice False identifier str I don't know why this is here. Service needs it. None Source code in adviser/services/hci/speech/SpeechRecorder.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def __init__ ( self , domain : Union [ str , Domain ] = \"\" , conversation_log_dir : str = None , enable_plotting : bool = False , threshold : int = 8000 , voice_privacy : bool = False , identifier : str = None ) -> None : \"\"\" A service that can record a microphone upon a key pressing event and publish the result as an array. The end of the utterance is detected automatically, also the voice can be masked to alleviate privacy issues. Args: domain (Domain): I don't know why this is here. Service needs it, but it means nothing in this context. conversation_log_dir (string): If this parameter is given, log files of the conversation will be created in this directory enable_plotting (boolean): If this is set to True, the recorder is no longer real time able and thus the recordings don't work properly. This is just to be used to tune the threshold for the end of utterance detection, not during deployment. threshold (int): The threshold below which the assumption of the end of utterance detection is silence voice_privacy (boolean): Whether or not to enable the masking of the users voice identifier (string): I don't know why this is here. Service needs it. \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir self . recording_indicator = False self . audio_interface = pyaudio . PyAudio () self . push_to_talk_listener = keyboard . Listener ( on_press = self . start_recording ) self . threshold = threshold self . enable_plotting = enable_plotting self . voice_privacy = voice_privacy adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.start_recorder ( self ) Starts the listener and outputs that the speech recorder is ready for use Source code in adviser/services/hci/speech/SpeechRecorder.py 137 138 139 140 141 142 143 def start_recorder ( self ): \"\"\" Starts the listener and outputs that the speech recorder is ready for use \"\"\" self . push_to_talk_listener . start () print ( \"To speak to the system, tap your right [CTRL] or [CMD] key. \\n \" \"It will try to automatically detect when your utterance is over. \\n \" ) adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.start_recording ( self , key ) This method is a callback of the push to talk key listener. It calls the recorder, if it's not already recording. Parameters: Name Type Description Default key Key The pressed key required Source code in adviser/services/hci/speech/SpeechRecorder.py 126 127 128 129 130 131 132 133 134 135 def start_recording ( self , key ): \"\"\" This method is a callback of the push to talk key listener. It calls the recorder, if it's not already recording. Args: key (Key): The pressed key \"\"\" if ( key is keyboard . Key . cmd_r or key is keyboard . Key . ctrl_r ) and not self . recording_indicator : self . record_user_utterance () adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.threshold_plotter_generator ( self ) Generates a plotter to visualize when the signal is above the set threshold Returns: Type Description function Plots the threshold with the current continuous waveform Source code in adviser/services/hci/speech/SpeechRecorder.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def threshold_plotter_generator ( self ): \"\"\" Generates a plotter to visualize when the signal is above the set threshold Returns: function: Plots the threshold with the current continuous waveform \"\"\" import matplotlib matplotlib . use ( 'TkAgg' ) plt . figure ( figsize = ( 10 , 2 )) plt . axhline ( y = self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . axhline ( y =- self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . pause ( 0.000000000001 ) def threshold_plotter ( data ): plt . clf () plt . tight_layout () plt . axis ([ 0 , len ( data ), - 20000 , 20000 ]) plt . plot ( data , color = 'b' ) plt . axhline ( y = self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . axhline ( y =- self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . pause ( 0.000000000001 ) return threshold_plotter Functions adviser.services.hci.speech.SpeechRecorder.voice_sanitizer ( audio ) While this is by no means a good voice sanitizer, it works as a proof of concept. It randomly shifts the spectrogram of a speakers utterance up or down, making automatic speaker identification much harder while keeping impact on asr performance as low as possible. The use should be turned off by default. Parameters: Name Type Description Default audio np.array The audio represented as array required Returns: Type Description np.array The mutated audio as array Source code in adviser/services/hci/speech/SpeechRecorder.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def voice_sanitizer ( audio ): \"\"\" While this is by no means a good voice sanitizer, it works as a proof of concept. It randomly shifts the spectrogram of a speakers utterance up or down, making automatic speaker identification much harder while keeping impact on asr performance as low as possible. The use should be turned off by default. Args: audio (np.array): The audio represented as array Returns: np.array: The mutated audio as array \"\"\" spectrogram = librosa . stft ( audio ) voice_shift = np . random . randint ( 3 , 6 ) if np . random . choice ([ True , False ]): for frequency_index , _ in enumerate ( spectrogram ): # mutate the voice to be higher try : spectrogram [ len ( spectrogram ) - ( frequency_index + 1 )] = spectrogram [ len ( spectrogram ) - ( frequency_index + 1 + voice_shift )] except IndexError : pass else : for frequency_index , _ in enumerate ( spectrogram ): # mutate the voice to be lower try : spectrogram [ frequency_index ] = spectrogram [ frequency_index + voice_shift ] except IndexError : pass return librosa . istft ( spectrogram ) adviser.services.hci.video special Modules adviser.services.hci.video.FeatureExtractor Feature extraction with openSMILE Classes adviser.services.hci.video.FeatureExtractor.VideoFeatureExtractor TODO adviser.services.hci.video.VideoInput Classes adviser.services.hci.video.VideoInput.VideoInput Captures frames with a specified capture interval between two consecutive dialog turns and returns a list of frames. Methods adviser.services.hci.video.VideoInput.VideoInput.__init__ ( self , domain = None , camera_id = 0 , capture_interval = 1000000.0 , identifier = None ) special Parameters: Name Type Description Default camera_id int device id (if only 1 camera device is connected, id is 0, if two are connected choose between 0 and 1, ...) 0 capture_interval int try to capture a frame every x microseconds - is a lower bound, no hard time guarantees (e.g. 5e5 -> every >= 0.5 seconds) 1000000.0 Source code in adviser/services/hci/video/VideoInput.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , domain = None , camera_id : int = 0 , capture_interval : int = 10e5 , identifier : str = None ): \"\"\" Args: camera_id (int): device id (if only 1 camera device is connected, id is 0, if two are connected choose between 0 and 1, ...) capture_interval (int): try to capture a frame every x microseconds - is a lower bound, no hard time guarantees (e.g. 5e5 -> every >= 0.5 seconds) \"\"\" Service . __init__ ( self , domain , identifier = identifier ) self . cap = cv2 . VideoCapture ( camera_id ) # get handle to camera device if not self . cap . isOpened (): self . cap . open () # open self . terminating = Event () self . terminating . clear () self . capture_thread = Thread ( target = self . capture ) # create thread object for capturing self . capture_interval = capture_interval adviser.services.hci.video.VideoInput.VideoInput.capture ( self ) Continuous video capture, meant to be run in a loop. Calls publish_img once per interval tick to publish the captured image. Source code in adviser/services/hci/video/VideoInput.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def capture ( self ): \"\"\" Continuous video capture, meant to be run in a loop. Calls `publish_img` once per interval tick to publish the captured image. \"\"\" while self . cap . isOpened () and not self . terminating . isSet (): start_time = datetime . datetime . now () # Capture frame-by-frame # cap.read() returns a bool (true when frame was read correctly) ret , frame = self . cap . read () # Our operations on the frame come here if ret : # rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) self . publish_img ( rgb_img = frame ) end_time = datetime . datetime . now () time_diff = end_time - start_time wait_seconds = ( self . capture_interval - time_diff . microseconds ) * 1e-6 # note: time to wait for next capture to match specified sampling rate in seconds if wait_seconds > 0.0 : time . sleep ( wait_seconds ) if self . cap . isOpened (): self . cap . release () adviser.services.hci.video.VideoInput.VideoInput.dialog_end ( self ) This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/hci/video/VideoInput.py 76 77 def dialog_end ( self ): self . terminating . set () adviser.services.hci.video.VideoInput.VideoInput.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/hci/video/VideoInput.py 79 80 81 82 def dialog_start ( self ): if not self . capture_thread . is_alive (): print ( \"Starting video capture...\" ) self . capture_thread . start () adviser.services.nlg special Modules adviser.services.nlg.affective_nlg Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.services.nlg.affective_nlg.HandcraftedEmotionNLG A child of the HandcraftedNLG, the HandcraftedEmotionNLG can choose between multiple affective response templates for each sys_act dependingon the current sys_emotion adviser.services.nlg.bc_nlg Handcrafted (i.e. template-based) Natural Language Generation Module with backchannel Classes adviser.services.nlg.bc_nlg.BackchannelHandcraftedNLG Handcrafted (i.e. template-based) Natural Language Generation Module A rule - based approach on natural language generation . The rules have to be specified within a template file using the ADVISER NLG syntax . Python methods that are called within a template file must be specified in the HandcraftedNLG class by using the prefix \"_template_\" . For example , the method \"_template_genitive_s\" can be accessed in the template file via calling { genitive_s ( name ) } !!! attributes domain ( Domain ) : the domain template_filename ( str ) : the NLG template filename templates ( TemplateFile ) : the parsed and ready - to - go NLG template file template_english ( str ) : the name of the English NLG template file template_german ( str ) : the name of the German NLG template file language ( Language ) : the language of the dialogue adviser.services.nlg.nlg Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.services.nlg.nlg.HandcraftedNLG Handcrafted (i.e. template-based) Natural Language Generation Module A rule - based approach on natural language generation . The rules have to be specified within a template file using the ADVISER NLG syntax . Python methods that are called within a template file must be specified in the HandcraftedNLG class by using the prefix \"_template_\" . For example , the method \"_template_genitive_s\" can be accessed in the template file via calling { genitive_s ( name ) } !!! attributes domain ( Domain ) : the domain template_filename ( str ) : the NLG template filename templates ( TemplateFile ) : the parsed and ready - to - go NLG template file template_english ( str ) : the name of the English NLG template file template_german ( str ) : the name of the German NLG template file language ( Language ) : the language of the dialogue Methods adviser.services.nlg.nlg.HandcraftedNLG.__init__ ( self , domain , template_file = None , sub_topic_domains = {}, logger =< DiasysLogger adviser ( NOTSET ) > , template_file_german = None , language = None ) special Constructor mainly extracts methods and rules from the template file Source code in adviser/services/nlg/nlg.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , domain : Domain , template_file : str = None , sub_topic_domains : Dict [ str , str ] = {}, logger : DiasysLogger = DiasysLogger (), template_file_german : str = None , language : Language = None ): \"\"\"Constructor mainly extracts methods and rules from the template file\"\"\" Service . __init__ ( self , domain = domain , sub_topic_domains = sub_topic_domains ) self . language = language if language else Language . ENGLISH self . template_english = template_file # TODO: at some point if we expand languages, maybe make kwargs? --LV self . template_german = template_file_german self . domain = domain self . template_filename = None self . templates = None self . logger = logger self . language = Language . ENGLISH self . _initialise_language ( self . language ) adviser.services.nlg.nlg.HandcraftedNLG.generate_system_utterance ( self , sys_act = None ) Main function of the NLG module Takes a system act, searches for a fitting rule, applies it and returns the message. Overwrite this function if you inherit from the NLG module. Parameters: Name Type Description Default sys_act SysAct The system act None Returns: Type Description str The utterance generated by applying a fitting template Source code in adviser/services/nlg/nlg.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def generate_system_utterance ( self , sys_act : SysAct = None ) -> str : \"\"\"Main function of the NLG module Takes a system act, searches for a fitting rule, applies it and returns the message. Overwrite this function if you inherit from the NLG module. Args: sys_act (SysAct): The system act Returns: The utterance generated by applying a fitting template \"\"\" rule_found = True message = \"\" try : message = self . templates . create_message ( sys_act ) except BaseException as error : rule_found = False self . logger . error ( error ) raise ( error ) # inform if no applicable rule could be found in the template file if not rule_found : self . logger . info ( 'Could not find a fitting rule for the given system act!' ) self . logger . info ( \"System Action: \" + str ( sys_act . type ) + \" - Slots: \" + str ( sys_act . slot_values )) # self.logger.dialog_turn(\"System Action: \" + message) return message adviser.services.nlg.templates special Modules adviser.services.nlg.templates.templatefile Classes adviser.services.nlg.templates.templatefile.TemplateFile Interprets a template file !!! attributes global_memory {GlobalMemory} -- memory that can be accessed at all times in the tempaltes Methods adviser.services.nlg.templates.templatefile.TemplateFile.add_python_function ( self , function_name , python_function , obligatory_arguments = []) Add a python function to the global memory of the template file interpreter Keyword Arguments: obligatory_arguments {List[object]} -- objects that are always passed as first arguments to the python function, e.g. \"self\" (default: {[]}) Source code in adviser/services/nlg/templates/templatefile.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def add_python_function ( self , function_name : str , python_function : Callable [[ object ], str ], obligatory_arguments : List [ object ] = []): \"\"\"Add a python function to the global memory of the template file interpreter Arguments: function_name {str} -- name under which the function can be accessed in template file python_function {Callable[[object], str]} -- python function which is called when being accessed in the template file Keyword Arguments: obligatory_arguments {List[object]} -- objects that are always passed as first arguments to the python function, e.g. \"self\" (default: {[]}) \"\"\" self . global_memory . add_function ( PythonFunction ( function_name , python_function , obligatory_arguments )) adviser.services.nlg.templates.templatefile.TemplateFile.create_message ( self , sys_act ) Iterates through all possible templates and applies the first one to fit the system act Exceptions: Type Description BaseException when no template could be applied Returns: Type Description str str -- the message returned by the template Source code in adviser/services/nlg/templates/templatefile.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def create_message ( self , sys_act : SysAct ) -> str : \"\"\"Iterates through all possible templates and applies the first one to fit the system act Arguments: sys_act {SysAct} -- the system act to find a template for Raises: BaseException: when no template could be applied Returns: str -- the message returned by the template \"\"\" slots = self . _create_memory_from_sys_act ( sys_act ) for template in self . _templates [ sys_act . type . value ]: if template . is_applicable ( slots ): return template . apply ( slots ) raise BaseException ( 'No template was found for the given system act.' ) adviser.services.nlu special Modules adviser.services.nlu.nlu Classes adviser.services.nlu.nlu.HandcraftedNLU Class for Handcrafted Natural Language Understanding Module (HDC-NLU). HDC-NLU is a rule-based approach to recognize the user acts as well as their respective slots and values from the user input (i.e. text) by means of regular expressions. HDC-NLU is domain-independet. The regular expressions of are read from JSON files. There exist a JSON file that stores general rules (GeneralRules.json), i.e. rules that apply to any domain, e.g. rules to detect salutation (Hello, Hi). There are two more files per domain that contain the domain-specific rules for request and inform user acts, e.g. ImsCoursesInformRules.json and ImsCoursesRequestRules.json. The output during dialog interaction of this module is a semantic representation of the user input. \"I am looking for pizza\" --> inform(slot=food,value=italian) See the regex_generator under tools, if the existing regular expressions need to be changed or a new domain should be added. Methods adviser.services.nlu.nlu.HandcraftedNLU.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > , language = None ) special Loads - domain key - informable slots - requestable slots - domain-independent regular expressions - domain-specific regualer espressions It sets the previous system act to None Source code in adviser/services/nlu/nlu.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , domain : JSONLookupDomain , logger : DiasysLogger = DiasysLogger (), language : Language = None ): \"\"\" Loads - domain key - informable slots - requestable slots - domain-independent regular expressions - domain-specific regualer espressions It sets the previous system act to None Args: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain \"\"\" Service . __init__ ( self , domain = domain ) self . logger = logger self . language = language if language else Language . ENGLISH # Getting domain information self . domain_name = domain . get_domain_name () self . domain_key = domain . get_primary_key () # Getting lists of informable and requestable slots self . USER_INFORMABLE = domain . get_informable_slots () self . USER_REQUESTABLE = domain . get_requestable_slots () # Getting the relative path where regexes are stored self . base_folder = os . path . join ( get_root_dir (), 'resources' , 'nlu_regexes' ) # Setting previous system act to None to signal the first turn # self.prev_sys_act = None self . sys_act_info = { 'last_act' : None , 'lastInformedPrimKeyVal' : None , 'lastRequestSlot' : None } self . language = Language . ENGLISH self . _initialize () adviser.services.nlu.nlu.HandcraftedNLU.start_dialog ( self ) Sets the previous system act as None. This function is called when the dialog starts Returns: Type Description dict Empty dictionary Source code in adviser/services/nlu/nlu.py 390 391 392 393 394 395 396 397 398 399 400 def start_dialog ( self ) -> dict : \"\"\" Sets the previous system act as None. This function is called when the dialog starts Returns: Empty dictionary \"\"\" self . sys_act_info = { 'last_act' : None , 'lastInformedPrimKeyVal' : None , 'lastRequestSlot' : None } adviser.services.policy special Modules adviser.services.policy.affective_policy Classes adviser.services.policy.affective_policy.EmotionPolicy Module for deciding what type of emotional response/ engagement level of response, the system should give Methods adviser.services.policy.affective_policy.EmotionPolicy.__init__ ( self , domain = None , logger =< DiasysLogger adviser ( NOTSET ) > ) special Initializes the policy Parameters: Name Type Description Default domain JSONLookupDomain the domain that the affective policy should operate in None Source code in adviser/services/policy/affective_policy.py 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , domain : JSONLookupDomain = None , logger : DiasysLogger = DiasysLogger ()): \"\"\" Initializes the policy Arguments: domain (JSONLookupDomain): the domain that the affective policy should operate in \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . logger = logger adviser.services.policy.affective_policy.EmotionPolicy.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/affective_policy.py 46 47 def dialog_start ( self ): pass adviser.services.policy.policy_api Classes adviser.services.policy.policy_api.HandcraftedPolicy Handcrafted policy for API domains Differs from the default HandcraftedPolicy class by taking into account mandatory slots, i.e. slots which have to be informed about before an API can even be called. The class is currently a copy of an older version of the HandcraftedPolicy class with the required changes for API usage. The classes will probably be merged in the future. Methods adviser.services.policy.policy_api.HandcraftedPolicy.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > ) special Initializes the policy Source code in adviser/services/policy/policy_api.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def __init__ ( self , domain : LookupDomain , logger : DiasysLogger = DiasysLogger ()): \"\"\" Initializes the policy Arguments: domain {domain.lookupdomain.LookupDomain} -- Domain \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . last_action = None self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation self . domain_key = domain . get_primary_key () self . logger = logger adviser.services.policy.policy_api.HandcraftedPolicy.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/policy_api.py 124 125 126 127 128 def dialog_start ( self ): self . first_turn = True self . last_action = None self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation adviser.services.policy.policy_handcrafted Classes adviser.services.policy.policy_handcrafted.HandcraftedPolicy Base class for handcrafted policies. Provides a simple rule-based policy. Can be used for any domain where a user is trying to find an entity (eg. a course from a module handbook) from a database by providing constraints (eg. semester the course is offered) or where a user is trying to find out additional information about a named entity. Output is a system action such as: * inform : provides information on an entity * request : request more information from the user * bye : issue parting message and end dialog In order to create your own policy, you can inherit from this class. Make sure to overwrite the choose_sys_act -method with whatever additionally rules/functionality required. Methods adviser.services.policy.policy_handcrafted.HandcraftedPolicy.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > , max_turns = 25 ) special Initializes the policy Source code in adviser/services/policy/policy_handcrafted.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , domain : JSONLookupDomain , logger : DiasysLogger = DiasysLogger (), max_turns : int = 25 ): \"\"\" Initializes the policy Arguments: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation self . domain_key = domain . get_primary_key () self . logger = logger self . max_turns = max_turns adviser.services.policy.policy_handcrafted.HandcraftedPolicy.dialog_start ( self ) resets the policy after each dialog Source code in adviser/services/policy/policy_handcrafted.py 68 69 70 71 72 73 74 75 def dialog_start ( self ): \"\"\" resets the policy after each dialog \"\"\" self . turns = 0 self . first_turn = True self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation adviser.services.policy.rl special Modules adviser.services.policy.rl.dqn Classes adviser.services.policy.rl.dqn.DQN Simple Deep Q-Network Methods adviser.services.policy.rl.dqn.DQN.__init__ ( self , state_dim , action_dim , hidden_layer_sizes = [ 300 , 300 ], dropout_rate = 0.0 ) special Initialize a DQN Network with an arbitrary amount of linear hidden layers Source code in adviser/services/policy/rl/dqn.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self , state_dim : int , action_dim : int , hidden_layer_sizes : List [ int ] = [ 300 , 300 ], dropout_rate : float = 0.0 ): \"\"\" Initialize a DQN Network with an arbitrary amount of linear hidden layers \"\"\" super ( DQN , self ) . __init__ () print ( \"Architecture: DQN\" ) self . dropout_rate = dropout_rate # create layers self . layers = nn . ModuleList () current_input_dim = state_dim for layer_size in hidden_layer_sizes : self . layers . append ( nn . Linear ( current_input_dim , layer_size )) self . layers . append ( nn . ReLU ()) if dropout_rate > 0.0 : self . layers . append ( nn . Dropout ( p = dropout_rate )) current_input_dim = layer_size # output layer self . layers . append ( nn . Linear ( current_input_dim , action_dim )) adviser.services.policy.rl.dqn.DQN.forward ( self , state_batch ) Forward pass: calculate Q(state) for all actions Parameters: Name Type Description Default state_batch FloatTensor tensor of size batch_size x state_dim required Returns: Type Description output tensor of size batch_size x action_dim Source code in adviser/services/policy/rl/dqn.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def forward ( self , state_batch : torch . FloatTensor ): \"\"\" Forward pass: calculate Q(state) for all actions Args: state_batch (torch.FloatTensor): tensor of size batch_size x state_dim Returns: output: tensor of size batch_size x action_dim \"\"\" output = state_batch for layer in self . layers : output = layer ( output ) return output adviser.services.policy.rl.dqn.DuelingDQN Dueling DQN network architecture Splits network into value- and advantage stream (V(s) and A(s,a)), recombined in final layer to form Q-value again: Q(s,a) = V(s) + A(s,a). Methods adviser.services.policy.rl.dqn.DuelingDQN.forward ( self , state_batch ) Forward pass: calculate Q(state) for all actions Parameters: Name Type Description Default input torch.FloatTensor tensor of size batch_size x state_dim required Returns: Type Description tensor of size batch_size x action_dim Source code in adviser/services/policy/rl/dqn.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def forward ( self , state_batch : torch . FloatTensor ): \"\"\" Forward pass: calculate Q(state) for all actions Args: input (torch.FloatTensor): tensor of size batch_size x state_dim Returns: tensor of size batch_size x action_dim \"\"\" shared_output = state_batch # shared layer representation for layer in self . shared_layers : shared_output = layer ( shared_output ) # value stream value_stream = shared_output for layer in self . value_layers : value_stream = layer ( value_stream ) # advantage stream advantage_stream = shared_output for layer in self . advantage_layers : advantage_stream = layer ( advantage_stream ) # combine value and advantage streams into Q values result = value_stream + advantage_stream - advantage_stream . mean () return result adviser.services.policy.rl.dqn.NetArchitecture Network architecture for DQN vanilla: normal MLP dueling: splits network into value- and advantage stream, recombined in final layer adviser.services.policy.rl.dqnpolicy Classes adviser.services.policy.rl.dqnpolicy.DQNPolicy Methods adviser.services.policy.rl.dqnpolicy.DQNPolicy.__init__ ( self , domain , architecture =< NetArchitecture . DUELING : 'dueling' > , hidden_layer_sizes = [ 256 , 700 , 700 ], shared_layer_sizes = [ 256 ], value_layer_sizes = [ 300 , 300 ], advantage_layer_sizes = [ 400 , 400 ], lr = 0.0001 , discount_gamma = 0.99 , target_update_rate = 3 , replay_buffer_size = 8192 , batch_size = 64 , buffer_cls =< class ' services . policy . rl . experience_buffer . NaivePrioritizedBuffer '>, eps_start=0.3, eps_end=0.0, l2_regularisation=0.0, gradient_clipping=5.0, p_dropout=0.0, training_frequency=2, train_dialogs=1000, include_confreq=False, logger=<DiasysLogger adviser (NOTSET)>, max_turns=25, summary_writer=None, device=device(type=' cpu ')) special Parameters: Name Type Description Default target_update_rate int if 1, vanilla dqn update if > 1, double dqn with specified target update rate 3 Source code in adviser/services/policy/rl/dqnpolicy.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def __init__ ( self , domain : JSONLookupDomain , architecture : NetArchitecture = NetArchitecture . DUELING , hidden_layer_sizes : List [ int ] = [ 256 , 700 , 700 ], # vanilla architecture shared_layer_sizes : List [ int ] = [ 256 ], value_layer_sizes : List [ int ] = [ 300 , 300 ], advantage_layer_sizes : List [ int ] = [ 400 , 400 ], # dueling architecture lr : float = 0.0001 , discount_gamma : float = 0.99 , target_update_rate : int = 3 , replay_buffer_size : int = 8192 , batch_size : int = 64 , buffer_cls : Type [ Buffer ] = NaivePrioritizedBuffer , eps_start : float = 0.3 , eps_end : float = 0.0 , l2_regularisation : float = 0.0 , gradient_clipping : float = 5.0 , p_dropout : float = 0.0 , training_frequency : int = 2 , train_dialogs : int = 1000 , include_confreq : bool = False , logger : DiasysLogger = DiasysLogger (), max_turns : int = 25 , summary_writer : SummaryWriter = None , device = torch . device ( 'cpu' )): \"\"\" Args: target_update_rate: if 1, vanilla dqn update if > 1, double dqn with specified target update rate \"\"\" RLPolicy . __init__ ( self , domain , buffer_cls = buffer_cls , buffer_size = replay_buffer_size , batch_size = batch_size , discount_gamma = discount_gamma , include_confreq = include_confreq , logger = logger , max_turns = max_turns , device = device ) Service . __init__ ( self , domain = domain ) self . writer = summary_writer self . training_frequency = training_frequency self . train_dialogs = train_dialogs self . lr = lr self . gradient_clipping = gradient_clipping if gradient_clipping > 0.0 and self . logger : self . logger . info ( \"Gradient Clipping: \" + str ( gradient_clipping )) self . target_update_rate = target_update_rate self . epsilon_start = eps_start self . epsilon_end = eps_end # Select network architecture if architecture == NetArchitecture . VANILLA : if self . logger : self . logger . info ( \"Architecture: Vanilla\" ) self . model = DQN ( self . state_dim , self . action_dim , hidden_layer_sizes = hidden_layer_sizes , dropout_rate = p_dropout ) else : if self . logger : self . logger . info ( \"Architecture: Dueling\" ) self . model = DuelingDQN ( self . state_dim , self . action_dim , shared_layer_sizes = shared_layer_sizes , value_layer_sizes = value_layer_sizes , advantage_layer_sizes = advantage_layer_sizes , dropout_rate = p_dropout ) # Select network update self . target_model = None if target_update_rate > 1 : if self . logger : self . logger . info ( \"Update: Double\" ) if architecture == NetArchitecture . VANILLA : self . target_model = copy . deepcopy ( self . model ) elif self . logger : self . logger . info ( \"Update: Vanilla\" ) self . optim = optim . Adam ( self . model . parameters (), lr = lr , weight_decay = l2_regularisation ) self . loss_fun = nn . SmoothL1Loss ( reduction = 'none' ) # self.loss_fun = nn.MSELoss(reduction='none') self . train_call_count = 0 self . total_train_dialogs = 0 self . epsilon = self . epsilon_start self . turns = 0 self . cumulative_train_dialogs = - 1 adviser.services.policy.rl.dqnpolicy.DQNPolicy.dialog_end ( self ) clean up needed at the end of a dialog Source code in adviser/services/policy/rl/dqnpolicy.py 163 164 165 166 167 168 169 170 def dialog_end ( self ): \"\"\" clean up needed at the end of a dialog \"\"\" self . end_dialog ( self . sim_goal ) if self . is_training : self . total_train_dialogs += 1 self . train_batch () adviser.services.policy.rl.dqnpolicy.DQNPolicy.dialog_start ( self , dialog_start = False ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/rl/dqnpolicy.py 121 122 123 124 125 126 127 128 129 130 def dialog_start ( self , dialog_start = False ): self . turns = 0 self . last_sys_act = None if self . is_training : self . cumulative_train_dialogs += 1 self . sys_state = { \"lastInformedPrimKeyVal\" : None , \"lastActionInformNone\" : False , \"offerHappened\" : False , 'informedPrimKeyValsSinceNone' : []} adviser.services.policy.rl.dqnpolicy.DQNPolicy.eps_scheduler ( self ) Linear epsilon decay Source code in adviser/services/policy/rl/dqnpolicy.py 377 378 379 380 381 382 383 384 def eps_scheduler ( self ): \"\"\" Linear epsilon decay \"\"\" if self . is_training : self . epsilon = max ( 0 , self . epsilon_start - ( self . epsilon_start - self . epsilon_end ) * float ( self . num_dialogs ) / float ( self . train_dialogs )) if self . writer is not None : self . writer . add_scalar ( 'train/eps' , self . epsilon , self . total_train_dialogs ) adviser.services.policy.rl.dqnpolicy.DQNPolicy.eval ( self , eval = True ) Sets module and its subgraph to eval mode Source code in adviser/services/policy/rl/dqnpolicy.py 425 426 427 428 429 430 431 def eval ( self , eval = True ): \"\"\" Sets module and its subgraph to eval mode \"\"\" super ( DQNPolicy , self ) . eval () self . is_training = False self . model . eval () if self . target_model is not None : self . target_model . eval () adviser.services.policy.rl.dqnpolicy.DQNPolicy.load ( self , path = 'models/dqn' , version = '1.0' ) Load model weights Parameters: Name Type Description Default path str path to model folder 'models/dqn' version str appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) '1.0' Source code in adviser/services/policy/rl/dqnpolicy.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 def load ( self , path : str = os . path . join ( 'models' , 'dqn' ), version : str = \"1.0\" ): \"\"\" Load model weights Args: path (str): path to model folder version (str): appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) \"\"\" model_file = os . path . join ( path , \"rlpolicy_\" + self . domain . get_domain_name () + \"_\" + version + \".pt\" ) if not os . path . isfile ( model_file ): raise FileNotFoundError ( \"Could not find DQN policy weight file \" , model_file ) self . model = torch . load ( model_file ) self . logger . info ( \"Loaded DQN weights from file \" + model_file ) if self . target_model is not None : self . target_model . load_state_dict ( self . model . state_dict ()) adviser.services.policy.rl.dqnpolicy.DQNPolicy.loss ( self , s_batch , a_batch , s2_batch , r_batch , t_batch , gamma ) Calculate TD-loss for given experience tuples Parameters: Name Type Description Default s_batch FloatTensor states (dimension batch x state_dim) required a_batch LongTensor actions (dimension batch x 1) required s2_batch FloatTensor next states (dimension: batch x state_dim) required r_batch FloatTensor rewards (dimension batch x 1) required t_batch FloatTensor indicator {0,1} for terminal states (dimension: batch x 1) required gamma float discount factor required Returns: Type Description TD-loss Source code in adviser/services/policy/rl/dqnpolicy.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def loss ( self , s_batch : torch . FloatTensor , a_batch : torch . LongTensor , s2_batch : torch . FloatTensor , r_batch : torch . FloatTensor , t_batch : torch . FloatTensor , gamma : float ): \"\"\" Calculate TD-loss for given experience tuples Args: s_batch (torch.FloatTensor): states (dimension batch x state_dim) a_batch (torch.LongTensor): actions (dimension batch x 1) s2_batch (torch.FloatTensor): next states (dimension: batch x state_dim) r_batch (torch.FloatTensor): rewards (dimension batch x 1) t_batch (torch.FloatTensor): indicator {0,1} for terminal states (dimension: batch x 1) gamma (float): discount factor Returns: TD-loss \"\"\" # forward value torch . autograd . set_grad_enabled ( True ) q_val = self . _forward ( s_batch , a_batch ) # forward target torch . autograd . set_grad_enabled ( False ) if self . target_model is None : q_target = self . _forward_target ( s2_batch , r_batch , t_batch , gamma ) else : q_target = self . _forward_target_ddqn ( s2_batch , r_batch , t_batch , gamma ) torch . autograd . set_grad_enabled ( True ) # loss loss = self . loss_fun ( q_val , q_target ) return loss adviser.services.policy.rl.dqnpolicy.DQNPolicy.save ( self , path = 'models/dqn' , version = '1.0' ) Save model weights Parameters: Name Type Description Default path str path to model folder 'models/dqn' version str appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) '1.0' Source code in adviser/services/policy/rl/dqnpolicy.py 386 387 388 389 390 391 392 393 394 395 396 397 398 def save ( self , path : str = os . path . join ( 'models' , 'dqn' ), version : str = \"1.0\" ): \"\"\" Save model weights Args: path (str): path to model folder version (str): appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) \"\"\" if not os . path . exists ( path ): os . makedirs ( path , exist_ok = True ) model_file = os . path . join ( path , \"rlpolicy_\" + self . domain . get_domain_name () + \"_\" + version + \".pt\" ) torch . save ( self . model , model_file ) adviser.services.policy.rl.dqnpolicy.DQNPolicy.select_action_eps_greedy ( self , state_vector ) Epsilon-greedy policy. Parameters: Name Type Description Default state_vector FloatTensor current state (dimension 1 x state_dim) required Returns: Type Description action index for action selected by the agent for the current state Source code in adviser/services/policy/rl/dqnpolicy.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def select_action_eps_greedy ( self , state_vector : torch . FloatTensor ): \"\"\" Epsilon-greedy policy. Args: state_vector (torch.FloatTensor): current state (dimension 1 x state_dim) Returns: action index for action selected by the agent for the current state \"\"\" self . eps_scheduler () # epsilon greedy exploration if self . is_training and common . random . random () < self . epsilon : next_action_idx = common . random . randint ( 0 , self . action_dim - 1 ) else : torch . autograd . set_grad_enabled ( False ) q_values = self . model ( state_vector ) next_action_idx = q_values . squeeze ( dim = 0 ) . max ( dim = 0 )[ 1 ] . item () torch . autograd . set_grad_enabled ( True ) return next_action_idx adviser.services.policy.rl.dqnpolicy.DQNPolicy.train ( self , train = True ) Sets module and its subgraph to training mode Source code in adviser/services/policy/rl/dqnpolicy.py 417 418 419 420 421 422 423 def train ( self , train = True ): \"\"\" Sets module and its subgraph to training mode \"\"\" super ( DQNPolicy , self ) . train () self . is_training = True self . model . train () if self . target_model is not None : self . target_model . train () adviser.services.policy.rl.dqnpolicy.DQNPolicy.train_batch ( self ) Train on a minibatch drawn from the experience buffer. Source code in adviser/services/policy/rl/dqnpolicy.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def train_batch ( self ): \"\"\" Train on a minibatch drawn from the experience buffer. \"\"\" if not self . is_training : return if len ( self . buffer ) >= self . batch_size * 10 and \\ self . total_train_dialogs % self . training_frequency == 0 : self . train_call_count += 1 s_batch , a_batch , r_batch , s2_batch , t_batch , indices , importance_weights = \\ self . buffer . sample () self . optim . zero_grad () torch . autograd . set_grad_enabled ( True ) s_batch . requires_grad_ () gamma = torch . tensor ([ self . discount_gamma ] * self . batch_size , dtype = torch . float , device = self . device ) . view ( self . batch_size , 1 ) # calculate loss loss = self . loss ( s_batch , a_batch , s2_batch , r_batch , t_batch , gamma ) if importance_weights is not None : loss = loss * importance_weights for i in range ( self . batch_size ): # importance weighting # update priorities self . buffer . update ( i , loss [ i ] . item ()) loss = loss . mean () loss . backward () # clip gradients if self . gradient_clipping > 0.0 : nn . utils . clip_grad_norm_ ( self . model . parameters (), self . gradient_clipping ) # update weights self . optim . step () current_loss = loss . item () torch . autograd . set_grad_enabled ( False ) if self . writer is not None : # plot loss self . writer . add_scalar ( 'train/loss' , current_loss , self . train_call_count ) # plot min/max gradients max_grad_norm = - 1.0 min_grad_norm = 1000000.0 for param in self . model . parameters (): if param . grad is not None : # TODO decide on norm current_grad_norm = torch . norm ( param . grad , 2 ) if current_grad_norm > max_grad_norm : max_grad_norm = current_grad_norm if current_grad_norm < min_grad_norm : min_grad_norm = current_grad_norm self . writer . add_scalar ( 'train/min_grad' , min_grad_norm , self . train_call_count ) self . writer . add_scalar ( 'train/max_grad' , max_grad_norm , self . train_call_count ) # update target net if self . target_model is not None and \\ self . train_call_count % self . target_update_rate == 0 : self . target_model . load_state_dict ( self . model . state_dict ()) adviser.services.policy.rl.experience_buffer Classes adviser.services.policy.rl.experience_buffer.Buffer Base class for experience replay buffers Initializes the memory, provides a print function for the memory contents and a method to insert new items into the buffer. Sampling has to be implemented by child classes. Methods adviser.services.policy.rl.experience_buffer.Buffer.__len__ ( self ) special Returns the number of items currently inside the buffer Source code in adviser/services/policy/rl/experience_buffer.py 145 146 147 def __len__ ( self ): \"\"\" Returns the number of items currently inside the buffer \"\"\" return self . buffer_count adviser.services.policy.rl.experience_buffer.Buffer.print_contents ( self , max_size = None ) Print contents of the experience replay memory. Parameters: Name Type Description Default max_size int restrict the number of printed items to this number (if not None) None Source code in adviser/services/policy/rl/experience_buffer.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def print_contents ( self , max_size : int = None ): \"\"\" Print contents of the experience replay memory. Args: max_size (int): restrict the number of printed items to this number (if not None) \"\"\" # how many entries to print print_items = len ( self ) if max_size is not None : print_items = min ( print_items , max_size ) print ( \"# REPLAY BUFFER CAPACITY: \" , self . buffer_size ) print ( \"# CURRENT ITEM COUNT\" , len ( self )) for i in range ( print_items ): print ( \"entry \" , i ) print ( \" action\" , self . mem_action [ i ]) print ( \" reward\" , self . mem_reward [ i ]) print ( \" terminal\" , self . mem_terminal [ i ]) print ( '---------' ) adviser.services.policy.rl.experience_buffer.Buffer.sample ( self ) Sample from buffer, has to be implemented by subclasses Source code in adviser/services/policy/rl/experience_buffer.py 149 150 151 def sample ( self ): \"\"\" Sample from buffer, has to be implemented by subclasses \"\"\" raise NotImplementedError adviser.services.policy.rl.experience_buffer.Buffer.store ( self , state , action , reward , terminal = False ) Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Parameters: Name Type Description Default state FloatTensor this turn's state tensor, or None if terminal = True required action LongTensor this turn's action index (int), or None if terminal = True required reward float this turn's reward (float) required terminal bool indicates whether episode finished (boolean) False Source code in adviser/services/policy/rl/experience_buffer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def store ( self , state : torch . FloatTensor , action : torch . LongTensor , reward : float , terminal : bool = False ): \"\"\" Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Args: state (torch.tensor): this turn's state tensor, or None if terminal = True action (torch.tensor): this turn's action index (int), or None if terminal = True reward (torch.tensor): this turn's reward (float) terminal (bool): indicates whether episode finished (boolean) \"\"\" reward /= 20.0 if isinstance ( self . last_state , type ( None )): # and terminal == False: # first turn of trajectory, don't record since s' is needed self . last_state = state self . last_action = action self . last_reward = reward return False else : if terminal == True : if self . episode_length > 0 : # update last state's reward and set it to terminal self . mem_terminal [ self . last_write_pos ] = float ( True ) self . mem_reward [ self . last_write_pos ] += reward self . _reset () return False else : # in-between turn of trajectory: record self . mem_state [ self . write_pos ] = \\ self . last_state . clone () . detach () self . mem_action [ self . write_pos ][ 0 ] = self . last_action self . mem_reward [ self . write_pos ][ 0 ] = self . last_reward self . mem_next_state [ self . write_pos ] = state . clone () . detach () self . mem_terminal [ self . write_pos ] = float ( False ) # update last encountered state self . last_state = state . clone () . detach () self . last_action = action self . last_reward = reward # update write index self . last_write_pos = self . write_pos self . write_pos = ( self . write_pos + 1 ) % self . buffer_size if self . buffer_count < self . buffer_size : self . buffer_count += 1 self . episode_length += 1 return True adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer Prioritized experience replay buffer. Assigns sampling probabilities dependent on TD-error of the transitions. Methods adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.sample ( self ) Sample from buffer. Returns: Type Description states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, importance weights Source code in adviser/services/policy/rl/experience_buffer.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def sample ( self ): \"\"\" Sample from buffer. Returns: states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, importance weights \"\"\" batch_size = self . batch_size batch_write_pos = 0 data_indices = torch . empty ( self . batch_size , dtype = torch . long , device = self . device ) probabilities = torch . empty ( self . batch_size , dtype = torch . float , device = self . device ) indices = [] self . sample_last_transition = True p_normed = np . array ( self . probs [: self . buffer_count ]) / np . linalg . norm ( self . probs [: self . buffer_count ], ord = 1 ) indices = common . numpy . random . choice ( list ( range ( self . buffer_count )), size = self . batch_size , p = p_normed ) if self . sample_last_transition : # include last transition (was at tree.write - 1) # -> see Sutton: A deeper look at experience replay data_indices [ 0 ] = self . last_write_pos probabilities [ 0 ] = self . probs [ self . last_write_pos ] # correct size of batch batch_size = batch_size - 1 batch_write_pos += 1 # TODO add option to sample each segment uniformly for i in range ( batch_write_pos , self . batch_size ): data_indices [ i ] = int ( indices [ i ]) probabilities [ i ] = self . probs [ data_indices [ i ]] # assemble batch from data indices s_batch = self . mem_state . index_select ( 0 , data_indices ) a_batch = self . mem_action . index_select ( 0 , data_indices ) r_batch = self . mem_reward . index_select ( 0 , data_indices ) t_batch = self . mem_terminal . index_select ( 0 , data_indices ) s2_batch = self . mem_next_state . index_select ( 0 , data_indices ) # calculate importance sampling weights importance_weights = float ( len ( self )) * probabilities importance_weights = importance_weights . pow ( - self . beta ) importance_weights = importance_weights / importance_weights . max ( dim = 0 )[ 0 ] . item () return s_batch , a_batch , r_batch , s2_batch , t_batch , data_indices , \\ importance_weights . view ( - 1 , 1 ) adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.store ( self , state , action , reward , terminal = False ) Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Newly added experience tuples will be assigned maximum priority. Parameters: Name Type Description Default state FloatTensor this turn's state tensor, or None if terminal = True required action LongTensor this turn's action index (int), or None if terminal = True required reward float this turn's reward (float) required terminal bool indicates whether episode finished (boolean) False Source code in adviser/services/policy/rl/experience_buffer.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def store ( self , state : torch . FloatTensor , action : torch . LongTensor , reward : float , terminal : bool = False ): \"\"\" Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Newly added experience tuples will be assigned maximum priority. Args: state: this turn's state tensor, or None if terminal = True action: this turn's action index (int), or None if terminal = True reward: this turn's reward (float) terminal: indicates whether episode finished (boolean) \"\"\" if super ( NaivePrioritizedBuffer , self ) . store ( state , action , reward , terminal = terminal ): # create new tree node only if something new was added to the buffers self . probs [ self . last_write_pos ] = self . _priority_to_probability ( self . max_p ) adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.update ( self , idx , error ) Update the priority of transition with index idx Source code in adviser/services/policy/rl/experience_buffer.py 252 253 254 255 256 257 def update ( self , idx : int , error : float ): \"\"\" Update the priority of transition with index idx \"\"\" p = self . _priority_to_probability ( error ) if p > self . max_p : self . max_p = p self . probs [ idx ] = p adviser.services.policy.rl.experience_buffer.UniformBuffer Experience replay buffer with uniformly random sampling Methods adviser.services.policy.rl.experience_buffer.UniformBuffer.__init__ ( self , buffer_size , batch_size , state_dim , discount_gamma = 0.99 , sample_last_transition = True , device = device ( type = 'cpu' )) special Parameters: Name Type Description Default sample_last_transition bool if True, a batch will always include the most recent transition (see Sutton: A deeper look at experience replay) True Source code in adviser/services/policy/rl/experience_buffer.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , buffer_size : int , batch_size : int , state_dim : int , discount_gamma : float = 0.99 , sample_last_transition : bool = True , device = torch . device ( 'cpu' )): \"\"\" Args: sample_last_transition (bool): if True, a batch will always include the most recent transition (see Sutton: A deeper look at experience replay) \"\"\" super ( UniformBuffer , self ) . __init__ ( buffer_size , batch_size , state_dim , discount_gamma = discount_gamma , device = device ) print ( \" REPLAY MEMORY: Uniform\" ) self . sample_last_transition = sample_last_transition adviser.services.policy.rl.experience_buffer.UniformBuffer.sample ( self ) Sample from buffer. Returns: Type Description states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, None Source code in adviser/services/policy/rl/experience_buffer.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 def sample ( self ): \"\"\" Sample from buffer. Returns: states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, None \"\"\" # create random indices data_indices = [] if self . sample_last_transition : # include last transition (was at write - 1) # - see Sutton: A deeper look at experience replay if self . write_pos - 1 < 0 : # last transition filled the capacity of the buffer data_indices = [ self . buffer_size - 1 ] else : data_indices = [ self . write_pos - 1 ] data_indices . extend ([ common . random . randint ( 0 , self . buffer_count - 1 ) for i in range ( self . batch_size - int ( self . sample_last_transition ))]) data_indices = torch . tensor ( data_indices , dtype = torch . long , device = self . device ) state_batch = self . mem_state . index_select ( 0 , data_indices ) action_batch = self . mem_action . index_select ( 0 , data_indices ) reward_batch = self . mem_reward . index_select ( 0 , data_indices ) next_state_batch = self . mem_next_state . index_select ( 0 , data_indices ) terminal_batch = self . mem_terminal . index_select ( 0 , data_indices ) return state_batch , action_batch , reward_batch , next_state_batch , terminal_batch , \\ data_indices , None adviser.services.policy.rl.policy_rl Classes adviser.services.policy.rl.policy_rl.RLPolicy Base class for Reinforcement Learning based policies. Functionality provided includes the setup of state- and action spaces, conversion of BeliefState objects into pytorch tensors, updating the last performed system actions and informed entities, populating the experience replay buffer, extraction of most probable user hypothesis and candidate action expansion. Output of an agent is a candidate action like inform_food which is then populated with the most probable slot/value pair from the beliefstate and database candidates by the expand_system_action -function to become inform(slot=food,value=italian) . In order to create your own policy, you can inherit from this class. Make sure to call the turn_end -function after each system turn and the end_dialog -function after each completed dialog. Methods adviser.services.policy.rl.policy_rl.RLPolicy.__init__ ( self , domain , buffer_cls =< class ' services . policy . rl . experience_buffer . UniformBuffer '>, buffer_size=6000, batch_size=64, discount_gamma=0.99, max_turns=25, include_confreq=False, logger=<DiasysLogger adviser (NOTSET)>, include_select=False, device=device(type=' cpu ')) special Creates state- and action spaces, initializes experience replay buffers. Keyword Arguments: subgraph {[type]} -- [see services.Module] (default: {None}) buffer_cls {services.policy.rl.experience_buffer.Buffer} -- [Experience replay buffer class , not an instance - will be initialized by this constructor!] (default: {UniformBuffer}) buffer_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {6000}) batch_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {64}) discount_gamma {float} -- [Discount factor] (default: {0.99}) include_confreq {bool} -- [Use confirm_request actions] (default: {False}) Source code in adviser/services/policy/rl/policy_rl.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __init__ ( self , domain : JSONLookupDomain , buffer_cls = UniformBuffer , buffer_size = 6000 , batch_size = 64 , discount_gamma = 0.99 , max_turns : int = 25 , include_confreq = False , logger : DiasysLogger = DiasysLogger (), include_select : bool = False , device = torch . device ( 'cpu' )): \"\"\" Creates state- and action spaces, initializes experience replay buffers. Arguments: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain Keyword Arguments: subgraph {[type]} -- [see services.Module] (default: {None}) buffer_cls {services.policy.rl.experience_buffer.Buffer} -- [Experience replay buffer *class*, **not** an instance - will be initialized by this constructor!] (default: {UniformBuffer}) buffer_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {6000}) batch_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {64}) discount_gamma {float} -- [Discount factor] (default: {0.99}) include_confreq {bool} -- [Use confirm_request actions] (default: {False}) \"\"\" self . device = device self . sys_state = { \"lastInformedPrimKeyVal\" : None , \"lastActionInformNone\" : False , \"offerHappened\" : False , 'informedPrimKeyValsSinceNone' : []} self . max_turns = max_turns self . logger = logger self . domain = domain # setup evaluator for training self . evaluator = ObjectiveReachedEvaluator ( domain , logger = logger ) self . buffer_size = buffer_size self . batch_size = batch_size self . discount_gamma = discount_gamma self . writer = None # get state size self . state_dim = self . beliefstate_dict_to_vector ( BeliefState ( domain ) . _init_beliefstate ()) . size ( 1 ) self . logger . info ( \"state space dim: \" + str ( self . state_dim )) # get system action list self . actions = [ \"inform_byname\" , # TODO rename to 'bykey' \"inform_alternatives\" , \"reqmore\" ] # TODO badaction # NOTE repeat not supported by user simulator for req_slot in self . domain . get_system_requestable_slots (): self . actions . append ( 'request#' + req_slot ) self . actions . append ( 'confirm#' + req_slot ) if include_select : self . actions . append ( 'select#' + req_slot ) if include_confreq : for conf_slot in self . domain . get_system_requestable_slots (): if not req_slot == conf_slot : # skip case where confirm slot = request slot self . actions . append ( 'confreq#' + conf_slot + '#' + req_slot ) self . action_dim = len ( self . actions ) # don't include closingmsg in learnable actions self . actions . append ( 'closingmsg' ) # self.actions.append(\"closingmsg\") self . logger . info ( \"action space dim: \" + str ( self . action_dim )) self . primary_key = self . domain . get_primary_key () # init replay memory self . buffer = buffer_cls ( buffer_size , batch_size , self . state_dim , discount_gamma = discount_gamma , device = device ) self . sys_state = {} self . last_sys_act = None adviser.services.policy.rl.policy_rl.RLPolicy.action_idx ( self , action_name ) Returns the action index for the specified action name Source code in adviser/services/policy/rl/policy_rl.py 141 142 143 def action_idx ( self , action_name : str ): \"\"\" Returns the action index for the specified action name \"\"\" return self . actions . index ( action_name ) adviser.services.policy.rl.policy_rl.RLPolicy.action_name ( self , action_idx ) Returns the action name for the specified action index Source code in adviser/services/policy/rl/policy_rl.py 137 138 139 def action_name ( self , action_idx : int ): \"\"\" Returns the action name for the specified action index \"\"\" return self . actions [ action_idx ] adviser.services.policy.rl.policy_rl.RLPolicy.beliefstate_dict_to_vector ( self , beliefstate ) Converts the beliefstate dict to a torch tensor Parameters: Name Type Description Default beliefstate BeliefState dict of belief (with at least beliefs and system keys) required Returns: Type Description belief tensor with dimension 1 x state_dim Source code in adviser/services/policy/rl/policy_rl.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def beliefstate_dict_to_vector ( self , beliefstate : BeliefState ): \"\"\" Converts the beliefstate dict to a torch tensor Args: beliefstate: dict of belief (with at least beliefs and system keys) Returns: belief tensor with dimension 1 x state_dim \"\"\" belief_vec = [] # add user acts belief_vec += [ 1 if act in beliefstate [ 'user_acts' ] else 0 for act in UserActionType ] # handle none actions belief_vec . append ( 1 if sum ( belief_vec ) == 0 else 1 ) # add informs (including special flag if slot not mentioned) for slot in sorted ( self . domain . get_informable_slots ()): values = self . domain . get_possible_values ( slot ) + [ \"dontcare\" ] if slot not in beliefstate [ 'informs' ]: # add **NONE** value first, then 0.0 for all others belief_vec . append ( 1.0 ) # also add value for don't care belief_vec += [ 0 for i in range ( len ( values ))] else : # add **NONE** value first belief_vec . append ( 0.0 ) bs_slot = beliefstate [ 'informs' ][ slot ] belief_vec += [ bs_slot [ value ] if value in bs_slot else 0.0 for value in values ] # add requests for slot in sorted ( self . domain . get_requestable_slots ()): if slot in beliefstate [ 'requests' ]: belief_vec . append ( 1.0 ) else : belief_vec . append ( 0.0 ) # append system features belief_vec . append ( float ( self . sys_state [ 'lastActionInformNone' ])) belief_vec . append ( float ( self . sys_state [ 'offerHappened' ])) candidate_count = beliefstate [ 'num_matches' ] # buckets for match count: 0, 1, 2-4, >4 belief_vec . append ( float ( candidate_count == 0 )) belief_vec . append ( float ( candidate_count == 1 )) belief_vec . append ( float ( 2 <= candidate_count <= 4 )) belief_vec . append ( float ( candidate_count > 4 )) belief_vec . append ( float ( beliefstate [ \"discriminable\" ])) # convert to torch tensor return torch . tensor ([ belief_vec ], dtype = torch . float , device = self . device ) adviser.services.policy.rl.policy_rl.RLPolicy.end_dialog ( self , sim_goal ) Call this function when a dialog ended Source code in adviser/services/policy/rl/policy_rl.py 550 551 552 553 554 555 556 557 558 559 560 def end_dialog ( self , sim_goal : Goal ): \"\"\" Call this function when a dialog ended \"\"\" if sim_goal is None : # real user interaction, no simulator - don't have to evaluate # anything, just reset counters return final_reward , success = self . evaluator . get_final_reward ( sim_goal , logging = False ) if self . is_training : self . buffer . store ( None , None , final_reward , terminal = True ) adviser.services.policy.rl.policy_rl.RLPolicy.expand_system_action ( self , action_idx , beliefstate ) Expands an action index to a real sytem act Source code in adviser/services/policy/rl/policy_rl.py 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 def expand_system_action ( self , action_idx : int , beliefstate : BeliefState ): \"\"\" Expands an action index to a real sytem act \"\"\" action_name = self . action_name ( action_idx ) if 'request#' in action_name : return self . _expand_request ( action_name ) elif 'select#' in action_name : return self . _expand_select ( action_name , beliefstate ) elif 'confirm#' in action_name : return self . _expand_confirm ( action_name , beliefstate ) elif 'confreq#' in action_name : return self . _expand_confreq ( action_name , beliefstate ) elif action_name == 'inform_byname' : return self . _expand_informbyname ( beliefstate ) elif action_name == 'inform_alternatives' : return self . _expand_informbyalternatives ( beliefstate ) elif action_name == 'closingmsg' : return self . _expand_bye () elif action_name == 'repeat' : return self . last_sys_act elif action_name == 'reqmore' : return self . _expand_reqmore () elif self . logger : self . logger . warning ( \"RL POLICY: system action not supported: \" + action_name ) # TODO restart: not supported by former systems # -> check if user simulator supports this return None adviser.services.policy.rl.policy_rl.RLPolicy.turn_end ( self , beliefstate , state_vector , sys_act_idx ) Call this function after a turn is done by the system Source code in adviser/services/policy/rl/policy_rl.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 def turn_end ( self , beliefstate : BeliefState , state_vector : torch . FloatTensor , sys_act_idx : int ): \"\"\" Call this function after a turn is done by the system \"\"\" self . last_sys_act = self . expand_system_action ( sys_act_idx , beliefstate ) # TODO COMPATIBILITY TO FORMER SYSTEM'S USER SIMULATOR AND NLG CURRENTLY - REMOVE LATER # if self.last_sys_act.type == SysActionType.InformByName: # self.last_sys_act.type = SysActionType.Inform if self . logger : self . logger . dialog_turn ( \"system action > \" + str ( self . last_sys_act )) self . _update_system_belief ( beliefstate , self . last_sys_act ) turn_reward = self . evaluator . get_turn_reward () if self . is_training : self . buffer . store ( state_vector , sys_act_idx , turn_reward , terminal = False ) adviser.services.policy.rl.train_dqnpolicy This script can be executed to train a DQN policy. It will create a policy model (file ending with .pt). You need to execute this script before you can interact with the RL agent. Functions adviser.services.policy.rl.train_dqnpolicy.train ( domain_name , log_to_file , seed , train_epochs , train_dialogs , eval_dialogs , max_turns , train_error_rate , test_error_rate , lr , eps_start , grad_clipping , buffer_classname , buffer_size , use_tensorboard ) Training loop for the RL policy, for information on the parameters, look at the descriptions of commandline arguments in the \"if main\" below Source code in adviser/services/policy/rl/train_dqnpolicy.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def train ( domain_name : str , log_to_file : bool , seed : int , train_epochs : int , train_dialogs : int , eval_dialogs : int , max_turns : int , train_error_rate : float , test_error_rate : float , lr : float , eps_start : float , grad_clipping : float , buffer_classname : str , buffer_size : int , use_tensorboard : bool ): \"\"\" Training loop for the RL policy, for information on the parameters, look at the descriptions of commandline arguments in the \"if main\" below \"\"\" common . init_random ( seed = seed ) file_log_lvl = LogLevel . DIALOGS if log_to_file else LogLevel . NONE logger = DiasysLogger ( console_log_lvl = LogLevel . RESULTS , file_log_lvl = file_log_lvl ) if buffer_classname == \"prioritized\" : buffer_cls = NaivePrioritizedBuffer elif buffer_classname == \"uniform\" : buffer_cls = UniformBuffer domain = JSONLookupDomain ( name = domain_name ) bst = HandcraftedBST ( domain = domain , logger = logger ) user = HandcraftedUserSimulator ( domain , logger = logger ) # noise = SimpleNoise(domain=domain, train_error_rate=train_error_rate, # test_error_rate=test_error_rate, logger=logger) policy = DQNPolicy ( domain = domain , lr = lr , eps_start = eps_start , gradient_clipping = grad_clipping , buffer_cls = buffer_cls , replay_buffer_size = buffer_size , train_dialogs = train_dialogs , logger = logger ) evaluator = PolicyEvaluator ( domain = domain , use_tensorboard = use_tensorboard , experiment_name = domain_name , logger = logger ) ds = DialogSystem ( services = [ user , bst , policy , evaluator ], protocol = 'tcp' ) # ds.draw_system_graph() error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_local_inconsistencies () for j in range ( train_epochs ): # START TRAIN EPOCH evaluator . train () policy . train () evaluator . start_epoch () for episode in range ( train_dialogs ): if episode % 100 == 0 : print ( \"DIALOG\" , episode ) logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () policy . save () # START EVAL EPOCH evaluator . eval () policy . eval () evaluator . start_epoch () for episode in range ( eval_dialogs ): logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () ds . shutdown () adviser.services.service Classes adviser.services.service.DialogSystem This class will constrct a dialog system from the list of services provided to the constructor. It will also handle synchronization for initalization of services before dialog start / after dialog end / on system shutdown and lets you discover potential conflicts in you messaging pipeline. This class is also used to communicate / synchronize with services running on different nodes. Methods adviser.services.service.DialogSystem.__init__ ( self , services , sub_port = 65533 , pub_port = 65534 , reg_port = 65535 , protocol = 'tcp' , debug_logger = None ) special Parameters: Name Type Description Default services List[Union[adviser.services.service.Service, adviser.services.service.RemoteService]] List of all (remote) services to connect to. Only once they're specified here will they start listening for messages. required sub_port(int) subscriber port required sub_addr(str) IP-address or domain name of proxy subscriber interface (e.g. 127.0.0.1 for your local machine) required pub_port(int) publisher port required pub_addr(str) IP-address or domain name of proxy publisher interface (e.g. 127.0.0.1 for your local machine) required reg_port int registration port for remote services 65535 protocol(str) communication protol, either 'inproc' or 'tcp' or ipc required debug_logger DiasysLogger If not None , all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the DialogSystem even if they are never forwarded (as expected) to your Service None Source code in adviser/services/service.py 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 def __init__ ( self , services : List [ Union [ Service , RemoteService ]], sub_port : int = 65533 , pub_port : int = 65534 , reg_port : int = 65535 , protocol : str = 'tcp' , debug_logger : DiasysLogger = None ): \"\"\" Args: services (List[Union[Service, RemoteService]]): List of all (remote) services to connect to. Only once they're specified here will they start listening for messages. sub_port(int): subscriber port sub_addr(str): IP-address or domain name of proxy subscriber interface (e.g. 127.0.0.1 for your local machine) pub_port(int): publisher port pub_addr(str): IP-address or domain name of proxy publisher interface (e.g. 127.0.0.1 for your local machine) reg_port (int): registration port for remote services protocol(str): communication protol, either 'inproc' or 'tcp' or `ipc` debug_logger (DiasysLogger): If not `None`, all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the `DialogSystem` even if they are never forwarded (as expected) to your `Service` \"\"\" # node-local topics self . debug_logger = debug_logger self . protocol = protocol self . _sub_topics = {} self . _pub_topics = {} self . _remote_identifiers = set () self . _services = [] # collects names and instances of local services self . _start_dialog_services = set () # collects names of local services that subscribe to dialog_start # node-local sockets self . _domains = set () # start proxy thread self . _proxy_dev = ProcessProxy ( in_type = zmq . XSUB , out_type = zmq . XPUB ) # , mon_type=zmq.XSUB) self . _proxy_dev . bind_in ( f \" { protocol } ://127.0.0.1: { pub_port } \" ) self . _proxy_dev . bind_out ( f \" { protocol } ://127.0.0.1: { sub_port } \" ) self . _proxy_dev . start () self . _sub_port = sub_port self . _pub_port = pub_port # thread control self . _start_topics = set () self . _end_topics = set () self . _terminate_topics = set () self . _stopEvent = threading . Event () # control channels ctx = Context . instance () self . _control_channel_pub = ctx . socket ( zmq . PUB ) self . _control_channel_pub . sndhwm = 1100000 self . _control_channel_pub . connect ( f \" { protocol } ://127.0.0.1: { pub_port } \" ) self . _control_channel_sub = ctx . socket ( zmq . SUB ) # register services (local and remote) remote_services = {} for service in services : if isinstance ( service , Service ): # register local service service_name = type ( service ) . __name__ if service . _identifier is None else service . _identifier service . _init_pubsub () self . _add_service_info ( service_name , service . _domain_name , service . _sub_topics , service . _pub_topics , service . _start_topic , service . _end_topic , service . _terminate_topic ) service . _register_with_dialogsystem () elif isinstance ( service , RemoteService ): remote_services [ getattr ( service , 'identifier' )] = service self . _register_remote_services ( remote_services , reg_port ) self . _control_channel_sub . connect ( f \" { protocol } ://127.0.0.1: { sub_port } \" ) self . _setup_dialog_end_listener () time . sleep ( 0.25 ) adviser.services.service.DialogSystem.draw_system_graph ( self , name = 'system' , format = 'png' , show = True ) Draws a graph of the system as a directed graph. Services are represented by nodes, messages by directed edges (from publisher to subscriber). Warnings are drawn as yellow edges (and the missing subscribers represented by an 'UNCONNECTED SERVICES' node), errors as red edges (and the missing publishers represented by the 'UNCONNECTED SERVICES' node as well). Will mark remote services with blue. Parameters: Name Type Description Default name str used to construct the name of your output file 'system' format str output file format (e.g. png, pdf, jpg, ...) 'png' show bool if True, the graph image will be opened in your default image viewer application True Requires graphviz library (pip install graphviz) Source code in adviser/services/service.py 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 def draw_system_graph ( self , name : str = 'system' , format : str = \"png\" , show : bool = True ): \"\"\" Draws a graph of the system as a directed graph. Services are represented by nodes, messages by directed edges (from publisher to subscriber). Warnings are drawn as yellow edges (and the missing subscribers represented by an 'UNCONNECTED SERVICES' node), errors as red edges (and the missing publishers represented by the 'UNCONNECTED SERVICES' node as well). Will mark remote services with blue. Args: name (str): used to construct the name of your output file format (str): output file format (e.g. png, pdf, jpg, ...) show (bool): if True, the graph image will be opened in your default image viewer application Requires: graphviz library (pip install graphviz) \"\"\" from graphviz import Digraph g = Digraph ( name = name , format = format ) # collect all services, errors and warnings services = set () for service_set in self . _pub_topics . values (): services = services . union ( service_set ) for service_set in self . _sub_topics . values (): services = services . union ( service_set ) errors , warnings = self . list_inconsistencies () # add services as nodes for service in services : if service in self . _remote_identifiers : g . node ( service , color = '#1f618d' , style = 'filled' , fontcolor = 'white' , shape = 'box' ) # remote service else : g . node ( service , color = '#1c2833' , shape = 'box' ) # local service if len ( errors ) > 0 or len ( warnings ) > 0 : g . node ( 'UNCONNECTED SERVICES' , style = 'filled' , color = '#922b21' , fontcolor = 'white' , shape = 'box' ) # draw connections from publisher to subscribers as edges for topic in self . _pub_topics : publishers = self . _pub_topics [ topic ] receivers = self . _sub_topics [ topic ] if topic in self . _sub_topics else [] for receiver in receivers : for publisher in publishers : g . edge ( publisher , receiver , label = topic ) # draw warnings and errors as edges to node 'UNCONNECTED SERVICES' for topic in errors : receivers = errors [ topic ] for receiver in receivers : g . edge ( 'UNCONNECTED SERVICES' , receiver , color = '#c34400' , fontcolor = '#c34400' , label = topic ) for topic in warnings : publishers = warnings [ topic ] for publisher in publishers : g . edge ( publisher , 'UNCONNECTED SERVICES' , color = '#e37c02' , fontcolor = '#e37c02' , label = topic ) # draw graph g . render ( view = show , cleanup = True ) adviser.services.service.DialogSystem.is_error_free_messaging_pipeline ( self ) Checks the current messaging pipeline for potential errors. (Potential) Errors are defined in this context as subscribed topics without publishers. Returns: Type Description True, if no potential errors could be found - else, False Notes Call this method after instantiating all services. Lists only node-local (or process-local) inconsistencies. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 def is_error_free_messaging_pipeline ( self ): \"\"\" Checks the current messaging pipeline for potential errors. (Potential) Errors are defined in this context as subscribed topics without publishers. Returns: True, if no potential errors could be found - else, False Notes: * Call this method after instantiating all services. * Lists only node-local (or process-local) inconsistencies. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" return len ( self . list_inconsistencies ()[ 0 ]) == 0 adviser.services.service.DialogSystem.list_inconsistencies ( self ) Checks for potential errors in the current messaging pipleline: e.g. len(list_inconsistencies()[0]) == 0 -> error free pipeline (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Returns: Type Description A touple of dictionaries the first dictionary contains potential errors (with the mapping topics -> subsribing services) the second dictionary contains warnings (with the mapping topics -> publishing services). Notes Call this method after instantiating all services. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 def list_inconsistencies ( self ): \"\"\" Checks for potential errors in the current messaging pipleline: e.g. len(list_inconsistencies()[0]) == 0 -> error free pipeline (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Returns: A touple of dictionaries: * the first dictionary contains potential errors (with the mapping topics -> subsribing services) * the second dictionary contains warnings (with the mapping topics -> publishing services). Notes: * Call this method after instantiating all services. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" # look for subscribers w/o publishers by checking topic prefixes errors = {} for sub_topic in self . _sub_topics : found_pub = False for pub_topic in self . _pub_topics : if pub_topic . startswith ( sub_topic ): found_pub = True break if not found_pub : errors [ sub_topic ] = self . _sub_topics [ sub_topic ] # look for publishers w/o subscribers by checking topic prefixes warnings = {} for pub_topic in self . _pub_topics : found_sub = False for sub_topic in self . _sub_topics : if pub_topic . startswith ( sub_topic ): found_sub = True break if not found_sub : warnings [ pub_topic ] = self . _pub_topics [ pub_topic ] return errors , warnings adviser.services.service.DialogSystem.list_published_topics ( self ) Get all declared publisher topics. Returns: Type Description A dictionary with mapping topic (str) -> publishing services (Set[str]). Note Call this method after instantiating all services. Even though a publishing topic might be listed here, there is no guarantee that its publisher(s) might ever publish to it. Source code in adviser/services/service.py 852 853 854 855 856 857 858 859 860 861 862 863 def list_published_topics ( self ): \"\"\" Get all declared publisher topics. Returns: A dictionary with mapping topic (str) -> publishing services (Set[str]). Note: * Call this method after instantiating all services. * Even though a publishing topic might be listed here, there is no guarantee that its publisher(s) might ever publish to it. \"\"\" return copy . deepcopy ( self . _pub_topics ) # copy s.t. no user changes this list adviser.services.service.DialogSystem.list_subscribed_topics ( self ) Get all declared subscribed topics. Returns: Type Description A dictionary with mapping topic (str) -> subscribing services (Set[str]). Notes Call this method after instantiating all services. Source code in adviser/services/service.py 865 866 867 868 869 870 871 872 873 874 def list_subscribed_topics ( self ): \"\"\" Get all declared subscribed topics. Returns: A dictionary with mapping topic (str) -> subscribing services (Set[str]). Notes: * Call this method after instantiating all services. \"\"\" return copy . deepcopy ( self . _sub_topics ) # copy s.t. no user changes this list adviser.services.service.DialogSystem.print_inconsistencies ( self ) Checks for potential errors in the current messaging pipleline: e.g. len(list_local_inconsistencies()[0]) == 0 -> error free pipeline and prints them to the console. (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Notes Call this method after instantiating all services. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 def print_inconsistencies ( self ): \"\"\" Checks for potential errors in the current messaging pipleline: e.g. len(list_local_inconsistencies()[0]) == 0 -> error free pipeline and prints them to the console. (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Notes: * Call this method after instantiating all services. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" # console colors WARNING = ' \\033 [93m' ERROR = ' \\033 [91m' ENDC = ' \\033 [0m' errors , warnings = self . list_inconsistencies () print ( ERROR ) print ( \"(Potential) Errors (subscribed topics without publishers):\" ) for topic in errors : print ( f \" topic: ' { topic } ', subscribed to in services: { errors [ topic ] } \" ) print ( ENDC ) print ( WARNING ) print ( \"Warnings (published topics without subscribers):\" ) for topic in warnings : print ( f \" topic: ' { topic } ', published in services: { warnings [ topic ] } \" ) print ( ENDC ) adviser.services.service.DialogSystem.run_dialog ( self , start_signals = { 'dialog_end' : False }) Run a complete dialog (blocking). Dialog will be started via messages to the topics specified in start_signals . The dialog will end on receiving any Topic.DIALOG_END message with value 'True', so make sure at least one service in your dialog graph will publish this message eventually. Parameters: Name Type Description Default start_signals dict mapping from topic -> value Publishes the value given for each topic to the respective topic. Use this to trigger the start of your dialog system. {'dialog_end': False} Source code in adviser/services/service.py 838 839 840 841 842 843 844 845 846 847 848 849 850 def run_dialog ( self , start_signals : dict = { Topic . DIALOG_END : False }): \"\"\" Run a complete dialog (blocking). Dialog will be started via messages to the topics specified in `start_signals`. The dialog will end on receiving any `Topic.DIALOG_END` message with value 'True', so make sure at least one service in your dialog graph will publish this message eventually. Args: start_signals (Dict[str, Any]): mapping from topic -> value Publishes the value given for each topic to the respective topic. Use this to trigger the start of your dialog system. \"\"\" self . _start_dialog ( start_signals ) self . _end_dialog () adviser.services.service.DialogSystem.shutdown ( self ) Shutdown dialog system. This will trigger terminate messages to be sent to all registered services to stop their listener loops. Should be called in the end before exiting your program. Blocks until all services sent ACK's confirming they're stopped. Source code in adviser/services/service.py 780 781 782 783 784 785 786 787 788 789 def shutdown ( self ): \"\"\" Shutdown dialog system. This will trigger `terminate` messages to be sent to all registered services to stop their listener loops. Should be called in the end before exiting your program. Blocks until all services sent ACK's confirming they're stopped. \"\"\" self . _stopEvent . set () for terminate_topic in self . _terminate_topics : _send_msg ( self . _control_channel_pub , terminate_topic , True ) _recv_ack ( self . _control_channel_sub , terminate_topic ) adviser.services.service.DialogSystem.stop ( self ) Set stop event (can be queried by services via the terminating() function) Source code in adviser/services/service.py 771 772 773 774 def stop ( self ): \"\"\" Set stop event (can be queried by services via the `terminating()` function) \"\"\" self . _stopEvent . set () pass adviser.services.service.DialogSystem.terminating ( self ) Returns True if the system is stopping, else False Source code in adviser/services/service.py 776 777 778 def terminating ( self ): \"\"\" Returns True if the system is stopping, else False \"\"\" return self . _stopEvent . is_set () adviser.services.service.RemoteService This is a placeholder to be used in the service list argument when constructing a DialogSystem : * Run the real Service instance on a remote node, give it a *UNIQUE* identifier * call run_standalone() on this instance * Instantiate a remote service on the node about to run the DialogSystem , assign the *SAME* identifier to it * add it to the DialogSystem service list * Now, when calling the constructor of DialogSystem`, you should see messages informing you about the successfull connection, or if the system is still trying to connect, it will block until connected to the remote service. Methods adviser.services.service.RemoteService.__init__ ( self , identifier ) special Parameters: Name Type Description Default identifier str the UNIQUE identifier to call the remote service instance required Source code in adviser/services/service.py 94 95 96 97 98 99 def __init__ ( self , identifier : str ): \"\"\" Args: identifier (str): the *UNIQUE* identifier to call the remote service instance \"\"\" self . identifier = identifier adviser.services.service.Service Service base class. Inherit from this class, if you want to publish / subscribe to topics (Don't forget to call the super constructor!) . You may decorate arbitrary functions in the child class with the services.service.PublishSubscribe decorator for this purpose. A Service will only start listening to messages once it is added to a DialogSystem (or calling run_standalone() in the remote case and adding a corresponding RemoteService to the DialogSystem ). Methods adviser.services.service.Service.__init__ ( self , domain = '' , sub_topic_domains = {}, pub_topic_domains = {}, ds_host_addr = '127.0.0.1' , sub_port = 65533 , pub_port = 65534 , protocol = 'tcp' , debug_logger = None , identifier = None ) special Create a new service instance (call this super constructor from your inheriting classes!) . Parameters: Name Type Description Default domain Union[str, utils.domain.domain.Domain] The domain(-name) of your service (or empty string, if domain-agnostic). If a domain(-name) is set, it will automatically filter out all messages from other domains. If no domain(-name) is set, messages from all domains will be received. '' sub_topic_domains Dict[str, str] change subscribed to topics to listen to a specific domain (e.g. 'erase'/append a domain for a specific topic) {} pub_topic_domains Dict[str, str] change published topics to a specific domain (e.g. 'erase'/append a domain for a specific topic) {} ds_host_addr str IP-address of the parent DialogSystem (default: localhost) '127.0.0.1' sub_port int subscriber port following zmq's XSUB/XPUB pattern 65533 pub_port int publisher port following zmq's XSUB/XPUB pattern 65534 protocol str communication protocol with DialogSystem - has to match! Possible options: tcp , inproc , ipc 'tcp' debug_logger DiasysLogger If not None , all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the DialogSystem even if they are never forwarded (as expected) to your Service . None identifier str Set this to a UNIQUE identifier per service to be run remotely. See RemoteService for more details. None Source code in adviser/services/service.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def __init__ ( self , domain : Union [ str , Domain ] = \"\" , sub_topic_domains : Dict [ str , str ] = {}, pub_topic_domains : Dict [ str , str ] = {}, ds_host_addr : str = \"127.0.0.1\" , sub_port : int = 65533 , pub_port : int = 65534 , protocol : str = \"tcp\" , debug_logger : DiasysLogger = None , identifier : str = None ): \"\"\" Create a new service instance *(call this super constructor from your inheriting classes!)*. Args: domain (Union[str, Domain]): The domain(-name) of your service (or empty string, if domain-agnostic). If a domain(-name) is set, it will automatically filter out all messages from other domains. If no domain(-name) is set, messages from all domains will be received. sub_topic_domains (Dict[str, str]): change subscribed to topics to listen to a specific domain (e.g. 'erase'/append a domain for a specific topic) pub_topic_domains (Dict[str, str]): change published topics to a specific domain (e.g. 'erase'/append a domain for a specific topic) ds_host_addr (str): IP-address of the parent `DialogSystem` (default: localhost) sub_port (int): subscriber port following zmq's XSUB/XPUB pattern pub_port (int): publisher port following zmq's XSUB/XPUB pattern protocol (string): communication protocol with `DialogSystem` - has to match! Possible options: `tcp`, `inproc`, `ipc` debug_logger (DiasysLogger): If not `None`, all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the `DialogSystem` even if they are never forwarded (as expected) to your `Service`. identifier (str): Set this to a *UNIQUE* identifier per service to be run remotely. See `RemoteService` for more details. \"\"\" self . is_training = False self . domain = domain # get domain name (gets appended to all sub/pub topics so that different domain topics don't get shared) if domain is not None : self . _domain_name = domain . get_domain_name () if isinstance ( domain , Domain ) else domain else : self . _domain_name = \"\" self . _sub_topic_domains = sub_topic_domains self . _pub_topic_domains = pub_topic_domains # socket information self . _host_addr = ds_host_addr self . _sub_port = sub_port self . _pub_port = pub_port self . _protocol = protocol self . _identifier = identifier self . debug_logger = debug_logger self . _sub_topics = set () self . _pub_topics = set () self . _publish_sockets = dict () self . _internal_start_topics = dict () self . _internal_end_topics = dict () self . _internal_terminate_topics = dict () # NOTE: class name + memory pointer make topic unique (required, e.g. for running mutliple instances of same module!) self . _start_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /START\" self . _end_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /END\" self . _terminate_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /TERMINATE\" self . _train_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /TRAIN\" self . _eval_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /EVAL\" adviser.services.service.Service.dialog_end ( self ) This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/service.py 331 332 333 334 def dialog_end ( self ): \"\"\" This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. \"\"\" pass adviser.services.service.Service.dialog_exit ( self ) This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. Source code in adviser/services/service.py 336 337 338 339 def dialog_exit ( self ): \"\"\" This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. \"\"\" pass adviser.services.service.Service.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/service.py 326 327 328 329 def dialog_start ( self ): \"\"\" This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. \"\"\" pass adviser.services.service.Service.eval ( self ) Sets module to eval mode Source code in adviser/services/service.py 345 346 347 def eval ( self ): \"\"\" Sets module to eval mode \"\"\" self . is_training = False adviser.services.service.Service.get_all_published_topics ( self ) Returns: Type Description Set of all topics published to by this Service Source code in adviser/services/service.py 391 392 393 394 395 396 def get_all_published_topics ( self ): \"\"\" Returns: Set of all topics published to by this `Service` \"\"\" return copy . deepcopy ( self . _pub_topics ) adviser.services.service.Service.get_all_subscribed_topics ( self ) Returns: Type Description Set of all topics subscribed to by this Service Source code in adviser/services/service.py 384 385 386 387 388 389 def get_all_subscribed_topics ( self ): \"\"\" Returns: Set of all topics subscribed to by this `Service` \"\"\" return copy . deepcopy ( self . _sub_topics ) adviser.services.service.Service.run_standalone ( self , host_reg_port = 65535 ) Run this service as a standalone serivce (without a DialogSystem ) on a remote node. Use a RemoteService with corresponding identifier on the DialogSystem node to connect both. Note: this call is blocking! Parameters: Name Type Description Default host_reg_port int The port on the DialogSystem node listening for Service register requests 65535 Source code in adviser/services/service.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def run_standalone ( self , host_reg_port : int = 65535 ): \"\"\" Run this service as a standalone serivce (without a `DialogSystem`) on a remote node. Use a `RemoteService` with *corresponding identifier* on the `DialogSystem` node to connect both. Note: this call is blocking! Args: host_reg_port (int): The port on the `DialogSystem` node listening for `Service` register requests \"\"\" assert self . _identifier is not None , \"running a service on a remote node requires a unique identifier\" print ( \"Waiting for dialog system host...\" ) # send service info to dialog system node self . _init_pubsub () ctx = Context . instance () sync_endpoint = ctx . socket ( zmq . REQ ) sync_endpoint . connect ( f \"tcp:// { self . _host_addr } : { host_reg_port } \" ) data = pickle . dumps (( self . _domain_name , self . _sub_topics , self . _pub_topics , self . _start_topic , self . _end_topic , self . _terminate_topic )) sync_endpoint . send_multipart (( bytes ( f \"REGISTER_ { self . _identifier } \" , encoding = \"ascii\" ), data )) # wait for registration confirmation registered = False while not registered : msg = sync_endpoint . recv () msg = msg . decode ( \"utf-8\" ) if msg . startswith ( \"ACK_REGISTER_\" ): remote_service_identifier = msg [ len ( \"ACK_REGISTER_\" ):] if remote_service_identifier == self . _identifier : self . _register_with_dialogsystem () sync_endpoint . send_multipart ( ( bytes ( f \"CONF_REGISTER_ { self . _identifier } \" , encoding = \"ascii\" ), pickle . dumps ( True ))) registered = True print ( f \"Done\" ) adviser.services.service.Service.train ( self ) Sets module to training mode Source code in adviser/services/service.py 341 342 343 def train ( self ): \"\"\" Sets module to training mode \"\"\" self . is_training = True Functions adviser.services.service.PublishSubscribe ( sub_topics = [], pub_topics = [], queued_sub_topics = []) Decorator function for services. To be able to publish / subscribe to / from topics, your class is required to inherit from services.service.Service. Then, decorate any function you like. Your function will be called as soon as: * at least one message is received for each topic in sub_topics (only latest message will be forwarded, others dropped) * at least one message is received for each topic in queued_sub_topics (all messages since the previous function call will be forwarded as a list) Parameters: Name Type Description Default sub_topics(List[str or utils.topics.Topic] The topics you want to get the latest messages from. If multiple messages are received until your function is called, you will only receive the value of the latest message, previously received values will be discarded. required pub_topics(List[str or utils.topics.Topic] The topics you want to publish messages to. required queued_sub_topics(List[str or utils.topics.Topic] The topics you want to get all messages from. If multiple messages are received until your function is called, you will receive all values since the previous function call as a list. required Notes Subscription topic names have to match your function keywords Your function should return a dictionary with the keys matching your publish topics names and the value being any arbitrary python object or primitive type you want to send sub_topics and queued_sub_topics have to be disjoint! If you need timestamps for your messages, specify a 'timestamps' argument in your subscribing function. It will be filled by a dictionary providing timestamps for each received value, indexed by name. Technical notes: * Data will be automatically pickled / unpickled during send / receive to reduce meassage size. However, some python objects are not serializable (e.g. database connections) for good reasons and will throw an error if you try to publish them. * The domain name of your service class will be appended to your publish topics. Subscription topics are prefix-matched, so you will receive all messages from 'topic/suffix' if you subscibe to 'topic'. Source code in adviser/services/service.py 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 def PublishSubscribe ( sub_topics : List [ str ] = [], pub_topics : List [ str ] = [], queued_sub_topics : List [ str ] = []): \"\"\" Decorator function for services. To be able to publish / subscribe to / from topics, your class is required to inherit from services.service.Service. Then, decorate any function you like. Your function will be called as soon as: * at least one message is received for each topic in sub_topics (only latest message will be forwarded, others dropped) * at least one message is received for each topic in queued_sub_topics (all messages since the previous function call will be forwarded as a list) Args: sub_topics(List[str or utils.topics.Topic]): The topics you want to get the latest messages from. If multiple messages are received until your function is called, you will only receive the value of the latest message, previously received values will be discarded. pub_topics(List[str or utils.topics.Topic]): The topics you want to publish messages to. queued_sub_topics(List[str or utils.topics.Topic]): The topics you want to get all messages from. If multiple messages are received until your function is called, you will receive all values since the previous function call as a list. Notes: * Subscription topic names have to match your function keywords * Your function should return a dictionary with the keys matching your publish topics names and the value being any arbitrary python object or primitive type you want to send * sub_topics and queued_sub_topics have to be disjoint! * If you need timestamps for your messages, specify a 'timestamps' argument in your subscribing function. It will be filled by a dictionary providing timestamps for each received value, indexed by name. Technical notes: * Data will be automatically pickled / unpickled during send / receive to reduce meassage size. However, some python objects are not serializable (e.g. database connections) for good reasons and will throw an error if you try to publish them. * The domain name of your service class will be appended to your publish topics. Subscription topics are prefix-matched, so you will receive all messages from 'topic/suffix' if you subscibe to 'topic'. \"\"\" def wrapper ( func ): def delegate ( self , * args , ** kwargs ): func_inst = getattr ( self , func . __name__ ) callargs = list ( args ) if self in callargs : # remove self when in *args, because already known to function callargs . remove ( self ) result = func ( self , * callargs , ** kwargs ) if result : # fix! (user could have multiple \"/\" characters in topic - only use last one ) domains = { res . split ( \"/\" )[ 0 ]: res . split ( \"/\" )[ 1 ] if \"/\" in res else \"\" for res in result } result = { key . split ( \"/\" )[ 0 ]: result [ key ] for key in result } if func_inst not in self . _publish_sockets : # not a publisher, just normal function return result socket = self . _publish_sockets [ func_inst ] domain = self . _domain_name if socket and result : # publish messages for topic in pub_topics : # for topic in result: # NOTE publish any returned value in dict with it's key as topic if topic in result : domain = domain if domain else domains [ topic ] topic_domain_str = f \" { topic } / { domain } \" if domain else topic if topic in self . _pub_topic_domains : topic_domain_str = f \" { topic } / { self . _pub_topic_domains [ topic ] } \" if self . _pub_topic_domains [ topic ] else topic _send_msg ( socket , topic_domain_str , result [ topic ]) if self . debug_logger : self . debug_logger . info ( f \"- (DS): sent message from { func } to topic { topic_domain_str } : \\n { result [ topic ] } \" ) return result # declare function as publish / subscribe functions and attach the respective topics delegate . pubsub = True delegate . sub_topics = sub_topics delegate . queued_sub_topics = queued_sub_topics delegate . pub_topics = pub_topics # check arguments: is subsriber interested in timestamps? delegate . timestamp_enabled = 'timestamps' in inspect . getfullargspec ( func )[ 0 ] return delegate return wrapper adviser.services.simulator special This package contains the handcrafted user simulatod and related services. Modules adviser.services.simulator.emotion_simulator Classes adviser.services.simulator.emotion_simulator.EmotionSimulator Class which generates user emotion/engagements. Currently outputs either a user defined or random emotion/engagement level and was designed to test the affective services work correctly. However, in the future it could be extended to be more realistic. adviser.services.simulator.goal This module provides the Goal class and related stuff. Classes adviser.services.simulator.goal.Constraint The class for a constraint as used in the goal. Parameters: Name Type Description Default slot str The slot. required value str The value. required Methods adviser.services.simulator.goal.Constraint.__eq__ ( self , other ) special Constraint should be equal if the slot and value is the same. Source code in adviser/services/simulator/goal.py 42 43 44 45 46 47 def __eq__ ( self , other ): \"\"\"Constraint should be equal if the slot and value is the same.\"\"\" if isinstance ( other , Constraint ): return ( self . slot == other . slot and self . value == other . value ) return False adviser.services.simulator.goal.Goal The class representing a goal, therefore containing requests and constraints. Parameters: Name Type Description Default domain Domain The domain for which the goal will be instantiated. required parameters dict The parameters for the goal defined by a key=value mapping: 'MinVenues' required Methods adviser.services.simulator.goal.Goal.fulfill_request ( self , slot , value ) Fulfills a request, i.e. sets value for request slot . Parameters: Name Type Description Default slot str The request slot which will be filled. required value str The value the request slot will be filled with. required Source code in adviser/services/simulator/goal.py 282 283 284 285 286 287 288 289 290 291 292 def fulfill_request ( self , slot , value ): \"\"\" Fulfills a request, i.e. sets ``value`` for request ``slot``. Args: slot (str): The request slot which will be filled. value (str): The value the request slot will be filled with. \"\"\" if slot in self . requests : self . requests [ slot ] = value adviser.services.simulator.goal.Goal.get_constraint ( self , slot ) Gets the value for a given constraint slot . Parameters: Name Type Description Default slot str The constraint slot which will be looked up. required Returns: Type Description bool The constraint value . Source code in adviser/services/simulator/goal.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 def get_constraint ( self , slot ): \"\"\" Gets the value for a given constraint ``slot``. Args: slot (str): The constraint ``slot`` which will be looked up. Returns: bool: The constraint ``value``. \"\"\" for _constraint in self . constraints : if _constraint . slot == slot : return _constraint . value return 'dontcare' adviser.services.simulator.goal.Goal.init ( self , random_goal = True , constraints = None , requests = None ) Initializes a goal randomly OR using the given constraints and requests. Parameters: Name Type Description Default random_goal bool If True, a goal will be drawn randomly from available constraints True constraints List[Constraint] The constraints which will be used for the goal. None requests dict The requests which will be used for the goal. None Source code in adviser/services/simulator/goal.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def init ( self , random_goal = True , constraints = None , requests = None ): \"\"\" Initializes a goal randomly OR using the given constraints and requests. Args: random_goal (bool): If True, a goal will be drawn randomly from available constraints and requests (considering the parameters given in the constructor, if any). However if constraints and requests are given and both don't equal None, this parameter is considered as False. If False, the given constraints and requests are used. constraints (List[Constraint]): The constraints which will be used for the goal. requests (dict): The requests which will be used for the goal. \"\"\" # reset goal self . constraints = [] self . requests = {} self . excluded_inf_slot_values = { key : set () for key in self . inf_slot_values } # TODO implement possibility to pass either constraints or requests as a parameter if random_goal and constraints is None and requests is None : self . _init_random_goal () else : self . _init_from_parameters ( constraints , requests ) # make sure that primary key is always requested self . requests [ self . domain . get_primary_key ()] = None self . missing_informs = [ UserAct ( act_type = UserActionType . Inform , slot = _constraint . slot , value = _constraint . value ) for _constraint in self . constraints ] adviser.services.simulator.goal.Goal.is_fulfilled ( self ) Checks whether all requests have been fulfilled. Returns: Type Description bool True if all requests have been fulfilled, False otherwise. .. note:: Does not check whether the venue (issued by the system) fulfills the constraints since it's the system's task to give an appropriate venue by requesting the user's constraints. Source code in adviser/services/simulator/goal.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def is_fulfilled ( self ): \"\"\" Checks whether all requests have been fulfilled. Returns: bool: ``True`` if all requests have been fulfilled, ``False`` otherwise. .. note:: Does not check whether the venue (issued by the system) fulfills the constraints since it's the system's task to give an appropriate venue by requesting the user's constraints. \"\"\" for slot , value in self . requests . items (): assert slot != self . domain . get_primary_key () or value != 'none' # TODO remove later if value is None : return False return True adviser.services.simulator.goal.Goal.is_inconsistent_constraint ( self , constraint ) Checks whether the given constraint is consistent with the goal. A constraint is also consistent if it's value is 'dontcare' in the current goal. Parameters: Name Type Description Default constraint Constraint The constraint which will be checked for consistency. required Returns: Type Description bool True if values match or value in goal is 'dontcare', False otherwise. Source code in adviser/services/simulator/goal.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 def is_inconsistent_constraint ( self , constraint ): \"\"\" Checks whether the given constraint is consistent with the goal. A constraint is also consistent if it's value is 'dontcare' in the current goal. Args: constraint (Constraint): The constraint which will be checked for consistency. Returns: bool: True if values match or value in goal is 'dontcare', False otherwise. \"\"\" for _constraint in self . constraints : if _constraint . slot == constraint . slot and ( _constraint . value != constraint . value \\ and _constraint . value != 'dontcare' ): return True return False adviser.services.simulator.goal.Goal.is_inconsistent_constraint_strict ( self , constraint ) Checks whether the given constraint is strictly consistent with the goal, whereby 'dontcare' is treated as a different value (no match). Parameters: Name Type Description Default constraint Constraint The constraint which will be checked for consistency. required Returns: Type Description bool True if values match, False otherwise. .. seealso:: :func: is_inconsistent_constraint() Source code in adviser/services/simulator/goal.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 def is_inconsistent_constraint_strict ( self , constraint ): \"\"\" Checks whether the given constraint is strictly consistent with the goal, whereby 'dontcare' is treated as a different value (no match). Args: constraint (Constraint): The constraint which will be checked for consistency. Returns: bool: True if values match, False otherwise. .. seealso:: :func:`is_inconsistent_constraint()` \"\"\" for _constraint in self . constraints : if _constraint . slot == constraint . slot and _constraint . value == constraint . value : return False # here there are only two possibilities: the constraint is implicitly 'dontcare' because # it is not explicitly listed and the given constraint is either 1) 'dontcare' or 2) not return constraint . value != 'dontcare' adviser.services.simulator.goal.Goal.reset ( self ) Resets all requests of the goal. Source code in adviser/services/simulator/goal.py 252 253 254 255 def reset ( self ): \"\"\"Resets all requests of the goal.\"\"\" # reset goal -> empty all requests self . requests = dict . fromkeys ( self . requests ) adviser.services.simulator.goal.Goal.update_constraint ( self , slot , value ) Update a given constraint slot with value . Parameters: Name Type Description Default slot str The constraint slot which will be updated. required value str The value with which the constraint will be updated. required Returns: Type Description bool True if update was successful, i.e. the constraint slot is included in the goal, False otherwise. .. todo:: think about always setting a value Source code in adviser/services/simulator/goal.py 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 def update_constraint ( self , slot , value ): \"\"\" Update a given constraint ``slot`` with ``value``. Args: slot (str): The constraint *slot* which will be updated. value (str): The *value* with which the constraint will be updated. Returns: bool: ``True`` if update was successful, i.e. the constraint ``slot`` is included in the goal, ``False`` otherwise. .. todo:: think about always setting a value \"\"\" for _constraint in self . constraints : if _constraint . slot == slot : _constraint . value = value return True return False adviser.services.simulator.simulator This module provides the agenda-based user model for the handcrafted simulator. Classes adviser.services.simulator.simulator.Agenda A stack-like object representing an agenda. Actions can be pushed on and popped off the agenda. Methods adviser.services.simulator.simulator.Agenda.clean ( self , goal ) Cleans the agenda, i.e. makes sure that actions are consistent with goal and in the correct order. Parameters: Name Type Description Default goal Goal The goal which is needed to determine the consistent actions. required Source code in adviser/services/simulator/simulator.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 def clean ( self , goal : Goal ): \"\"\"Cleans the agenda, i.e. makes sure that actions are consistent with goal and in the correct order. Args: goal (Goal): The goal which is needed to determine the consistent actions. \"\"\" cleaned_stack = [] # reverse order since most recent actions are on top of agenda for action in self . stack [:: - 1 ]: if action not in cleaned_stack : # NOTE sufficient if there is only one slot per (request) action # remove accomplished requests if ( action . type is not UserActionType . Request or ( action . slot in goal . requests and goal . requests [ action . slot ] is None ) or action . slot not in goal . requests ): # make sure to remove \"old\" inform actions if action . type is UserActionType . Inform : if not goal . is_inconsistent_constraint ( Constraint ( action . slot , action . value )): cleaned_stack . insert ( 0 , action ) else : cleaned_stack . insert ( 0 , action ) self . stack = cleaned_stack adviser.services.simulator.simulator.Agenda.clear ( self ) Empties the agenda. Source code in adviser/services/simulator/simulator.py 766 767 768 def clear ( self ): \"\"\"Empties the agenda.\"\"\" self . stack . clear () adviser.services.simulator.simulator.Agenda.contains_action_of_type ( self , act_type , consider_dontcare = True ) Checks whether agenda contains actions of a specific type. Parameters: Name Type Description Default act_type UserActionType The action type (intent) for which the agenda will be checked. required consider_dontcare bool If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. True Returns: Type Description (bool) True if agenda contains act_type , False otherwise. Source code in adviser/services/simulator/simulator.py 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 def contains_action_of_type ( self , act_type : UserActionType , consider_dontcare = True ): \"\"\"Checks whether agenda contains actions of a specific type. Args: act_type (UserActionType): The action type (intent) for which the agenda will be checked. consider_dontcare (bool): If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. Returns: (bool): True if agenda contains *act_type*, False otherwise. \"\"\" for _action in self . stack : if not consider_dontcare and _action . value == 'dontcare' : continue if _action . type == act_type : return True return False adviser.services.simulator.simulator.Agenda.fill_with_constraints ( self , goal ) Adds all inform actions to the agenda necessary to fulfill the goal . Generally there is no need to add all constraints from the goal to the agenda apart from the initialisation. Parameters: Name Type Description Default goal Goal The current goal of the (simulated) user for which actions will be pushed to the required Source code in adviser/services/simulator/simulator.py 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 def fill_with_constraints ( self , goal : Goal ): \"\"\" Adds all inform actions to the agenda necessary to fulfill the *goal*. Generally there is no need to add all constraints from the goal to the agenda apart from the initialisation. Args: goal (Goal): The current goal of the (simulated) user for which actions will be pushed to the agenda. \"\"\" # add informs from goal for constraint in goal . constraints : self . stack . append ( UserAct ( act_type = UserActionType . Inform , slot = constraint . slot , value = constraint . value , score = 1.0 )) adviser.services.simulator.simulator.Agenda.fill_with_requests ( self , goal , exclude_name = True ) Adds all request actions to the agenda necessary to fulfill the goal . Parameters: Name Type Description Default goal Goal The current goal of the (simulated) user for which actions will be pushed to the agenda. required exclude_name bool whehter or not to include an action to request an entities name. True Source code in adviser/services/simulator/simulator.py 838 839 840 841 842 843 844 845 846 847 848 849 850 851 def fill_with_requests ( self , goal : Goal , exclude_name : bool = True ): \"\"\"Adds all request actions to the agenda necessary to fulfill the *goal*. Args: goal (Goal): The current goal of the (simulated) user for which actions will be pushed to the agenda. exclude_name (bool): whehter or not to include an action to request an entities name. \"\"\" # add requests and make sure to add the name at the end (i.e. ask first for name) for key , value in goal . requests . items (): if (( key != 'name' and exclude_name ) or not exclude_name ) and value is None : self . stack . append ( UserAct ( act_type = UserActionType . Request , slot = key , value = value , score = 1.0 )) adviser.services.simulator.simulator.Agenda.get_actions ( self , num_actions ) Retrieves num_actions actions from the agenda. Parameters: Name Type Description Default num_actions int Amount of actions which will be retrieved from the agenda. required Returns: Type Description (List[UserAct]) list of num_actions user actions. Source code in adviser/services/simulator/simulator.py 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def get_actions ( self , num_actions : int ): \"\"\"Retrieves *num_actions* actions from the agenda. Args: num_actions (int): Amount of actions which will be retrieved from the agenda. Returns: (List[UserAct]): list of *num_actions* user actions. \"\"\" if num_actions < 0 or num_actions > len ( self . stack ): num_actions = len ( self . stack ) return [ self . stack . pop () for _ in range ( 0 , num_actions )] adviser.services.simulator.simulator.Agenda.get_actions_of_type ( self , act_type =< enum 'UserActionType' > , consider_dontcare = True ) Get actions of a specific type from the agenda. Parameters: Name Type Description Default act_type UserActionType The action type (intent) for which the agenda will be checked. <enum 'UserActionType'> consider_dontcare bool If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. True Returns: Type Description (Iterable[UserAct]) A list of user actions of the given type/intent. Source code in adviser/services/simulator/simulator.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 def get_actions_of_type ( self , act_type = UserActionType , consider_dontcare = True ): \"\"\"Get actions of a specific type from the agenda. Args: act_type (UserActionType): The action type (intent) for which the agenda will be checked. consider_dontcare (bool): If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. Returns: (Iterable[UserAct]): A list of user actions of the given type/intent. \"\"\" return filter ( lambda x : x . type == act_type and ( consider_dontcare or x . value != 'dontcare' ), self . stack ) adviser.services.simulator.simulator.Agenda.init ( self , goal ) Initializes the agenda given a goal. For this purpose, inform actions for constraints in the goal and request actions for requests in the goal are added such that the informs are handled first followed by the requests. Parameters: Name Type Description Default goal Goal The goal for which the agenda will be initialized. required Source code in adviser/services/simulator/simulator.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def init ( self , goal ): \"\"\" Initializes the agenda given a goal. For this purpose, inform actions for constraints in the goal and request actions for requests in the goal are added such that the informs are handled first followed by the requests. Args: goal (Goal): The goal for which the agenda will be initialized. \"\"\" self . stack . clear () # populate agenda according to goal # NOTE don't push bye action here since bye action could be poppped with another (missing) # request, but user should not end dialog before having the goal fulfilled # NOTE do not add requests to agenda since system can't handle inform and request action in # same turn currently! # self.fill_with_requests(goal) self . fill_with_constraints ( goal ) adviser.services.simulator.simulator.Agenda.is_empty ( self ) Checks whether the agenda is empty. Returns: Type Description (bool) True if agenda is empty, False otherwise. Source code in adviser/services/simulator/simulator.py 770 771 772 773 774 775 776 777 def is_empty ( self ): \"\"\"Checks whether the agenda is empty. Returns: (bool): True if agenda is empty, False otherwise. \"\"\" return len ( self . stack ) == 0 adviser.services.simulator.simulator.Agenda.push ( self , item ) Pushes item onto the agenda. Parameters: Name Type Description Default item The goal for which the agenda will be initialized. required Source code in adviser/services/simulator/simulator.py 712 713 714 715 716 717 718 719 720 721 722 def push ( self , item ): \"\"\"Pushes *item* onto the agenda. Args: item: The goal for which the agenda will be initialized. \"\"\" if isinstance ( item , list ): self . stack += item else : self . stack . append ( item ) adviser.services.simulator.simulator.Agenda.remove_actions ( self , act_type , slot , value = None ) Removes actions of a specific type, slot and optionally value from the agenda. All arguments (value only if given) have to match in conjunction. Parameters: Name Type Description Default act_type UserActionType The action type (intent) which will be removed from the agenda. required slot str The action type (intent) which will be removed from the agenda. required value str The action type (intent) which will be removed from the agenda. None Source code in adviser/services/simulator/simulator.py 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 def remove_actions ( self , act_type : UserActionType , slot : str , value : str = None ): \"\"\"Removes actions of a specific type, slot and optionally value from the agenda. All arguments (value only if given) have to match in conjunction. Args: act_type (UserActionType): The action type (intent) which will be removed from the agenda. slot (str): The action type (intent) which will be removed from the agenda. value (str): The action type (intent) which will be removed from the agenda. \"\"\" if value is None : self . stack = list ( filter ( lambda x : x . type != act_type or x . slot != slot , self . stack )) else : self . stack = list ( filter ( lambda x : x . type != act_type or x . slot != slot or x . value != value , self . stack )) adviser.services.simulator.simulator.Agenda.remove_actions_of_type ( self , act_type ) Removes actions of a specific type from the agenda. Parameters: Name Type Description Default act_type UserActionType The action type (intent) which will be removed from the agenda. required Source code in adviser/services/simulator/simulator.py 813 814 815 816 817 818 819 820 def remove_actions_of_type ( self , act_type : UserActionType ): \"\"\"Removes actions of a specific type from the agenda. Args: act_type (UserActionType): The action type (intent) which will be removed from the agenda. \"\"\" self . stack = list ( filter ( lambda x : x . type != act_type , self . stack )) adviser.services.simulator.simulator.HandcraftedUserSimulator The class for a handcrafted (agenda-based) user simulator. !!! args domain (Domain): The domain for which the user simulator will be instantiated. It will use this domain to generate the goals. Methods adviser.services.simulator.simulator.HandcraftedUserSimulator.dialog_start ( self ) Resets the user model at the beginning of a dialog, e.g. draws a new goal and populates the agenda according to the goal. Source code in adviser/services/simulator/simulator.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def dialog_start ( self ): \"\"\"Resets the user model at the beginning of a dialog, e.g. draws a new goal and populates the agenda according to the goal.\"\"\" # self.goal = Goal(self.domain, self.parameters['goal']) self . goal . init () self . agenda . init ( self . goal ) if self . logger : self . logger . dialog_turn ( \"New goal has constraints {} and requests {} .\" . format ( self . goal . constraints , self . goal . requests )) self . logger . dialog_turn ( \"New agenda initialized: {} \" . format ( self . agenda )) # add hello action with some probability if common . random . random () < self . parameters [ 'usermodel' ][ 'Greeting' ]: self . agenda . push ( UserAct ( act_type = UserActionType . Hello , score = 1.0 )) # needed for possibility to reset patience if len ( self . parameters [ 'usermodel' ][ 'patience' ]) == 1 : self . dialog_patience = self . parameters [ 'usermodel' ][ 'patience' ][ 0 ] else : self . dialog_patience = common . random . randint ( * self . parameters [ 'usermodel' ][ 'patience' ]) self . patience = self . dialog_patience self . last_user_actions = None self . last_system_action = None self . excluded_venues = [] self . turn = 0 adviser.services.simulator.simulator.HandcraftedUserSimulator.receive ( self , sys_act ) This function makes sure that the agenda reflects all changes needed for the received system action. Parameters: Name Type Description Default sys_act SysAct The action the system took required Source code in adviser/services/simulator/simulator.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def receive ( self , sys_act : SysAct ): \"\"\" This function makes sure that the agenda reflects all changes needed for the received system action. Args: sys_act (SysAct): The action the system took \"\"\" if self . last_system_action is not None : # check whether system action is the same as before if sys_act == self . last_system_action : self . patience -= 1 elif self . parameters [ 'usermodel' ][ 'resetPatience' ]: self . patience = self . dialog_patience self . last_system_action = sys_act if self . patience == 0 : self . logger . dialog_turn ( \"User patience run out, ending dialog.\" ) self . agenda . clear () self . _finish_dialog ( ungrateful = True ) else : ignored_requests , ignored_requests_alt = self . _check_system_ignored_request ( self . last_user_actions , sys_act ) # first stage: push operations on top of agenda if sys_act . type in self . receive_options : self . receive_options [ sys_act . type ]( sys_act ) # handle missing requests if ignored_requests : # repeat unanswered requests from user from last turn self . agenda . push ( ignored_requests ) if ignored_requests_alt : self . agenda . push ( ignored_requests_alt ) # make sure to pick only the requestalt actions (should be 1) self . num_actions_next_turn = len ( ignored_requests_alt ) # make sure that old request actions verifying an offer are removed self . agenda . remove_actions_of_type ( act_type = UserActionType . Request ) # second stage: clean agenda self . agenda . clean ( self . goal ) # agenda might be empty -> add requests again if self . agenda . is_empty (): if self . goal . is_fulfilled (): self . _finish_dialog () else : self . agenda . fill_with_requests ( self . goal , exclude_name = False ) else : self . logger . error ( \"System Action Type is {} , but I don't know how to handle it!\" . format ( sys_act . type )) adviser.services.simulator.simulator.HandcraftedUserSimulator.respond ( self ) Gets n actions from the agenda, where n is drawn depending on the agenda or a pdf. Source code in adviser/services/simulator/simulator.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 def respond ( self ): \"\"\" Gets n actions from the agenda, where n is drawn depending on the agenda or a pdf. \"\"\" # get some actions from the agenda assert len ( self . agenda ) > 0 , \"Agenda is empty, this must not happen at this point!\" if self . num_actions_next_turn > 0 : # use and reset self.num_actions_next_turn if set num_actions = self . num_actions_next_turn self . num_actions_next_turn = - 1 elif self . agenda . stack [ - 1 ] . type == UserActionType . Bye : # pop all actions from agenda since agenda can only contain thanks (optional) and # bye action num_actions = - 1 else : # draw amount of actions num_actions = min ( len ( self . agenda ), common . numpy . random . choice ( [ 1 , 2 , 3 ], p = [ . 6 , . 3 , . 1 ])) # hardcoded pdf # get actions from agenda user_actions = self . agenda . get_actions ( num_actions ) # copy needed for repeat action since they might be changed in other modules self . last_user_actions = copy . deepcopy ( user_actions ) for action in user_actions : if action . type == UserActionType . Inform : _constraint = Constraint ( action . slot , action . value ) # if _constraint in self.goal.constraints: if action in self . goal . missing_informs : self . goal . missing_informs . remove ( action ) return user_actions adviser.services.stats special Modules adviser.services.stats.evaluation Classes adviser.services.stats.evaluation.ObjectiveReachedEvaluator Evaluate single turns and complete dialog. This class assigns a negative reward to each turn . In case the user ' s goal could be satisfied ( meaning a matching database entry was found ), a large final reward is returned . Only needed when training against a simulator . Methods adviser.services.stats.evaluation.ObjectiveReachedEvaluator.get_final_reward ( self , sim_goal , logging = True ) Check whether the user's goal was completed. Parameters: Name Type Description Default sim_goal Goal the simulation's goal required logging bool whether or not the evaluation results should be logged True Returns: Type Description Reward - the final reward (0 (unsuccessful) or 20 (successful)) Success - True or false Source code in adviser/services/stats/evaluation.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def get_final_reward ( self , sim_goal : Goal , logging = True ): \"\"\" Check whether the user's goal was completed. Args: sim_goal (Goal): the simulation's goal logging (bool): whether or not the evaluation results should be logged Returns: Reward - the final reward (0 (unsuccessful) or 20 (successful)) Success - True or false \"\"\" requests = sim_goal . requests constraints = sim_goal . constraints # list of constraints # self.logger.dialog_turn(\"User Goal > \" + str(sim_goal.constraints)) if None in requests . values () or requests [ 'name' ] == 'none' : if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False # TODO think about this more? if goals not satisfiable, # should system take the blame? not fair # print(requests['name']) db_matches = self . domain . find_info_about_entity ( entity_id = requests [ 'name' ], requested_slots = [ constraint . slot for constraint in constraints ]) if db_matches : match = db_matches [ 0 ] for const in constraints : if const . value != match [ const . slot ] and const . value != 'dontcare' : if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False if logging : self . logger . dialog_turn ( \"Success with user requests \\n {} \" . format ( requests )) return 20.0 , True if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False adviser.services.stats.evaluation.ObjectiveReachedEvaluator.get_turn_reward ( self ) Get the reward for one turn Returns: Type Description (int) the reward for the given turn Source code in adviser/services/stats/evaluation.py 46 47 48 49 50 51 52 53 def get_turn_reward ( self ): \"\"\" Get the reward for one turn Returns: (int): the reward for the given turn \"\"\" return self . turn_reward adviser.services.stats.evaluation.PolicyEvaluator Policy evaluation module Plug this module into the dialog graph (somewhere after the policy), and policy metrics like success rate and reward will be recorded. Methods adviser.services.stats.evaluation.PolicyEvaluator.__init__ ( self , domain , subgraph = None , use_tensorboard = False , experiment_name = '' , turn_reward =- 1 , success_reward = 20 , logger =< DiasysLogger adviser ( NOTSET ) > , summary_writer = None ) special Keyword Arguments: use_tensorboard {bool} -- [If true, metrics will be written to tensorboard in a runs directory] (default: {False}) experiment_name {str} -- [Name suffix for the log files] (default: {''}) turn_reward {float} -- [Reward for one turn - usually negative to penalize dialog length] (default: {-1}) success_reward {float} -- [Reward of the final transition if the dialog goal was reached] (default: {20}) Source code in adviser/services/stats/evaluation.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def __init__ ( self , domain : Domain , subgraph : dict = None , use_tensorboard = False , experiment_name : str = '' , turn_reward =- 1 , success_reward = 20 , logger : DiasysLogger = DiasysLogger (), summary_writer = None ): \"\"\" Keyword Arguments: use_tensorboard {bool} -- [If true, metrics will be written to tensorboard in a *runs* directory] (default: {False}) experiment_name {str} -- [Name suffix for the log files] (default: {''}) turn_reward {float} -- [Reward for one turn - usually negative to penalize dialog length] (default: {-1}) success_reward {float} -- [Reward of the final transition if the dialog goal was reached] (default: {20}) \"\"\" super ( PolicyEvaluator , self ) . __init__ ( domain ) self . logger = logger self . epoch = 0 self . evaluator = ObjectiveReachedEvaluator ( domain , turn_reward = turn_reward , success_reward = success_reward , logger = logger ) self . writer = summary_writer self . total_train_dialogs = 0 self . total_eval_dialogs = 0 self . epoch_train_dialogs = 0 self . epoch_eval_dialogs = 0 self . train_rewards = [] self . eval_rewards = [] self . train_success = [] self . eval_success = [] self . train_turns = [] self . eval_turns = [] self . is_training = False adviser.services.stats.evaluation.PolicyEvaluator.dialog_start ( self , dialog_start = False ) Clears the state of the evaluator in preparation to start a new dialog Source code in adviser/services/stats/evaluation.py 159 160 161 162 163 164 def dialog_start ( self , dialog_start = False ): \"\"\" Clears the state of the evaluator in preparation to start a new dialog \"\"\" self . dialog_reward = 0.0 self . dialog_turns = 0 adviser.services.stats.evaluation.PolicyEvaluator.end_epoch ( self ) Handles calculating statistics at the end of an epoch Source code in adviser/services/stats/evaluation.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def end_epoch ( self ): \"\"\" Handles calculating statistics at the end of an epoch \"\"\" if self . logger : if self . epoch_train_dialogs > 0 : self . logger . result ( \" ### Train ###\" ) self . logger . result ( \"# Num Dialogs \" + str ( self . epoch_train_dialogs )) self . logger . result ( \"# Avg Turns \" + str ( sum ( self . train_turns ) / self . epoch_train_dialogs )) self . logger . result ( \"# Avg Success \" + str ( sum ( self . train_success ) / self . epoch_train_dialogs )) self . logger . result ( \"# Avg Reward \" + str ( sum ( self . train_rewards ) / self . epoch_train_dialogs )) if self . epoch_eval_dialogs > 0 : self . logger . result ( \" ### Eval ###\" ) self . logger . result ( \"# Num Dialogs \" + str ( self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Turns \" + str ( sum ( self . eval_turns ) / self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Success \" + str ( sum ( self . eval_success ) / self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Reward \" + str ( sum ( self . eval_rewards ) / self . epoch_eval_dialogs )) if self . is_training : return { 'num_dialogs' : self . epoch_train_dialogs , 'turns' : sum ( self . train_turns ) / self . epoch_train_dialogs , 'success' : float ( sum ( self . train_success )) / self . epoch_train_dialogs , 'reward' : float ( sum ( self . eval_rewards )) / self . epoch_train_dialogs } else : return { 'num_dialogs' : self . epoch_eval_dialogs , 'turns' : sum ( self . eval_turns ) / self . epoch_eval_dialogs , 'success' : float ( sum ( self . eval_success )) / self . epoch_eval_dialogs , 'reward' : float ( sum ( self . eval_rewards )) / self . epoch_eval_dialogs } adviser.services.stats.evaluation.PolicyEvaluator.eval ( self ) sets teh evaluator in eval mode Source code in adviser/services/stats/evaluation.py 172 173 174 175 176 def eval ( self ): \"\"\" sets teh evaluator in eval mode \"\"\" self . is_training = False adviser.services.stats.evaluation.PolicyEvaluator.start_epoch ( self ) Handles resetting variables between epochs Source code in adviser/services/stats/evaluation.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 def start_epoch ( self ): \"\"\" Handles resetting variables between epochs \"\"\" # global statistics self . epoch_train_dialogs = 0 self . epoch_eval_dialogs = 0 self . train_rewards = [] self . eval_rewards = [] self . train_success = [] self . eval_success = [] self . train_turns = [] self . eval_turns = [] self . epoch += 1 self . logger . info ( \"### \\n ### EPOCH\" + str ( self . epoch ) + \" ### \\n ###\" ) adviser.services.stats.evaluation.PolicyEvaluator.train ( self ) sets the evaluator in train mode Source code in adviser/services/stats/evaluation.py 166 167 168 169 170 def train ( self ): \"\"\" sets the evaluator in train mode \"\"\" self . is_training = True adviser.services.ust special Modules adviser.services.ust.ust Classes adviser.services.ust.ust.HandcraftedUST A rule-based approach on user state tracking. Currently very minimalist Methods adviser.services.ust.ust.HandcraftedUST.dialog_start ( self ) Resets the user state so it is ready for a new dialog Source code in adviser/services/ust/ust.py 56 57 58 59 60 61 def dialog_start ( self ): \"\"\" Resets the user state so it is ready for a new dialog \"\"\" # initialize belief state self . us = UserState ()","title":"Services"},{"location":"api/services/#services","text":"","title":"Services"},{"location":"api/services/#adviser.services","text":"","title":"services"},{"location":"api/services/#modules","text":"","title":"Modules"},{"location":"api/services/#adviser.services.backchannel","text":"","title":"backchannel"},{"location":"api/services/#modules_1","text":"","title":"Modules"},{"location":"api/services/#adviser.services.backchannel.acoustic_backchanneller","text":"Classes adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller AcousticBackchanneller predicts a backchannel given the last user utterance. The model can predict: No backchannel (0), Assessment (1), Continuer (2) The backchannel realization is added in the NLG module. Methods adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller.load_model ( self ) The PyTorch Backchannel model is instantiated and the pretrained parameters are loaded. Source code in adviser/services/backchannel/acoustic_backchanneller.py 48 49 50 51 52 53 54 55 56 def load_model ( self ): \"\"\" The PyTorch Backchannel model is instantiated and the pretrained parameters are loaded. Returns: \"\"\" self . model = PytorchAcousticBackchanneler () self . model . load_state_dict ( torch . load ( self . trained_model_path )) self . model . eval () adviser.services.backchannel.acoustic_backchanneller.AcousticBackchanneller.split_input_data ( self , mfcc_features ) Preprocess and segmentation of MFCC features of the user's speech. Segmentation is done every 150ms without overlapping. Parameters: Name Type Description Default mfcc_features numpy.array mffcc features of users speech required Returns: Type Description new_data (list) segmented mfcc features Source code in adviser/services/backchannel/acoustic_backchanneller.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def split_input_data ( self , mfcc_features ): \"\"\" Preprocess and segmentation of MFCC features of the user's speech. Segmentation is done every 150ms without overlapping. Args: mfcc_features (numpy.array): mffcc features of users speech Returns: new_data (list): segmented mfcc features \"\"\" input_height = 150 # this stands for 150ms input_length = mfcc_features . shape [ 0 ] zero_shape = list ( mfcc_features . shape ) zero_shape [ 0 ] = input_height ranges = list ( reversed ([ idx for idx in range ( input_length - 1 , 0 , - input_height )])) new_data = [] for r in ranges : if r < input_height : zero_data = np . zeros ( zero_shape ) zero_data [ - r :, :] = mfcc_features [: r , :] new_data . append ( zero_data ) else : new_data . append ( mfcc_features [ r - input_height : r , :]) return ( new_data )","title":"acoustic_backchanneller"},{"location":"api/services/#adviser.services.backchannel.PytorchAcousticBackchanneler","text":"Classes adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler Class for defining the Deep Backchannel model in PyTorch Methods adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler.__init__ ( self , parameters = [], load_params = False ) special Defines the elements/layers of the neural network as well as loads the pretrained parameters The model is constituted by two parallel CNNs followed by a concatenation, a FFN and a softmax layer. Parameters: Name Type Description Default parameters list list of pre-trained parameters to be used for prediction [] load_params bool Bool to signal if params should be loaded False Source code in adviser/services/backchannel/PytorchAcousticBackchanneler.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , parameters : list = [], load_params : bool = False ): \"\"\" Defines the elements/layers of the neural network as well as loads the pretrained parameters The model is constituted by two parallel CNNs followed by a concatenation, a FFN and a softmax layer. Args: parameters (list): list of pre-trained parameters to be used for prediction load_params (bool): Bool to signal if params should be loaded \"\"\" super ( PytorchAcousticBackchanneler , self ) . __init__ () # First CNN cnn = nn . Conv2d ( in_channels = 1 , out_channels = 16 , kernel_size = ( 11 , 13 ), stride = ( 3 , 1 )) if load_params : weights = np . transpose ( parameters [ 0 ][ 0 ], ( 3 , 2 , 0 , 1 )) cnn . weight = torch . nn . Parameter ( torch . tensor ( weights ) . float ()) cnn . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 0 ][ 1 ]) . float ()) self . cnn1 = nn . Sequential ( cnn , nn . ReLU (), nn . MaxPool2d (( 23 , 1 )) ) # Second CNN cnn = nn . Conv2d ( in_channels = 1 , out_channels = 16 , kernel_size = ( 12 , 13 ), stride = ( 3 , 1 )) if load_params : weights = np . transpose ( parameters [ 1 ][ 0 ], ( 3 , 2 , 0 , 1 )) cnn . weight = torch . nn . Parameter ( torch . tensor ( weights ) . float ()) cnn . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 1 ][ 1 ]) . float ()) self . cnn2 = nn . Sequential ( cnn , nn . ReLU (), nn . MaxPool2d (( 23 , 1 )) ) # Linear layer self . linear1 = nn . Linear ( in_features = 64 , out_features = 100 ) if load_params : self . linear1 . weight = torch . nn . Parameter ( torch . tensor ( parameters [ 2 ][ 0 ] . T ) . float ()) self . linear1 . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 2 ][ 1 ]) . float ()) self . relu = nn . ReLU () self . dropout = nn . Dropout ( 0.5 ) # Softmax self . linear2 = nn . Linear ( in_features = 100 , out_features = 3 ) if load_params : self . linear2 . weight = torch . nn . Parameter ( torch . tensor ( parameters [ 3 ][ 0 ] . T ) . float ()) self . linear2 . bias = torch . nn . Parameter ( torch . tensor ( parameters [ 3 ][ 1 ]) . float ()) self . softmax = nn . Softmax ( dim = 1 ) adviser.services.backchannel.PytorchAcousticBackchanneler.PytorchAcousticBackchanneler.forward ( self , feat_inputs ) PyTorch forward method used for training and prediction. It defines the interaction between layers. Parameters: Name Type Description Default feat_inputs numpy array It contains the network's input. required Returns: Type Description out (torch.tensor) Network's output Source code in adviser/services/backchannel/PytorchAcousticBackchanneler.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def forward ( self , feat_inputs ): \"\"\" PyTorch forward method used for training and prediction. It defines the interaction between layers. Args: feat_inputs (numpy array): It contains the network's input. Returns: out (torch.tensor): Network's output \"\"\" feat_inputs = torch . tensor ( feat_inputs ) . float () feat_inputs = feat_inputs . unsqueeze ( 1 ) cnn_1 = self . cnn1 ( feat_inputs ) cnn_1 = cnn_1 . flatten ( 1 ) cnn_2 = self . cnn2 ( feat_inputs ) . flatten ( 1 ) out = torch . cat (( cnn_1 , cnn_2 ), 1 ) out = self . linear1 ( out ) out = self . relu ( out ) out = self . dropout ( out ) out = self . linear2 ( out ) out = self . softmax ( out ) return out","title":"PytorchAcousticBackchanneler"},{"location":"api/services/#adviser.services.bst","text":"","title":"bst"},{"location":"api/services/#modules_2","text":"","title":"Modules"},{"location":"api/services/#adviser.services.bst.bst","text":"Classes adviser.services.bst.bst.HandcraftedBST A rule-based approach to belief state tracking. Methods adviser.services.bst.bst.HandcraftedBST.dialog_start ( self ) Restets the belief state so it is ready for a new dialog Returns: Type Description (dict) a dictionary with a single entry where the key is 'beliefstate'and the value is a new BeliefState object Source code in adviser/services/bst/bst.py 69 70 71 72 73 74 75 76 77 78 def dialog_start ( self ): \"\"\" Restets the belief state so it is ready for a new dialog Returns: (dict): a dictionary with a single entry where the key is 'beliefstate'and the value is a new BeliefState object \"\"\" # initialize belief state self . bs = BeliefState ( self . domain )","title":"bst"},{"location":"api/services/#adviser.services.domain_tracker","text":"","title":"domain_tracker"},{"location":"api/services/#modules_3","text":"","title":"Modules"},{"location":"api/services/#adviser.services.domain_tracker.domain_tracker","text":"The console module provides ADVISER services for tracking current domain Classes adviser.services.domain_tracker.domain_tracker.DomainTracker Responsible for selecting which domain should be active at a given time. Current implmentation uses keywords to switch domains. Methods adviser.services.domain_tracker.domain_tracker.DomainTracker.dialog_start ( self ) Resets the domain tracker for the start of a new dialog Source code in adviser/services/domain_tracker/domain_tracker.py 40 41 42 43 44 45 def dialog_start ( self ): \"\"\" Resets the domain tracker for the start of a new dialog \"\"\" self . turn = 0 self . current_domain = None adviser.services.domain_tracker.domain_tracker.DomainTracker.domains_to_str ( self ) Method to create the greeting on the first turn, grammatically joins the names of possible domains into a string Returns: Type Description (str) String representing a list of all domain names the system can talk about Source code in adviser/services/domain_tracker/domain_tracker.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def domains_to_str ( self ): \"\"\" Method to create the greeting on the first turn, grammatically joins the names of possible domains into a string Returns: (str): String representing a list of all domain names the system can talk about \"\"\" if len ( self . domains ) == 1 : return self . domains [ 0 ] . get_display_name () elif len ( self . domains ) == 2 : return \" and \" . join ([ d . get_display_name () for d in self . domains ]) else : return \", \" . join ([ d . get_display_name () for d in self . domains ][: - 1 ]) + f \", and { self . domains [ - 1 ] . get_display_name () } \"","title":"domain_tracker"},{"location":"api/services/#adviser.services.emotion","text":"","title":"emotion"},{"location":"api/services/#modules_4","text":"","title":"Modules"},{"location":"api/services/#adviser.services.emotion.EmotionRecognition","text":"Emotion recognition module. Classes adviser.services.emotion.EmotionRecognition.EmotionRecognition Emotion recognition module. This module receives acoustic features, loads pretrained models and outputs predictions of emotional states. It can easily be extended/adapted to use different models and facial features in addition. Methods adviser.services.emotion.EmotionRecognition.EmotionRecognition.__init__ ( self ) special Emotion recognition module. On initialization all necessary models are loaded. Source code in adviser/services/emotion/EmotionRecognition.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self ): \"\"\" Emotion recognition module. On initialization all necessary models are loaded. \"\"\" Service . __init__ ( self ) self . emotion_dir = os . path . dirname ( os . path . abspath ( __file__ )) self . model_path = os . path . abspath ( os . path . join ( self . emotion_dir , \"..\" , \"..\" , \"resources\" , \"models\" , \"emotion\" ) ) def load_args ( emo_representation ): arg_dict = pickle . load ( open ( os . path . join ( self . model_path , f ' { emo_representation } _args.pkl' ), 'rb' ) ) return arg_dict def load_model ( emo_representation , arg_dict ): ARGS = arg_dict [ 'args' ] model = cnn ( kernel_size = ( ARGS . height , arg_dict [ 'D_in' ]), D_out = arg_dict [ 'D_out' ], args = ARGS ) model . load_state_dict ( torch . load ( os . path . join ( self . model_path , f ' { emo_representation } _model_params.pt' ), map_location = torch . device ( 'cpu' ) ) ) model . eval () return model self . emo_representations = [ 'category' , 'arousal' , 'valence' ] self . models = {} self . args = {} for emo_representation in self . emo_representations : self . args [ emo_representation ] = load_args ( emo_representation ) self . models [ emo_representation ] = load_model ( emo_representation , self . args [ emo_representation ] ) self . arousal_mapping = { 0 : 'low' , 1 : 'medium' , 2 : 'high' } self . valence_mapping = { 0 : 'negative' , 1 : 'neutral' , 2 : 'positive' } self . category_mapping = { 0 : EmotionType . Angry , 1 : EmotionType . Happy , 2 : EmotionType . Neutral , 3 : EmotionType . Sad }","title":"EmotionRecognition"},{"location":"api/services/#adviser.services.engagement","text":"","title":"engagement"},{"location":"api/services/#modules_5","text":"","title":"Modules"},{"location":"api/services/#adviser.services.engagement.engagement_tracker","text":"Classes adviser.services.engagement.engagement_tracker.EngagementTracker Start feature extraction with OpenFace. Requires OpenFace to be installed - instructions can be found in tool/openface.txt Methods adviser.services.engagement.engagement_tracker.EngagementTracker.__init__ ( self , domain = '' , camera_id = 0 , openface_port = 6004 , delay = 2 , identifier = None ) special Parameters: Name Type Description Default camera_id int index of the camera you want to use (if you only have one camera: 0) 0 Source code in adviser/services/engagement/engagement_tracker.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , domain = \"\" , camera_id : int = 0 , openface_port : int = 6004 , delay : int = 2 , identifier = None ): \"\"\" Args: camera_id: index of the camera you want to use (if you only have one camera: 0) \"\"\" Service . __init__ ( self , domain = \"\" , identifier = identifier ) self . camera_id = camera_id self . openface_port = openface_port self . openface_running = False self . threshold = delay # provide number of seconds as parameter, one second = 15 frames ctx = Context . instance () self . openface_endpoint = ctx . socket ( zmq . PAIR ) self . openface_endpoint . bind ( f \"tcp://127.0.0.1: { self . openface_port } \" ) startExtraction = f \" { os . path . join ( get_root_dir (), 'tools/OpenFace/build/bin/FaceLandmarkVidZMQ' ) } -device { self . camera_id } -port 6004\" # todo config open face port self . p_openface = subprocess . Popen ( startExtraction . split (), stdout = subprocess . PIPE ) # start OpenFace self . extracting = False self . extractor_thread = None adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_end ( self ) This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/engagement/engagement_tracker.py 145 146 147 148 149 def dialog_end ( self ): # Set openface to non-publishing mode and wait until it is ready self . openface_endpoint . send ( bytes ( f \"OPENFACE_END\" , encoding = \"ascii\" )) if self . extractor_thread : self . extractor_thread . join () adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_exit ( self ) This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. Source code in adviser/services/engagement/engagement_tracker.py 151 152 153 def dialog_exit ( self ): # close openface process self . p_openface . kill () adviser.services.engagement.engagement_tracker.EngagementTracker.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/engagement/engagement_tracker.py 69 70 71 72 73 74 75 76 77 78 79 80 def dialog_start ( self ): # Set openface to publishing mode and wait until it is ready self . openface_endpoint . send ( bytes ( f \"OPENFACE_START\" , encoding = \"ascii\" )) self . extracting = False while not self . extracting : msg = self . openface_endpoint . recv () # receive started signal msg = msg . decode ( \"utf-8\" ) if msg == \"OPENFACE_STARTED\" : print ( \"START EXTRACTION\" ) self . extracting = True self . extractor_thread = Thread ( target = self . publish_gaze_directions ) self . extractor_thread . start () adviser.services.engagement.engagement_tracker.EngagementTracker.publish_gaze_directions ( self ) Meant to be used in a thread. Runs an inifinte loop polling features from OpenFace library, parsing them and extracting engagement features. Calls yield_gaze_direction to publish the polled and processed engagement features. Source code in adviser/services/engagement/engagement_tracker.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def publish_gaze_directions ( self ): \"\"\" Meant to be used in a thread. Runs an inifinte loop polling features from OpenFace library, parsing them and extracting engagement features. Calls `yield_gaze_direction` to publish the polled and processed engagement features. \"\"\" x_coordinates = [] y_coordinates = [] norm = 0.0 # center point of screen; should be close(r) to 0 looking = True while self . extracting : req = self . openface_endpoint . send ( bytes ( f \"OPENFACE_PULL\" , encoding = \"ascii\" )) msg = self . openface_endpoint . recv () try : msg = msg . decode ( \"utf-8\" ) if msg == \"OPENFACE_ENDED\" : self . extracting = False msg_data = json . loads ( msg ) gaze_x = msg_data [ \"gaze\" ][ \"angle\" ][ \"x\" ] gaze_y = msg_data [ \"gaze\" ][ \"angle\" ][ \"y\" ] gaze_x = sqrt ( gaze_x ** 2 ) # gaze_angle_x (left-right movement), square + root is done to yield only positive values gaze_y = sqrt ( gaze_y ** 2 ) # gaze_angle_y (up-down movement) x_coordinates . append ( gaze_x ) y_coordinates . append ( gaze_y ) current = ( len ( x_coordinates )) - 1 if current > self . threshold : previous_x = mean ( x_coordinates [ current - ( self . threshold + 1 ): current ]) # obtain the average of previous frames previous_y = mean ( y_coordinates [ current - ( self . threshold + 1 ): current ]) difference_x = sqrt (( norm - previous_x ) ** 2 ) # compare current frame to average of previous frames difference_y = sqrt (( norm - previous_y ) ** 2 ) # print(difference_x, difference_y) if difference_x < 0.15 and difference_y < 0.15 : # check whether difference between current and previous frames exceeds certain threshold (regulates tolerance/strictness) if looking != True : looking = True self . yield_gaze_direction ( engagement = EngagementType . High , gaze_direction = ( gaze_x , gaze_y )) else : if looking != False : looking = False self . yield_gaze_direction ( engagement = EngagementType . Low , gaze_direction = ( gaze_x , gaze_y )) except : # import traceback # traceback.print_exc() pass","title":"engagement_tracker"},{"location":"api/services/#adviser.services.hci","text":"","title":"hci"},{"location":"api/services/#modules_6","text":"","title":"Modules"},{"location":"api/services/#adviser.services.hci.console","text":"The console module provides ADVISER modules that access the console for input and output. Classes adviser.services.hci.console.ConsoleInput Gets the user utterance from the console. Waits for the built-in input function to return a non-empty text. Methods adviser.services.hci.console.ConsoleInput.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/hci/console.py 48 49 def dialog_start ( self ): self . interaction_count = 0 adviser.services.hci.console.ConsoleOutput Writes the system utterance to the console.","title":"console"},{"location":"api/services/#adviser.services.hci.gui","text":"Classes adviser.services.hci.gui.GUIServer Service for the React-based Web-UI. Run this as a remote service: * run this file seperately, will start the GUI Server * run the dialog system in another python instance, add a RemoteService with identifier GUIServer","title":"gui"},{"location":"api/services/#adviser.services.hci.speech","text":"Modules adviser.services.hci.speech.cleaners This file is derived from https://github.com/keithito/tacotron. Functions adviser.services.hci.speech.cleaners.basic_cleaners ( text ) Basic pipeline that lowercases and collapses whitespace without transliteration. Source code in adviser/services/hci/speech/cleaners.py 208 209 210 211 212 def basic_cleaners ( text ): \"\"\"Basic pipeline that lowercases and collapses whitespace without transliteration.\"\"\" text = lowercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.custom_english_cleaners ( text ) Custom pipeline for English text, including number and abbreviation expansion. Source code in adviser/services/hci/speech/cleaners.py 254 255 256 257 258 259 260 261 262 263 264 265 266 def custom_english_cleaners ( text ): \"\"\"Custom pipeline for English text, including number and abbreviation expansion.\"\"\" text = convert_to_ascii ( text ) text = expand_email ( text ) text = expand_acronym ( text ) text = lowercase ( text ) text = expand_numbers ( text ) text = expand_abbreviations ( text ) text = expand_symbols ( text ) text = remove_unnecessary_symbols ( text ) text = uppercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.english_cleaners ( text ) Pipeline for English text, including number and abbreviation expansion. Source code in adviser/services/hci/speech/cleaners.py 223 224 225 226 227 228 229 230 def english_cleaners ( text ): \"\"\"Pipeline for English text, including number and abbreviation expansion.\"\"\" text = convert_to_ascii ( text ) text = lowercase ( text ) text = expand_numbers ( text ) text = expand_abbreviations ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.cleaners.expand_abbreviations ( text ) Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 137 138 139 140 141 142 143 144 145 def expand_abbreviations ( text ): \"\"\" Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for regex , replacement in _abbreviations : text = re . sub ( regex , replacement , text ) return text adviser.services.hci.speech.cleaners.expand_acronym ( text ) Preprocesses a text to turn acronyms into forms that the TTS can pronounce properly text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 171 172 173 174 175 176 177 178 179 def expand_acronym ( text ): \"\"\" Preprocesses a text to turn acronyms into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for word , replacement in _acronym : text = re . sub ( word , replacement , text ) return text adviser.services.hci.speech.cleaners.normalize_numbers ( text ) Normalizes numbers in an utterance as preparation for TTS text (string): Text to be preprocessed Source code in adviser/services/hci/speech/cleaners.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def normalize_numbers ( text ): \"\"\" Normalizes numbers in an utterance as preparation for TTS text (string): Text to be preprocessed \"\"\" text = re . sub ( _comma_number_re , _remove_commas , text ) text = re . sub ( _pounds_re , r '\\1 pounds' , text ) text = re . sub ( _dollars_re , _expand_dollars , text ) text = re . sub ( _decimal_number_re , _expand_decimal_point , text ) text = re . sub ( _ordinal_re , _expand_ordinal , text ) text = re . sub ( _ID_number_re , _expand_ID_number , text ) text = re . sub ( _number_re , _expand_number , text ) return text adviser.services.hci.speech.cleaners.transliteration_cleaners ( text ) Pipeline for non-English text that transliterates to ASCII. Source code in adviser/services/hci/speech/cleaners.py 215 216 217 218 219 220 def transliteration_cleaners ( text ): \"\"\"Pipeline for non-English text that transliterates to ASCII.\"\"\" text = convert_to_ascii ( text ) text = lowercase ( text ) text = collapse_whitespace ( text ) return text adviser.services.hci.speech.FeatureExtractor Feature extraction with openSMILE. This module provides a feature extractor which uses the openSMILE toolkit to extract features from raw audio. The user utterance which is represented as a numpy array in-memory needs to be written to a temporary file first, so that openSMILE can read it. Classes adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor SpeechFeatureExtractor calls openSMILE to extract features from audio. Note : openSMILE will be downloaded & compiled to tools / opensmile if not found there .","title":"speech"},{"location":"api/services/#methods","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.__init__","text":"SpeechFeatureExtractor. The following things are setup on initialization: * directory for temporary audio files * path to openSMILE config files * path to openSMILE executable Source code in adviser/services/hci/speech/FeatureExtractor.py 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self ): \"\"\" SpeechFeatureExtractor. The following things are setup on initialization: * directory for temporary audio files * path to openSMILE config files * path to openSMILE executable \"\"\" Service . __init__ ( self ) self . speech_out_dir = os . path . join ( \"resources\" , \"tmp_audio_and_features\" ) self . cfg_dir = os . path . join ( \"resources\" , \"opensmile_config\" ) self . openSmile_path = get_opensmile_executable_path ()","title":"__init__()"},{"location":"api/services/#adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.extract_wav_file_features","text":"Extracting acoustic features using openSMILE. Parameters: Name Type Description Default features str path to openSMILE's feature config required new_audio_file str path to audio file required Returns: Type Description numpy.ndarray extracted features for the audio file Source code in adviser/services/hci/speech/FeatureExtractor.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def extract_wav_file_features ( self , features , new_audio_file ): \"\"\"Extracting acoustic features using openSMILE. Args: features (str): path to openSMILE's feature config new_audio_file (str): path to audio file Returns: numpy.ndarray: extracted features for the audio file \"\"\" output_file = new_audio_file + '.csv' config_file = os . path . join ( self . cfg_dir , features + \".conf\" ) f = open ( os . devnull , 'w' ) try : # OpenSMILE command to extract features # SMILExtract -C <configfile> -I <input_file> \u2212O <output_file> command = ' ' . join ([ self . openSmile_path , '-C' , config_file , '-I' , new_audio_file , '-csvoutput' , output_file , '-headercsv' , '0' , '-timestampcsv' , '0' , '-instname' , '0' ]) subprocess . call ( command , stdout = f , stderr = f , shell = True ) return self . preprocess_csv ( output_file ) except OSError as err : print ( command ) print ( \"OS error: {0} \" . format ( err ))","title":"extract_wav_file_features()"},{"location":"api/services/#adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.preprocess_csv","text":"Get features from csv file and normalize them if necessary. openSMILE feature are written to temporary csv file. This function reads them into a numpy array, removes instance names and could do a normalization step if needed. This is not implemented right now. Parameters: Name Type Description Default csv_file str path to csv file required Returns: Type Description numpy.ndarray raw feature values Source code in adviser/services/hci/speech/FeatureExtractor.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def preprocess_csv ( self , csv_file ): \"\"\"Get features from csv file and normalize them if necessary. openSMILE feature are written to temporary csv file. This function reads them into a numpy array, removes instance names and could do a normalization step if needed. This is not implemented right now. Args: csv_file (str): path to csv file Returns: numpy.ndarray: raw feature values \"\"\" feats = np . genfromtxt ( csv_file , delimiter = ';' ) if len ( feats . shape ) == 1 : # reshape one-dimensional features, e.g. gemaps feats = feats . reshape ( 1 , - 1 ) # take everything except first column which is the instance name feats = feats [:, 1 :] # StandardScaler normalizes feats to zero mean and unit variance # for frame-wise LLDs, it will standardize across frames # for gemaps (or functionals in general), it's not possible to scale # ideal setup: fit StandardScaler on training set across samples # and apply it with .transform() to new samples # scaler = preprocessing.StandardScaler() self . remove_file ( csv_file ) return feats","title":"preprocess_csv()"},{"location":"api/services/#adviser.services.hci.speech.FeatureExtractor.SpeechFeatureExtractor.remove_file","text":"Remove specified file. Parameters: Name Type Description Default file_name str full path of file which shall be removed required Source code in adviser/services/hci/speech/FeatureExtractor.py 94 95 96 97 98 99 100 101 102 103 104 def remove_file ( self , file_name ): \"\"\" Remove specified file. Args: file_name (str): full path of file which shall be removed \"\"\" try : os . remove ( file_name ) except FileNotFoundError as error : self . logger . error ( error ) raise ( error ) adviser.services.hci.speech.speech_utility Utility for the emotion recognition script that needs the utterance a s file Functions adviser.services.hci.speech.speech_utility.delete_file ( filepath ) Deletes the file at the given path to clean up the audio file once it's not needed anymore. This is why unique filenames are important. filepath (string): path to the file that is to be deleted Source code in adviser/services/hci/speech/speech_utility.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def delete_file ( filepath ): \"\"\" Deletes the file at the given path to clean up the audio file once it's not needed anymore. This is why unique filenames are important. filepath (string): path to the file that is to be deleted \"\"\" if os . path . exists ( filepath ): os . remove ( filepath ) else : print ( \"The file cannot be deleted, as it was not found. \" \"Please check the provided path for errors: \\n {} \" . format ( filepath )) adviser.services.hci.speech.speech_utility.sound_array_to_file ( filepath , sampling_rate , sound_as_array ) Saves the recording of the recorder to a file Turns the audio from the recorder service into a wav file for processing with opensmile c++ scripts filepath (string): full path, including filename and .wav suffix at an arbitrary location. Careful: python takes paths as relative to the main script. The name should be unique, to ensure files don't get mixed up if there are multiple calls in short time and one file might get overwriteen or deleted before it's done being processed. sampling_rate (int): the sampling rate of the audio, as published by the recorder sound_as_array (np.array): the audio in form of an array as published by the recorder Source code in adviser/services/hci/speech/speech_utility.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def sound_array_to_file ( filepath , sampling_rate , sound_as_array ): \"\"\" Saves the recording of the recorder to a file Turns the audio from the recorder service into a wav file for processing with opensmile c++ scripts filepath (string): full path, including filename and .wav suffix at an arbitrary location. Careful: python takes paths as relative to the main script. The name should be unique, to ensure files don't get mixed up if there are multiple calls in short time and one file might get overwriteen or deleted before it's done being processed. sampling_rate (int): the sampling rate of the audio, as published by the recorder sound_as_array (np.array): the audio in form of an array as published by the recorder \"\"\" librosa . output . write_wav ( filepath , sound_as_array , sampling_rate ) adviser.services.hci.speech.SpeechInputDecoder Classes adviser.services.hci.speech.SpeechInputDecoder.SpeechInputDecoder","title":"remove_file()"},{"location":"api/services/#methods_1","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.SpeechInputDecoder.SpeechInputDecoder.__init__","text":"Transforms spoken input from the user to text for further processing. Parameters: Name Type Description Default domain Domain Needed for Service, but has no meaning here '' identifier string Needed for Service None conversation_log_dir str If this is provided, logfiles will be placed by this Service into the specified directory. None use_cuda boolean Whether or not to run the computations on a GPU False Source code in adviser/services/hci/speech/SpeechInputDecoder.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , domain : Domain = \"\" , identifier = None , conversation_log_dir : str = None , use_cuda = False ): \"\"\" Transforms spoken input from the user to text for further processing. Args: domain (Domain): Needed for Service, but has no meaning here identifier (string): Needed for Service conversation_log_dir (string): If this is provided, logfiles will be placed by this Service into the specified directory. use_cuda (boolean): Whether or not to run the computations on a GPU \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir # load model model_dir = os . path . join ( get_root_dir (), \"resources\" , \"models\" , \"speech\" , \"multi_en_20190916\" ) self . model , conf = load_trained_model ( os . path . join ( model_dir , \"model.bin\" )) self . vocab = conf . char_list # setup beam search self . bs = BeamSearch ( scorers = self . model . scorers (), weights = { \"decoder\" : 1.0 , \"ctc\" : 0.0 }, sos = self . model . sos , eos = self . model . eos , beam_size = 4 , vocab_size = len ( self . vocab ), pre_beam_score_key = \"decoder\" ) self . bs . __class__ = BatchBeamSearch # choose hardware to run on if use_cuda : self . device = \"cuda\" else : self . device = \"cpu\" self . model . to ( self . device ) self . bs . to ( self . device ) # change from training mode to eval mode self . model . eval () self . bs . eval () # scale and offset for feature normalization # follows https://github.com/kaldi-asr/kaldi/blob/33255ed224500f55c8387f1e4fa40e08b73ff48a/src/transform/cmvn.cc#L92-L111 norm = torch . load ( os . path . join ( model_dir , \"cmvn.bin\" )) count = norm [ 0 ][ - 1 ] mean = norm [ 0 ][: - 1 ] / count var = ( norm [ 1 ][: - 1 ] / count ) - mean * mean self . scale = 1.0 / torch . sqrt ( var ) self . offset = - ( mean * self . scale ) adviser.services.hci.speech.SpeechInputFeatureExtractor Classes adviser.services.hci.speech.SpeechInputFeatureExtractor.SpeechInputFeatureExtractor","title":"__init__()"},{"location":"api/services/#methods_2","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.SpeechInputFeatureExtractor.SpeechInputFeatureExtractor.__init__","text":"Given a sound, this service extracts features and passes them on to the decoder for ASR Parameters: Name Type Description Default domain Domain Needed for Service, no meaning here '' Source code in adviser/services/hci/speech/SpeechInputFeatureExtractor.py 32 33 34 35 36 37 38 39 def __init__ ( self , domain : Domain = \"\" ): \"\"\" Given a sound, this service extracts features and passes them on to the decoder for ASR Args: domain (Domain): Needed for Service, no meaning here \"\"\" Service . __init__ ( self , domain = domain ) adviser.services.hci.speech.SpeechOutputGenerator Classes adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator","title":"__init__()"},{"location":"api/services/#methods_3","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator.__init__","text":"Text To Speech Module that reads out the system utterance. Parameters: Name Type Description Default domain Domain Needed for Service, no meaning here '' identifier str Needed for Service None use_cuda boolean Whether or not to perform computations on GPU. Highly recommended if available False sub_topic_domains Dict[str, str] Needed for Service TODO: (<-- is it really or can we get rid of it?) {} Source code in adviser/services/hci/speech/SpeechOutputGenerator.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , domain : Domain = \"\" , identifier : str = None , use_cuda = False , sub_topic_domains : Dict [ str , str ] = {}): \"\"\" Text To Speech Module that reads out the system utterance. Args: domain (Domain): Needed for Service, no meaning here identifier (string): Needed for Service use_cuda (boolean): Whether or not to perform computations on GPU. Highly recommended if available sub_topic_domains: Needed for Service TODO: (<-- is it really or can we get rid of it?) \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier , sub_topic_domains = sub_topic_domains ) self . models_directory = os . path . join ( get_root_dir (), \"resources\" , \"models\" , \"speech\" ) # The following lines can be changed to incorporate different models. # This is the only thing that needs to be changed for that, everything else should be dynamic. self . transcription_type = \"phn\" self . dict_path = os . path . join ( self . models_directory , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"data\" , \"lang_1phn\" , \"train_no_dev_units.txt\" ) self . model_path = os . path . join ( self . models_directory , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"exp\" , \"phn_train_no_dev_pytorch_train_fastspeech.v4\" , \"results\" , \"model.last1.avg.best\" ) self . vocoder_path = os . path . join ( self . models_directory , \"ljspeech.parallel_wavegan.v1\" , \"checkpoint-400000steps.pkl\" ) self . vocoder_conf = os . path . join ( self . models_directory , \"ljspeech.parallel_wavegan.v1\" , \"config.yml\" ) # define device to run the synthesis on if use_cuda : self . device = torch . device ( \"cuda\" ) else : self . device = torch . device ( \"cpu\" ) # define end to end TTS model self . input_dimensions , self . output_dimensions , self . train_args = get_model_conf ( self . model_path ) model_class = dynamic_import . dynamic_import ( self . train_args . model_module ) model = model_class ( self . input_dimensions , self . output_dimensions , self . train_args ) torch_load ( self . model_path , model ) self . model = model . eval () . to ( self . device ) self . inference_args = Namespace ( ** { \"threshold\" : 0.5 , \"minlenratio\" : 0.0 , \"maxlenratio\" : 10.0 }) # define neural vocoder with open ( self . vocoder_conf ) as vocoder_config_file : self . config = yaml . load ( vocoder_config_file , Loader = yaml . Loader ) vocoder = ParallelWaveGANGenerator ( ** self . config [ \"generator_params\" ]) vocoder . load_state_dict ( torch . load ( self . vocoder_path , map_location = \"cpu\" )[ \"model\" ][ \"generator\" ]) vocoder . remove_weight_norm () self . vocoder = vocoder . eval () . to ( self . device ) with open ( self . dict_path ) as dictionary_file : lines = dictionary_file . readlines () lines = [ line . replace ( \" \\n \" , \"\" ) . split ( \" \" ) for line in lines ] self . char_to_id = { c : int ( i ) for c , i in lines } self . g2p = G2p () # download the pretrained Punkt tokenizer from NLTK. This is done only # the first time the code is executed on a machine, if it has been done # before, this line will be skipped and output a warning. We will probably # redirect warnings into a file rather than std_err in the future, since # there's also a lot of pytorch warnings going on etc. nltk . download ( 'punkt' , quiet = True )","title":"__init__()"},{"location":"api/services/#adviser.services.hci.speech.SpeechOutputGenerator.SpeechOutputGenerator.preprocess_text_input","text":"Clean the text and then convert it to id sequence. Parameters: Name Type Description Default text string The text to preprocess required Source code in adviser/services/hci/speech/SpeechOutputGenerator.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def preprocess_text_input ( self , text ): \"\"\" Clean the text and then convert it to id sequence. Args: text (string): The text to preprocess \"\"\" text = custom_english_cleaners ( text ) # cleans the text if self . transcription_type == \"phn\" : # depending on the model type, different preprocessing is needed. text = filter ( lambda s : s != \" \" , self . g2p ( text )) text = \" \" . join ( text ) char_sequence = text . split ( \" \" ) else : char_sequence = list ( text ) id_sequence = [] for c in char_sequence : if c . isspace (): id_sequence += [ self . char_to_id [ \"<space>\" ]] elif c not in self . char_to_id . keys (): id_sequence += [ self . char_to_id [ \"<unk>\" ]] else : id_sequence += [ self . char_to_id [ c ]] id_sequence += [ self . input_dimensions - 1 ] # <eos> return torch . LongTensor ( id_sequence ) . view ( - 1 ) . to ( self . device ) adviser.services.hci.speech.SpeechOutputPlayer Classes adviser.services.hci.speech.SpeechOutputPlayer.SpeechOutputPlayer","title":"preprocess_text_input()"},{"location":"api/services/#methods_4","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.SpeechOutputPlayer.SpeechOutputPlayer.__init__","text":"Service that plays the system utterance as sound Parameters: Name Type Description Default domain Domain Needed for Service, but has no meaning here '' conversation_log_dir str If this is provided it will create log files in the specified directory. None identifier str Needed for Service. None Source code in adviser/services/hci/speech/SpeechOutputPlayer.py 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , domain : Domain = \"\" , conversation_log_dir : str = None , identifier : str = None ): \"\"\" Service that plays the system utterance as sound Args: domain (Domain): Needed for Service, but has no meaning here conversation_log_dir (string): If this is provided it will create log files in the specified directory. identifier (string): Needed for Service. \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir self . interaction_count = 0 adviser.services.hci.speech.SpeechRecorder Classes adviser.services.hci.speech.SpeechRecorder.SpeechRecorder","title":"__init__()"},{"location":"api/services/#methods_5","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.__init__","text":"A service that can record a microphone upon a key pressing event and publish the result as an array. The end of the utterance is detected automatically, also the voice can be masked to alleviate privacy issues. Parameters: Name Type Description Default domain Union[str, utils.domain.domain.Domain] I don't know why this is here. Service needs it, but it means nothing in this context. '' conversation_log_dir str If this parameter is given, log files of the conversation will be created in this directory None enable_plotting bool If this is set to True, the recorder is no longer real time able and thus the recordings don't work properly. This is just to be used to tune the threshold for the end of utterance detection, not during deployment. False threshold int The threshold below which the assumption of the end of utterance detection is silence 8000 voice_privacy bool Whether or not to enable the masking of the users voice False identifier str I don't know why this is here. Service needs it. None Source code in adviser/services/hci/speech/SpeechRecorder.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def __init__ ( self , domain : Union [ str , Domain ] = \"\" , conversation_log_dir : str = None , enable_plotting : bool = False , threshold : int = 8000 , voice_privacy : bool = False , identifier : str = None ) -> None : \"\"\" A service that can record a microphone upon a key pressing event and publish the result as an array. The end of the utterance is detected automatically, also the voice can be masked to alleviate privacy issues. Args: domain (Domain): I don't know why this is here. Service needs it, but it means nothing in this context. conversation_log_dir (string): If this parameter is given, log files of the conversation will be created in this directory enable_plotting (boolean): If this is set to True, the recorder is no longer real time able and thus the recordings don't work properly. This is just to be used to tune the threshold for the end of utterance detection, not during deployment. threshold (int): The threshold below which the assumption of the end of utterance detection is silence voice_privacy (boolean): Whether or not to enable the masking of the users voice identifier (string): I don't know why this is here. Service needs it. \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) self . conversation_log_dir = conversation_log_dir self . recording_indicator = False self . audio_interface = pyaudio . PyAudio () self . push_to_talk_listener = keyboard . Listener ( on_press = self . start_recording ) self . threshold = threshold self . enable_plotting = enable_plotting self . voice_privacy = voice_privacy","title":"__init__()"},{"location":"api/services/#adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.start_recorder","text":"Starts the listener and outputs that the speech recorder is ready for use Source code in adviser/services/hci/speech/SpeechRecorder.py 137 138 139 140 141 142 143 def start_recorder ( self ): \"\"\" Starts the listener and outputs that the speech recorder is ready for use \"\"\" self . push_to_talk_listener . start () print ( \"To speak to the system, tap your right [CTRL] or [CMD] key. \\n \" \"It will try to automatically detect when your utterance is over. \\n \" )","title":"start_recorder()"},{"location":"api/services/#adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.start_recording","text":"This method is a callback of the push to talk key listener. It calls the recorder, if it's not already recording. Parameters: Name Type Description Default key Key The pressed key required Source code in adviser/services/hci/speech/SpeechRecorder.py 126 127 128 129 130 131 132 133 134 135 def start_recording ( self , key ): \"\"\" This method is a callback of the push to talk key listener. It calls the recorder, if it's not already recording. Args: key (Key): The pressed key \"\"\" if ( key is keyboard . Key . cmd_r or key is keyboard . Key . ctrl_r ) and not self . recording_indicator : self . record_user_utterance ()","title":"start_recording()"},{"location":"api/services/#adviser.services.hci.speech.SpeechRecorder.SpeechRecorder.threshold_plotter_generator","text":"Generates a plotter to visualize when the signal is above the set threshold Returns: Type Description function Plots the threshold with the current continuous waveform Source code in adviser/services/hci/speech/SpeechRecorder.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def threshold_plotter_generator ( self ): \"\"\" Generates a plotter to visualize when the signal is above the set threshold Returns: function: Plots the threshold with the current continuous waveform \"\"\" import matplotlib matplotlib . use ( 'TkAgg' ) plt . figure ( figsize = ( 10 , 2 )) plt . axhline ( y = self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . axhline ( y =- self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . pause ( 0.000000000001 ) def threshold_plotter ( data ): plt . clf () plt . tight_layout () plt . axis ([ 0 , len ( data ), - 20000 , 20000 ]) plt . plot ( data , color = 'b' ) plt . axhline ( y = self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . axhline ( y =- self . threshold , xmin = 0.0 , xmax = 1.0 , color = 'r' ) plt . pause ( 0.000000000001 ) return threshold_plotter Functions adviser.services.hci.speech.SpeechRecorder.voice_sanitizer ( audio ) While this is by no means a good voice sanitizer, it works as a proof of concept. It randomly shifts the spectrogram of a speakers utterance up or down, making automatic speaker identification much harder while keeping impact on asr performance as low as possible. The use should be turned off by default. Parameters: Name Type Description Default audio np.array The audio represented as array required Returns: Type Description np.array The mutated audio as array Source code in adviser/services/hci/speech/SpeechRecorder.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def voice_sanitizer ( audio ): \"\"\" While this is by no means a good voice sanitizer, it works as a proof of concept. It randomly shifts the spectrogram of a speakers utterance up or down, making automatic speaker identification much harder while keeping impact on asr performance as low as possible. The use should be turned off by default. Args: audio (np.array): The audio represented as array Returns: np.array: The mutated audio as array \"\"\" spectrogram = librosa . stft ( audio ) voice_shift = np . random . randint ( 3 , 6 ) if np . random . choice ([ True , False ]): for frequency_index , _ in enumerate ( spectrogram ): # mutate the voice to be higher try : spectrogram [ len ( spectrogram ) - ( frequency_index + 1 )] = spectrogram [ len ( spectrogram ) - ( frequency_index + 1 + voice_shift )] except IndexError : pass else : for frequency_index , _ in enumerate ( spectrogram ): # mutate the voice to be lower try : spectrogram [ frequency_index ] = spectrogram [ frequency_index + voice_shift ] except IndexError : pass return librosa . istft ( spectrogram )","title":"threshold_plotter_generator()"},{"location":"api/services/#adviser.services.hci.video","text":"Modules adviser.services.hci.video.FeatureExtractor Feature extraction with openSMILE Classes adviser.services.hci.video.FeatureExtractor.VideoFeatureExtractor TODO adviser.services.hci.video.VideoInput Classes adviser.services.hci.video.VideoInput.VideoInput Captures frames with a specified capture interval between two consecutive dialog turns and returns a list of frames.","title":"video"},{"location":"api/services/#methods_6","text":"","title":"Methods"},{"location":"api/services/#adviser.services.hci.video.VideoInput.VideoInput.__init__","text":"Parameters: Name Type Description Default camera_id int device id (if only 1 camera device is connected, id is 0, if two are connected choose between 0 and 1, ...) 0 capture_interval int try to capture a frame every x microseconds - is a lower bound, no hard time guarantees (e.g. 5e5 -> every >= 0.5 seconds) 1000000.0 Source code in adviser/services/hci/video/VideoInput.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , domain = None , camera_id : int = 0 , capture_interval : int = 10e5 , identifier : str = None ): \"\"\" Args: camera_id (int): device id (if only 1 camera device is connected, id is 0, if two are connected choose between 0 and 1, ...) capture_interval (int): try to capture a frame every x microseconds - is a lower bound, no hard time guarantees (e.g. 5e5 -> every >= 0.5 seconds) \"\"\" Service . __init__ ( self , domain , identifier = identifier ) self . cap = cv2 . VideoCapture ( camera_id ) # get handle to camera device if not self . cap . isOpened (): self . cap . open () # open self . terminating = Event () self . terminating . clear () self . capture_thread = Thread ( target = self . capture ) # create thread object for capturing self . capture_interval = capture_interval","title":"__init__()"},{"location":"api/services/#adviser.services.hci.video.VideoInput.VideoInput.capture","text":"Continuous video capture, meant to be run in a loop. Calls publish_img once per interval tick to publish the captured image. Source code in adviser/services/hci/video/VideoInput.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def capture ( self ): \"\"\" Continuous video capture, meant to be run in a loop. Calls `publish_img` once per interval tick to publish the captured image. \"\"\" while self . cap . isOpened () and not self . terminating . isSet (): start_time = datetime . datetime . now () # Capture frame-by-frame # cap.read() returns a bool (true when frame was read correctly) ret , frame = self . cap . read () # Our operations on the frame come here if ret : # rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) self . publish_img ( rgb_img = frame ) end_time = datetime . datetime . now () time_diff = end_time - start_time wait_seconds = ( self . capture_interval - time_diff . microseconds ) * 1e-6 # note: time to wait for next capture to match specified sampling rate in seconds if wait_seconds > 0.0 : time . sleep ( wait_seconds ) if self . cap . isOpened (): self . cap . release ()","title":"capture()"},{"location":"api/services/#adviser.services.hci.video.VideoInput.VideoInput.dialog_end","text":"This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/hci/video/VideoInput.py 76 77 def dialog_end ( self ): self . terminating . set ()","title":"dialog_end()"},{"location":"api/services/#adviser.services.hci.video.VideoInput.VideoInput.dialog_start","text":"This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/hci/video/VideoInput.py 79 80 81 82 def dialog_start ( self ): if not self . capture_thread . is_alive (): print ( \"Starting video capture...\" ) self . capture_thread . start ()","title":"dialog_start()"},{"location":"api/services/#adviser.services.nlg","text":"","title":"nlg"},{"location":"api/services/#modules_7","text":"","title":"Modules"},{"location":"api/services/#adviser.services.nlg.affective_nlg","text":"Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.services.nlg.affective_nlg.HandcraftedEmotionNLG A child of the HandcraftedNLG, the HandcraftedEmotionNLG can choose between multiple affective response templates for each sys_act dependingon the current sys_emotion","title":"affective_nlg"},{"location":"api/services/#adviser.services.nlg.bc_nlg","text":"Handcrafted (i.e. template-based) Natural Language Generation Module with backchannel Classes adviser.services.nlg.bc_nlg.BackchannelHandcraftedNLG Handcrafted (i.e. template-based) Natural Language Generation Module A rule - based approach on natural language generation . The rules have to be specified within a template file using the ADVISER NLG syntax . Python methods that are called within a template file must be specified in the HandcraftedNLG class by using the prefix \"_template_\" . For example , the method \"_template_genitive_s\" can be accessed in the template file via calling { genitive_s ( name ) } !!! attributes domain ( Domain ) : the domain template_filename ( str ) : the NLG template filename templates ( TemplateFile ) : the parsed and ready - to - go NLG template file template_english ( str ) : the name of the English NLG template file template_german ( str ) : the name of the German NLG template file language ( Language ) : the language of the dialogue","title":"bc_nlg"},{"location":"api/services/#adviser.services.nlg.nlg","text":"Handcrafted (i.e. template-based) Natural Language Generation Module Classes adviser.services.nlg.nlg.HandcraftedNLG Handcrafted (i.e. template-based) Natural Language Generation Module A rule - based approach on natural language generation . The rules have to be specified within a template file using the ADVISER NLG syntax . Python methods that are called within a template file must be specified in the HandcraftedNLG class by using the prefix \"_template_\" . For example , the method \"_template_genitive_s\" can be accessed in the template file via calling { genitive_s ( name ) } !!! attributes domain ( Domain ) : the domain template_filename ( str ) : the NLG template filename templates ( TemplateFile ) : the parsed and ready - to - go NLG template file template_english ( str ) : the name of the English NLG template file template_german ( str ) : the name of the German NLG template file language ( Language ) : the language of the dialogue Methods adviser.services.nlg.nlg.HandcraftedNLG.__init__ ( self , domain , template_file = None , sub_topic_domains = {}, logger =< DiasysLogger adviser ( NOTSET ) > , template_file_german = None , language = None ) special Constructor mainly extracts methods and rules from the template file Source code in adviser/services/nlg/nlg.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , domain : Domain , template_file : str = None , sub_topic_domains : Dict [ str , str ] = {}, logger : DiasysLogger = DiasysLogger (), template_file_german : str = None , language : Language = None ): \"\"\"Constructor mainly extracts methods and rules from the template file\"\"\" Service . __init__ ( self , domain = domain , sub_topic_domains = sub_topic_domains ) self . language = language if language else Language . ENGLISH self . template_english = template_file # TODO: at some point if we expand languages, maybe make kwargs? --LV self . template_german = template_file_german self . domain = domain self . template_filename = None self . templates = None self . logger = logger self . language = Language . ENGLISH self . _initialise_language ( self . language ) adviser.services.nlg.nlg.HandcraftedNLG.generate_system_utterance ( self , sys_act = None ) Main function of the NLG module Takes a system act, searches for a fitting rule, applies it and returns the message. Overwrite this function if you inherit from the NLG module. Parameters: Name Type Description Default sys_act SysAct The system act None Returns: Type Description str The utterance generated by applying a fitting template Source code in adviser/services/nlg/nlg.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def generate_system_utterance ( self , sys_act : SysAct = None ) -> str : \"\"\"Main function of the NLG module Takes a system act, searches for a fitting rule, applies it and returns the message. Overwrite this function if you inherit from the NLG module. Args: sys_act (SysAct): The system act Returns: The utterance generated by applying a fitting template \"\"\" rule_found = True message = \"\" try : message = self . templates . create_message ( sys_act ) except BaseException as error : rule_found = False self . logger . error ( error ) raise ( error ) # inform if no applicable rule could be found in the template file if not rule_found : self . logger . info ( 'Could not find a fitting rule for the given system act!' ) self . logger . info ( \"System Action: \" + str ( sys_act . type ) + \" - Slots: \" + str ( sys_act . slot_values )) # self.logger.dialog_turn(\"System Action: \" + message) return message","title":"nlg"},{"location":"api/services/#adviser.services.nlg.templates","text":"Modules adviser.services.nlg.templates.templatefile Classes adviser.services.nlg.templates.templatefile.TemplateFile Interprets a template file !!! attributes global_memory {GlobalMemory} -- memory that can be accessed at all times in the tempaltes","title":"templates"},{"location":"api/services/#methods_7","text":"","title":"Methods"},{"location":"api/services/#adviser.services.nlg.templates.templatefile.TemplateFile.add_python_function","text":"Add a python function to the global memory of the template file interpreter Keyword Arguments: obligatory_arguments {List[object]} -- objects that are always passed as first arguments to the python function, e.g. \"self\" (default: {[]}) Source code in adviser/services/nlg/templates/templatefile.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def add_python_function ( self , function_name : str , python_function : Callable [[ object ], str ], obligatory_arguments : List [ object ] = []): \"\"\"Add a python function to the global memory of the template file interpreter Arguments: function_name {str} -- name under which the function can be accessed in template file python_function {Callable[[object], str]} -- python function which is called when being accessed in the template file Keyword Arguments: obligatory_arguments {List[object]} -- objects that are always passed as first arguments to the python function, e.g. \"self\" (default: {[]}) \"\"\" self . global_memory . add_function ( PythonFunction ( function_name , python_function , obligatory_arguments ))","title":"add_python_function()"},{"location":"api/services/#adviser.services.nlg.templates.templatefile.TemplateFile.create_message","text":"Iterates through all possible templates and applies the first one to fit the system act Exceptions: Type Description BaseException when no template could be applied Returns: Type Description str str -- the message returned by the template Source code in adviser/services/nlg/templates/templatefile.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def create_message ( self , sys_act : SysAct ) -> str : \"\"\"Iterates through all possible templates and applies the first one to fit the system act Arguments: sys_act {SysAct} -- the system act to find a template for Raises: BaseException: when no template could be applied Returns: str -- the message returned by the template \"\"\" slots = self . _create_memory_from_sys_act ( sys_act ) for template in self . _templates [ sys_act . type . value ]: if template . is_applicable ( slots ): return template . apply ( slots ) raise BaseException ( 'No template was found for the given system act.' )","title":"create_message()"},{"location":"api/services/#adviser.services.nlu","text":"","title":"nlu"},{"location":"api/services/#modules_8","text":"","title":"Modules"},{"location":"api/services/#adviser.services.nlu.nlu","text":"Classes adviser.services.nlu.nlu.HandcraftedNLU Class for Handcrafted Natural Language Understanding Module (HDC-NLU). HDC-NLU is a rule-based approach to recognize the user acts as well as their respective slots and values from the user input (i.e. text) by means of regular expressions. HDC-NLU is domain-independet. The regular expressions of are read from JSON files. There exist a JSON file that stores general rules (GeneralRules.json), i.e. rules that apply to any domain, e.g. rules to detect salutation (Hello, Hi). There are two more files per domain that contain the domain-specific rules for request and inform user acts, e.g. ImsCoursesInformRules.json and ImsCoursesRequestRules.json. The output during dialog interaction of this module is a semantic representation of the user input. \"I am looking for pizza\" --> inform(slot=food,value=italian) See the regex_generator under tools, if the existing regular expressions need to be changed or a new domain should be added. Methods adviser.services.nlu.nlu.HandcraftedNLU.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > , language = None ) special Loads - domain key - informable slots - requestable slots - domain-independent regular expressions - domain-specific regualer espressions It sets the previous system act to None Source code in adviser/services/nlu/nlu.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , domain : JSONLookupDomain , logger : DiasysLogger = DiasysLogger (), language : Language = None ): \"\"\" Loads - domain key - informable slots - requestable slots - domain-independent regular expressions - domain-specific regualer espressions It sets the previous system act to None Args: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain \"\"\" Service . __init__ ( self , domain = domain ) self . logger = logger self . language = language if language else Language . ENGLISH # Getting domain information self . domain_name = domain . get_domain_name () self . domain_key = domain . get_primary_key () # Getting lists of informable and requestable slots self . USER_INFORMABLE = domain . get_informable_slots () self . USER_REQUESTABLE = domain . get_requestable_slots () # Getting the relative path where regexes are stored self . base_folder = os . path . join ( get_root_dir (), 'resources' , 'nlu_regexes' ) # Setting previous system act to None to signal the first turn # self.prev_sys_act = None self . sys_act_info = { 'last_act' : None , 'lastInformedPrimKeyVal' : None , 'lastRequestSlot' : None } self . language = Language . ENGLISH self . _initialize () adviser.services.nlu.nlu.HandcraftedNLU.start_dialog ( self ) Sets the previous system act as None. This function is called when the dialog starts Returns: Type Description dict Empty dictionary Source code in adviser/services/nlu/nlu.py 390 391 392 393 394 395 396 397 398 399 400 def start_dialog ( self ) -> dict : \"\"\" Sets the previous system act as None. This function is called when the dialog starts Returns: Empty dictionary \"\"\" self . sys_act_info = { 'last_act' : None , 'lastInformedPrimKeyVal' : None , 'lastRequestSlot' : None }","title":"nlu"},{"location":"api/services/#adviser.services.policy","text":"","title":"policy"},{"location":"api/services/#modules_9","text":"","title":"Modules"},{"location":"api/services/#adviser.services.policy.affective_policy","text":"Classes adviser.services.policy.affective_policy.EmotionPolicy Module for deciding what type of emotional response/ engagement level of response, the system should give Methods adviser.services.policy.affective_policy.EmotionPolicy.__init__ ( self , domain = None , logger =< DiasysLogger adviser ( NOTSET ) > ) special Initializes the policy Parameters: Name Type Description Default domain JSONLookupDomain the domain that the affective policy should operate in None Source code in adviser/services/policy/affective_policy.py 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , domain : JSONLookupDomain = None , logger : DiasysLogger = DiasysLogger ()): \"\"\" Initializes the policy Arguments: domain (JSONLookupDomain): the domain that the affective policy should operate in \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . logger = logger adviser.services.policy.affective_policy.EmotionPolicy.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/affective_policy.py 46 47 def dialog_start ( self ): pass","title":"affective_policy"},{"location":"api/services/#adviser.services.policy.policy_api","text":"Classes adviser.services.policy.policy_api.HandcraftedPolicy Handcrafted policy for API domains Differs from the default HandcraftedPolicy class by taking into account mandatory slots, i.e. slots which have to be informed about before an API can even be called. The class is currently a copy of an older version of the HandcraftedPolicy class with the required changes for API usage. The classes will probably be merged in the future. Methods adviser.services.policy.policy_api.HandcraftedPolicy.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > ) special Initializes the policy Source code in adviser/services/policy/policy_api.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def __init__ ( self , domain : LookupDomain , logger : DiasysLogger = DiasysLogger ()): \"\"\" Initializes the policy Arguments: domain {domain.lookupdomain.LookupDomain} -- Domain \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . last_action = None self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation self . domain_key = domain . get_primary_key () self . logger = logger adviser.services.policy.policy_api.HandcraftedPolicy.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/policy_api.py 124 125 126 127 128 def dialog_start ( self ): self . first_turn = True self . last_action = None self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation","title":"policy_api"},{"location":"api/services/#adviser.services.policy.policy_handcrafted","text":"Classes adviser.services.policy.policy_handcrafted.HandcraftedPolicy Base class for handcrafted policies. Provides a simple rule-based policy. Can be used for any domain where a user is trying to find an entity (eg. a course from a module handbook) from a database by providing constraints (eg. semester the course is offered) or where a user is trying to find out additional information about a named entity. Output is a system action such as: * inform : provides information on an entity * request : request more information from the user * bye : issue parting message and end dialog In order to create your own policy, you can inherit from this class. Make sure to overwrite the choose_sys_act -method with whatever additionally rules/functionality required. Methods adviser.services.policy.policy_handcrafted.HandcraftedPolicy.__init__ ( self , domain , logger =< DiasysLogger adviser ( NOTSET ) > , max_turns = 25 ) special Initializes the policy Source code in adviser/services/policy/policy_handcrafted.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , domain : JSONLookupDomain , logger : DiasysLogger = DiasysLogger (), max_turns : int = 25 ): \"\"\" Initializes the policy Arguments: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain \"\"\" self . first_turn = True Service . __init__ ( self , domain = domain ) self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation self . domain_key = domain . get_primary_key () self . logger = logger self . max_turns = max_turns adviser.services.policy.policy_handcrafted.HandcraftedPolicy.dialog_start ( self ) resets the policy after each dialog Source code in adviser/services/policy/policy_handcrafted.py 68 69 70 71 72 73 74 75 def dialog_start ( self ): \"\"\" resets the policy after each dialog \"\"\" self . turns = 0 self . first_turn = True self . current_suggestions = [] # list of current suggestions self . s_index = 0 # the index in current suggestions for the current system reccomendation","title":"policy_handcrafted"},{"location":"api/services/#adviser.services.policy.rl","text":"Modules adviser.services.policy.rl.dqn Classes adviser.services.policy.rl.dqn.DQN Simple Deep Q-Network","title":"rl"},{"location":"api/services/#methods_8","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.dqn.DQN.__init__","text":"Initialize a DQN Network with an arbitrary amount of linear hidden layers Source code in adviser/services/policy/rl/dqn.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self , state_dim : int , action_dim : int , hidden_layer_sizes : List [ int ] = [ 300 , 300 ], dropout_rate : float = 0.0 ): \"\"\" Initialize a DQN Network with an arbitrary amount of linear hidden layers \"\"\" super ( DQN , self ) . __init__ () print ( \"Architecture: DQN\" ) self . dropout_rate = dropout_rate # create layers self . layers = nn . ModuleList () current_input_dim = state_dim for layer_size in hidden_layer_sizes : self . layers . append ( nn . Linear ( current_input_dim , layer_size )) self . layers . append ( nn . ReLU ()) if dropout_rate > 0.0 : self . layers . append ( nn . Dropout ( p = dropout_rate )) current_input_dim = layer_size # output layer self . layers . append ( nn . Linear ( current_input_dim , action_dim ))","title":"__init__()"},{"location":"api/services/#adviser.services.policy.rl.dqn.DQN.forward","text":"Forward pass: calculate Q(state) for all actions Parameters: Name Type Description Default state_batch FloatTensor tensor of size batch_size x state_dim required Returns: Type Description output tensor of size batch_size x action_dim Source code in adviser/services/policy/rl/dqn.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def forward ( self , state_batch : torch . FloatTensor ): \"\"\" Forward pass: calculate Q(state) for all actions Args: state_batch (torch.FloatTensor): tensor of size batch_size x state_dim Returns: output: tensor of size batch_size x action_dim \"\"\" output = state_batch for layer in self . layers : output = layer ( output ) return output adviser.services.policy.rl.dqn.DuelingDQN Dueling DQN network architecture Splits network into value- and advantage stream (V(s) and A(s,a)), recombined in final layer to form Q-value again: Q(s,a) = V(s) + A(s,a).","title":"forward()"},{"location":"api/services/#methods_9","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.dqn.DuelingDQN.forward","text":"Forward pass: calculate Q(state) for all actions Parameters: Name Type Description Default input torch.FloatTensor tensor of size batch_size x state_dim required Returns: Type Description tensor of size batch_size x action_dim Source code in adviser/services/policy/rl/dqn.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def forward ( self , state_batch : torch . FloatTensor ): \"\"\" Forward pass: calculate Q(state) for all actions Args: input (torch.FloatTensor): tensor of size batch_size x state_dim Returns: tensor of size batch_size x action_dim \"\"\" shared_output = state_batch # shared layer representation for layer in self . shared_layers : shared_output = layer ( shared_output ) # value stream value_stream = shared_output for layer in self . value_layers : value_stream = layer ( value_stream ) # advantage stream advantage_stream = shared_output for layer in self . advantage_layers : advantage_stream = layer ( advantage_stream ) # combine value and advantage streams into Q values result = value_stream + advantage_stream - advantage_stream . mean () return result adviser.services.policy.rl.dqn.NetArchitecture Network architecture for DQN vanilla: normal MLP dueling: splits network into value- and advantage stream, recombined in final layer adviser.services.policy.rl.dqnpolicy Classes adviser.services.policy.rl.dqnpolicy.DQNPolicy","title":"forward()"},{"location":"api/services/#methods_10","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.__init__","text":"Parameters: Name Type Description Default target_update_rate int if 1, vanilla dqn update if > 1, double dqn with specified target update rate 3 Source code in adviser/services/policy/rl/dqnpolicy.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def __init__ ( self , domain : JSONLookupDomain , architecture : NetArchitecture = NetArchitecture . DUELING , hidden_layer_sizes : List [ int ] = [ 256 , 700 , 700 ], # vanilla architecture shared_layer_sizes : List [ int ] = [ 256 ], value_layer_sizes : List [ int ] = [ 300 , 300 ], advantage_layer_sizes : List [ int ] = [ 400 , 400 ], # dueling architecture lr : float = 0.0001 , discount_gamma : float = 0.99 , target_update_rate : int = 3 , replay_buffer_size : int = 8192 , batch_size : int = 64 , buffer_cls : Type [ Buffer ] = NaivePrioritizedBuffer , eps_start : float = 0.3 , eps_end : float = 0.0 , l2_regularisation : float = 0.0 , gradient_clipping : float = 5.0 , p_dropout : float = 0.0 , training_frequency : int = 2 , train_dialogs : int = 1000 , include_confreq : bool = False , logger : DiasysLogger = DiasysLogger (), max_turns : int = 25 , summary_writer : SummaryWriter = None , device = torch . device ( 'cpu' )): \"\"\" Args: target_update_rate: if 1, vanilla dqn update if > 1, double dqn with specified target update rate \"\"\" RLPolicy . __init__ ( self , domain , buffer_cls = buffer_cls , buffer_size = replay_buffer_size , batch_size = batch_size , discount_gamma = discount_gamma , include_confreq = include_confreq , logger = logger , max_turns = max_turns , device = device ) Service . __init__ ( self , domain = domain ) self . writer = summary_writer self . training_frequency = training_frequency self . train_dialogs = train_dialogs self . lr = lr self . gradient_clipping = gradient_clipping if gradient_clipping > 0.0 and self . logger : self . logger . info ( \"Gradient Clipping: \" + str ( gradient_clipping )) self . target_update_rate = target_update_rate self . epsilon_start = eps_start self . epsilon_end = eps_end # Select network architecture if architecture == NetArchitecture . VANILLA : if self . logger : self . logger . info ( \"Architecture: Vanilla\" ) self . model = DQN ( self . state_dim , self . action_dim , hidden_layer_sizes = hidden_layer_sizes , dropout_rate = p_dropout ) else : if self . logger : self . logger . info ( \"Architecture: Dueling\" ) self . model = DuelingDQN ( self . state_dim , self . action_dim , shared_layer_sizes = shared_layer_sizes , value_layer_sizes = value_layer_sizes , advantage_layer_sizes = advantage_layer_sizes , dropout_rate = p_dropout ) # Select network update self . target_model = None if target_update_rate > 1 : if self . logger : self . logger . info ( \"Update: Double\" ) if architecture == NetArchitecture . VANILLA : self . target_model = copy . deepcopy ( self . model ) elif self . logger : self . logger . info ( \"Update: Vanilla\" ) self . optim = optim . Adam ( self . model . parameters (), lr = lr , weight_decay = l2_regularisation ) self . loss_fun = nn . SmoothL1Loss ( reduction = 'none' ) # self.loss_fun = nn.MSELoss(reduction='none') self . train_call_count = 0 self . total_train_dialogs = 0 self . epsilon = self . epsilon_start self . turns = 0 self . cumulative_train_dialogs = - 1","title":"__init__()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.dialog_end","text":"clean up needed at the end of a dialog Source code in adviser/services/policy/rl/dqnpolicy.py 163 164 165 166 167 168 169 170 def dialog_end ( self ): \"\"\" clean up needed at the end of a dialog \"\"\" self . end_dialog ( self . sim_goal ) if self . is_training : self . total_train_dialogs += 1 self . train_batch ()","title":"dialog_end()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.dialog_start","text":"This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/policy/rl/dqnpolicy.py 121 122 123 124 125 126 127 128 129 130 def dialog_start ( self , dialog_start = False ): self . turns = 0 self . last_sys_act = None if self . is_training : self . cumulative_train_dialogs += 1 self . sys_state = { \"lastInformedPrimKeyVal\" : None , \"lastActionInformNone\" : False , \"offerHappened\" : False , 'informedPrimKeyValsSinceNone' : []}","title":"dialog_start()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.eps_scheduler","text":"Linear epsilon decay Source code in adviser/services/policy/rl/dqnpolicy.py 377 378 379 380 381 382 383 384 def eps_scheduler ( self ): \"\"\" Linear epsilon decay \"\"\" if self . is_training : self . epsilon = max ( 0 , self . epsilon_start - ( self . epsilon_start - self . epsilon_end ) * float ( self . num_dialogs ) / float ( self . train_dialogs )) if self . writer is not None : self . writer . add_scalar ( 'train/eps' , self . epsilon , self . total_train_dialogs )","title":"eps_scheduler()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.eval","text":"Sets module and its subgraph to eval mode Source code in adviser/services/policy/rl/dqnpolicy.py 425 426 427 428 429 430 431 def eval ( self , eval = True ): \"\"\" Sets module and its subgraph to eval mode \"\"\" super ( DQNPolicy , self ) . eval () self . is_training = False self . model . eval () if self . target_model is not None : self . target_model . eval ()","title":"eval()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.load","text":"Load model weights Parameters: Name Type Description Default path str path to model folder 'models/dqn' version str appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) '1.0' Source code in adviser/services/policy/rl/dqnpolicy.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 def load ( self , path : str = os . path . join ( 'models' , 'dqn' ), version : str = \"1.0\" ): \"\"\" Load model weights Args: path (str): path to model folder version (str): appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) \"\"\" model_file = os . path . join ( path , \"rlpolicy_\" + self . domain . get_domain_name () + \"_\" + version + \".pt\" ) if not os . path . isfile ( model_file ): raise FileNotFoundError ( \"Could not find DQN policy weight file \" , model_file ) self . model = torch . load ( model_file ) self . logger . info ( \"Loaded DQN weights from file \" + model_file ) if self . target_model is not None : self . target_model . load_state_dict ( self . model . state_dict ())","title":"load()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.loss","text":"Calculate TD-loss for given experience tuples Parameters: Name Type Description Default s_batch FloatTensor states (dimension batch x state_dim) required a_batch LongTensor actions (dimension batch x 1) required s2_batch FloatTensor next states (dimension: batch x state_dim) required r_batch FloatTensor rewards (dimension batch x 1) required t_batch FloatTensor indicator {0,1} for terminal states (dimension: batch x 1) required gamma float discount factor required Returns: Type Description TD-loss Source code in adviser/services/policy/rl/dqnpolicy.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def loss ( self , s_batch : torch . FloatTensor , a_batch : torch . LongTensor , s2_batch : torch . FloatTensor , r_batch : torch . FloatTensor , t_batch : torch . FloatTensor , gamma : float ): \"\"\" Calculate TD-loss for given experience tuples Args: s_batch (torch.FloatTensor): states (dimension batch x state_dim) a_batch (torch.LongTensor): actions (dimension batch x 1) s2_batch (torch.FloatTensor): next states (dimension: batch x state_dim) r_batch (torch.FloatTensor): rewards (dimension batch x 1) t_batch (torch.FloatTensor): indicator {0,1} for terminal states (dimension: batch x 1) gamma (float): discount factor Returns: TD-loss \"\"\" # forward value torch . autograd . set_grad_enabled ( True ) q_val = self . _forward ( s_batch , a_batch ) # forward target torch . autograd . set_grad_enabled ( False ) if self . target_model is None : q_target = self . _forward_target ( s2_batch , r_batch , t_batch , gamma ) else : q_target = self . _forward_target_ddqn ( s2_batch , r_batch , t_batch , gamma ) torch . autograd . set_grad_enabled ( True ) # loss loss = self . loss_fun ( q_val , q_target ) return loss","title":"loss()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.save","text":"Save model weights Parameters: Name Type Description Default path str path to model folder 'models/dqn' version str appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) '1.0' Source code in adviser/services/policy/rl/dqnpolicy.py 386 387 388 389 390 391 392 393 394 395 396 397 398 def save ( self , path : str = os . path . join ( 'models' , 'dqn' ), version : str = \"1.0\" ): \"\"\" Save model weights Args: path (str): path to model folder version (str): appendix to filename, enables having multiple models for the same domain (or saving a model after each training epoch) \"\"\" if not os . path . exists ( path ): os . makedirs ( path , exist_ok = True ) model_file = os . path . join ( path , \"rlpolicy_\" + self . domain . get_domain_name () + \"_\" + version + \".pt\" ) torch . save ( self . model , model_file )","title":"save()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.select_action_eps_greedy","text":"Epsilon-greedy policy. Parameters: Name Type Description Default state_vector FloatTensor current state (dimension 1 x state_dim) required Returns: Type Description action index for action selected by the agent for the current state Source code in adviser/services/policy/rl/dqnpolicy.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def select_action_eps_greedy ( self , state_vector : torch . FloatTensor ): \"\"\" Epsilon-greedy policy. Args: state_vector (torch.FloatTensor): current state (dimension 1 x state_dim) Returns: action index for action selected by the agent for the current state \"\"\" self . eps_scheduler () # epsilon greedy exploration if self . is_training and common . random . random () < self . epsilon : next_action_idx = common . random . randint ( 0 , self . action_dim - 1 ) else : torch . autograd . set_grad_enabled ( False ) q_values = self . model ( state_vector ) next_action_idx = q_values . squeeze ( dim = 0 ) . max ( dim = 0 )[ 1 ] . item () torch . autograd . set_grad_enabled ( True ) return next_action_idx","title":"select_action_eps_greedy()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.train","text":"Sets module and its subgraph to training mode Source code in adviser/services/policy/rl/dqnpolicy.py 417 418 419 420 421 422 423 def train ( self , train = True ): \"\"\" Sets module and its subgraph to training mode \"\"\" super ( DQNPolicy , self ) . train () self . is_training = True self . model . train () if self . target_model is not None : self . target_model . train ()","title":"train()"},{"location":"api/services/#adviser.services.policy.rl.dqnpolicy.DQNPolicy.train_batch","text":"Train on a minibatch drawn from the experience buffer. Source code in adviser/services/policy/rl/dqnpolicy.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def train_batch ( self ): \"\"\" Train on a minibatch drawn from the experience buffer. \"\"\" if not self . is_training : return if len ( self . buffer ) >= self . batch_size * 10 and \\ self . total_train_dialogs % self . training_frequency == 0 : self . train_call_count += 1 s_batch , a_batch , r_batch , s2_batch , t_batch , indices , importance_weights = \\ self . buffer . sample () self . optim . zero_grad () torch . autograd . set_grad_enabled ( True ) s_batch . requires_grad_ () gamma = torch . tensor ([ self . discount_gamma ] * self . batch_size , dtype = torch . float , device = self . device ) . view ( self . batch_size , 1 ) # calculate loss loss = self . loss ( s_batch , a_batch , s2_batch , r_batch , t_batch , gamma ) if importance_weights is not None : loss = loss * importance_weights for i in range ( self . batch_size ): # importance weighting # update priorities self . buffer . update ( i , loss [ i ] . item ()) loss = loss . mean () loss . backward () # clip gradients if self . gradient_clipping > 0.0 : nn . utils . clip_grad_norm_ ( self . model . parameters (), self . gradient_clipping ) # update weights self . optim . step () current_loss = loss . item () torch . autograd . set_grad_enabled ( False ) if self . writer is not None : # plot loss self . writer . add_scalar ( 'train/loss' , current_loss , self . train_call_count ) # plot min/max gradients max_grad_norm = - 1.0 min_grad_norm = 1000000.0 for param in self . model . parameters (): if param . grad is not None : # TODO decide on norm current_grad_norm = torch . norm ( param . grad , 2 ) if current_grad_norm > max_grad_norm : max_grad_norm = current_grad_norm if current_grad_norm < min_grad_norm : min_grad_norm = current_grad_norm self . writer . add_scalar ( 'train/min_grad' , min_grad_norm , self . train_call_count ) self . writer . add_scalar ( 'train/max_grad' , max_grad_norm , self . train_call_count ) # update target net if self . target_model is not None and \\ self . train_call_count % self . target_update_rate == 0 : self . target_model . load_state_dict ( self . model . state_dict ()) adviser.services.policy.rl.experience_buffer Classes adviser.services.policy.rl.experience_buffer.Buffer Base class for experience replay buffers Initializes the memory, provides a print function for the memory contents and a method to insert new items into the buffer. Sampling has to be implemented by child classes.","title":"train_batch()"},{"location":"api/services/#methods_11","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.Buffer.__len__","text":"Returns the number of items currently inside the buffer Source code in adviser/services/policy/rl/experience_buffer.py 145 146 147 def __len__ ( self ): \"\"\" Returns the number of items currently inside the buffer \"\"\" return self . buffer_count","title":"__len__()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.Buffer.print_contents","text":"Print contents of the experience replay memory. Parameters: Name Type Description Default max_size int restrict the number of printed items to this number (if not None) None Source code in adviser/services/policy/rl/experience_buffer.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def print_contents ( self , max_size : int = None ): \"\"\" Print contents of the experience replay memory. Args: max_size (int): restrict the number of printed items to this number (if not None) \"\"\" # how many entries to print print_items = len ( self ) if max_size is not None : print_items = min ( print_items , max_size ) print ( \"# REPLAY BUFFER CAPACITY: \" , self . buffer_size ) print ( \"# CURRENT ITEM COUNT\" , len ( self )) for i in range ( print_items ): print ( \"entry \" , i ) print ( \" action\" , self . mem_action [ i ]) print ( \" reward\" , self . mem_reward [ i ]) print ( \" terminal\" , self . mem_terminal [ i ]) print ( '---------' )","title":"print_contents()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.Buffer.sample","text":"Sample from buffer, has to be implemented by subclasses Source code in adviser/services/policy/rl/experience_buffer.py 149 150 151 def sample ( self ): \"\"\" Sample from buffer, has to be implemented by subclasses \"\"\" raise NotImplementedError","title":"sample()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.Buffer.store","text":"Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Parameters: Name Type Description Default state FloatTensor this turn's state tensor, or None if terminal = True required action LongTensor this turn's action index (int), or None if terminal = True required reward float this turn's reward (float) required terminal bool indicates whether episode finished (boolean) False Source code in adviser/services/policy/rl/experience_buffer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def store ( self , state : torch . FloatTensor , action : torch . LongTensor , reward : float , terminal : bool = False ): \"\"\" Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Args: state (torch.tensor): this turn's state tensor, or None if terminal = True action (torch.tensor): this turn's action index (int), or None if terminal = True reward (torch.tensor): this turn's reward (float) terminal (bool): indicates whether episode finished (boolean) \"\"\" reward /= 20.0 if isinstance ( self . last_state , type ( None )): # and terminal == False: # first turn of trajectory, don't record since s' is needed self . last_state = state self . last_action = action self . last_reward = reward return False else : if terminal == True : if self . episode_length > 0 : # update last state's reward and set it to terminal self . mem_terminal [ self . last_write_pos ] = float ( True ) self . mem_reward [ self . last_write_pos ] += reward self . _reset () return False else : # in-between turn of trajectory: record self . mem_state [ self . write_pos ] = \\ self . last_state . clone () . detach () self . mem_action [ self . write_pos ][ 0 ] = self . last_action self . mem_reward [ self . write_pos ][ 0 ] = self . last_reward self . mem_next_state [ self . write_pos ] = state . clone () . detach () self . mem_terminal [ self . write_pos ] = float ( False ) # update last encountered state self . last_state = state . clone () . detach () self . last_action = action self . last_reward = reward # update write index self . last_write_pos = self . write_pos self . write_pos = ( self . write_pos + 1 ) % self . buffer_size if self . buffer_count < self . buffer_size : self . buffer_count += 1 self . episode_length += 1 return True adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer Prioritized experience replay buffer. Assigns sampling probabilities dependent on TD-error of the transitions.","title":"store()"},{"location":"api/services/#methods_12","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.sample","text":"Sample from buffer. Returns: Type Description states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, importance weights Source code in adviser/services/policy/rl/experience_buffer.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def sample ( self ): \"\"\" Sample from buffer. Returns: states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, importance weights \"\"\" batch_size = self . batch_size batch_write_pos = 0 data_indices = torch . empty ( self . batch_size , dtype = torch . long , device = self . device ) probabilities = torch . empty ( self . batch_size , dtype = torch . float , device = self . device ) indices = [] self . sample_last_transition = True p_normed = np . array ( self . probs [: self . buffer_count ]) / np . linalg . norm ( self . probs [: self . buffer_count ], ord = 1 ) indices = common . numpy . random . choice ( list ( range ( self . buffer_count )), size = self . batch_size , p = p_normed ) if self . sample_last_transition : # include last transition (was at tree.write - 1) # -> see Sutton: A deeper look at experience replay data_indices [ 0 ] = self . last_write_pos probabilities [ 0 ] = self . probs [ self . last_write_pos ] # correct size of batch batch_size = batch_size - 1 batch_write_pos += 1 # TODO add option to sample each segment uniformly for i in range ( batch_write_pos , self . batch_size ): data_indices [ i ] = int ( indices [ i ]) probabilities [ i ] = self . probs [ data_indices [ i ]] # assemble batch from data indices s_batch = self . mem_state . index_select ( 0 , data_indices ) a_batch = self . mem_action . index_select ( 0 , data_indices ) r_batch = self . mem_reward . index_select ( 0 , data_indices ) t_batch = self . mem_terminal . index_select ( 0 , data_indices ) s2_batch = self . mem_next_state . index_select ( 0 , data_indices ) # calculate importance sampling weights importance_weights = float ( len ( self )) * probabilities importance_weights = importance_weights . pow ( - self . beta ) importance_weights = importance_weights / importance_weights . max ( dim = 0 )[ 0 ] . item () return s_batch , a_batch , r_batch , s2_batch , t_batch , data_indices , \\ importance_weights . view ( - 1 , 1 )","title":"sample()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.store","text":"Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Newly added experience tuples will be assigned maximum priority. Parameters: Name Type Description Default state FloatTensor this turn's state tensor, or None if terminal = True required action LongTensor this turn's action index (int), or None if terminal = True required reward float this turn's reward (float) required terminal bool indicates whether episode finished (boolean) False Source code in adviser/services/policy/rl/experience_buffer.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def store ( self , state : torch . FloatTensor , action : torch . LongTensor , reward : float , terminal : bool = False ): \"\"\" Store an experience of the form (s,a,r,s',t). Only needs the current state s (will construct transition to s' automatically). Newly added experience tuples will be assigned maximum priority. Args: state: this turn's state tensor, or None if terminal = True action: this turn's action index (int), or None if terminal = True reward: this turn's reward (float) terminal: indicates whether episode finished (boolean) \"\"\" if super ( NaivePrioritizedBuffer , self ) . store ( state , action , reward , terminal = terminal ): # create new tree node only if something new was added to the buffers self . probs [ self . last_write_pos ] = self . _priority_to_probability ( self . max_p )","title":"store()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.NaivePrioritizedBuffer.update","text":"Update the priority of transition with index idx Source code in adviser/services/policy/rl/experience_buffer.py 252 253 254 255 256 257 def update ( self , idx : int , error : float ): \"\"\" Update the priority of transition with index idx \"\"\" p = self . _priority_to_probability ( error ) if p > self . max_p : self . max_p = p self . probs [ idx ] = p adviser.services.policy.rl.experience_buffer.UniformBuffer Experience replay buffer with uniformly random sampling","title":"update()"},{"location":"api/services/#methods_13","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.UniformBuffer.__init__","text":"Parameters: Name Type Description Default sample_last_transition bool if True, a batch will always include the most recent transition (see Sutton: A deeper look at experience replay) True Source code in adviser/services/policy/rl/experience_buffer.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , buffer_size : int , batch_size : int , state_dim : int , discount_gamma : float = 0.99 , sample_last_transition : bool = True , device = torch . device ( 'cpu' )): \"\"\" Args: sample_last_transition (bool): if True, a batch will always include the most recent transition (see Sutton: A deeper look at experience replay) \"\"\" super ( UniformBuffer , self ) . __init__ ( buffer_size , batch_size , state_dim , discount_gamma = discount_gamma , device = device ) print ( \" REPLAY MEMORY: Uniform\" ) self . sample_last_transition = sample_last_transition","title":"__init__()"},{"location":"api/services/#adviser.services.policy.rl.experience_buffer.UniformBuffer.sample","text":"Sample from buffer. Returns: Type Description states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, None Source code in adviser/services/policy/rl/experience_buffer.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 def sample ( self ): \"\"\" Sample from buffer. Returns: states, actions, rewards, next states, terminal state indicator {0,1}, buffer indices, None \"\"\" # create random indices data_indices = [] if self . sample_last_transition : # include last transition (was at write - 1) # - see Sutton: A deeper look at experience replay if self . write_pos - 1 < 0 : # last transition filled the capacity of the buffer data_indices = [ self . buffer_size - 1 ] else : data_indices = [ self . write_pos - 1 ] data_indices . extend ([ common . random . randint ( 0 , self . buffer_count - 1 ) for i in range ( self . batch_size - int ( self . sample_last_transition ))]) data_indices = torch . tensor ( data_indices , dtype = torch . long , device = self . device ) state_batch = self . mem_state . index_select ( 0 , data_indices ) action_batch = self . mem_action . index_select ( 0 , data_indices ) reward_batch = self . mem_reward . index_select ( 0 , data_indices ) next_state_batch = self . mem_next_state . index_select ( 0 , data_indices ) terminal_batch = self . mem_terminal . index_select ( 0 , data_indices ) return state_batch , action_batch , reward_batch , next_state_batch , terminal_batch , \\ data_indices , None adviser.services.policy.rl.policy_rl Classes adviser.services.policy.rl.policy_rl.RLPolicy Base class for Reinforcement Learning based policies. Functionality provided includes the setup of state- and action spaces, conversion of BeliefState objects into pytorch tensors, updating the last performed system actions and informed entities, populating the experience replay buffer, extraction of most probable user hypothesis and candidate action expansion. Output of an agent is a candidate action like inform_food which is then populated with the most probable slot/value pair from the beliefstate and database candidates by the expand_system_action -function to become inform(slot=food,value=italian) . In order to create your own policy, you can inherit from this class. Make sure to call the turn_end -function after each system turn and the end_dialog -function after each completed dialog.","title":"sample()"},{"location":"api/services/#methods_14","text":"","title":"Methods"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.__init__","text":"Creates state- and action spaces, initializes experience replay buffers. Keyword Arguments: subgraph {[type]} -- [see services.Module] (default: {None}) buffer_cls {services.policy.rl.experience_buffer.Buffer} -- [Experience replay buffer class , not an instance - will be initialized by this constructor!] (default: {UniformBuffer}) buffer_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {6000}) batch_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {64}) discount_gamma {float} -- [Discount factor] (default: {0.99}) include_confreq {bool} -- [Use confirm_request actions] (default: {False}) Source code in adviser/services/policy/rl/policy_rl.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __init__ ( self , domain : JSONLookupDomain , buffer_cls = UniformBuffer , buffer_size = 6000 , batch_size = 64 , discount_gamma = 0.99 , max_turns : int = 25 , include_confreq = False , logger : DiasysLogger = DiasysLogger (), include_select : bool = False , device = torch . device ( 'cpu' )): \"\"\" Creates state- and action spaces, initializes experience replay buffers. Arguments: domain {domain.jsonlookupdomain.JSONLookupDomain} -- Domain Keyword Arguments: subgraph {[type]} -- [see services.Module] (default: {None}) buffer_cls {services.policy.rl.experience_buffer.Buffer} -- [Experience replay buffer *class*, **not** an instance - will be initialized by this constructor!] (default: {UniformBuffer}) buffer_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {6000}) batch_size {int} -- [see services.policy.rl.experience_buffer. Buffer] (default: {64}) discount_gamma {float} -- [Discount factor] (default: {0.99}) include_confreq {bool} -- [Use confirm_request actions] (default: {False}) \"\"\" self . device = device self . sys_state = { \"lastInformedPrimKeyVal\" : None , \"lastActionInformNone\" : False , \"offerHappened\" : False , 'informedPrimKeyValsSinceNone' : []} self . max_turns = max_turns self . logger = logger self . domain = domain # setup evaluator for training self . evaluator = ObjectiveReachedEvaluator ( domain , logger = logger ) self . buffer_size = buffer_size self . batch_size = batch_size self . discount_gamma = discount_gamma self . writer = None # get state size self . state_dim = self . beliefstate_dict_to_vector ( BeliefState ( domain ) . _init_beliefstate ()) . size ( 1 ) self . logger . info ( \"state space dim: \" + str ( self . state_dim )) # get system action list self . actions = [ \"inform_byname\" , # TODO rename to 'bykey' \"inform_alternatives\" , \"reqmore\" ] # TODO badaction # NOTE repeat not supported by user simulator for req_slot in self . domain . get_system_requestable_slots (): self . actions . append ( 'request#' + req_slot ) self . actions . append ( 'confirm#' + req_slot ) if include_select : self . actions . append ( 'select#' + req_slot ) if include_confreq : for conf_slot in self . domain . get_system_requestable_slots (): if not req_slot == conf_slot : # skip case where confirm slot = request slot self . actions . append ( 'confreq#' + conf_slot + '#' + req_slot ) self . action_dim = len ( self . actions ) # don't include closingmsg in learnable actions self . actions . append ( 'closingmsg' ) # self.actions.append(\"closingmsg\") self . logger . info ( \"action space dim: \" + str ( self . action_dim )) self . primary_key = self . domain . get_primary_key () # init replay memory self . buffer = buffer_cls ( buffer_size , batch_size , self . state_dim , discount_gamma = discount_gamma , device = device ) self . sys_state = {} self . last_sys_act = None","title":"__init__()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.action_idx","text":"Returns the action index for the specified action name Source code in adviser/services/policy/rl/policy_rl.py 141 142 143 def action_idx ( self , action_name : str ): \"\"\" Returns the action index for the specified action name \"\"\" return self . actions . index ( action_name )","title":"action_idx()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.action_name","text":"Returns the action name for the specified action index Source code in adviser/services/policy/rl/policy_rl.py 137 138 139 def action_name ( self , action_idx : int ): \"\"\" Returns the action name for the specified action index \"\"\" return self . actions [ action_idx ]","title":"action_name()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.beliefstate_dict_to_vector","text":"Converts the beliefstate dict to a torch tensor Parameters: Name Type Description Default beliefstate BeliefState dict of belief (with at least beliefs and system keys) required Returns: Type Description belief tensor with dimension 1 x state_dim Source code in adviser/services/policy/rl/policy_rl.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def beliefstate_dict_to_vector ( self , beliefstate : BeliefState ): \"\"\" Converts the beliefstate dict to a torch tensor Args: beliefstate: dict of belief (with at least beliefs and system keys) Returns: belief tensor with dimension 1 x state_dim \"\"\" belief_vec = [] # add user acts belief_vec += [ 1 if act in beliefstate [ 'user_acts' ] else 0 for act in UserActionType ] # handle none actions belief_vec . append ( 1 if sum ( belief_vec ) == 0 else 1 ) # add informs (including special flag if slot not mentioned) for slot in sorted ( self . domain . get_informable_slots ()): values = self . domain . get_possible_values ( slot ) + [ \"dontcare\" ] if slot not in beliefstate [ 'informs' ]: # add **NONE** value first, then 0.0 for all others belief_vec . append ( 1.0 ) # also add value for don't care belief_vec += [ 0 for i in range ( len ( values ))] else : # add **NONE** value first belief_vec . append ( 0.0 ) bs_slot = beliefstate [ 'informs' ][ slot ] belief_vec += [ bs_slot [ value ] if value in bs_slot else 0.0 for value in values ] # add requests for slot in sorted ( self . domain . get_requestable_slots ()): if slot in beliefstate [ 'requests' ]: belief_vec . append ( 1.0 ) else : belief_vec . append ( 0.0 ) # append system features belief_vec . append ( float ( self . sys_state [ 'lastActionInformNone' ])) belief_vec . append ( float ( self . sys_state [ 'offerHappened' ])) candidate_count = beliefstate [ 'num_matches' ] # buckets for match count: 0, 1, 2-4, >4 belief_vec . append ( float ( candidate_count == 0 )) belief_vec . append ( float ( candidate_count == 1 )) belief_vec . append ( float ( 2 <= candidate_count <= 4 )) belief_vec . append ( float ( candidate_count > 4 )) belief_vec . append ( float ( beliefstate [ \"discriminable\" ])) # convert to torch tensor return torch . tensor ([ belief_vec ], dtype = torch . float , device = self . device )","title":"beliefstate_dict_to_vector()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.end_dialog","text":"Call this function when a dialog ended Source code in adviser/services/policy/rl/policy_rl.py 550 551 552 553 554 555 556 557 558 559 560 def end_dialog ( self , sim_goal : Goal ): \"\"\" Call this function when a dialog ended \"\"\" if sim_goal is None : # real user interaction, no simulator - don't have to evaluate # anything, just reset counters return final_reward , success = self . evaluator . get_final_reward ( sim_goal , logging = False ) if self . is_training : self . buffer . store ( None , None , final_reward , terminal = True )","title":"end_dialog()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.expand_system_action","text":"Expands an action index to a real sytem act Source code in adviser/services/policy/rl/policy_rl.py 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 def expand_system_action ( self , action_idx : int , beliefstate : BeliefState ): \"\"\" Expands an action index to a real sytem act \"\"\" action_name = self . action_name ( action_idx ) if 'request#' in action_name : return self . _expand_request ( action_name ) elif 'select#' in action_name : return self . _expand_select ( action_name , beliefstate ) elif 'confirm#' in action_name : return self . _expand_confirm ( action_name , beliefstate ) elif 'confreq#' in action_name : return self . _expand_confreq ( action_name , beliefstate ) elif action_name == 'inform_byname' : return self . _expand_informbyname ( beliefstate ) elif action_name == 'inform_alternatives' : return self . _expand_informbyalternatives ( beliefstate ) elif action_name == 'closingmsg' : return self . _expand_bye () elif action_name == 'repeat' : return self . last_sys_act elif action_name == 'reqmore' : return self . _expand_reqmore () elif self . logger : self . logger . warning ( \"RL POLICY: system action not supported: \" + action_name ) # TODO restart: not supported by former systems # -> check if user simulator supports this return None","title":"expand_system_action()"},{"location":"api/services/#adviser.services.policy.rl.policy_rl.RLPolicy.turn_end","text":"Call this function after a turn is done by the system Source code in adviser/services/policy/rl/policy_rl.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 def turn_end ( self , beliefstate : BeliefState , state_vector : torch . FloatTensor , sys_act_idx : int ): \"\"\" Call this function after a turn is done by the system \"\"\" self . last_sys_act = self . expand_system_action ( sys_act_idx , beliefstate ) # TODO COMPATIBILITY TO FORMER SYSTEM'S USER SIMULATOR AND NLG CURRENTLY - REMOVE LATER # if self.last_sys_act.type == SysActionType.InformByName: # self.last_sys_act.type = SysActionType.Inform if self . logger : self . logger . dialog_turn ( \"system action > \" + str ( self . last_sys_act )) self . _update_system_belief ( beliefstate , self . last_sys_act ) turn_reward = self . evaluator . get_turn_reward () if self . is_training : self . buffer . store ( state_vector , sys_act_idx , turn_reward , terminal = False ) adviser.services.policy.rl.train_dqnpolicy","title":"turn_end()"},{"location":"api/services/#this-script-can-be-executed-to-train-a-dqn-policy","text":"","title":"This script can be executed to train a DQN policy."},{"location":"api/services/#it-will-create-a-policy-model-file-ending-with-pt","text":"","title":"It will create a policy model (file ending with .pt)."},{"location":"api/services/#you-need-to-execute-this-script-before-you-can-interact-with-the-rl-agent","text":"","title":"You need to execute this script before you can interact with the RL agent."},{"location":"api/services/#_1","text":"Functions adviser.services.policy.rl.train_dqnpolicy.train ( domain_name , log_to_file , seed , train_epochs , train_dialogs , eval_dialogs , max_turns , train_error_rate , test_error_rate , lr , eps_start , grad_clipping , buffer_classname , buffer_size , use_tensorboard ) Training loop for the RL policy, for information on the parameters, look at the descriptions of commandline arguments in the \"if main\" below Source code in adviser/services/policy/rl/train_dqnpolicy.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def train ( domain_name : str , log_to_file : bool , seed : int , train_epochs : int , train_dialogs : int , eval_dialogs : int , max_turns : int , train_error_rate : float , test_error_rate : float , lr : float , eps_start : float , grad_clipping : float , buffer_classname : str , buffer_size : int , use_tensorboard : bool ): \"\"\" Training loop for the RL policy, for information on the parameters, look at the descriptions of commandline arguments in the \"if main\" below \"\"\" common . init_random ( seed = seed ) file_log_lvl = LogLevel . DIALOGS if log_to_file else LogLevel . NONE logger = DiasysLogger ( console_log_lvl = LogLevel . RESULTS , file_log_lvl = file_log_lvl ) if buffer_classname == \"prioritized\" : buffer_cls = NaivePrioritizedBuffer elif buffer_classname == \"uniform\" : buffer_cls = UniformBuffer domain = JSONLookupDomain ( name = domain_name ) bst = HandcraftedBST ( domain = domain , logger = logger ) user = HandcraftedUserSimulator ( domain , logger = logger ) # noise = SimpleNoise(domain=domain, train_error_rate=train_error_rate, # test_error_rate=test_error_rate, logger=logger) policy = DQNPolicy ( domain = domain , lr = lr , eps_start = eps_start , gradient_clipping = grad_clipping , buffer_cls = buffer_cls , replay_buffer_size = buffer_size , train_dialogs = train_dialogs , logger = logger ) evaluator = PolicyEvaluator ( domain = domain , use_tensorboard = use_tensorboard , experiment_name = domain_name , logger = logger ) ds = DialogSystem ( services = [ user , bst , policy , evaluator ], protocol = 'tcp' ) # ds.draw_system_graph() error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_local_inconsistencies () for j in range ( train_epochs ): # START TRAIN EPOCH evaluator . train () policy . train () evaluator . start_epoch () for episode in range ( train_dialogs ): if episode % 100 == 0 : print ( \"DIALOG\" , episode ) logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () policy . save () # START EVAL EPOCH evaluator . eval () policy . eval () evaluator . start_epoch () for episode in range ( eval_dialogs ): logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () ds . shutdown ()","title":""},{"location":"api/services/#adviser.services.service","text":"","title":"service"},{"location":"api/services/#classes","text":"","title":"Classes"},{"location":"api/services/#adviser.services.service.DialogSystem","text":"This class will constrct a dialog system from the list of services provided to the constructor. It will also handle synchronization for initalization of services before dialog start / after dialog end / on system shutdown and lets you discover potential conflicts in you messaging pipeline. This class is also used to communicate / synchronize with services running on different nodes. Methods adviser.services.service.DialogSystem.__init__ ( self , services , sub_port = 65533 , pub_port = 65534 , reg_port = 65535 , protocol = 'tcp' , debug_logger = None ) special Parameters: Name Type Description Default services List[Union[adviser.services.service.Service, adviser.services.service.RemoteService]] List of all (remote) services to connect to. Only once they're specified here will they start listening for messages. required sub_port(int) subscriber port required sub_addr(str) IP-address or domain name of proxy subscriber interface (e.g. 127.0.0.1 for your local machine) required pub_port(int) publisher port required pub_addr(str) IP-address or domain name of proxy publisher interface (e.g. 127.0.0.1 for your local machine) required reg_port int registration port for remote services 65535 protocol(str) communication protol, either 'inproc' or 'tcp' or ipc required debug_logger DiasysLogger If not None , all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the DialogSystem even if they are never forwarded (as expected) to your Service None Source code in adviser/services/service.py 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 def __init__ ( self , services : List [ Union [ Service , RemoteService ]], sub_port : int = 65533 , pub_port : int = 65534 , reg_port : int = 65535 , protocol : str = 'tcp' , debug_logger : DiasysLogger = None ): \"\"\" Args: services (List[Union[Service, RemoteService]]): List of all (remote) services to connect to. Only once they're specified here will they start listening for messages. sub_port(int): subscriber port sub_addr(str): IP-address or domain name of proxy subscriber interface (e.g. 127.0.0.1 for your local machine) pub_port(int): publisher port pub_addr(str): IP-address or domain name of proxy publisher interface (e.g. 127.0.0.1 for your local machine) reg_port (int): registration port for remote services protocol(str): communication protol, either 'inproc' or 'tcp' or `ipc` debug_logger (DiasysLogger): If not `None`, all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the `DialogSystem` even if they are never forwarded (as expected) to your `Service` \"\"\" # node-local topics self . debug_logger = debug_logger self . protocol = protocol self . _sub_topics = {} self . _pub_topics = {} self . _remote_identifiers = set () self . _services = [] # collects names and instances of local services self . _start_dialog_services = set () # collects names of local services that subscribe to dialog_start # node-local sockets self . _domains = set () # start proxy thread self . _proxy_dev = ProcessProxy ( in_type = zmq . XSUB , out_type = zmq . XPUB ) # , mon_type=zmq.XSUB) self . _proxy_dev . bind_in ( f \" { protocol } ://127.0.0.1: { pub_port } \" ) self . _proxy_dev . bind_out ( f \" { protocol } ://127.0.0.1: { sub_port } \" ) self . _proxy_dev . start () self . _sub_port = sub_port self . _pub_port = pub_port # thread control self . _start_topics = set () self . _end_topics = set () self . _terminate_topics = set () self . _stopEvent = threading . Event () # control channels ctx = Context . instance () self . _control_channel_pub = ctx . socket ( zmq . PUB ) self . _control_channel_pub . sndhwm = 1100000 self . _control_channel_pub . connect ( f \" { protocol } ://127.0.0.1: { pub_port } \" ) self . _control_channel_sub = ctx . socket ( zmq . SUB ) # register services (local and remote) remote_services = {} for service in services : if isinstance ( service , Service ): # register local service service_name = type ( service ) . __name__ if service . _identifier is None else service . _identifier service . _init_pubsub () self . _add_service_info ( service_name , service . _domain_name , service . _sub_topics , service . _pub_topics , service . _start_topic , service . _end_topic , service . _terminate_topic ) service . _register_with_dialogsystem () elif isinstance ( service , RemoteService ): remote_services [ getattr ( service , 'identifier' )] = service self . _register_remote_services ( remote_services , reg_port ) self . _control_channel_sub . connect ( f \" { protocol } ://127.0.0.1: { sub_port } \" ) self . _setup_dialog_end_listener () time . sleep ( 0.25 ) adviser.services.service.DialogSystem.draw_system_graph ( self , name = 'system' , format = 'png' , show = True ) Draws a graph of the system as a directed graph. Services are represented by nodes, messages by directed edges (from publisher to subscriber). Warnings are drawn as yellow edges (and the missing subscribers represented by an 'UNCONNECTED SERVICES' node), errors as red edges (and the missing publishers represented by the 'UNCONNECTED SERVICES' node as well). Will mark remote services with blue. Parameters: Name Type Description Default name str used to construct the name of your output file 'system' format str output file format (e.g. png, pdf, jpg, ...) 'png' show bool if True, the graph image will be opened in your default image viewer application True Requires graphviz library (pip install graphviz) Source code in adviser/services/service.py 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 def draw_system_graph ( self , name : str = 'system' , format : str = \"png\" , show : bool = True ): \"\"\" Draws a graph of the system as a directed graph. Services are represented by nodes, messages by directed edges (from publisher to subscriber). Warnings are drawn as yellow edges (and the missing subscribers represented by an 'UNCONNECTED SERVICES' node), errors as red edges (and the missing publishers represented by the 'UNCONNECTED SERVICES' node as well). Will mark remote services with blue. Args: name (str): used to construct the name of your output file format (str): output file format (e.g. png, pdf, jpg, ...) show (bool): if True, the graph image will be opened in your default image viewer application Requires: graphviz library (pip install graphviz) \"\"\" from graphviz import Digraph g = Digraph ( name = name , format = format ) # collect all services, errors and warnings services = set () for service_set in self . _pub_topics . values (): services = services . union ( service_set ) for service_set in self . _sub_topics . values (): services = services . union ( service_set ) errors , warnings = self . list_inconsistencies () # add services as nodes for service in services : if service in self . _remote_identifiers : g . node ( service , color = '#1f618d' , style = 'filled' , fontcolor = 'white' , shape = 'box' ) # remote service else : g . node ( service , color = '#1c2833' , shape = 'box' ) # local service if len ( errors ) > 0 or len ( warnings ) > 0 : g . node ( 'UNCONNECTED SERVICES' , style = 'filled' , color = '#922b21' , fontcolor = 'white' , shape = 'box' ) # draw connections from publisher to subscribers as edges for topic in self . _pub_topics : publishers = self . _pub_topics [ topic ] receivers = self . _sub_topics [ topic ] if topic in self . _sub_topics else [] for receiver in receivers : for publisher in publishers : g . edge ( publisher , receiver , label = topic ) # draw warnings and errors as edges to node 'UNCONNECTED SERVICES' for topic in errors : receivers = errors [ topic ] for receiver in receivers : g . edge ( 'UNCONNECTED SERVICES' , receiver , color = '#c34400' , fontcolor = '#c34400' , label = topic ) for topic in warnings : publishers = warnings [ topic ] for publisher in publishers : g . edge ( publisher , 'UNCONNECTED SERVICES' , color = '#e37c02' , fontcolor = '#e37c02' , label = topic ) # draw graph g . render ( view = show , cleanup = True ) adviser.services.service.DialogSystem.is_error_free_messaging_pipeline ( self ) Checks the current messaging pipeline for potential errors. (Potential) Errors are defined in this context as subscribed topics without publishers. Returns: Type Description True, if no potential errors could be found - else, False Notes Call this method after instantiating all services. Lists only node-local (or process-local) inconsistencies. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 def is_error_free_messaging_pipeline ( self ): \"\"\" Checks the current messaging pipeline for potential errors. (Potential) Errors are defined in this context as subscribed topics without publishers. Returns: True, if no potential errors could be found - else, False Notes: * Call this method after instantiating all services. * Lists only node-local (or process-local) inconsistencies. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" return len ( self . list_inconsistencies ()[ 0 ]) == 0 adviser.services.service.DialogSystem.list_inconsistencies ( self ) Checks for potential errors in the current messaging pipleline: e.g. len(list_inconsistencies()[0]) == 0 -> error free pipeline (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Returns: Type Description A touple of dictionaries the first dictionary contains potential errors (with the mapping topics -> subsribing services) the second dictionary contains warnings (with the mapping topics -> publishing services). Notes Call this method after instantiating all services. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 def list_inconsistencies ( self ): \"\"\" Checks for potential errors in the current messaging pipleline: e.g. len(list_inconsistencies()[0]) == 0 -> error free pipeline (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Returns: A touple of dictionaries: * the first dictionary contains potential errors (with the mapping topics -> subsribing services) * the second dictionary contains warnings (with the mapping topics -> publishing services). Notes: * Call this method after instantiating all services. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" # look for subscribers w/o publishers by checking topic prefixes errors = {} for sub_topic in self . _sub_topics : found_pub = False for pub_topic in self . _pub_topics : if pub_topic . startswith ( sub_topic ): found_pub = True break if not found_pub : errors [ sub_topic ] = self . _sub_topics [ sub_topic ] # look for publishers w/o subscribers by checking topic prefixes warnings = {} for pub_topic in self . _pub_topics : found_sub = False for sub_topic in self . _sub_topics : if pub_topic . startswith ( sub_topic ): found_sub = True break if not found_sub : warnings [ pub_topic ] = self . _pub_topics [ pub_topic ] return errors , warnings adviser.services.service.DialogSystem.list_published_topics ( self ) Get all declared publisher topics. Returns: Type Description A dictionary with mapping topic (str) -> publishing services (Set[str]). Note Call this method after instantiating all services. Even though a publishing topic might be listed here, there is no guarantee that its publisher(s) might ever publish to it. Source code in adviser/services/service.py 852 853 854 855 856 857 858 859 860 861 862 863 def list_published_topics ( self ): \"\"\" Get all declared publisher topics. Returns: A dictionary with mapping topic (str) -> publishing services (Set[str]). Note: * Call this method after instantiating all services. * Even though a publishing topic might be listed here, there is no guarantee that its publisher(s) might ever publish to it. \"\"\" return copy . deepcopy ( self . _pub_topics ) # copy s.t. no user changes this list adviser.services.service.DialogSystem.list_subscribed_topics ( self ) Get all declared subscribed topics. Returns: Type Description A dictionary with mapping topic (str) -> subscribing services (Set[str]). Notes Call this method after instantiating all services. Source code in adviser/services/service.py 865 866 867 868 869 870 871 872 873 874 def list_subscribed_topics ( self ): \"\"\" Get all declared subscribed topics. Returns: A dictionary with mapping topic (str) -> subscribing services (Set[str]). Notes: * Call this method after instantiating all services. \"\"\" return copy . deepcopy ( self . _sub_topics ) # copy s.t. no user changes this list adviser.services.service.DialogSystem.print_inconsistencies ( self ) Checks for potential errors in the current messaging pipleline: e.g. len(list_local_inconsistencies()[0]) == 0 -> error free pipeline and prints them to the console. (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Notes Call this method after instantiating all services. Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. Source code in adviser/services/service.py 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 def print_inconsistencies ( self ): \"\"\" Checks for potential errors in the current messaging pipleline: e.g. len(list_local_inconsistencies()[0]) == 0 -> error free pipeline and prints them to the console. (Potential) Errors are defined in this context as subscribed topics without publishers. Warnings are defined in this context as published topics without subscribers. Notes: * Call this method after instantiating all services. * Even if there are no errors returned by this method, there is not guarantee that all publishers eventually publish to their respective topics. \"\"\" # console colors WARNING = ' \\033 [93m' ERROR = ' \\033 [91m' ENDC = ' \\033 [0m' errors , warnings = self . list_inconsistencies () print ( ERROR ) print ( \"(Potential) Errors (subscribed topics without publishers):\" ) for topic in errors : print ( f \" topic: ' { topic } ', subscribed to in services: { errors [ topic ] } \" ) print ( ENDC ) print ( WARNING ) print ( \"Warnings (published topics without subscribers):\" ) for topic in warnings : print ( f \" topic: ' { topic } ', published in services: { warnings [ topic ] } \" ) print ( ENDC ) adviser.services.service.DialogSystem.run_dialog ( self , start_signals = { 'dialog_end' : False }) Run a complete dialog (blocking). Dialog will be started via messages to the topics specified in start_signals . The dialog will end on receiving any Topic.DIALOG_END message with value 'True', so make sure at least one service in your dialog graph will publish this message eventually. Parameters: Name Type Description Default start_signals dict mapping from topic -> value Publishes the value given for each topic to the respective topic. Use this to trigger the start of your dialog system. {'dialog_end': False} Source code in adviser/services/service.py 838 839 840 841 842 843 844 845 846 847 848 849 850 def run_dialog ( self , start_signals : dict = { Topic . DIALOG_END : False }): \"\"\" Run a complete dialog (blocking). Dialog will be started via messages to the topics specified in `start_signals`. The dialog will end on receiving any `Topic.DIALOG_END` message with value 'True', so make sure at least one service in your dialog graph will publish this message eventually. Args: start_signals (Dict[str, Any]): mapping from topic -> value Publishes the value given for each topic to the respective topic. Use this to trigger the start of your dialog system. \"\"\" self . _start_dialog ( start_signals ) self . _end_dialog () adviser.services.service.DialogSystem.shutdown ( self ) Shutdown dialog system. This will trigger terminate messages to be sent to all registered services to stop their listener loops. Should be called in the end before exiting your program. Blocks until all services sent ACK's confirming they're stopped. Source code in adviser/services/service.py 780 781 782 783 784 785 786 787 788 789 def shutdown ( self ): \"\"\" Shutdown dialog system. This will trigger `terminate` messages to be sent to all registered services to stop their listener loops. Should be called in the end before exiting your program. Blocks until all services sent ACK's confirming they're stopped. \"\"\" self . _stopEvent . set () for terminate_topic in self . _terminate_topics : _send_msg ( self . _control_channel_pub , terminate_topic , True ) _recv_ack ( self . _control_channel_sub , terminate_topic ) adviser.services.service.DialogSystem.stop ( self ) Set stop event (can be queried by services via the terminating() function) Source code in adviser/services/service.py 771 772 773 774 def stop ( self ): \"\"\" Set stop event (can be queried by services via the `terminating()` function) \"\"\" self . _stopEvent . set () pass adviser.services.service.DialogSystem.terminating ( self ) Returns True if the system is stopping, else False Source code in adviser/services/service.py 776 777 778 def terminating ( self ): \"\"\" Returns True if the system is stopping, else False \"\"\" return self . _stopEvent . is_set ()","title":"DialogSystem"},{"location":"api/services/#adviser.services.service.RemoteService","text":"This is a placeholder to be used in the service list argument when constructing a DialogSystem : * Run the real Service instance on a remote node, give it a *UNIQUE* identifier * call run_standalone() on this instance * Instantiate a remote service on the node about to run the DialogSystem , assign the *SAME* identifier to it * add it to the DialogSystem service list * Now, when calling the constructor of DialogSystem`, you should see messages informing you about the successfull connection, or if the system is still trying to connect, it will block until connected to the remote service. Methods adviser.services.service.RemoteService.__init__ ( self , identifier ) special Parameters: Name Type Description Default identifier str the UNIQUE identifier to call the remote service instance required Source code in adviser/services/service.py 94 95 96 97 98 99 def __init__ ( self , identifier : str ): \"\"\" Args: identifier (str): the *UNIQUE* identifier to call the remote service instance \"\"\" self . identifier = identifier","title":"RemoteService"},{"location":"api/services/#adviser.services.service.Service","text":"Service base class. Inherit from this class, if you want to publish / subscribe to topics (Don't forget to call the super constructor!) . You may decorate arbitrary functions in the child class with the services.service.PublishSubscribe decorator for this purpose. A Service will only start listening to messages once it is added to a DialogSystem (or calling run_standalone() in the remote case and adding a corresponding RemoteService to the DialogSystem ). Methods adviser.services.service.Service.__init__ ( self , domain = '' , sub_topic_domains = {}, pub_topic_domains = {}, ds_host_addr = '127.0.0.1' , sub_port = 65533 , pub_port = 65534 , protocol = 'tcp' , debug_logger = None , identifier = None ) special Create a new service instance (call this super constructor from your inheriting classes!) . Parameters: Name Type Description Default domain Union[str, utils.domain.domain.Domain] The domain(-name) of your service (or empty string, if domain-agnostic). If a domain(-name) is set, it will automatically filter out all messages from other domains. If no domain(-name) is set, messages from all domains will be received. '' sub_topic_domains Dict[str, str] change subscribed to topics to listen to a specific domain (e.g. 'erase'/append a domain for a specific topic) {} pub_topic_domains Dict[str, str] change published topics to a specific domain (e.g. 'erase'/append a domain for a specific topic) {} ds_host_addr str IP-address of the parent DialogSystem (default: localhost) '127.0.0.1' sub_port int subscriber port following zmq's XSUB/XPUB pattern 65533 pub_port int publisher port following zmq's XSUB/XPUB pattern 65534 protocol str communication protocol with DialogSystem - has to match! Possible options: tcp , inproc , ipc 'tcp' debug_logger DiasysLogger If not None , all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the DialogSystem even if they are never forwarded (as expected) to your Service . None identifier str Set this to a UNIQUE identifier per service to be run remotely. See RemoteService for more details. None Source code in adviser/services/service.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def __init__ ( self , domain : Union [ str , Domain ] = \"\" , sub_topic_domains : Dict [ str , str ] = {}, pub_topic_domains : Dict [ str , str ] = {}, ds_host_addr : str = \"127.0.0.1\" , sub_port : int = 65533 , pub_port : int = 65534 , protocol : str = \"tcp\" , debug_logger : DiasysLogger = None , identifier : str = None ): \"\"\" Create a new service instance *(call this super constructor from your inheriting classes!)*. Args: domain (Union[str, Domain]): The domain(-name) of your service (or empty string, if domain-agnostic). If a domain(-name) is set, it will automatically filter out all messages from other domains. If no domain(-name) is set, messages from all domains will be received. sub_topic_domains (Dict[str, str]): change subscribed to topics to listen to a specific domain (e.g. 'erase'/append a domain for a specific topic) pub_topic_domains (Dict[str, str]): change published topics to a specific domain (e.g. 'erase'/append a domain for a specific topic) ds_host_addr (str): IP-address of the parent `DialogSystem` (default: localhost) sub_port (int): subscriber port following zmq's XSUB/XPUB pattern pub_port (int): publisher port following zmq's XSUB/XPUB pattern protocol (string): communication protocol with `DialogSystem` - has to match! Possible options: `tcp`, `inproc`, `ipc` debug_logger (DiasysLogger): If not `None`, all messags are printed to the logger, including send/receive events. Can be useful for debugging because you can still see messages received by the `DialogSystem` even if they are never forwarded (as expected) to your `Service`. identifier (str): Set this to a *UNIQUE* identifier per service to be run remotely. See `RemoteService` for more details. \"\"\" self . is_training = False self . domain = domain # get domain name (gets appended to all sub/pub topics so that different domain topics don't get shared) if domain is not None : self . _domain_name = domain . get_domain_name () if isinstance ( domain , Domain ) else domain else : self . _domain_name = \"\" self . _sub_topic_domains = sub_topic_domains self . _pub_topic_domains = pub_topic_domains # socket information self . _host_addr = ds_host_addr self . _sub_port = sub_port self . _pub_port = pub_port self . _protocol = protocol self . _identifier = identifier self . debug_logger = debug_logger self . _sub_topics = set () self . _pub_topics = set () self . _publish_sockets = dict () self . _internal_start_topics = dict () self . _internal_end_topics = dict () self . _internal_terminate_topics = dict () # NOTE: class name + memory pointer make topic unique (required, e.g. for running mutliple instances of same module!) self . _start_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /START\" self . _end_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /END\" self . _terminate_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /TERMINATE\" self . _train_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /TRAIN\" self . _eval_topic = f \" { type ( self ) . __name__ } / { id ( self ) } /EVAL\" adviser.services.service.Service.dialog_end ( self ) This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. Source code in adviser/services/service.py 331 332 333 334 def dialog_end ( self ): \"\"\" This function is called after a dialog ended (Topics.DIALOG_END message was received). You should overwrite this function to record dialog-level information. \"\"\" pass adviser.services.service.Service.dialog_exit ( self ) This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. Source code in adviser/services/service.py 336 337 338 339 def dialog_exit ( self ): \"\"\" This function is called when the dialog system is shutting down. You should overwrite this function to stop your threads and cleanup any open resources. \"\"\" pass adviser.services.service.Service.dialog_start ( self ) This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. Source code in adviser/services/service.py 326 327 328 329 def dialog_start ( self ): \"\"\" This function is called before the first message to a new dialog is published. You should overwrite this function to set/reset dialog-level variables. \"\"\" pass adviser.services.service.Service.eval ( self ) Sets module to eval mode Source code in adviser/services/service.py 345 346 347 def eval ( self ): \"\"\" Sets module to eval mode \"\"\" self . is_training = False adviser.services.service.Service.get_all_published_topics ( self ) Returns: Type Description Set of all topics published to by this Service Source code in adviser/services/service.py 391 392 393 394 395 396 def get_all_published_topics ( self ): \"\"\" Returns: Set of all topics published to by this `Service` \"\"\" return copy . deepcopy ( self . _pub_topics ) adviser.services.service.Service.get_all_subscribed_topics ( self ) Returns: Type Description Set of all topics subscribed to by this Service Source code in adviser/services/service.py 384 385 386 387 388 389 def get_all_subscribed_topics ( self ): \"\"\" Returns: Set of all topics subscribed to by this `Service` \"\"\" return copy . deepcopy ( self . _sub_topics ) adviser.services.service.Service.run_standalone ( self , host_reg_port = 65535 ) Run this service as a standalone serivce (without a DialogSystem ) on a remote node. Use a RemoteService with corresponding identifier on the DialogSystem node to connect both. Note: this call is blocking! Parameters: Name Type Description Default host_reg_port int The port on the DialogSystem node listening for Service register requests 65535 Source code in adviser/services/service.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def run_standalone ( self , host_reg_port : int = 65535 ): \"\"\" Run this service as a standalone serivce (without a `DialogSystem`) on a remote node. Use a `RemoteService` with *corresponding identifier* on the `DialogSystem` node to connect both. Note: this call is blocking! Args: host_reg_port (int): The port on the `DialogSystem` node listening for `Service` register requests \"\"\" assert self . _identifier is not None , \"running a service on a remote node requires a unique identifier\" print ( \"Waiting for dialog system host...\" ) # send service info to dialog system node self . _init_pubsub () ctx = Context . instance () sync_endpoint = ctx . socket ( zmq . REQ ) sync_endpoint . connect ( f \"tcp:// { self . _host_addr } : { host_reg_port } \" ) data = pickle . dumps (( self . _domain_name , self . _sub_topics , self . _pub_topics , self . _start_topic , self . _end_topic , self . _terminate_topic )) sync_endpoint . send_multipart (( bytes ( f \"REGISTER_ { self . _identifier } \" , encoding = \"ascii\" ), data )) # wait for registration confirmation registered = False while not registered : msg = sync_endpoint . recv () msg = msg . decode ( \"utf-8\" ) if msg . startswith ( \"ACK_REGISTER_\" ): remote_service_identifier = msg [ len ( \"ACK_REGISTER_\" ):] if remote_service_identifier == self . _identifier : self . _register_with_dialogsystem () sync_endpoint . send_multipart ( ( bytes ( f \"CONF_REGISTER_ { self . _identifier } \" , encoding = \"ascii\" ), pickle . dumps ( True ))) registered = True print ( f \"Done\" ) adviser.services.service.Service.train ( self ) Sets module to training mode Source code in adviser/services/service.py 341 342 343 def train ( self ): \"\"\" Sets module to training mode \"\"\" self . is_training = True","title":"Service"},{"location":"api/services/#functions","text":"","title":"Functions"},{"location":"api/services/#adviser.services.service.PublishSubscribe","text":"Decorator function for services. To be able to publish / subscribe to / from topics, your class is required to inherit from services.service.Service. Then, decorate any function you like. Your function will be called as soon as: * at least one message is received for each topic in sub_topics (only latest message will be forwarded, others dropped) * at least one message is received for each topic in queued_sub_topics (all messages since the previous function call will be forwarded as a list) Parameters: Name Type Description Default sub_topics(List[str or utils.topics.Topic] The topics you want to get the latest messages from. If multiple messages are received until your function is called, you will only receive the value of the latest message, previously received values will be discarded. required pub_topics(List[str or utils.topics.Topic] The topics you want to publish messages to. required queued_sub_topics(List[str or utils.topics.Topic] The topics you want to get all messages from. If multiple messages are received until your function is called, you will receive all values since the previous function call as a list. required Notes Subscription topic names have to match your function keywords Your function should return a dictionary with the keys matching your publish topics names and the value being any arbitrary python object or primitive type you want to send sub_topics and queued_sub_topics have to be disjoint! If you need timestamps for your messages, specify a 'timestamps' argument in your subscribing function. It will be filled by a dictionary providing timestamps for each received value, indexed by name. Technical notes: * Data will be automatically pickled / unpickled during send / receive to reduce meassage size. However, some python objects are not serializable (e.g. database connections) for good reasons and will throw an error if you try to publish them. * The domain name of your service class will be appended to your publish topics. Subscription topics are prefix-matched, so you will receive all messages from 'topic/suffix' if you subscibe to 'topic'. Source code in adviser/services/service.py 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 def PublishSubscribe ( sub_topics : List [ str ] = [], pub_topics : List [ str ] = [], queued_sub_topics : List [ str ] = []): \"\"\" Decorator function for services. To be able to publish / subscribe to / from topics, your class is required to inherit from services.service.Service. Then, decorate any function you like. Your function will be called as soon as: * at least one message is received for each topic in sub_topics (only latest message will be forwarded, others dropped) * at least one message is received for each topic in queued_sub_topics (all messages since the previous function call will be forwarded as a list) Args: sub_topics(List[str or utils.topics.Topic]): The topics you want to get the latest messages from. If multiple messages are received until your function is called, you will only receive the value of the latest message, previously received values will be discarded. pub_topics(List[str or utils.topics.Topic]): The topics you want to publish messages to. queued_sub_topics(List[str or utils.topics.Topic]): The topics you want to get all messages from. If multiple messages are received until your function is called, you will receive all values since the previous function call as a list. Notes: * Subscription topic names have to match your function keywords * Your function should return a dictionary with the keys matching your publish topics names and the value being any arbitrary python object or primitive type you want to send * sub_topics and queued_sub_topics have to be disjoint! * If you need timestamps for your messages, specify a 'timestamps' argument in your subscribing function. It will be filled by a dictionary providing timestamps for each received value, indexed by name. Technical notes: * Data will be automatically pickled / unpickled during send / receive to reduce meassage size. However, some python objects are not serializable (e.g. database connections) for good reasons and will throw an error if you try to publish them. * The domain name of your service class will be appended to your publish topics. Subscription topics are prefix-matched, so you will receive all messages from 'topic/suffix' if you subscibe to 'topic'. \"\"\" def wrapper ( func ): def delegate ( self , * args , ** kwargs ): func_inst = getattr ( self , func . __name__ ) callargs = list ( args ) if self in callargs : # remove self when in *args, because already known to function callargs . remove ( self ) result = func ( self , * callargs , ** kwargs ) if result : # fix! (user could have multiple \"/\" characters in topic - only use last one ) domains = { res . split ( \"/\" )[ 0 ]: res . split ( \"/\" )[ 1 ] if \"/\" in res else \"\" for res in result } result = { key . split ( \"/\" )[ 0 ]: result [ key ] for key in result } if func_inst not in self . _publish_sockets : # not a publisher, just normal function return result socket = self . _publish_sockets [ func_inst ] domain = self . _domain_name if socket and result : # publish messages for topic in pub_topics : # for topic in result: # NOTE publish any returned value in dict with it's key as topic if topic in result : domain = domain if domain else domains [ topic ] topic_domain_str = f \" { topic } / { domain } \" if domain else topic if topic in self . _pub_topic_domains : topic_domain_str = f \" { topic } / { self . _pub_topic_domains [ topic ] } \" if self . _pub_topic_domains [ topic ] else topic _send_msg ( socket , topic_domain_str , result [ topic ]) if self . debug_logger : self . debug_logger . info ( f \"- (DS): sent message from { func } to topic { topic_domain_str } : \\n { result [ topic ] } \" ) return result # declare function as publish / subscribe functions and attach the respective topics delegate . pubsub = True delegate . sub_topics = sub_topics delegate . queued_sub_topics = queued_sub_topics delegate . pub_topics = pub_topics # check arguments: is subsriber interested in timestamps? delegate . timestamp_enabled = 'timestamps' in inspect . getfullargspec ( func )[ 0 ] return delegate return wrapper","title":"PublishSubscribe()"},{"location":"api/services/#adviser.services.simulator","text":"This package contains the handcrafted user simulatod and related services.","title":"simulator"},{"location":"api/services/#modules_10","text":"","title":"Modules"},{"location":"api/services/#adviser.services.simulator.emotion_simulator","text":"Classes adviser.services.simulator.emotion_simulator.EmotionSimulator Class which generates user emotion/engagements. Currently outputs either a user defined or random emotion/engagement level and was designed to test the affective services work correctly. However, in the future it could be extended to be more realistic.","title":"emotion_simulator"},{"location":"api/services/#adviser.services.simulator.goal","text":"This module provides the Goal class and related stuff. Classes adviser.services.simulator.goal.Constraint The class for a constraint as used in the goal. Parameters: Name Type Description Default slot str The slot. required value str The value. required Methods adviser.services.simulator.goal.Constraint.__eq__ ( self , other ) special Constraint should be equal if the slot and value is the same. Source code in adviser/services/simulator/goal.py 42 43 44 45 46 47 def __eq__ ( self , other ): \"\"\"Constraint should be equal if the slot and value is the same.\"\"\" if isinstance ( other , Constraint ): return ( self . slot == other . slot and self . value == other . value ) return False adviser.services.simulator.goal.Goal The class representing a goal, therefore containing requests and constraints. Parameters: Name Type Description Default domain Domain The domain for which the goal will be instantiated. required parameters dict The parameters for the goal defined by a key=value mapping: 'MinVenues' required Methods adviser.services.simulator.goal.Goal.fulfill_request ( self , slot , value ) Fulfills a request, i.e. sets value for request slot . Parameters: Name Type Description Default slot str The request slot which will be filled. required value str The value the request slot will be filled with. required Source code in adviser/services/simulator/goal.py 282 283 284 285 286 287 288 289 290 291 292 def fulfill_request ( self , slot , value ): \"\"\" Fulfills a request, i.e. sets ``value`` for request ``slot``. Args: slot (str): The request slot which will be filled. value (str): The value the request slot will be filled with. \"\"\" if slot in self . requests : self . requests [ slot ] = value adviser.services.simulator.goal.Goal.get_constraint ( self , slot ) Gets the value for a given constraint slot . Parameters: Name Type Description Default slot str The constraint slot which will be looked up. required Returns: Type Description bool The constraint value . Source code in adviser/services/simulator/goal.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 def get_constraint ( self , slot ): \"\"\" Gets the value for a given constraint ``slot``. Args: slot (str): The constraint ``slot`` which will be looked up. Returns: bool: The constraint ``value``. \"\"\" for _constraint in self . constraints : if _constraint . slot == slot : return _constraint . value return 'dontcare' adviser.services.simulator.goal.Goal.init ( self , random_goal = True , constraints = None , requests = None ) Initializes a goal randomly OR using the given constraints and requests. Parameters: Name Type Description Default random_goal bool If True, a goal will be drawn randomly from available constraints True constraints List[Constraint] The constraints which will be used for the goal. None requests dict The requests which will be used for the goal. None Source code in adviser/services/simulator/goal.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def init ( self , random_goal = True , constraints = None , requests = None ): \"\"\" Initializes a goal randomly OR using the given constraints and requests. Args: random_goal (bool): If True, a goal will be drawn randomly from available constraints and requests (considering the parameters given in the constructor, if any). However if constraints and requests are given and both don't equal None, this parameter is considered as False. If False, the given constraints and requests are used. constraints (List[Constraint]): The constraints which will be used for the goal. requests (dict): The requests which will be used for the goal. \"\"\" # reset goal self . constraints = [] self . requests = {} self . excluded_inf_slot_values = { key : set () for key in self . inf_slot_values } # TODO implement possibility to pass either constraints or requests as a parameter if random_goal and constraints is None and requests is None : self . _init_random_goal () else : self . _init_from_parameters ( constraints , requests ) # make sure that primary key is always requested self . requests [ self . domain . get_primary_key ()] = None self . missing_informs = [ UserAct ( act_type = UserActionType . Inform , slot = _constraint . slot , value = _constraint . value ) for _constraint in self . constraints ] adviser.services.simulator.goal.Goal.is_fulfilled ( self ) Checks whether all requests have been fulfilled. Returns: Type Description bool True if all requests have been fulfilled, False otherwise. .. note:: Does not check whether the venue (issued by the system) fulfills the constraints since it's the system's task to give an appropriate venue by requesting the user's constraints. Source code in adviser/services/simulator/goal.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def is_fulfilled ( self ): \"\"\" Checks whether all requests have been fulfilled. Returns: bool: ``True`` if all requests have been fulfilled, ``False`` otherwise. .. note:: Does not check whether the venue (issued by the system) fulfills the constraints since it's the system's task to give an appropriate venue by requesting the user's constraints. \"\"\" for slot , value in self . requests . items (): assert slot != self . domain . get_primary_key () or value != 'none' # TODO remove later if value is None : return False return True adviser.services.simulator.goal.Goal.is_inconsistent_constraint ( self , constraint ) Checks whether the given constraint is consistent with the goal. A constraint is also consistent if it's value is 'dontcare' in the current goal. Parameters: Name Type Description Default constraint Constraint The constraint which will be checked for consistency. required Returns: Type Description bool True if values match or value in goal is 'dontcare', False otherwise. Source code in adviser/services/simulator/goal.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 def is_inconsistent_constraint ( self , constraint ): \"\"\" Checks whether the given constraint is consistent with the goal. A constraint is also consistent if it's value is 'dontcare' in the current goal. Args: constraint (Constraint): The constraint which will be checked for consistency. Returns: bool: True if values match or value in goal is 'dontcare', False otherwise. \"\"\" for _constraint in self . constraints : if _constraint . slot == constraint . slot and ( _constraint . value != constraint . value \\ and _constraint . value != 'dontcare' ): return True return False adviser.services.simulator.goal.Goal.is_inconsistent_constraint_strict ( self , constraint ) Checks whether the given constraint is strictly consistent with the goal, whereby 'dontcare' is treated as a different value (no match). Parameters: Name Type Description Default constraint Constraint The constraint which will be checked for consistency. required Returns: Type Description bool True if values match, False otherwise. .. seealso:: :func: is_inconsistent_constraint() Source code in adviser/services/simulator/goal.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 def is_inconsistent_constraint_strict ( self , constraint ): \"\"\" Checks whether the given constraint is strictly consistent with the goal, whereby 'dontcare' is treated as a different value (no match). Args: constraint (Constraint): The constraint which will be checked for consistency. Returns: bool: True if values match, False otherwise. .. seealso:: :func:`is_inconsistent_constraint()` \"\"\" for _constraint in self . constraints : if _constraint . slot == constraint . slot and _constraint . value == constraint . value : return False # here there are only two possibilities: the constraint is implicitly 'dontcare' because # it is not explicitly listed and the given constraint is either 1) 'dontcare' or 2) not return constraint . value != 'dontcare' adviser.services.simulator.goal.Goal.reset ( self ) Resets all requests of the goal. Source code in adviser/services/simulator/goal.py 252 253 254 255 def reset ( self ): \"\"\"Resets all requests of the goal.\"\"\" # reset goal -> empty all requests self . requests = dict . fromkeys ( self . requests ) adviser.services.simulator.goal.Goal.update_constraint ( self , slot , value ) Update a given constraint slot with value . Parameters: Name Type Description Default slot str The constraint slot which will be updated. required value str The value with which the constraint will be updated. required Returns: Type Description bool True if update was successful, i.e. the constraint slot is included in the goal, False otherwise. .. todo:: think about always setting a value Source code in adviser/services/simulator/goal.py 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 def update_constraint ( self , slot , value ): \"\"\" Update a given constraint ``slot`` with ``value``. Args: slot (str): The constraint *slot* which will be updated. value (str): The *value* with which the constraint will be updated. Returns: bool: ``True`` if update was successful, i.e. the constraint ``slot`` is included in the goal, ``False`` otherwise. .. todo:: think about always setting a value \"\"\" for _constraint in self . constraints : if _constraint . slot == slot : _constraint . value = value return True return False","title":"goal"},{"location":"api/services/#adviser.services.simulator.simulator","text":"This module provides the agenda-based user model for the handcrafted simulator. Classes adviser.services.simulator.simulator.Agenda A stack-like object representing an agenda. Actions can be pushed on and popped off the agenda. Methods adviser.services.simulator.simulator.Agenda.clean ( self , goal ) Cleans the agenda, i.e. makes sure that actions are consistent with goal and in the correct order. Parameters: Name Type Description Default goal Goal The goal which is needed to determine the consistent actions. required Source code in adviser/services/simulator/simulator.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 def clean ( self , goal : Goal ): \"\"\"Cleans the agenda, i.e. makes sure that actions are consistent with goal and in the correct order. Args: goal (Goal): The goal which is needed to determine the consistent actions. \"\"\" cleaned_stack = [] # reverse order since most recent actions are on top of agenda for action in self . stack [:: - 1 ]: if action not in cleaned_stack : # NOTE sufficient if there is only one slot per (request) action # remove accomplished requests if ( action . type is not UserActionType . Request or ( action . slot in goal . requests and goal . requests [ action . slot ] is None ) or action . slot not in goal . requests ): # make sure to remove \"old\" inform actions if action . type is UserActionType . Inform : if not goal . is_inconsistent_constraint ( Constraint ( action . slot , action . value )): cleaned_stack . insert ( 0 , action ) else : cleaned_stack . insert ( 0 , action ) self . stack = cleaned_stack adviser.services.simulator.simulator.Agenda.clear ( self ) Empties the agenda. Source code in adviser/services/simulator/simulator.py 766 767 768 def clear ( self ): \"\"\"Empties the agenda.\"\"\" self . stack . clear () adviser.services.simulator.simulator.Agenda.contains_action_of_type ( self , act_type , consider_dontcare = True ) Checks whether agenda contains actions of a specific type. Parameters: Name Type Description Default act_type UserActionType The action type (intent) for which the agenda will be checked. required consider_dontcare bool If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. True Returns: Type Description (bool) True if agenda contains act_type , False otherwise. Source code in adviser/services/simulator/simulator.py 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 def contains_action_of_type ( self , act_type : UserActionType , consider_dontcare = True ): \"\"\"Checks whether agenda contains actions of a specific type. Args: act_type (UserActionType): The action type (intent) for which the agenda will be checked. consider_dontcare (bool): If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. Returns: (bool): True if agenda contains *act_type*, False otherwise. \"\"\" for _action in self . stack : if not consider_dontcare and _action . value == 'dontcare' : continue if _action . type == act_type : return True return False adviser.services.simulator.simulator.Agenda.fill_with_constraints ( self , goal ) Adds all inform actions to the agenda necessary to fulfill the goal . Generally there is no need to add all constraints from the goal to the agenda apart from the initialisation. Parameters: Name Type Description Default goal Goal The current goal of the (simulated) user for which actions will be pushed to the required Source code in adviser/services/simulator/simulator.py 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 def fill_with_constraints ( self , goal : Goal ): \"\"\" Adds all inform actions to the agenda necessary to fulfill the *goal*. Generally there is no need to add all constraints from the goal to the agenda apart from the initialisation. Args: goal (Goal): The current goal of the (simulated) user for which actions will be pushed to the agenda. \"\"\" # add informs from goal for constraint in goal . constraints : self . stack . append ( UserAct ( act_type = UserActionType . Inform , slot = constraint . slot , value = constraint . value , score = 1.0 )) adviser.services.simulator.simulator.Agenda.fill_with_requests ( self , goal , exclude_name = True ) Adds all request actions to the agenda necessary to fulfill the goal . Parameters: Name Type Description Default goal Goal The current goal of the (simulated) user for which actions will be pushed to the agenda. required exclude_name bool whehter or not to include an action to request an entities name. True Source code in adviser/services/simulator/simulator.py 838 839 840 841 842 843 844 845 846 847 848 849 850 851 def fill_with_requests ( self , goal : Goal , exclude_name : bool = True ): \"\"\"Adds all request actions to the agenda necessary to fulfill the *goal*. Args: goal (Goal): The current goal of the (simulated) user for which actions will be pushed to the agenda. exclude_name (bool): whehter or not to include an action to request an entities name. \"\"\" # add requests and make sure to add the name at the end (i.e. ask first for name) for key , value in goal . requests . items (): if (( key != 'name' and exclude_name ) or not exclude_name ) and value is None : self . stack . append ( UserAct ( act_type = UserActionType . Request , slot = key , value = value , score = 1.0 )) adviser.services.simulator.simulator.Agenda.get_actions ( self , num_actions ) Retrieves num_actions actions from the agenda. Parameters: Name Type Description Default num_actions int Amount of actions which will be retrieved from the agenda. required Returns: Type Description (List[UserAct]) list of num_actions user actions. Source code in adviser/services/simulator/simulator.py 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def get_actions ( self , num_actions : int ): \"\"\"Retrieves *num_actions* actions from the agenda. Args: num_actions (int): Amount of actions which will be retrieved from the agenda. Returns: (List[UserAct]): list of *num_actions* user actions. \"\"\" if num_actions < 0 or num_actions > len ( self . stack ): num_actions = len ( self . stack ) return [ self . stack . pop () for _ in range ( 0 , num_actions )] adviser.services.simulator.simulator.Agenda.get_actions_of_type ( self , act_type =< enum 'UserActionType' > , consider_dontcare = True ) Get actions of a specific type from the agenda. Parameters: Name Type Description Default act_type UserActionType The action type (intent) for which the agenda will be checked. <enum 'UserActionType'> consider_dontcare bool If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. True Returns: Type Description (Iterable[UserAct]) A list of user actions of the given type/intent. Source code in adviser/services/simulator/simulator.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 def get_actions_of_type ( self , act_type = UserActionType , consider_dontcare = True ): \"\"\"Get actions of a specific type from the agenda. Args: act_type (UserActionType): The action type (intent) for which the agenda will be checked. consider_dontcare (bool): If set to True also considers actions for which the value is 'dontcare', and ignores them otherwise. Returns: (Iterable[UserAct]): A list of user actions of the given type/intent. \"\"\" return filter ( lambda x : x . type == act_type and ( consider_dontcare or x . value != 'dontcare' ), self . stack ) adviser.services.simulator.simulator.Agenda.init ( self , goal ) Initializes the agenda given a goal. For this purpose, inform actions for constraints in the goal and request actions for requests in the goal are added such that the informs are handled first followed by the requests. Parameters: Name Type Description Default goal Goal The goal for which the agenda will be initialized. required Source code in adviser/services/simulator/simulator.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def init ( self , goal ): \"\"\" Initializes the agenda given a goal. For this purpose, inform actions for constraints in the goal and request actions for requests in the goal are added such that the informs are handled first followed by the requests. Args: goal (Goal): The goal for which the agenda will be initialized. \"\"\" self . stack . clear () # populate agenda according to goal # NOTE don't push bye action here since bye action could be poppped with another (missing) # request, but user should not end dialog before having the goal fulfilled # NOTE do not add requests to agenda since system can't handle inform and request action in # same turn currently! # self.fill_with_requests(goal) self . fill_with_constraints ( goal ) adviser.services.simulator.simulator.Agenda.is_empty ( self ) Checks whether the agenda is empty. Returns: Type Description (bool) True if agenda is empty, False otherwise. Source code in adviser/services/simulator/simulator.py 770 771 772 773 774 775 776 777 def is_empty ( self ): \"\"\"Checks whether the agenda is empty. Returns: (bool): True if agenda is empty, False otherwise. \"\"\" return len ( self . stack ) == 0 adviser.services.simulator.simulator.Agenda.push ( self , item ) Pushes item onto the agenda. Parameters: Name Type Description Default item The goal for which the agenda will be initialized. required Source code in adviser/services/simulator/simulator.py 712 713 714 715 716 717 718 719 720 721 722 def push ( self , item ): \"\"\"Pushes *item* onto the agenda. Args: item: The goal for which the agenda will be initialized. \"\"\" if isinstance ( item , list ): self . stack += item else : self . stack . append ( item ) adviser.services.simulator.simulator.Agenda.remove_actions ( self , act_type , slot , value = None ) Removes actions of a specific type, slot and optionally value from the agenda. All arguments (value only if given) have to match in conjunction. Parameters: Name Type Description Default act_type UserActionType The action type (intent) which will be removed from the agenda. required slot str The action type (intent) which will be removed from the agenda. required value str The action type (intent) which will be removed from the agenda. None Source code in adviser/services/simulator/simulator.py 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 def remove_actions ( self , act_type : UserActionType , slot : str , value : str = None ): \"\"\"Removes actions of a specific type, slot and optionally value from the agenda. All arguments (value only if given) have to match in conjunction. Args: act_type (UserActionType): The action type (intent) which will be removed from the agenda. slot (str): The action type (intent) which will be removed from the agenda. value (str): The action type (intent) which will be removed from the agenda. \"\"\" if value is None : self . stack = list ( filter ( lambda x : x . type != act_type or x . slot != slot , self . stack )) else : self . stack = list ( filter ( lambda x : x . type != act_type or x . slot != slot or x . value != value , self . stack )) adviser.services.simulator.simulator.Agenda.remove_actions_of_type ( self , act_type ) Removes actions of a specific type from the agenda. Parameters: Name Type Description Default act_type UserActionType The action type (intent) which will be removed from the agenda. required Source code in adviser/services/simulator/simulator.py 813 814 815 816 817 818 819 820 def remove_actions_of_type ( self , act_type : UserActionType ): \"\"\"Removes actions of a specific type from the agenda. Args: act_type (UserActionType): The action type (intent) which will be removed from the agenda. \"\"\" self . stack = list ( filter ( lambda x : x . type != act_type , self . stack )) adviser.services.simulator.simulator.HandcraftedUserSimulator The class for a handcrafted (agenda-based) user simulator. !!! args domain (Domain): The domain for which the user simulator will be instantiated. It will use this domain to generate the goals. Methods adviser.services.simulator.simulator.HandcraftedUserSimulator.dialog_start ( self ) Resets the user model at the beginning of a dialog, e.g. draws a new goal and populates the agenda according to the goal. Source code in adviser/services/simulator/simulator.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def dialog_start ( self ): \"\"\"Resets the user model at the beginning of a dialog, e.g. draws a new goal and populates the agenda according to the goal.\"\"\" # self.goal = Goal(self.domain, self.parameters['goal']) self . goal . init () self . agenda . init ( self . goal ) if self . logger : self . logger . dialog_turn ( \"New goal has constraints {} and requests {} .\" . format ( self . goal . constraints , self . goal . requests )) self . logger . dialog_turn ( \"New agenda initialized: {} \" . format ( self . agenda )) # add hello action with some probability if common . random . random () < self . parameters [ 'usermodel' ][ 'Greeting' ]: self . agenda . push ( UserAct ( act_type = UserActionType . Hello , score = 1.0 )) # needed for possibility to reset patience if len ( self . parameters [ 'usermodel' ][ 'patience' ]) == 1 : self . dialog_patience = self . parameters [ 'usermodel' ][ 'patience' ][ 0 ] else : self . dialog_patience = common . random . randint ( * self . parameters [ 'usermodel' ][ 'patience' ]) self . patience = self . dialog_patience self . last_user_actions = None self . last_system_action = None self . excluded_venues = [] self . turn = 0 adviser.services.simulator.simulator.HandcraftedUserSimulator.receive ( self , sys_act ) This function makes sure that the agenda reflects all changes needed for the received system action. Parameters: Name Type Description Default sys_act SysAct The action the system took required Source code in adviser/services/simulator/simulator.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def receive ( self , sys_act : SysAct ): \"\"\" This function makes sure that the agenda reflects all changes needed for the received system action. Args: sys_act (SysAct): The action the system took \"\"\" if self . last_system_action is not None : # check whether system action is the same as before if sys_act == self . last_system_action : self . patience -= 1 elif self . parameters [ 'usermodel' ][ 'resetPatience' ]: self . patience = self . dialog_patience self . last_system_action = sys_act if self . patience == 0 : self . logger . dialog_turn ( \"User patience run out, ending dialog.\" ) self . agenda . clear () self . _finish_dialog ( ungrateful = True ) else : ignored_requests , ignored_requests_alt = self . _check_system_ignored_request ( self . last_user_actions , sys_act ) # first stage: push operations on top of agenda if sys_act . type in self . receive_options : self . receive_options [ sys_act . type ]( sys_act ) # handle missing requests if ignored_requests : # repeat unanswered requests from user from last turn self . agenda . push ( ignored_requests ) if ignored_requests_alt : self . agenda . push ( ignored_requests_alt ) # make sure to pick only the requestalt actions (should be 1) self . num_actions_next_turn = len ( ignored_requests_alt ) # make sure that old request actions verifying an offer are removed self . agenda . remove_actions_of_type ( act_type = UserActionType . Request ) # second stage: clean agenda self . agenda . clean ( self . goal ) # agenda might be empty -> add requests again if self . agenda . is_empty (): if self . goal . is_fulfilled (): self . _finish_dialog () else : self . agenda . fill_with_requests ( self . goal , exclude_name = False ) else : self . logger . error ( \"System Action Type is {} , but I don't know how to handle it!\" . format ( sys_act . type )) adviser.services.simulator.simulator.HandcraftedUserSimulator.respond ( self ) Gets n actions from the agenda, where n is drawn depending on the agenda or a pdf. Source code in adviser/services/simulator/simulator.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 def respond ( self ): \"\"\" Gets n actions from the agenda, where n is drawn depending on the agenda or a pdf. \"\"\" # get some actions from the agenda assert len ( self . agenda ) > 0 , \"Agenda is empty, this must not happen at this point!\" if self . num_actions_next_turn > 0 : # use and reset self.num_actions_next_turn if set num_actions = self . num_actions_next_turn self . num_actions_next_turn = - 1 elif self . agenda . stack [ - 1 ] . type == UserActionType . Bye : # pop all actions from agenda since agenda can only contain thanks (optional) and # bye action num_actions = - 1 else : # draw amount of actions num_actions = min ( len ( self . agenda ), common . numpy . random . choice ( [ 1 , 2 , 3 ], p = [ . 6 , . 3 , . 1 ])) # hardcoded pdf # get actions from agenda user_actions = self . agenda . get_actions ( num_actions ) # copy needed for repeat action since they might be changed in other modules self . last_user_actions = copy . deepcopy ( user_actions ) for action in user_actions : if action . type == UserActionType . Inform : _constraint = Constraint ( action . slot , action . value ) # if _constraint in self.goal.constraints: if action in self . goal . missing_informs : self . goal . missing_informs . remove ( action ) return user_actions","title":"simulator"},{"location":"api/services/#adviser.services.stats","text":"","title":"stats"},{"location":"api/services/#modules_11","text":"","title":"Modules"},{"location":"api/services/#adviser.services.stats.evaluation","text":"Classes adviser.services.stats.evaluation.ObjectiveReachedEvaluator Evaluate single turns and complete dialog. This class assigns a negative reward to each turn . In case the user ' s goal could be satisfied ( meaning a matching database entry was found ), a large final reward is returned . Only needed when training against a simulator . Methods adviser.services.stats.evaluation.ObjectiveReachedEvaluator.get_final_reward ( self , sim_goal , logging = True ) Check whether the user's goal was completed. Parameters: Name Type Description Default sim_goal Goal the simulation's goal required logging bool whether or not the evaluation results should be logged True Returns: Type Description Reward - the final reward (0 (unsuccessful) or 20 (successful)) Success - True or false Source code in adviser/services/stats/evaluation.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def get_final_reward ( self , sim_goal : Goal , logging = True ): \"\"\" Check whether the user's goal was completed. Args: sim_goal (Goal): the simulation's goal logging (bool): whether or not the evaluation results should be logged Returns: Reward - the final reward (0 (unsuccessful) or 20 (successful)) Success - True or false \"\"\" requests = sim_goal . requests constraints = sim_goal . constraints # list of constraints # self.logger.dialog_turn(\"User Goal > \" + str(sim_goal.constraints)) if None in requests . values () or requests [ 'name' ] == 'none' : if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False # TODO think about this more? if goals not satisfiable, # should system take the blame? not fair # print(requests['name']) db_matches = self . domain . find_info_about_entity ( entity_id = requests [ 'name' ], requested_slots = [ constraint . slot for constraint in constraints ]) if db_matches : match = db_matches [ 0 ] for const in constraints : if const . value != match [ const . slot ] and const . value != 'dontcare' : if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False if logging : self . logger . dialog_turn ( \"Success with user requests \\n {} \" . format ( requests )) return 20.0 , True if logging : self . logger . dialog_turn ( \"Fail with user requests \\n {} \" . format ( requests )) return 0.0 , False adviser.services.stats.evaluation.ObjectiveReachedEvaluator.get_turn_reward ( self ) Get the reward for one turn Returns: Type Description (int) the reward for the given turn Source code in adviser/services/stats/evaluation.py 46 47 48 49 50 51 52 53 def get_turn_reward ( self ): \"\"\" Get the reward for one turn Returns: (int): the reward for the given turn \"\"\" return self . turn_reward adviser.services.stats.evaluation.PolicyEvaluator Policy evaluation module Plug this module into the dialog graph (somewhere after the policy), and policy metrics like success rate and reward will be recorded. Methods adviser.services.stats.evaluation.PolicyEvaluator.__init__ ( self , domain , subgraph = None , use_tensorboard = False , experiment_name = '' , turn_reward =- 1 , success_reward = 20 , logger =< DiasysLogger adviser ( NOTSET ) > , summary_writer = None ) special Keyword Arguments: use_tensorboard {bool} -- [If true, metrics will be written to tensorboard in a runs directory] (default: {False}) experiment_name {str} -- [Name suffix for the log files] (default: {''}) turn_reward {float} -- [Reward for one turn - usually negative to penalize dialog length] (default: {-1}) success_reward {float} -- [Reward of the final transition if the dialog goal was reached] (default: {20}) Source code in adviser/services/stats/evaluation.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def __init__ ( self , domain : Domain , subgraph : dict = None , use_tensorboard = False , experiment_name : str = '' , turn_reward =- 1 , success_reward = 20 , logger : DiasysLogger = DiasysLogger (), summary_writer = None ): \"\"\" Keyword Arguments: use_tensorboard {bool} -- [If true, metrics will be written to tensorboard in a *runs* directory] (default: {False}) experiment_name {str} -- [Name suffix for the log files] (default: {''}) turn_reward {float} -- [Reward for one turn - usually negative to penalize dialog length] (default: {-1}) success_reward {float} -- [Reward of the final transition if the dialog goal was reached] (default: {20}) \"\"\" super ( PolicyEvaluator , self ) . __init__ ( domain ) self . logger = logger self . epoch = 0 self . evaluator = ObjectiveReachedEvaluator ( domain , turn_reward = turn_reward , success_reward = success_reward , logger = logger ) self . writer = summary_writer self . total_train_dialogs = 0 self . total_eval_dialogs = 0 self . epoch_train_dialogs = 0 self . epoch_eval_dialogs = 0 self . train_rewards = [] self . eval_rewards = [] self . train_success = [] self . eval_success = [] self . train_turns = [] self . eval_turns = [] self . is_training = False adviser.services.stats.evaluation.PolicyEvaluator.dialog_start ( self , dialog_start = False ) Clears the state of the evaluator in preparation to start a new dialog Source code in adviser/services/stats/evaluation.py 159 160 161 162 163 164 def dialog_start ( self , dialog_start = False ): \"\"\" Clears the state of the evaluator in preparation to start a new dialog \"\"\" self . dialog_reward = 0.0 self . dialog_turns = 0 adviser.services.stats.evaluation.PolicyEvaluator.end_epoch ( self ) Handles calculating statistics at the end of an epoch Source code in adviser/services/stats/evaluation.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def end_epoch ( self ): \"\"\" Handles calculating statistics at the end of an epoch \"\"\" if self . logger : if self . epoch_train_dialogs > 0 : self . logger . result ( \" ### Train ###\" ) self . logger . result ( \"# Num Dialogs \" + str ( self . epoch_train_dialogs )) self . logger . result ( \"# Avg Turns \" + str ( sum ( self . train_turns ) / self . epoch_train_dialogs )) self . logger . result ( \"# Avg Success \" + str ( sum ( self . train_success ) / self . epoch_train_dialogs )) self . logger . result ( \"# Avg Reward \" + str ( sum ( self . train_rewards ) / self . epoch_train_dialogs )) if self . epoch_eval_dialogs > 0 : self . logger . result ( \" ### Eval ###\" ) self . logger . result ( \"# Num Dialogs \" + str ( self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Turns \" + str ( sum ( self . eval_turns ) / self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Success \" + str ( sum ( self . eval_success ) / self . epoch_eval_dialogs )) self . logger . result ( \"# Avg Reward \" + str ( sum ( self . eval_rewards ) / self . epoch_eval_dialogs )) if self . is_training : return { 'num_dialogs' : self . epoch_train_dialogs , 'turns' : sum ( self . train_turns ) / self . epoch_train_dialogs , 'success' : float ( sum ( self . train_success )) / self . epoch_train_dialogs , 'reward' : float ( sum ( self . eval_rewards )) / self . epoch_train_dialogs } else : return { 'num_dialogs' : self . epoch_eval_dialogs , 'turns' : sum ( self . eval_turns ) / self . epoch_eval_dialogs , 'success' : float ( sum ( self . eval_success )) / self . epoch_eval_dialogs , 'reward' : float ( sum ( self . eval_rewards )) / self . epoch_eval_dialogs } adviser.services.stats.evaluation.PolicyEvaluator.eval ( self ) sets teh evaluator in eval mode Source code in adviser/services/stats/evaluation.py 172 173 174 175 176 def eval ( self ): \"\"\" sets teh evaluator in eval mode \"\"\" self . is_training = False adviser.services.stats.evaluation.PolicyEvaluator.start_epoch ( self ) Handles resetting variables between epochs Source code in adviser/services/stats/evaluation.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 def start_epoch ( self ): \"\"\" Handles resetting variables between epochs \"\"\" # global statistics self . epoch_train_dialogs = 0 self . epoch_eval_dialogs = 0 self . train_rewards = [] self . eval_rewards = [] self . train_success = [] self . eval_success = [] self . train_turns = [] self . eval_turns = [] self . epoch += 1 self . logger . info ( \"### \\n ### EPOCH\" + str ( self . epoch ) + \" ### \\n ###\" ) adviser.services.stats.evaluation.PolicyEvaluator.train ( self ) sets the evaluator in train mode Source code in adviser/services/stats/evaluation.py 166 167 168 169 170 def train ( self ): \"\"\" sets the evaluator in train mode \"\"\" self . is_training = True","title":"evaluation"},{"location":"api/services/#adviser.services.ust","text":"","title":"ust"},{"location":"api/services/#modules_12","text":"","title":"Modules"},{"location":"api/services/#adviser.services.ust.ust","text":"Classes adviser.services.ust.ust.HandcraftedUST A rule-based approach on user state tracking. Currently very minimalist Methods adviser.services.ust.ust.HandcraftedUST.dialog_start ( self ) Resets the user state so it is ready for a new dialog Source code in adviser/services/ust/ust.py 56 57 58 59 60 61 def dialog_start ( self ): \"\"\" Resets the user state so it is ready for a new dialog \"\"\" # initialize belief state self . us = UserState ()","title":"ust"},{"location":"api/tools/","text":"Tools","title":"Tools"},{"location":"api/tools/#tools","text":"","title":"Tools"},{"location":"api/utils/","text":"Utils adviser.utils special Modules adviser.utils.beliefstate This module provides the BeliefState class. Classes adviser.utils.beliefstate.BeliefState A representation of the belief state, can be accessed like a dictionary. Includes information on: * current set of UserActTypes * informs to date (dictionary where key is slot and value is {value: probaility}) * requests for the current turn * number of db matches for given constraints * if the db matches can further be split Methods adviser.utils.beliefstate.BeliefState.get_most_probable_inf_beliefs ( self , consider_NONE = True , threshold = 0.7 , max_results = 1 , turn_idx =- 1 ) Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Parameters: Name Type Description Default beliefstate beliefstate dict required consider_NONE bool If True, slots where NONE values have the highest probability will not be added to the result. If False, slots where NONE values have the highest probability will look for the best value != NONE . True threshold float minimum probability to be accepted to the 0.7 max_results int return at most #max_results best values per slot 1 turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Returns: Type Description A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. Source code in adviser/utils/beliefstate.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def get_most_probable_inf_beliefs ( self , consider_NONE : bool = True , threshold : float = 0.7 , max_results : int = 1 , turn_idx : int = - 1 ): \"\"\" Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Args: beliefstate: beliefstate dict consider_NONE: If True, slots where **NONE** values have the highest probability will not be added to the result. If False, slots where **NONE** values have the highest probability will look for the best value != **NONE**. threshold: minimum probability to be accepted to the max_results: return at most #max_results best values per slot turn_idx: index for accessing the belief state history (default = -1: use last turn) Returns: A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. \"\"\" # TODO: consider_NONE what does this even mean for the new beliefstate? candidates = {} informs = self . _history [ turn_idx ][ \"informs\" ] for slot in informs : # sort by belief sorted_slot_cands = sorted ( informs [ slot ] . items (), key = lambda kv : kv [ 1 ], reverse = True ) # restrict result count to specified maximum filtered_slot_cands = sorted_slot_cands [: max_results ] # threshold by probabilities filtered_slot_cands = [ slot_cand [ 0 ] for slot_cand in filtered_slot_cands if slot_cand [ 1 ] >= threshold ] if len ( filtered_slot_cands ) > 0 : # append results if any remain after filtering if max_results == 1 : # only float candidates [ slot ] = filtered_slot_cands [ 0 ] else : # list candidates [ slot ] = filtered_slot_cands return candidates adviser.utils.beliefstate.BeliefState.get_most_probable_slot_beliefs ( self , slot , consider_NONE = True , threshold = 0.7 , max_results = 1 , turn_idx =- 1 ) Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Parameters: Name Type Description Default beliefstate beliefstate dict required consider_NONE bool If True, slots where NONE values have the highest probability will not be added to the result. If False, slots where NONE values have the highest probability will look for the best value != NONE . True threshold float minimum probability to be accepted to the 0.7 max_results int return at most #max_results best values per slot 1 turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Returns: Type Description A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. Source code in adviser/utils/beliefstate.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def get_most_probable_slot_beliefs ( self , slot : str , consider_NONE : bool = True , threshold : float = 0.7 , max_results : int = 1 , turn_idx : int = - 1 ): \"\"\" Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Args: beliefstate: beliefstate dict consider_NONE: If True, slots where **NONE** values have the highest probability will not be added to the result. If False, slots where **NONE** values have the highest probability will look for the best value != **NONE**. threshold: minimum probability to be accepted to the max_results: return at most #max_results best values per slot turn_idx: index for accessing the belief state history (default = -1: use last turn) Returns: A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. \"\"\" # TODO: consider_NONE what does this even mean for the new beliefstate? informs = self . _history [ turn_idx ][ \"informs\" ] candidates = [] if slot in informs : sorted_slot_cands = sorted ( informs [ slot ] . items (), key = lambda kv : kv [ 1 ], reverse = True ) # restrict result count to specified maximum filtered_slot_cands = sorted_slot_cands [: max_results ] # threshold by probabilities filtered_slot_cands = [ slot_cand [ 0 ] for slot_cand in filtered_slot_cands if slot_cand [ 1 ] >= threshold ] return candidates adviser.utils.beliefstate.BeliefState.get_num_dbmatches ( self ) Updates the belief state's entry for the number of database matches given the constraints in the current turn. Source code in adviser/utils/beliefstate.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def get_num_dbmatches ( self ): \"\"\" Updates the belief state's entry for the number of database matches given the constraints in the current turn. \"\"\" # check how many db entities match the current constraints candidates = self . get_most_probable_inf_beliefs ( consider_NONE = True , threshold = 0.7 , max_results = 1 ) constraints = self . _remove_dontcare_slots ( candidates ) db_matches = self . domain . find_entities ( constraints , self . domain . get_informable_slots ()) num_matches = len ( db_matches ) # check if matching db entities could be discriminated by more # information from user discriminable = False if len ( db_matches ) > 1 : dontcare_slots = set ( candidates . keys ()) - set ( constraints . keys ()) informable_slots = set ( self . domain . get_informable_slots ()) - set ( self . domain . get_primary_key ()) for informable_slot in informable_slots : if informable_slot not in dontcare_slots : # this slot could be used to gather more information db_values_for_slot = set () for db_match in db_matches : db_values_for_slot . add ( db_match [ informable_slot ]) if len ( db_values_for_slot ) > 1 : # at least 2 different values for slot # ->can use this slot to differentiate between entities discriminable = True break return num_matches , discriminable adviser.utils.beliefstate.BeliefState.get_requested_slots ( self , turn_idx =- 1 ) Returns the slots requested by the user TODO: consider including some belief probability for requests Parameters: Name Type Description Default turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Source code in adviser/utils/beliefstate.py 198 199 200 201 202 203 204 205 206 207 208 209 210 def get_requested_slots ( self , turn_idx : int = - 1 ): \"\"\" Returns the slots requested by the user TODO: consider including some belief probability for requests Args: turn_idx: index for accessing the belief state history (default = -1: use last turn) \"\"\" candidates = [] for req_slot in self . _history [ turn_idx ][ 'requests' ]: candidates . append ( req_slot ) return candidates adviser.utils.beliefstate.BeliefState.start_new_turn ( self ) ONLY to be called by the belief state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules Source code in adviser/utils/beliefstate.py 85 86 87 88 89 90 91 92 def start_new_turn ( self ): \"\"\" ONLY to be called by the belief state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules \"\"\" # copy last turn's dict self . _history . append ( copy . deepcopy ( self . _history [ - 1 ])) adviser.utils.common This modules provides a method to seed commonly used random generators. Classes adviser.utils.common.Language Set of recognized languaged Functions adviser.utils.common.init_random ( seed = None ) Initializes the random generators to allow seeding. Parameters: Name Type Description Default seed int The seed used for all random generators. None Source code in adviser/utils/common.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def init_random ( seed : int = None ): \"\"\" Initializes the random generators to allow seeding. Args: seed (int): The seed used for all random generators. \"\"\" global GLOBAL_SEED # pylint: disable=global-statement if GLOBAL_SEED is not None : return if seed is None : tmp_random = numpy . random . RandomState ( None ) GLOBAL_SEED = tmp_random . randint ( 2 ** 32 - 1 , dtype = 'uint32' ) else : GLOBAL_SEED = seed # initialize random generators numpy . random . seed ( GLOBAL_SEED ) random . seed ( GLOBAL_SEED ) try : # try to load torch and initialize random generator if available import torch torch . cuda . manual_seed_all ( GLOBAL_SEED ) # gpu torch . manual_seed ( GLOBAL_SEED ) # cpu except ImportError : pass try : # try to load tensorflow and initialize random generator if available import tensorflow tensorflow . random . set_random_seed ( GLOBAL_SEED ) except ImportError : pass # check whether all calls to torch.* use the same random generator (i.e. same instance) # works in a short test -- MS # print(torch.initial_seed()) # logger.info(\"Seed is {:d}\".format(GLOBAL_SEED)) return GLOBAL_SEED adviser.utils.domain special Modules adviser.utils.domain.domain Classes adviser.utils.domain.domain.Domain Abstract class for linking a domain with a data access method. Derive from this class if you need to implement a domain with a not yet supported data backend, otherwise choose a fitting existing child class. Methods adviser.utils.domain.domain.Domain.find_entities ( self , constraints ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required IMPORTANT: This function must be overridden! Source code in adviser/utils/domain/domain.py 38 39 40 41 42 43 44 45 46 def find_entities ( self , constraints : dict ): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints IMPORTANT: This function must be overridden! \"\"\" raise NotImplementedError adviser.utils.domain.domain.Domain.get_domain_name ( self ) Return the domain name of the current ontology. Returns: Type Description str object: Source code in adviser/utils/domain/domain.py 30 31 32 33 34 35 36 def get_domain_name ( self ) -> str : \"\"\" Return the domain name of the current ontology. Returns: object: \"\"\" return self . name adviser.utils.domain.jsonlookupdomain Classes adviser.utils.domain.jsonlookupdomain.JSONLookupDomain Abstract class for linking a domain based on a JSON-ontology with a database access method (sqllite). Methods adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.__init__ ( self , name , json_ontology_file = None , sqllite_db_file = None , display_name = None ) special Loads the ontology from a json file and the data from a sqllite database. To create a new domain using this format, inherit from this class and overwrite the _get_domain_name_()-method to return your domain's name. Parameters: Name Type Description Default name str the domain's name used as an identifier required json_ontology_file str relative path to the ontology file (from the top-level adviser directory, e.g. resources/ontologies) None sqllite_db_file str relative path to the database file (from the top-level adviser directory, e.g. resources/databases) None display_name str the domain's name as it appears on the screen (e.g. containing whitespaces) None Source code in adviser/utils/domain/jsonlookupdomain.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , json_ontology_file : str = None , sqllite_db_file : str = None , \\ display_name : str = None ): \"\"\" Loads the ontology from a json file and the data from a sqllite database. To create a new domain using this format, inherit from this class and overwrite the _get_domain_name_()-method to return your domain's name. Arguments: name (str): the domain's name used as an identifier json_ontology_file (str): relative path to the ontology file (from the top-level adviser directory, e.g. resources/ontologies) sqllite_db_file (str): relative path to the database file (from the top-level adviser directory, e.g. resources/databases) display_name (str): the domain's name as it appears on the screen (e.g. containing whitespaces) \"\"\" super ( JSONLookupDomain , self ) . __init__ ( name ) root_dir = self . _get_root_dir () self . sqllite_db_file = sqllite_db_file # make sure to set default values in case of None json_ontology_file = json_ontology_file or os . path . join ( 'resources' , 'ontologies' , name + '.json' ) sqllite_db_file = sqllite_db_file or os . path . join ( 'resources' , 'databases' , name + '.db' ) self . ontology_json = json . load ( open ( root_dir + '/' + json_ontology_file )) # load database self . db = self . _load_db_to_memory ( root_dir + '/' + sqllite_db_file ) self . display_name = display_name if display_name is not None else name adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15a3664c90 > ) Returns all entities from the data backend that meet the constraints, with values for the primary key and the system requestable slots (and optional slots, specifyable via requested_slots). Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15a3664c90> Source code in adviser/utils/domain/jsonlookupdomain.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints, with values for the primary key and the system requestable slots (and optional slots, specifyable via requested_slots). Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" # values for name and all system requestable slots select_clause = \", \" . join ( set ([ self . get_primary_key ()]) | set ( self . get_system_requestable_slots ()) | set ( requested_slots )) query = \"SELECT {} FROM {} \" . format ( select_clause , self . get_domain_name ()) constraints = { slot : value . replace ( \"'\" , \"''\" ) for slot , value in constraints . items () if value is not None and str ( value ) . lower () != 'dontcare' } if constraints : query += ' WHERE ' + ' AND ' . join ( \" {} =' {} ' COLLATE NOCASE\" . format ( key , str ( val )) for key , val in constraints . items ()) return self . query_db ( query ) adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/utils/domain/jsonlookupdomain.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" if requested_slots : select_clause = \", \" . join ( sorted ( requested_slots )) # If the user hasn't specified any slots we don't know what they want so we give everything else : select_clause = \"*\" query = 'SELECT {} FROM {} WHERE {} =\" {} \";' . format ( select_clause , self . get_domain_name (), self . get_primary_key (), entity_id ) return self . query_db ( query ) adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/utils/domain/jsonlookupdomain.py 187 188 189 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return self . ontology_json [ 'informable' ] . keys () adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/utils/domain/jsonlookupdomain.py 191 192 193 194 195 196 197 198 199 200 201 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" return self . ontology_json [ 'informable' ][ slot ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_primary_key ( self ) Returns the name of a column in the associated database which can be used to uniquely distinguish between database entities. Could be e.g. the name of a restaurant, an ID, ... Source code in adviser/utils/domain/jsonlookupdomain.py 203 204 205 206 207 def get_primary_key ( self ): \"\"\" Returns the name of a column in the associated database which can be used to uniquely distinguish between database entities. Could be e.g. the name of a restaurant, an ID, ... \"\"\" return self . ontology_json [ 'key' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/utils/domain/jsonlookupdomain.py 179 180 181 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return self . ontology_json [ 'requestable' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/utils/domain/jsonlookupdomain.py 183 184 185 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return self . ontology_json [ 'system_requestable' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.query_db ( self , query_str ) Function for querying the sqlite3 db Parameters: Name Type Description Default query_str string sqlite3 query style string required Returns: Type Description (iterable) rows of the query response set Source code in adviser/utils/domain/jsonlookupdomain.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def query_db ( self , query_str ): \"\"\" Function for querying the sqlite3 db Args: query_str (string): sqlite3 query style string Return: (iterable): rows of the query response set \"\"\" if \"db\" not in self . __dict__ : root_dir = self . _get_root_dir () sqllite_db_file = self . sqllite_db_file or os . path . join ( 'resources' , 'databases' , self . name + '.db' ) self . db = self . _load_db_to_memory ( root_dir + '/' + sqllite_db_file ) cursor = self . db . cursor () cursor . execute ( query_str ) res = cursor . fetchall () return res adviser.utils.domain.lookupdomain Classes adviser.utils.domain.lookupdomain.LookupDomain Abstract class for linking a domain with a data access method. Derive from this class if you need to implement a domain with a not yet supported data backend, otherwise choose a fitting existing child class. Methods adviser.utils.domain.lookupdomain.LookupDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15a3674910 > ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required IMPORTANT: This function must be overridden! Source code in adviser/utils/domain/lookupdomain.py 33 34 35 36 37 38 39 40 41 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints IMPORTANT: This function must be overridden! \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/utils/domain/lookupdomain.py 43 44 45 46 47 48 49 50 51 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/utils/domain/lookupdomain.py 64 65 66 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_mandatory_slots ( self ) Returns a list of all mandatory slots. Source code in adviser/utils/domain/lookupdomain.py 68 69 70 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/utils/domain/lookupdomain.py 84 85 86 87 88 89 90 91 92 93 94 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_primary_key ( self ) Returns the slot name that will be used as the 'name' of an entry Source code in adviser/utils/domain/lookupdomain.py 96 97 98 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/utils/domain/lookupdomain.py 56 57 58 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/utils/domain/lookupdomain.py 60 61 62 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" raise NotImplementedError adviser.utils.logger This module provides a logger for configurable output on different levels. Classes adviser.utils.logger.DiasysLogger Logger class. This class enables logging to both a logfile and the console with different information levels . It also provides logging methods for the newly introduced information levels ( LogLevel . DIALOGS and LogLevel . RESULTS ). If file_level is set to LogLevel . NONE , no log file will be created . Otherwise , the output directory can be configured by setting log_folder . Methods adviser.utils.logger.DiasysLogger.dialog_turn ( self , msg , dialog_act = None ) Logs a turn of a dialog Source code in adviser/utils/logger.py 113 114 115 116 117 118 119 def dialog_turn ( self , msg : str , dialog_act = None ): \"\"\" Logs a turn of a dialog \"\"\" log_msg = msg if dialog_act is not None : log_msg += \" \\n \" + str ( dialog_act ) self . log ( int ( LogLevel . DIALOGS ), log_msg ) adviser.utils.logger.DiasysLogger.result ( self , msg ) Logs the result of a dialog Source code in adviser/utils/logger.py 108 109 110 111 def result ( self , msg : str ): \"\"\" Logs the result of a dialog \"\"\" self . log ( int ( LogLevel . RESULTS ), msg ) adviser.utils.logger.LogLevel The available levels for the logger. adviser.utils.logger.MultilineFormatter A formatter for the logger taking care of multiline messages. Methods adviser.utils.logger.MultilineFormatter.format ( self , record ) Format the specified record as text. The record's attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. Source code in adviser/utils/logger.py 52 53 54 55 56 57 58 59 60 61 62 def format ( self , record : logging . LogRecord ): save_msg = record . msg output = \"\" for idx , line in enumerate ( save_msg . splitlines ()): if idx > 0 : output += \" \\n \" record . msg = line output += super () . format ( record ) record . msg = save_msg record . message = output return output Functions adviser.utils.logger.exception_logging_hook ( exc_type , exc_value , exc_traceback ) Used as a hook to log exceptions. Source code in adviser/utils/logger.py 43 44 45 46 def exception_logging_hook ( exc_type , exc_value , exc_traceback ): \"\"\" Used as a hook to log exceptions. \"\"\" logging . getLogger ( 'adviser' ) . error ( \"Uncaught exception\" , exc_info = ( exc_type , exc_value , exc_traceback )) adviser.utils.sysact This module provides the necessary classes for a system action. Classes adviser.utils.sysact.SysAct The class for a system action as used in the dialog. Parameters: Name Type Description Default act_type SysActionType The type of the system action. required slot_values Dict['str', List['str']] A mapping of slot -> value to which the system required action refers depending on the action type - might be ``None``. Default None . required .. todo:: value might be actually a list? Methods adviser.utils.sysact.SysAct.add_value ( self , slot , value = None ) Add a value (or just a slot, if value=None) to the system act Source code in adviser/utils/sysact.py 74 75 76 77 78 79 def add_value ( self , slot , value = None ): \"\"\" Add a value (or just a slot, if value=None) to the system act \"\"\" if slot not in self . slot_values : self . slot_values [ slot ] = [] if value is not None : self . slot_values [ slot ] . append ( value ) adviser.utils.sysact.SysAct.get_values ( self , slot ) Return all values for slot Returns: Type Description A list of values for slot or an empy list if there was no value specified for the given slot Source code in adviser/utils/sysact.py 81 82 83 84 85 86 87 88 89 90 91 def get_values ( self , slot ): \"\"\" Return all values for slot Returns: A list of values for slot or an empy list if there was no value specified for the given slot \"\"\" if slot not in self . slot_values : return [] else : return self . slot_values [ slot ] adviser.utils.sysact.SysActionType The type for a system action as used in :class: SystemAct . adviser.utils.useract This module provides the necessary classes for a user action. Classes adviser.utils.useract.UserAct The class for a user action as used in the dialog. Parameters: Name Type Description Default text str A textual representation of the user action. required act_type UserActionType The type of the user action. required slot str The slot to which the user action refers - might be None depending on the user action. Default: None . required value str The value to which the user action refers - might be None depending on the user action. Default: None . required score float A value from 0. (not important) to 1. (important) indicating how important the information is for the belief state. Default: 1.0 . required adviser.utils.useract.UserActionType The type for a user action as used in :class: UserAct . adviser.utils.userstate This module provides the UserState class. Classes adviser.utils.userstate.EmotionType The type for a user emotion as used in :class: UserState . adviser.utils.userstate.EngagementType The type for a user engagement as used in :class: UserState . adviser.utils.userstate.UserState The representation of a user state. Can be accessed like a dictionary Methods adviser.utils.userstate.UserState.start_new_turn ( self ) ONLY to be called by the user state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules Source code in adviser/utils/userstate.py 73 74 75 76 77 78 79 80 def start_new_turn ( self ): \"\"\" ONLY to be called by the user state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules \"\"\" # copy last turn's dict self . _history . append ( copy . deepcopy ( self . _history [ - 1 ]))","title":"Utils"},{"location":"api/utils/#utils","text":"","title":"Utils"},{"location":"api/utils/#adviser.utils","text":"","title":"utils"},{"location":"api/utils/#modules","text":"","title":"Modules"},{"location":"api/utils/#adviser.utils.beliefstate","text":"This module provides the BeliefState class.","title":"beliefstate"},{"location":"api/utils/#classes","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.beliefstate.BeliefState","text":"A representation of the belief state, can be accessed like a dictionary. Includes information on: * current set of UserActTypes * informs to date (dictionary where key is slot and value is {value: probaility}) * requests for the current turn * number of db matches for given constraints * if the db matches can further be split Methods adviser.utils.beliefstate.BeliefState.get_most_probable_inf_beliefs ( self , consider_NONE = True , threshold = 0.7 , max_results = 1 , turn_idx =- 1 ) Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Parameters: Name Type Description Default beliefstate beliefstate dict required consider_NONE bool If True, slots where NONE values have the highest probability will not be added to the result. If False, slots where NONE values have the highest probability will look for the best value != NONE . True threshold float minimum probability to be accepted to the 0.7 max_results int return at most #max_results best values per slot 1 turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Returns: Type Description A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. Source code in adviser/utils/beliefstate.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def get_most_probable_inf_beliefs ( self , consider_NONE : bool = True , threshold : float = 0.7 , max_results : int = 1 , turn_idx : int = - 1 ): \"\"\" Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Args: beliefstate: beliefstate dict consider_NONE: If True, slots where **NONE** values have the highest probability will not be added to the result. If False, slots where **NONE** values have the highest probability will look for the best value != **NONE**. threshold: minimum probability to be accepted to the max_results: return at most #max_results best values per slot turn_idx: index for accessing the belief state history (default = -1: use last turn) Returns: A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. \"\"\" # TODO: consider_NONE what does this even mean for the new beliefstate? candidates = {} informs = self . _history [ turn_idx ][ \"informs\" ] for slot in informs : # sort by belief sorted_slot_cands = sorted ( informs [ slot ] . items (), key = lambda kv : kv [ 1 ], reverse = True ) # restrict result count to specified maximum filtered_slot_cands = sorted_slot_cands [: max_results ] # threshold by probabilities filtered_slot_cands = [ slot_cand [ 0 ] for slot_cand in filtered_slot_cands if slot_cand [ 1 ] >= threshold ] if len ( filtered_slot_cands ) > 0 : # append results if any remain after filtering if max_results == 1 : # only float candidates [ slot ] = filtered_slot_cands [ 0 ] else : # list candidates [ slot ] = filtered_slot_cands return candidates adviser.utils.beliefstate.BeliefState.get_most_probable_slot_beliefs ( self , slot , consider_NONE = True , threshold = 0.7 , max_results = 1 , turn_idx =- 1 ) Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Parameters: Name Type Description Default beliefstate beliefstate dict required consider_NONE bool If True, slots where NONE values have the highest probability will not be added to the result. If False, slots where NONE values have the highest probability will look for the best value != NONE . True threshold float minimum probability to be accepted to the 0.7 max_results int return at most #max_results best values per slot 1 turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Returns: Type Description A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. Source code in adviser/utils/beliefstate.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def get_most_probable_slot_beliefs ( self , slot : str , consider_NONE : bool = True , threshold : float = 0.7 , max_results : int = 1 , turn_idx : int = - 1 ): \"\"\" Extract the most probable value for each system requestable slot If the most probable value for a slot does not exceed the threshold, then the slot will not be added to the result at all. Args: beliefstate: beliefstate dict consider_NONE: If True, slots where **NONE** values have the highest probability will not be added to the result. If False, slots where **NONE** values have the highest probability will look for the best value != **NONE**. threshold: minimum probability to be accepted to the max_results: return at most #max_results best values per slot turn_idx: index for accessing the belief state history (default = -1: use last turn) Returns: A dict with mapping from slots to a list (if max_results > 1) or a float (if max_results == 1) of values containing the slots which have at least one value whose probability exceeds the specified threshold. \"\"\" # TODO: consider_NONE what does this even mean for the new beliefstate? informs = self . _history [ turn_idx ][ \"informs\" ] candidates = [] if slot in informs : sorted_slot_cands = sorted ( informs [ slot ] . items (), key = lambda kv : kv [ 1 ], reverse = True ) # restrict result count to specified maximum filtered_slot_cands = sorted_slot_cands [: max_results ] # threshold by probabilities filtered_slot_cands = [ slot_cand [ 0 ] for slot_cand in filtered_slot_cands if slot_cand [ 1 ] >= threshold ] return candidates adviser.utils.beliefstate.BeliefState.get_num_dbmatches ( self ) Updates the belief state's entry for the number of database matches given the constraints in the current turn. Source code in adviser/utils/beliefstate.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def get_num_dbmatches ( self ): \"\"\" Updates the belief state's entry for the number of database matches given the constraints in the current turn. \"\"\" # check how many db entities match the current constraints candidates = self . get_most_probable_inf_beliefs ( consider_NONE = True , threshold = 0.7 , max_results = 1 ) constraints = self . _remove_dontcare_slots ( candidates ) db_matches = self . domain . find_entities ( constraints , self . domain . get_informable_slots ()) num_matches = len ( db_matches ) # check if matching db entities could be discriminated by more # information from user discriminable = False if len ( db_matches ) > 1 : dontcare_slots = set ( candidates . keys ()) - set ( constraints . keys ()) informable_slots = set ( self . domain . get_informable_slots ()) - set ( self . domain . get_primary_key ()) for informable_slot in informable_slots : if informable_slot not in dontcare_slots : # this slot could be used to gather more information db_values_for_slot = set () for db_match in db_matches : db_values_for_slot . add ( db_match [ informable_slot ]) if len ( db_values_for_slot ) > 1 : # at least 2 different values for slot # ->can use this slot to differentiate between entities discriminable = True break return num_matches , discriminable adviser.utils.beliefstate.BeliefState.get_requested_slots ( self , turn_idx =- 1 ) Returns the slots requested by the user TODO: consider including some belief probability for requests Parameters: Name Type Description Default turn_idx int index for accessing the belief state history (default = -1: use last turn) -1 Source code in adviser/utils/beliefstate.py 198 199 200 201 202 203 204 205 206 207 208 209 210 def get_requested_slots ( self , turn_idx : int = - 1 ): \"\"\" Returns the slots requested by the user TODO: consider including some belief probability for requests Args: turn_idx: index for accessing the belief state history (default = -1: use last turn) \"\"\" candidates = [] for req_slot in self . _history [ turn_idx ][ 'requests' ]: candidates . append ( req_slot ) return candidates adviser.utils.beliefstate.BeliefState.start_new_turn ( self ) ONLY to be called by the belief state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules Source code in adviser/utils/beliefstate.py 85 86 87 88 89 90 91 92 def start_new_turn ( self ): \"\"\" ONLY to be called by the belief state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules \"\"\" # copy last turn's dict self . _history . append ( copy . deepcopy ( self . _history [ - 1 ]))","title":"BeliefState"},{"location":"api/utils/#adviser.utils.common","text":"This modules provides a method to seed commonly used random generators.","title":"common"},{"location":"api/utils/#classes_1","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.common.Language","text":"Set of recognized languaged","title":"Language"},{"location":"api/utils/#functions","text":"","title":"Functions"},{"location":"api/utils/#adviser.utils.common.init_random","text":"Initializes the random generators to allow seeding. Parameters: Name Type Description Default seed int The seed used for all random generators. None Source code in adviser/utils/common.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def init_random ( seed : int = None ): \"\"\" Initializes the random generators to allow seeding. Args: seed (int): The seed used for all random generators. \"\"\" global GLOBAL_SEED # pylint: disable=global-statement if GLOBAL_SEED is not None : return if seed is None : tmp_random = numpy . random . RandomState ( None ) GLOBAL_SEED = tmp_random . randint ( 2 ** 32 - 1 , dtype = 'uint32' ) else : GLOBAL_SEED = seed # initialize random generators numpy . random . seed ( GLOBAL_SEED ) random . seed ( GLOBAL_SEED ) try : # try to load torch and initialize random generator if available import torch torch . cuda . manual_seed_all ( GLOBAL_SEED ) # gpu torch . manual_seed ( GLOBAL_SEED ) # cpu except ImportError : pass try : # try to load tensorflow and initialize random generator if available import tensorflow tensorflow . random . set_random_seed ( GLOBAL_SEED ) except ImportError : pass # check whether all calls to torch.* use the same random generator (i.e. same instance) # works in a short test -- MS # print(torch.initial_seed()) # logger.info(\"Seed is {:d}\".format(GLOBAL_SEED)) return GLOBAL_SEED","title":"init_random()"},{"location":"api/utils/#adviser.utils.domain","text":"","title":"domain"},{"location":"api/utils/#modules_1","text":"","title":"Modules"},{"location":"api/utils/#adviser.utils.domain.domain","text":"Classes adviser.utils.domain.domain.Domain Abstract class for linking a domain with a data access method. Derive from this class if you need to implement a domain with a not yet supported data backend, otherwise choose a fitting existing child class. Methods adviser.utils.domain.domain.Domain.find_entities ( self , constraints ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required IMPORTANT: This function must be overridden! Source code in adviser/utils/domain/domain.py 38 39 40 41 42 43 44 45 46 def find_entities ( self , constraints : dict ): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints IMPORTANT: This function must be overridden! \"\"\" raise NotImplementedError adviser.utils.domain.domain.Domain.get_domain_name ( self ) Return the domain name of the current ontology. Returns: Type Description str object: Source code in adviser/utils/domain/domain.py 30 31 32 33 34 35 36 def get_domain_name ( self ) -> str : \"\"\" Return the domain name of the current ontology. Returns: object: \"\"\" return self . name","title":"domain"},{"location":"api/utils/#adviser.utils.domain.jsonlookupdomain","text":"Classes adviser.utils.domain.jsonlookupdomain.JSONLookupDomain Abstract class for linking a domain based on a JSON-ontology with a database access method (sqllite). Methods adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.__init__ ( self , name , json_ontology_file = None , sqllite_db_file = None , display_name = None ) special Loads the ontology from a json file and the data from a sqllite database. To create a new domain using this format, inherit from this class and overwrite the _get_domain_name_()-method to return your domain's name. Parameters: Name Type Description Default name str the domain's name used as an identifier required json_ontology_file str relative path to the ontology file (from the top-level adviser directory, e.g. resources/ontologies) None sqllite_db_file str relative path to the database file (from the top-level adviser directory, e.g. resources/databases) None display_name str the domain's name as it appears on the screen (e.g. containing whitespaces) None Source code in adviser/utils/domain/jsonlookupdomain.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , json_ontology_file : str = None , sqllite_db_file : str = None , \\ display_name : str = None ): \"\"\" Loads the ontology from a json file and the data from a sqllite database. To create a new domain using this format, inherit from this class and overwrite the _get_domain_name_()-method to return your domain's name. Arguments: name (str): the domain's name used as an identifier json_ontology_file (str): relative path to the ontology file (from the top-level adviser directory, e.g. resources/ontologies) sqllite_db_file (str): relative path to the database file (from the top-level adviser directory, e.g. resources/databases) display_name (str): the domain's name as it appears on the screen (e.g. containing whitespaces) \"\"\" super ( JSONLookupDomain , self ) . __init__ ( name ) root_dir = self . _get_root_dir () self . sqllite_db_file = sqllite_db_file # make sure to set default values in case of None json_ontology_file = json_ontology_file or os . path . join ( 'resources' , 'ontologies' , name + '.json' ) sqllite_db_file = sqllite_db_file or os . path . join ( 'resources' , 'databases' , name + '.db' ) self . ontology_json = json . load ( open ( root_dir + '/' + json_ontology_file )) # load database self . db = self . _load_db_to_memory ( root_dir + '/' + sqllite_db_file ) self . display_name = display_name if display_name is not None else name adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15a3664c90 > ) Returns all entities from the data backend that meet the constraints, with values for the primary key and the system requestable slots (and optional slots, specifyable via requested_slots). Parameters: Name Type Description Default constraints dict Slot-value mapping of constraints. If empty, all entities in the database will be returned. required requested_slots Iterable list of slots that should be returned in addition to the system requestable slots and the primary key <tuple_iterator object at 0x7f15a3664c90> Source code in adviser/utils/domain/jsonlookupdomain.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints, with values for the primary key and the system requestable slots (and optional slots, specifyable via requested_slots). Args: constraints (dict): Slot-value mapping of constraints. If empty, all entities in the database will be returned. requested_slots (Iterable): list of slots that should be returned in addition to the system requestable slots and the primary key \"\"\" # values for name and all system requestable slots select_clause = \", \" . join ( set ([ self . get_primary_key ()]) | set ( self . get_system_requestable_slots ()) | set ( requested_slots )) query = \"SELECT {} FROM {} \" . format ( select_clause , self . get_domain_name ()) constraints = { slot : value . replace ( \"'\" , \"''\" ) for slot , value in constraints . items () if value is not None and str ( value ) . lower () != 'dontcare' } if constraints : query += ' WHERE ' + ' AND ' . join ( \" {} =' {} ' COLLATE NOCASE\" . format ( key , str ( val )) for key , val in constraints . items ()) return self . query_db ( query ) adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/utils/domain/jsonlookupdomain.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" if requested_slots : select_clause = \", \" . join ( sorted ( requested_slots )) # If the user hasn't specified any slots we don't know what they want so we give everything else : select_clause = \"*\" query = 'SELECT {} FROM {} WHERE {} =\" {} \";' . format ( select_clause , self . get_domain_name (), self . get_primary_key (), entity_id ) return self . query_db ( query ) adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/utils/domain/jsonlookupdomain.py 187 188 189 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" return self . ontology_json [ 'informable' ] . keys () adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/utils/domain/jsonlookupdomain.py 191 192 193 194 195 196 197 198 199 200 201 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" return self . ontology_json [ 'informable' ][ slot ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_primary_key ( self ) Returns the name of a column in the associated database which can be used to uniquely distinguish between database entities. Could be e.g. the name of a restaurant, an ID, ... Source code in adviser/utils/domain/jsonlookupdomain.py 203 204 205 206 207 def get_primary_key ( self ): \"\"\" Returns the name of a column in the associated database which can be used to uniquely distinguish between database entities. Could be e.g. the name of a restaurant, an ID, ... \"\"\" return self . ontology_json [ 'key' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/utils/domain/jsonlookupdomain.py 179 180 181 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" return self . ontology_json [ 'requestable' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/utils/domain/jsonlookupdomain.py 183 184 185 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" return self . ontology_json [ 'system_requestable' ] adviser.utils.domain.jsonlookupdomain.JSONLookupDomain.query_db ( self , query_str ) Function for querying the sqlite3 db Parameters: Name Type Description Default query_str string sqlite3 query style string required Returns: Type Description (iterable) rows of the query response set Source code in adviser/utils/domain/jsonlookupdomain.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def query_db ( self , query_str ): \"\"\" Function for querying the sqlite3 db Args: query_str (string): sqlite3 query style string Return: (iterable): rows of the query response set \"\"\" if \"db\" not in self . __dict__ : root_dir = self . _get_root_dir () sqllite_db_file = self . sqllite_db_file or os . path . join ( 'resources' , 'databases' , self . name + '.db' ) self . db = self . _load_db_to_memory ( root_dir + '/' + sqllite_db_file ) cursor = self . db . cursor () cursor . execute ( query_str ) res = cursor . fetchall () return res","title":"jsonlookupdomain"},{"location":"api/utils/#adviser.utils.domain.lookupdomain","text":"Classes adviser.utils.domain.lookupdomain.LookupDomain Abstract class for linking a domain with a data access method. Derive from this class if you need to implement a domain with a not yet supported data backend, otherwise choose a fitting existing child class. Methods adviser.utils.domain.lookupdomain.LookupDomain.find_entities ( self , constraints , requested_slots =< tuple_iterator object at 0x7f15a3674910 > ) Returns all entities from the data backend that meet the constraints. Parameters: Name Type Description Default constraints dict slot-value mapping of constraints required IMPORTANT: This function must be overridden! Source code in adviser/utils/domain/lookupdomain.py 33 34 35 36 37 38 39 40 41 def find_entities ( self , constraints : dict , requested_slots : Iterable = iter (())): \"\"\" Returns all entities from the data backend that meet the constraints. Args: constraints (dict): slot-value mapping of constraints IMPORTANT: This function must be overridden! \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.find_info_about_entity ( self , entity_id , requested_slots ) Returns the values (stored in the data backend) of the specified slots for the specified entity. Parameters: Name Type Description Default entity_id str primary key value of the entity required requested_slots Iterable slot-value mapping of constraints required Source code in adviser/utils/domain/lookupdomain.py 43 44 45 46 47 48 49 50 51 def find_info_about_entity ( self , entity_id , requested_slots : Iterable ): \"\"\" Returns the values (stored in the data backend) of the specified slots for the specified entity. Args: entity_id (str): primary key value of the entity requested_slots (dict): slot-value mapping of constraints \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_informable_slots ( self ) Returns a list of all informable slots. Source code in adviser/utils/domain/lookupdomain.py 64 65 66 def get_informable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all informable slots. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_mandatory_slots ( self ) Returns a list of all mandatory slots. Source code in adviser/utils/domain/lookupdomain.py 68 69 70 def get_mandatory_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all mandatory slots. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_possible_values ( self , slot ) Returns all possible values for an informable slot Parameters: Name Type Description Default slot str name of the slot required Returns: Type Description List[str] a list of strings, each string representing one possible value for the specified slot. Source code in adviser/utils/domain/lookupdomain.py 84 85 86 87 88 89 90 91 92 93 94 def get_possible_values ( self , slot : str ) -> List [ str ]: \"\"\" Returns all possible values for an informable slot Args: slot (str): name of the slot Returns: a list of strings, each string representing one possible value for the specified slot. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_primary_key ( self ) Returns the slot name that will be used as the 'name' of an entry Source code in adviser/utils/domain/lookupdomain.py 96 97 98 def get_primary_key ( self ) -> str : \"\"\" Returns the slot name that will be used as the 'name' of an entry \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_requestable_slots ( self ) Returns a list of all slots requestable by the user. Source code in adviser/utils/domain/lookupdomain.py 56 57 58 def get_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the user. \"\"\" raise NotImplementedError adviser.utils.domain.lookupdomain.LookupDomain.get_system_requestable_slots ( self ) Returns a list of all slots requestable by the system. Source code in adviser/utils/domain/lookupdomain.py 60 61 62 def get_system_requestable_slots ( self ) -> List [ str ]: \"\"\" Returns a list of all slots requestable by the system. \"\"\" raise NotImplementedError","title":"lookupdomain"},{"location":"api/utils/#adviser.utils.logger","text":"This module provides a logger for configurable output on different levels.","title":"logger"},{"location":"api/utils/#classes_2","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.logger.DiasysLogger","text":"Logger class. This class enables logging to both a logfile and the console with different information levels . It also provides logging methods for the newly introduced information levels ( LogLevel . DIALOGS and LogLevel . RESULTS ). If file_level is set to LogLevel . NONE , no log file will be created . Otherwise , the output directory can be configured by setting log_folder . Methods adviser.utils.logger.DiasysLogger.dialog_turn ( self , msg , dialog_act = None ) Logs a turn of a dialog Source code in adviser/utils/logger.py 113 114 115 116 117 118 119 def dialog_turn ( self , msg : str , dialog_act = None ): \"\"\" Logs a turn of a dialog \"\"\" log_msg = msg if dialog_act is not None : log_msg += \" \\n \" + str ( dialog_act ) self . log ( int ( LogLevel . DIALOGS ), log_msg ) adviser.utils.logger.DiasysLogger.result ( self , msg ) Logs the result of a dialog Source code in adviser/utils/logger.py 108 109 110 111 def result ( self , msg : str ): \"\"\" Logs the result of a dialog \"\"\" self . log ( int ( LogLevel . RESULTS ), msg )","title":"DiasysLogger"},{"location":"api/utils/#adviser.utils.logger.LogLevel","text":"The available levels for the logger.","title":"LogLevel"},{"location":"api/utils/#adviser.utils.logger.MultilineFormatter","text":"A formatter for the logger taking care of multiline messages. Methods adviser.utils.logger.MultilineFormatter.format ( self , record ) Format the specified record as text. The record's attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. Source code in adviser/utils/logger.py 52 53 54 55 56 57 58 59 60 61 62 def format ( self , record : logging . LogRecord ): save_msg = record . msg output = \"\" for idx , line in enumerate ( save_msg . splitlines ()): if idx > 0 : output += \" \\n \" record . msg = line output += super () . format ( record ) record . msg = save_msg record . message = output return output","title":"MultilineFormatter"},{"location":"api/utils/#functions_1","text":"","title":"Functions"},{"location":"api/utils/#adviser.utils.logger.exception_logging_hook","text":"Used as a hook to log exceptions. Source code in adviser/utils/logger.py 43 44 45 46 def exception_logging_hook ( exc_type , exc_value , exc_traceback ): \"\"\" Used as a hook to log exceptions. \"\"\" logging . getLogger ( 'adviser' ) . error ( \"Uncaught exception\" , exc_info = ( exc_type , exc_value , exc_traceback ))","title":"exception_logging_hook()"},{"location":"api/utils/#adviser.utils.sysact","text":"This module provides the necessary classes for a system action.","title":"sysact"},{"location":"api/utils/#classes_3","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.sysact.SysAct","text":"The class for a system action as used in the dialog. Parameters: Name Type Description Default act_type SysActionType The type of the system action. required slot_values Dict['str', List['str']] A mapping of slot -> value to which the system required action refers depending on the action type - might be ``None``. Default None . required .. todo:: value might be actually a list? Methods adviser.utils.sysact.SysAct.add_value ( self , slot , value = None ) Add a value (or just a slot, if value=None) to the system act Source code in adviser/utils/sysact.py 74 75 76 77 78 79 def add_value ( self , slot , value = None ): \"\"\" Add a value (or just a slot, if value=None) to the system act \"\"\" if slot not in self . slot_values : self . slot_values [ slot ] = [] if value is not None : self . slot_values [ slot ] . append ( value ) adviser.utils.sysact.SysAct.get_values ( self , slot ) Return all values for slot Returns: Type Description A list of values for slot or an empy list if there was no value specified for the given slot Source code in adviser/utils/sysact.py 81 82 83 84 85 86 87 88 89 90 91 def get_values ( self , slot ): \"\"\" Return all values for slot Returns: A list of values for slot or an empy list if there was no value specified for the given slot \"\"\" if slot not in self . slot_values : return [] else : return self . slot_values [ slot ]","title":"SysAct"},{"location":"api/utils/#adviser.utils.sysact.SysActionType","text":"The type for a system action as used in :class: SystemAct .","title":"SysActionType"},{"location":"api/utils/#adviser.utils.useract","text":"This module provides the necessary classes for a user action.","title":"useract"},{"location":"api/utils/#classes_4","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.useract.UserAct","text":"The class for a user action as used in the dialog. Parameters: Name Type Description Default text str A textual representation of the user action. required act_type UserActionType The type of the user action. required slot str The slot to which the user action refers - might be None depending on the user action. Default: None . required value str The value to which the user action refers - might be None depending on the user action. Default: None . required score float A value from 0. (not important) to 1. (important) indicating how important the information is for the belief state. Default: 1.0 . required","title":"UserAct"},{"location":"api/utils/#adviser.utils.useract.UserActionType","text":"The type for a user action as used in :class: UserAct .","title":"UserActionType"},{"location":"api/utils/#adviser.utils.userstate","text":"This module provides the UserState class.","title":"userstate"},{"location":"api/utils/#classes_5","text":"","title":"Classes"},{"location":"api/utils/#adviser.utils.userstate.EmotionType","text":"The type for a user emotion as used in :class: UserState .","title":"EmotionType"},{"location":"api/utils/#adviser.utils.userstate.EngagementType","text":"The type for a user engagement as used in :class: UserState .","title":"EngagementType"},{"location":"api/utils/#adviser.utils.userstate.UserState","text":"The representation of a user state. Can be accessed like a dictionary Methods adviser.utils.userstate.UserState.start_new_turn ( self ) ONLY to be called by the user state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules Source code in adviser/utils/userstate.py 73 74 75 76 77 78 79 80 def start_new_turn ( self ): \"\"\" ONLY to be called by the user state tracker at the begin of each turn, to ensure the correct history can be accessed correctly by other modules \"\"\" # copy last turn's dict self . _history . append ( copy . deepcopy ( self . _history [ - 1 ]))","title":"UserState"},{"location":"tutorials/advanced/","text":"Todo Add link to notebook Advanced Topics With ADVISER 2.0 Now that you have covered how to work with the existing core services of the ADVISER 2.0 Toolkit, let's discuss some of the more advanced features, such as running a distributed system, emotion detection, how create a new domain, and how to add new services Creating a New Domain Database In order to create a new domain, you need an SQLite database with the following properties: * it contains a single table * each row represents an entity in the database * each column in the table represents a slot (entity property such as \"name\", \"color\", \"last_known_location\", etc) * binary slots should only have values true or false As a note, it is also possible to create a new domain with an API backend instead of a fixed database, but in this case, it may not be possible to use the ontology generation tool shown in the next session. Ontology Once you have a database, the next step is to create an ontology for the new domain. This can be done using the ontology creation tool provided with ADVISER 2.0. The tool is located in the folder resources/ontologies/create_ontology.py To use the tool, open a terminal and navigate to the folder with the ontology creation tool. The tool can then be called by typing the following command: python3 create_ontology.py path/to/your/database/YourDomainName.db As a fist step, you must choose the table you want to use (we will use the ImsCourses database located in resources/databases for demonstration purposes). The interface for this tool can be seen in the image below: Afterwards, you are asked to name your new domain and then apply the appropriate labels to the different slots. Possible slots will be shown and can be navigated through with the arrow keys. The space bar can be used to select any slots a proposed label applies to. An active selection is indicated by a blue circle. Possible slot types are * Informable: information the user can inform the system about * System requestable: information the system can actively ask the user for * Requestable: information the user can request from the system When the system asks you to identify the primary key, this means you should reference the column in your database which uniquely discriminates all database entries (preferably in a human-readable way, not just an index) - in case of the IMSCourses domain, this is the name of the course. Selection screens for slots / values look like this: And the end output should be a file in JSON format like the one shown in the excerpt below: As a final step the system will ask if you want to copy the database, if your database is not already located inside the folder resources/databases , you should select \"yes\" to this operation, so a copy of your database is where it will be expected when creating a new Domain object. After the tool terminates successfully, check that the following two files were created inside the folders resources/databases and resources/ontologies : * [YourDomainName].db * [YourDomainName].json Domain Object Once you have your ontology and database, you can create a Domain object for your new domain, as seen in the previous tutorial: from utils.domain.jsonlookupdomain import JSONLookupDomain your_domain_instance = JSONLookupDomain ( name = 'YourDomainName' , json_ontology_file = 'resources/databases/YourDomainName.json' , sqllite_db_file = 'resources/databases/YourDomainName.db' ) You can than use the object to instantiate the modules that constitute your dialog graph. NLU and NLG Another important thing to remember is to create NLU regexes and NLG templates for your new domain, see the previous tutorial if you have questions on this process. Policy In some cases, a new domain may require a new policy and new user_acts or sys_acts if the new domain requires functionality not provided by the original policy, it may be neccessary to expand the list of user or system acts. For reference, these lists are shown in the previous sections under the NLU and Policy sections respectively. If new acts are added, the policy must be expanded to be able to accept the new user acts as input and to generate the new system actions as output. This can be done by inheriting from the current policy. Creating a New Service As we saw in Tutorial 2, all of the modules in the ADVISER 2.0 toolkit are children of the Service class. This means in order to create a new module, you need to create a new service. In the previous tutorial we showed an example of how to do this for a simple case. In this section, we will go into more depth on dialog system specifics to consider when creating a service. Inheriting from the service class Step one is always to inherit from the service class. Doing this means that your new service requires a domain argument on instantiation, but also that it can take the following optional arguments (which you saw in Tutorial 3): * sub_topic_domains * pub_topic_domains which allow users to overwrite subsribe/publish topics on instantiation. This can be useful in some cases when combining domain specific services with non domain specific services. Determine what methods need to be decorated The next important step is to consider which methods in your new service should be decorated and what topics it should subscibe to/publish. As a general rule, only methods which will directly interact with other services need to be decorated. If all communication happens inside of a class, normal class methods are sufficient. Another important note, when decorating a method make sure that the list of subscribe topics matches the list of method arguments and that you have checked the topics you subsrcibe to will be published by another method and the topics which you publish will be subscribed to by another method. Managing Dialog-Dependent State Another important concern is dialog dependent state. That is, information which gets tracked within a service over the course of a dialog, but should be reset between dialogs. If you want to initialize/reset per-dialog state or want to perform other actions before the first / after the last dialog turn, you can overwrite the dialog_start and dialog_end methods provided by the Service class. These will automatically be called before the start and end of a dialog, so you do not need to worry about decorating them extra. In fact, since topics don't have any guarantees on order of delivery using these methods is preferable to decorating because the methods are guranteed to be called before the first dialog turn and after the last one respectively. Since our dialog system might be migrated to multi-session support at some point, we consider it best practice to initialize/reset all dialog-dependent state not in the constructor but rather inside these two methods. Adding Task-specific Feature Extraction Certain tasks, such as emotion recognition or backchanneling, require specific acoustic and/or visual features as input (see the following sections). To retain maximum modularity, we recommend that feature extraction is separated from the actual task. Therefore, in this section we look at an example of a speech feature extraction module which subscribes to an audio recording and publishes a feature vector. The feature extractor is a service, i.e. it inherits from the service class: from services.service import PublishSubscribe from services.service import Service from torchaudio.compliance import kaldi class SpeechFeatureExtractor ( Service ): \"\"\"Simple feature extractor which uses torchaudio to compute MFCCs.\"\"\" def __init__ ( self ): Service . __init__ ( self ) Now, let's create a simple decorated method for feature extraction. Note, in the current ADVISER implementation, 'speech_in' is a tuple that consists of a numpy array representing the audio recording and the sampling rate: (data, sample_rate). This way, everything can be handled in memory without needing to write and delete files. @PublishSubscribe ( sub_topics = [ 'speech_in' ], pub_topics = [ 'mfcc_features' ]) def speech_to_features ( self , speech_in ): features = kaldi . mfcc ( speech_in [ 0 ], sample_frequency = speech_in [ 1 ]) return { 'mfcc_features' : features } For the sake of illustration, this example uses torchaudio to extract MFCC features . In the current ADVISER implementation, we use the openSMILE toolkit to extract MFCCs and addtionally, GeMAPS features, which are used for emotion recognition. Adding Emotion Recognition The current implementation of ADVISER 2.0 provides a basic module for emotion recognition from speech features. The prerequisites for this module are: * A pre-trained model for emotion prediction * The corresponding acoustic features as input ( see section above ) Implementation and training of a machine learning model for emotion prediction is not part of this tutorial. However, in the current ADVISER 2.0 system, we provide basic multi-layer perceptron models which are trained on the MSP-IMPROV database [1]. In the following code, we see an example emotion recognition class. As with any other module, it inherits from the Service class and uses the PublishSubscribe decorator to communicate with other services. In this example, there is only one model for arousal level prediction involved. Since emotions can be represented in different ways (e.g. arousal/valence levels or categories like 'angry', 'happy', 'sad'), the published topic 'emotion' contains a dictionary which can hold the different predicted representations. class EmotionRecognition ( Service ): def __init__ ( self ): Service . __init__ ( self ) self . emotion_dir = os . path . dirname ( os . path . abspath ( __file__ )) model_path = << file path to emotion recognition models >> self . arousal_model = joblib . load ( os . path . join ( model_path , 'mlp_audio_arousal.joblib' )) @PublishSubscribe ( sub_topics = [ \"gemaps_features\" ], pub_topics = [ \"emotion\" ]) def predict_from_audio ( self , gemaps_features ): arousal_prediction = self . arousal_model . predict_proba ( gemaps_features ) return { 'emotion' : { 'arousal' : arousal_prediction }} Note, this emotion recognition module is a very basic implementation for illustration purposes. It can easily be improved by inserting more sophisticated machine learning models or by adding video features to perform multimodal emotion recognition. [1] Busso, Carlos, et al. \"MSP-IMPROV: An acted corpus of dyadic interactions to study emotion perception.\" IEEE Transactions on Affective Computing 8.1 (2016): 67-80. Using Emotion in a Dialog System The ADVISER 2.0 currently provides a UserStateTracker service which keeps track of the detected user emotion and user engagement level. This module works in conjunction with a naive EmotionPolicy service to map user emotion to a system emotional response. Currently this is done with a direct mapping from the recognized user emotion to the same emotion for the system response. This \"system emotion\" can then be used bye the HandcraftedEmotionNLG service to select an affective NLG template in order to react to user emotion. This system can be seen below. This direct mapping is obviously highly simplistic and may be expanded in future versions of ADVISER. Adding Backchanneling Backchannel prediction ADVISER 2.0 comes with an acoustic backchannel module that makes use of a pre-trained backchanneler model and MFCC features as input ( see section above ). The backchanneller implementation consists of a convolutional neural network model based on [1] and trained on the Switchboard benchmark dataset [2]. As input, it receives 13 Mel-frequency-cepstral coefficients from the user\u2019s speech signal. The model assigns one of three categories from the proactive backchanneling theory [3] to each user utterance {no-backchannel, backchannel-continuer and backchannel-assessment}. The predicted category is used to add the backchannel realization, such as Okay or Um-hum, at the begining the next system response. In the our project, you can find two python files: acoustic_backchanneller.py (Definition of the backchannelling module) PytorchAcousticBackchanneler.py (PyTorch implementation that loads the pretrained model for prediction) We present a code extract from the class acoustic backchanneller (service). As any other module, it inherits from the Service class and uses the PublishSubscribe decorator to communicate with other services. class AcousticBackchanneller ( Service ): def __init__ ( self ): Service . __init__ ( self ) self . speech_in_dir = os . path . dirname ( os . path . abspath ( __file__ )) + '/' self . trained_model_path = os . path . join ( 'resources' , 'models' , 'backchannel' ) + '/pytorch_acoustic_backchanneller.pt' self . load_model () def load_model ( self ): self . model = PytorchAcousticBackchanneler () self . model . load_state_dict ( torch . load ( self . trained_model_path )) self . model . eval () @PublishSubscribe ( sub_topics = [ 'mfcc_features' ], pub_topics = [ \"predicted_BC\" ]) def backchannel_prediction ( self , mfcc_features : np . array ): \"\"\"Takes temporary user utterance wav file and extracts features from it.\"\"\" scaler = preprocessing . StandardScaler () mfcc_features = scaler . fit_transform ( mfcc_features ) input_splits = self . split_input_data ( mfcc_features ) prediction = self . model ( input_splits ) . detach () . numpy () . argmax ( axis = 1 ) # Returning the majority, unless a BC appears, # class_int_mapping = {0: b'no_bc', 1: b'assessment', 2: b'continuer'} if len ( set ( prediction )) == 1 : return { 'predicted_BC' : prediction [ 0 ]} elif 1 in prediction and 2 in prediction : ones = len ( prediction [ prediction == 1 ]) twos = len ( prediction [ prediction == 2 ]) return { 'predicted_BC' : 1 if ones > twos else 2 } else : return { 'predicted_BC' : 1 if 1 in prediction else 2 } This backchanneller only makes use of acoustic features, however, a more complex module can be implemented, so that it can also profit from ASR trancriptions as shown in [2]. Integrating backchannel to the system's response After the backchannel prediction is done, the corresponding backchannel realization should be added to the system response. For simplicity, we decided to add it at the beginning of the system response already generated by the NLG module. This code can be found in the class BackchannelHandcraftedNLG(HandcraftedNLG) . Here we have a sample of the most relevant code. class BackchannelHandcraftedNLG ( HandcraftedNLG ): def __init__ ( self , domain : Domain , sub_topic_domains : Dict [ str , str ] = {}, template_file : str = None , logger : DiasysLogger = DiasysLogger (), template_file_german : str = None , language : Language = None ): HandcraftedNLG . __init__ ( self , domain , template_file = None , logger = DiasysLogger (), template_file_german = None , language = None , sub_topic_domains = sub_topic_domains ) # class_int_mapping = {0: b'no_bc', 1: b'assessment', 2: b'continuer'} self . backchannels = { 0 : '' , 1 : 'Okay. ' , 2 : 'Um-hum. ' } @PublishSubscribe ( sub_topics = [ \"sys_act\" , 'predicted_BC' ], pub_topics = [ \"sys_utterance\" ]) def generate_system_utterance ( self , sys_act : SysAct = None , predicted_BC : int = None ) -> dict ( sys_utterance = str ): rule_found = True message = \"\" try : message = self . templates . create_message ( sys_act ) if 'Sorry' not in message : message = self . backchannels [ predicted_BC ] + message except BaseException as error : rule_found = False self . logger . error ( error ) raise ( error ) The backchanneller does not show variety in its realizations, however, this can be easily implemented if needed. [1] Daniel Ortega, Chia-Yu Li, NgocThang Vu. \"Oh,Jeez! or uh-huh?\" A listener- aware backchannel predictor on ASR transcriptions. ICASSP,2020. [2] D. Jurafsky and E. Shriberg. \u201cSwitchboard swbd-damsl shallow-discourse-function annotation coders manual.\u201d Institute of Cognitive Science Technical Report, 1997. [3] Charles Goodwin. 1986. Between and within: Alterna- tive sequential treatments of continuers and assess- ments.\" Journal of Human Studies. From Single- to Multidomain For more complex scenarios, it may make sense to split your dialog system into multiple domains. For example if your goal is to create a university student assistant bot. You may decide that as a start you want your system to help students find information about lecturers and help students to find out what the dining hall (Mensa) is serving. While in theory these two topics could be put together into the same domain, mensa information updates every day so accessing this through a web API is preferable to only having a fixed database. For the lecturers, however there is no web API, and this inofmration remains largely static, so a fixed database is preferable. At this point, since the data sources, and the actual topics of conversation for each topic are so different, giving each its own domain makes sense. But how do we do that? Domain Dependent Modules Services like the Natural Language Understanding, Belief State Tracker and Policy are domain dependent: they require domain-specific ontology knowledge (e.g. towns for weather, food names for the mensa) or database access to function. Rather than re-implementing these modules for your specific purposes, however, you can instantiate these services with the corresponding domains (one instance per domain). First we will handle importing all the modules we need and create our domain objects: # IMPORT DOMAINS AND SERVICES import sys import os from typing import List import time sys . path . insert ( 0 , os . path . abspath ( '../..' )) from services.service import Service , PublishSubscribe , RemoteService from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.policy.policy_api import HandcraftedPolicy as PolicyAPI from services.nlg import HandcraftedNLG from services.service import DialogSystem # from examples.webapi.mensa import MensaNLU from utils.domain.domain import Domain from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from examples.webapi.mensa.domain import MensaDomain from examples.webapi.mensa.nlu import MensaNLU # CREATE DOMAIN OBJECTS canteen = MensaDomain () lecturers = JSONLookupDomain ( 'ImsLecturers' ) Next let's start creating our Domain Dependent modules: * NLU is domain dependent because it needs access to different regex files depending on the domain # NLU needs domain to load correct regexe files lecturer_nlu = HandcraftedNLU ( domain = lecturers ) dining_hall_nlu = MensaNLU ( domain = canteen ) BST is domain dependent because it needs access to an ontology so it knows what the informable requestable slots it needs to track # BST needs domain to track correct informable/requestable slots lecturer_bst = HandcraftedBST ( domain = lecturers ) dining_hall_bst = HandcraftedBST ( domain = canteen ) Policy is domain dependent because it needs to know which database to query to determine the next system action # Policy needs domain to access the correct database lecturer_policy = HandcraftedPolicy ( domain = lecturers ) dining_hall_policy = PolicyAPI ( domain = canteen ) NLG is domain dependent because it needs to access the correct template files to generate natural language output # NLG needs to access domain dependent template files lecturer_nlg = HandcraftedNLG ( domain = lecturers ) dining_hall_nlg = HandcraftedNLG ( domain = canteen ) Domain Independent Modules In comparison to the previously shown services, there are also modules in a dialog system that are domain independent, such as ASR and TTS or console input and console output. Regardless of the domain, these modules do the same thing: take in a user input and pass it out as a string. Since these services do not change, domain-independent services only need to be instantiated once. An example using console input and console output modules is shown below. Where previously we passed in a domain, here since they are domain independent, we pass in an empty string. from services.hci.console import ConsoleInput , ConsoleOutput user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" ) Domain Tracker Module Once you have created all of domain dependent and independent modules, you will need some way to decide which domain should be active at a given time. That is where the DomainTracker module comes in. The goal of this module is to take in a domain independent user utterance and map it to the correct domain as shown in the image below: The domain tracker is something between domain dependent and domain independent. On instantiation, it takes in a list of possible domains which it can forward a user utterance to, although there is no need to create a new DomainTracker for each domain in the dialog system. In the current implementation, this module relies on keywords matching, inspired by commercial systems, to determine which domain should be active at any given time. This means that at any time, at most one domain will be active. However a more advanced domain tracker could be implemented to replace this in the future and might even be able to support dialog in multiple domains at the same time. To determine which domain should be active, the DomainTracker follows a series of simple rules shown in the image below: If there is only one domain, that domain is always active. If there are more domains, the tracker checks if it is the first turn. If so the system issues a greeting to the user and tells them what domains the dialog system can talk about. If not, the domain tracker checks for domain keywords. If any appear in the user utterance, the first to appear is the domain selected, as the dialog system is not yet capable of handling multiple domains active during the same turn. If there is no keyword, the tracker checks to see if a domain was active the previous turn, if yes, it is assumed that that domain remains active. If there was no active domain in the previous turn, the tracker checks to see if the user said 'bye', if so the tracker will also say 'bye'. If not, the tracker then reminds the user of the domains it is capable of tracking. This can also be seen in the code below: \"\"\" The domain tracker has to know all domains our application should be able to handle, but not not append domain names to topics by default, so it stores a list of domains, but doesn't forward any of them to the service base class constructor: \"\"\" class DomainTracker ( Service ): def __init__ ( self , domains : List [ Domain ], greet_on_first_turn : bool = False ): Service . __init__ ( self , domain = \"\" ) self . domains = domains self . current_domain = None self . greet_on_first_turn = greet_on_first_turn \"\"\" Since service output relies on per-dialog state (turn count, currently active domain), it needs to initialize this state before each new dialog:\"\"\" def dialog_start ( self ): self . turn = 0 \"\"\" Furthermore, it needs to subscribe to user utterances and forward them (`gen_user_utterance` is short for `generic user utterance`) as a domain-dependent user utterance, or, if no domain is active, publish a system utterance listing all available domains: \"\"\" @PublishSubscribe ( sub_topics = [ \"gen_user_utterance\" ], pub_topics = [ \"user_utterance\" , \"sys_utterance\" ]) def select_domain ( self , gen_user_utterance : str = None ) -> dict ( user_utterance = str ): self . turn += 1 if self . turn == 1 and self . greet_on_first_turn : return { 'sys_utterance' : \"Hello, please let me know how I can help you, I can discuss \" + f \"the following domains: { self . domains_to_str () } .\" } # if there is only a single domain, simply route the message forward if len ( self . domains ) == 1 : self . current_domain = self . domains [ 0 ] # make sure the utterance is lowercase if there is one user_utterance = gen_user_utterance if user_utterance : user_utterance = gen_user_utterance . lower () # perform keyword matching to see if any domains are explicitely made active active_domains = [ d for d in self . domains if d . get_keyword () in user_utterance ] # Even if no domain has been specified, we should be able to exit if \"bye\" in user_utterance and not self . current_domain : return { \"sys_utterance\" : \"Thank you, goodbye.\" } # if there are active domains, use the first one elif active_domains : out_key = f \"user_utterance/ { active_domains [ 0 ] . get_domain_name () } \" self . current_domain = active_domains [ 0 ] return { out_key : user_utterance } # if no domain is explicitely mentioned, assume the last one is still active elif self . current_domain : out_key = f \"user_utterance/ { self . current_domain . get_domain_name () } \" return { out_key : user_utterance } # Otherwise ask the user what domain they want else : return { \"sys_utterance\" : \"Hello, please let me know how I can help you, I can discuss \" + f \"the following domains: { self . domains_to_str () } .\" } \"\"\" Convert list of domains to a string for console output \"\"\" def domains_to_str ( self ): if len ( self . domains ) == 1 : return self . domains [ 0 ] . get_display_name () elif len ( self . domains ) == 2 : return \" and \" . join ([ d . get_display_name () for d in self . domains ]) else : return \", \" . join ([ d . get_display_name () for d in self . domains ][: - 1 ]) + f \", and { self . domains [ - 1 ] . get_display_name () } \" As a note, once the DomainTracker has selected a domain, this is appended to the output dictionary so that only modules of that same domain will receive the published message. Creating a Domain Tracker The code for creating a DomainTracker is nearly the same as any other module. However instead of taking in a domain argument as a string or Domain object, the DomainTracker takes in a domains argument which must be a list of domain objects domain_tracker = DomainTracker ( domains = [ lecturers , canteen ]) Putting it All Together The last thing left to do is now to combine all of this into one single dialog system and run it! * Sending an emty message to gen_user_utterance will trigger the domain tracker * The domian tracker will then see that we're on the first turn with no active domain, thus generating a system message which will inform the user of all available domains (lecturers and canteen) ds = DialogSystem ( services = [ user_in , user_out , # interfaces domain_tracker , lecturer_nlu , dining_hall_nlu , # NLUs lecturer_bst , dining_hall_bst , # BSTs lecturer_policy , dining_hall_policy , # Policies lecturer_nlg , dining_hall_nlg , # NLGs ]) ds . run_dialog ({ 'gen_user_utterance' : \"\" }) Alternatively, you can have a look at the run_chat.py file * calling python run_chat lecturers mensa from your terminal in the ADVISER main folder will do exactly the same * you can specify more options, e.g. for using ASR, TTS, etc. Running A Distributed Dialog System If you're relying on computationally intense services, e.g. ASR or TTS modules, ADVISER 2.0 provdies a way to split up dialog processing so these services can be run remotely, e.g. on more powerful machines, while the rest of the dialog system remains local. The easiest way to do this is to use ssh port-forwarding , but you can also specify arbitrary IP-adresses (you might have to adapt your router settings for this approach). Therefore, we will use the port-forwarding approach in the following description. The good news first: running some modules remotely, does not require any large changes! 1. The first change is that you will need to pass a unique identifier to your service constructor; so rather than just taking in a domain your service will also need to take in an identifier as shown below: class ConcatenateServiceWithDomain ( Service ): \"\"\" new here: identifier argument\"\"\" def __init__ ( self , domain : str = \"mydomain\" , identifier : str = None ): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) \"\"\" nothing changes here \"\"\" @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } Next create an instance of your service with an identifier of your choosing in a script on your remote machine ; The only important thing when choosing the identifier is that you don't use the same identifier for two different service instances. But it is recommended that the name is at least somewhat descriptive. In the same script, call this services's run_standalone() method. This will kickoff a registration routine with the dialog system instance we're going to run on your local machine concatenate_service = ConcatenateServiceWithDomain ( identifier = \"myconcatenateservice1\" ) concatenate_service . run_standalone () On your local machine which is going to run the dialog system, create a placeholder, RemoteService (This is really just a dummy class storing the identifier). This allows the remote service to register with the dialog system; important is that you use the same identifier here as you used to create the remote service Then, go ahead and instantiate your dialog system, providing the remote service intance instead of the real service to the service list # create dummy service remote_concatenate_service = RemoteService ( identifier = \"myconcatenateservice1\" ) # pass dummy service in as part of dialog system ds_with_remote = DialogSystem ( services = [ remote_concatenate_service , # remote service placeholder print_service ]) # local print service From here on, you can call your dialog system with the usual run_dialog(...) routine But to be able to connect to the remote machine, you need to forward the required ports. For this, on your local machine, call port forwarding for * subscriber port (default: 65533) * publisher port (default: 65534) * remote register port (default: 65535) ssh -fNR 65533 :localhost:65533 adress.to.your.remote@machine ssh -fNR 65534 :localhost:65534 adress.to.your.remote@machine ssh -fNR 65535 :localhost:65535 adress.to.your.remote@machine If those ports are already in use on your machine, you may change them explicitly in the Service AND DialogSystem constructors, just be consistent. See the docstrings on these classes for more information. Once you start the concatenate_service.run_standalone() on your remote machine and the ds_with_remote.run_dialog(...) on your local machine, you will see notifications on the terminal giving you information about the connection state between your local and remote services. If you want to have a look at another example (with both services running on the same machine, so you don't need to call ssh for this), look at the run_chat.py file with --gui option enabled: this starts a webserver as a remote service connecting to the dialog system.","title":"Advanced"},{"location":"tutorials/advanced/#advanced-topics-with-adviser-20","text":"Now that you have covered how to work with the existing core services of the ADVISER 2.0 Toolkit, let's discuss some of the more advanced features, such as running a distributed system, emotion detection, how create a new domain, and how to add new services","title":"Advanced Topics With ADVISER 2.0"},{"location":"tutorials/advanced/#creating-a-new-domain","text":"","title":"Creating a New Domain"},{"location":"tutorials/advanced/#database","text":"In order to create a new domain, you need an SQLite database with the following properties: * it contains a single table * each row represents an entity in the database * each column in the table represents a slot (entity property such as \"name\", \"color\", \"last_known_location\", etc) * binary slots should only have values true or false As a note, it is also possible to create a new domain with an API backend instead of a fixed database, but in this case, it may not be possible to use the ontology generation tool shown in the next session.","title":"Database"},{"location":"tutorials/advanced/#ontology","text":"Once you have a database, the next step is to create an ontology for the new domain. This can be done using the ontology creation tool provided with ADVISER 2.0. The tool is located in the folder resources/ontologies/create_ontology.py To use the tool, open a terminal and navigate to the folder with the ontology creation tool. The tool can then be called by typing the following command: python3 create_ontology.py path/to/your/database/YourDomainName.db As a fist step, you must choose the table you want to use (we will use the ImsCourses database located in resources/databases for demonstration purposes). The interface for this tool can be seen in the image below: Afterwards, you are asked to name your new domain and then apply the appropriate labels to the different slots. Possible slots will be shown and can be navigated through with the arrow keys. The space bar can be used to select any slots a proposed label applies to. An active selection is indicated by a blue circle. Possible slot types are * Informable: information the user can inform the system about * System requestable: information the system can actively ask the user for * Requestable: information the user can request from the system When the system asks you to identify the primary key, this means you should reference the column in your database which uniquely discriminates all database entries (preferably in a human-readable way, not just an index) - in case of the IMSCourses domain, this is the name of the course. Selection screens for slots / values look like this: And the end output should be a file in JSON format like the one shown in the excerpt below: As a final step the system will ask if you want to copy the database, if your database is not already located inside the folder resources/databases , you should select \"yes\" to this operation, so a copy of your database is where it will be expected when creating a new Domain object. After the tool terminates successfully, check that the following two files were created inside the folders resources/databases and resources/ontologies : * [YourDomainName].db * [YourDomainName].json","title":"Ontology"},{"location":"tutorials/advanced/#domain-object","text":"Once you have your ontology and database, you can create a Domain object for your new domain, as seen in the previous tutorial: from utils.domain.jsonlookupdomain import JSONLookupDomain your_domain_instance = JSONLookupDomain ( name = 'YourDomainName' , json_ontology_file = 'resources/databases/YourDomainName.json' , sqllite_db_file = 'resources/databases/YourDomainName.db' ) You can than use the object to instantiate the modules that constitute your dialog graph.","title":"Domain Object"},{"location":"tutorials/advanced/#nlu-and-nlg","text":"Another important thing to remember is to create NLU regexes and NLG templates for your new domain, see the previous tutorial if you have questions on this process.","title":"NLU and NLG"},{"location":"tutorials/advanced/#policy","text":"In some cases, a new domain may require a new policy and new user_acts or sys_acts if the new domain requires functionality not provided by the original policy, it may be neccessary to expand the list of user or system acts. For reference, these lists are shown in the previous sections under the NLU and Policy sections respectively. If new acts are added, the policy must be expanded to be able to accept the new user acts as input and to generate the new system actions as output. This can be done by inheriting from the current policy.","title":"Policy"},{"location":"tutorials/advanced/#creating-a-new-service","text":"As we saw in Tutorial 2, all of the modules in the ADVISER 2.0 toolkit are children of the Service class. This means in order to create a new module, you need to create a new service. In the previous tutorial we showed an example of how to do this for a simple case. In this section, we will go into more depth on dialog system specifics to consider when creating a service.","title":"Creating a New Service"},{"location":"tutorials/advanced/#inheriting-from-the-service-class","text":"Step one is always to inherit from the service class. Doing this means that your new service requires a domain argument on instantiation, but also that it can take the following optional arguments (which you saw in Tutorial 3): * sub_topic_domains * pub_topic_domains which allow users to overwrite subsribe/publish topics on instantiation. This can be useful in some cases when combining domain specific services with non domain specific services.","title":"Inheriting from the service class"},{"location":"tutorials/advanced/#determine-what-methods-need-to-be-decorated","text":"The next important step is to consider which methods in your new service should be decorated and what topics it should subscibe to/publish. As a general rule, only methods which will directly interact with other services need to be decorated. If all communication happens inside of a class, normal class methods are sufficient. Another important note, when decorating a method make sure that the list of subscribe topics matches the list of method arguments and that you have checked the topics you subsrcibe to will be published by another method and the topics which you publish will be subscribed to by another method.","title":"Determine what methods need to be decorated"},{"location":"tutorials/advanced/#managing-dialog-dependent-state","text":"Another important concern is dialog dependent state. That is, information which gets tracked within a service over the course of a dialog, but should be reset between dialogs. If you want to initialize/reset per-dialog state or want to perform other actions before the first / after the last dialog turn, you can overwrite the dialog_start and dialog_end methods provided by the Service class. These will automatically be called before the start and end of a dialog, so you do not need to worry about decorating them extra. In fact, since topics don't have any guarantees on order of delivery using these methods is preferable to decorating because the methods are guranteed to be called before the first dialog turn and after the last one respectively. Since our dialog system might be migrated to multi-session support at some point, we consider it best practice to initialize/reset all dialog-dependent state not in the constructor but rather inside these two methods.","title":"Managing Dialog-Dependent State"},{"location":"tutorials/advanced/#adding-task-specific-feature-extraction","text":"Certain tasks, such as emotion recognition or backchanneling, require specific acoustic and/or visual features as input (see the following sections). To retain maximum modularity, we recommend that feature extraction is separated from the actual task. Therefore, in this section we look at an example of a speech feature extraction module which subscribes to an audio recording and publishes a feature vector. The feature extractor is a service, i.e. it inherits from the service class: from services.service import PublishSubscribe from services.service import Service from torchaudio.compliance import kaldi class SpeechFeatureExtractor ( Service ): \"\"\"Simple feature extractor which uses torchaudio to compute MFCCs.\"\"\" def __init__ ( self ): Service . __init__ ( self ) Now, let's create a simple decorated method for feature extraction. Note, in the current ADVISER implementation, 'speech_in' is a tuple that consists of a numpy array representing the audio recording and the sampling rate: (data, sample_rate). This way, everything can be handled in memory without needing to write and delete files. @PublishSubscribe ( sub_topics = [ 'speech_in' ], pub_topics = [ 'mfcc_features' ]) def speech_to_features ( self , speech_in ): features = kaldi . mfcc ( speech_in [ 0 ], sample_frequency = speech_in [ 1 ]) return { 'mfcc_features' : features } For the sake of illustration, this example uses torchaudio to extract MFCC features . In the current ADVISER implementation, we use the openSMILE toolkit to extract MFCCs and addtionally, GeMAPS features, which are used for emotion recognition.","title":"Adding Task-specific Feature Extraction"},{"location":"tutorials/advanced/#adding-emotion-recognition","text":"The current implementation of ADVISER 2.0 provides a basic module for emotion recognition from speech features. The prerequisites for this module are: * A pre-trained model for emotion prediction * The corresponding acoustic features as input ( see section above ) Implementation and training of a machine learning model for emotion prediction is not part of this tutorial. However, in the current ADVISER 2.0 system, we provide basic multi-layer perceptron models which are trained on the MSP-IMPROV database [1]. In the following code, we see an example emotion recognition class. As with any other module, it inherits from the Service class and uses the PublishSubscribe decorator to communicate with other services. In this example, there is only one model for arousal level prediction involved. Since emotions can be represented in different ways (e.g. arousal/valence levels or categories like 'angry', 'happy', 'sad'), the published topic 'emotion' contains a dictionary which can hold the different predicted representations. class EmotionRecognition ( Service ): def __init__ ( self ): Service . __init__ ( self ) self . emotion_dir = os . path . dirname ( os . path . abspath ( __file__ )) model_path = << file path to emotion recognition models >> self . arousal_model = joblib . load ( os . path . join ( model_path , 'mlp_audio_arousal.joblib' )) @PublishSubscribe ( sub_topics = [ \"gemaps_features\" ], pub_topics = [ \"emotion\" ]) def predict_from_audio ( self , gemaps_features ): arousal_prediction = self . arousal_model . predict_proba ( gemaps_features ) return { 'emotion' : { 'arousal' : arousal_prediction }} Note, this emotion recognition module is a very basic implementation for illustration purposes. It can easily be improved by inserting more sophisticated machine learning models or by adding video features to perform multimodal emotion recognition. [1] Busso, Carlos, et al. \"MSP-IMPROV: An acted corpus of dyadic interactions to study emotion perception.\" IEEE Transactions on Affective Computing 8.1 (2016): 67-80.","title":"Adding Emotion Recognition"},{"location":"tutorials/advanced/#using-emotion-in-a-dialog-system","text":"The ADVISER 2.0 currently provides a UserStateTracker service which keeps track of the detected user emotion and user engagement level. This module works in conjunction with a naive EmotionPolicy service to map user emotion to a system emotional response. Currently this is done with a direct mapping from the recognized user emotion to the same emotion for the system response. This \"system emotion\" can then be used bye the HandcraftedEmotionNLG service to select an affective NLG template in order to react to user emotion. This system can be seen below. This direct mapping is obviously highly simplistic and may be expanded in future versions of ADVISER.","title":"Using Emotion in a Dialog System"},{"location":"tutorials/advanced/#adding-backchanneling","text":"","title":"Adding Backchanneling"},{"location":"tutorials/advanced/#backchannel-prediction","text":"ADVISER 2.0 comes with an acoustic backchannel module that makes use of a pre-trained backchanneler model and MFCC features as input ( see section above ). The backchanneller implementation consists of a convolutional neural network model based on [1] and trained on the Switchboard benchmark dataset [2]. As input, it receives 13 Mel-frequency-cepstral coefficients from the user\u2019s speech signal. The model assigns one of three categories from the proactive backchanneling theory [3] to each user utterance {no-backchannel, backchannel-continuer and backchannel-assessment}. The predicted category is used to add the backchannel realization, such as Okay or Um-hum, at the begining the next system response. In the our project, you can find two python files: acoustic_backchanneller.py (Definition of the backchannelling module) PytorchAcousticBackchanneler.py (PyTorch implementation that loads the pretrained model for prediction) We present a code extract from the class acoustic backchanneller (service). As any other module, it inherits from the Service class and uses the PublishSubscribe decorator to communicate with other services. class AcousticBackchanneller ( Service ): def __init__ ( self ): Service . __init__ ( self ) self . speech_in_dir = os . path . dirname ( os . path . abspath ( __file__ )) + '/' self . trained_model_path = os . path . join ( 'resources' , 'models' , 'backchannel' ) + '/pytorch_acoustic_backchanneller.pt' self . load_model () def load_model ( self ): self . model = PytorchAcousticBackchanneler () self . model . load_state_dict ( torch . load ( self . trained_model_path )) self . model . eval () @PublishSubscribe ( sub_topics = [ 'mfcc_features' ], pub_topics = [ \"predicted_BC\" ]) def backchannel_prediction ( self , mfcc_features : np . array ): \"\"\"Takes temporary user utterance wav file and extracts features from it.\"\"\" scaler = preprocessing . StandardScaler () mfcc_features = scaler . fit_transform ( mfcc_features ) input_splits = self . split_input_data ( mfcc_features ) prediction = self . model ( input_splits ) . detach () . numpy () . argmax ( axis = 1 ) # Returning the majority, unless a BC appears, # class_int_mapping = {0: b'no_bc', 1: b'assessment', 2: b'continuer'} if len ( set ( prediction )) == 1 : return { 'predicted_BC' : prediction [ 0 ]} elif 1 in prediction and 2 in prediction : ones = len ( prediction [ prediction == 1 ]) twos = len ( prediction [ prediction == 2 ]) return { 'predicted_BC' : 1 if ones > twos else 2 } else : return { 'predicted_BC' : 1 if 1 in prediction else 2 } This backchanneller only makes use of acoustic features, however, a more complex module can be implemented, so that it can also profit from ASR trancriptions as shown in [2].","title":"Backchannel prediction"},{"location":"tutorials/advanced/#integrating-backchannel-to-the-systems-response","text":"After the backchannel prediction is done, the corresponding backchannel realization should be added to the system response. For simplicity, we decided to add it at the beginning of the system response already generated by the NLG module. This code can be found in the class BackchannelHandcraftedNLG(HandcraftedNLG) . Here we have a sample of the most relevant code. class BackchannelHandcraftedNLG ( HandcraftedNLG ): def __init__ ( self , domain : Domain , sub_topic_domains : Dict [ str , str ] = {}, template_file : str = None , logger : DiasysLogger = DiasysLogger (), template_file_german : str = None , language : Language = None ): HandcraftedNLG . __init__ ( self , domain , template_file = None , logger = DiasysLogger (), template_file_german = None , language = None , sub_topic_domains = sub_topic_domains ) # class_int_mapping = {0: b'no_bc', 1: b'assessment', 2: b'continuer'} self . backchannels = { 0 : '' , 1 : 'Okay. ' , 2 : 'Um-hum. ' } @PublishSubscribe ( sub_topics = [ \"sys_act\" , 'predicted_BC' ], pub_topics = [ \"sys_utterance\" ]) def generate_system_utterance ( self , sys_act : SysAct = None , predicted_BC : int = None ) -> dict ( sys_utterance = str ): rule_found = True message = \"\" try : message = self . templates . create_message ( sys_act ) if 'Sorry' not in message : message = self . backchannels [ predicted_BC ] + message except BaseException as error : rule_found = False self . logger . error ( error ) raise ( error ) The backchanneller does not show variety in its realizations, however, this can be easily implemented if needed. [1] Daniel Ortega, Chia-Yu Li, NgocThang Vu. \"Oh,Jeez! or uh-huh?\" A listener- aware backchannel predictor on ASR transcriptions. ICASSP,2020. [2] D. Jurafsky and E. Shriberg. \u201cSwitchboard swbd-damsl shallow-discourse-function annotation coders manual.\u201d Institute of Cognitive Science Technical Report, 1997. [3] Charles Goodwin. 1986. Between and within: Alterna- tive sequential treatments of continuers and assess- ments.\" Journal of Human Studies.","title":"Integrating backchannel to the system's response"},{"location":"tutorials/advanced/#from-single-to-multidomain","text":"For more complex scenarios, it may make sense to split your dialog system into multiple domains. For example if your goal is to create a university student assistant bot. You may decide that as a start you want your system to help students find information about lecturers and help students to find out what the dining hall (Mensa) is serving. While in theory these two topics could be put together into the same domain, mensa information updates every day so accessing this through a web API is preferable to only having a fixed database. For the lecturers, however there is no web API, and this inofmration remains largely static, so a fixed database is preferable. At this point, since the data sources, and the actual topics of conversation for each topic are so different, giving each its own domain makes sense. But how do we do that?","title":"From Single- to Multidomain"},{"location":"tutorials/advanced/#domain-dependent-modules","text":"Services like the Natural Language Understanding, Belief State Tracker and Policy are domain dependent: they require domain-specific ontology knowledge (e.g. towns for weather, food names for the mensa) or database access to function. Rather than re-implementing these modules for your specific purposes, however, you can instantiate these services with the corresponding domains (one instance per domain). First we will handle importing all the modules we need and create our domain objects: # IMPORT DOMAINS AND SERVICES import sys import os from typing import List import time sys . path . insert ( 0 , os . path . abspath ( '../..' )) from services.service import Service , PublishSubscribe , RemoteService from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.policy.policy_api import HandcraftedPolicy as PolicyAPI from services.nlg import HandcraftedNLG from services.service import DialogSystem # from examples.webapi.mensa import MensaNLU from utils.domain.domain import Domain from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from examples.webapi.mensa.domain import MensaDomain from examples.webapi.mensa.nlu import MensaNLU # CREATE DOMAIN OBJECTS canteen = MensaDomain () lecturers = JSONLookupDomain ( 'ImsLecturers' ) Next let's start creating our Domain Dependent modules: * NLU is domain dependent because it needs access to different regex files depending on the domain # NLU needs domain to load correct regexe files lecturer_nlu = HandcraftedNLU ( domain = lecturers ) dining_hall_nlu = MensaNLU ( domain = canteen ) BST is domain dependent because it needs access to an ontology so it knows what the informable requestable slots it needs to track # BST needs domain to track correct informable/requestable slots lecturer_bst = HandcraftedBST ( domain = lecturers ) dining_hall_bst = HandcraftedBST ( domain = canteen ) Policy is domain dependent because it needs to know which database to query to determine the next system action # Policy needs domain to access the correct database lecturer_policy = HandcraftedPolicy ( domain = lecturers ) dining_hall_policy = PolicyAPI ( domain = canteen ) NLG is domain dependent because it needs to access the correct template files to generate natural language output # NLG needs to access domain dependent template files lecturer_nlg = HandcraftedNLG ( domain = lecturers ) dining_hall_nlg = HandcraftedNLG ( domain = canteen )","title":"Domain Dependent Modules"},{"location":"tutorials/advanced/#domain-independent-modules","text":"In comparison to the previously shown services, there are also modules in a dialog system that are domain independent, such as ASR and TTS or console input and console output. Regardless of the domain, these modules do the same thing: take in a user input and pass it out as a string. Since these services do not change, domain-independent services only need to be instantiated once. An example using console input and console output modules is shown below. Where previously we passed in a domain, here since they are domain independent, we pass in an empty string. from services.hci.console import ConsoleInput , ConsoleOutput user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" )","title":"Domain Independent Modules"},{"location":"tutorials/advanced/#domain-tracker-module","text":"Once you have created all of domain dependent and independent modules, you will need some way to decide which domain should be active at a given time. That is where the DomainTracker module comes in. The goal of this module is to take in a domain independent user utterance and map it to the correct domain as shown in the image below: The domain tracker is something between domain dependent and domain independent. On instantiation, it takes in a list of possible domains which it can forward a user utterance to, although there is no need to create a new DomainTracker for each domain in the dialog system. In the current implementation, this module relies on keywords matching, inspired by commercial systems, to determine which domain should be active at any given time. This means that at any time, at most one domain will be active. However a more advanced domain tracker could be implemented to replace this in the future and might even be able to support dialog in multiple domains at the same time. To determine which domain should be active, the DomainTracker follows a series of simple rules shown in the image below: If there is only one domain, that domain is always active. If there are more domains, the tracker checks if it is the first turn. If so the system issues a greeting to the user and tells them what domains the dialog system can talk about. If not, the domain tracker checks for domain keywords. If any appear in the user utterance, the first to appear is the domain selected, as the dialog system is not yet capable of handling multiple domains active during the same turn. If there is no keyword, the tracker checks to see if a domain was active the previous turn, if yes, it is assumed that that domain remains active. If there was no active domain in the previous turn, the tracker checks to see if the user said 'bye', if so the tracker will also say 'bye'. If not, the tracker then reminds the user of the domains it is capable of tracking. This can also be seen in the code below: \"\"\" The domain tracker has to know all domains our application should be able to handle, but not not append domain names to topics by default, so it stores a list of domains, but doesn't forward any of them to the service base class constructor: \"\"\" class DomainTracker ( Service ): def __init__ ( self , domains : List [ Domain ], greet_on_first_turn : bool = False ): Service . __init__ ( self , domain = \"\" ) self . domains = domains self . current_domain = None self . greet_on_first_turn = greet_on_first_turn \"\"\" Since service output relies on per-dialog state (turn count, currently active domain), it needs to initialize this state before each new dialog:\"\"\" def dialog_start ( self ): self . turn = 0 \"\"\" Furthermore, it needs to subscribe to user utterances and forward them (`gen_user_utterance` is short for `generic user utterance`) as a domain-dependent user utterance, or, if no domain is active, publish a system utterance listing all available domains: \"\"\" @PublishSubscribe ( sub_topics = [ \"gen_user_utterance\" ], pub_topics = [ \"user_utterance\" , \"sys_utterance\" ]) def select_domain ( self , gen_user_utterance : str = None ) -> dict ( user_utterance = str ): self . turn += 1 if self . turn == 1 and self . greet_on_first_turn : return { 'sys_utterance' : \"Hello, please let me know how I can help you, I can discuss \" + f \"the following domains: { self . domains_to_str () } .\" } # if there is only a single domain, simply route the message forward if len ( self . domains ) == 1 : self . current_domain = self . domains [ 0 ] # make sure the utterance is lowercase if there is one user_utterance = gen_user_utterance if user_utterance : user_utterance = gen_user_utterance . lower () # perform keyword matching to see if any domains are explicitely made active active_domains = [ d for d in self . domains if d . get_keyword () in user_utterance ] # Even if no domain has been specified, we should be able to exit if \"bye\" in user_utterance and not self . current_domain : return { \"sys_utterance\" : \"Thank you, goodbye.\" } # if there are active domains, use the first one elif active_domains : out_key = f \"user_utterance/ { active_domains [ 0 ] . get_domain_name () } \" self . current_domain = active_domains [ 0 ] return { out_key : user_utterance } # if no domain is explicitely mentioned, assume the last one is still active elif self . current_domain : out_key = f \"user_utterance/ { self . current_domain . get_domain_name () } \" return { out_key : user_utterance } # Otherwise ask the user what domain they want else : return { \"sys_utterance\" : \"Hello, please let me know how I can help you, I can discuss \" + f \"the following domains: { self . domains_to_str () } .\" } \"\"\" Convert list of domains to a string for console output \"\"\" def domains_to_str ( self ): if len ( self . domains ) == 1 : return self . domains [ 0 ] . get_display_name () elif len ( self . domains ) == 2 : return \" and \" . join ([ d . get_display_name () for d in self . domains ]) else : return \", \" . join ([ d . get_display_name () for d in self . domains ][: - 1 ]) + f \", and { self . domains [ - 1 ] . get_display_name () } \" As a note, once the DomainTracker has selected a domain, this is appended to the output dictionary so that only modules of that same domain will receive the published message.","title":"Domain Tracker Module"},{"location":"tutorials/advanced/#creating-a-domain-tracker","text":"The code for creating a DomainTracker is nearly the same as any other module. However instead of taking in a domain argument as a string or Domain object, the DomainTracker takes in a domains argument which must be a list of domain objects domain_tracker = DomainTracker ( domains = [ lecturers , canteen ])","title":"Creating a Domain Tracker"},{"location":"tutorials/advanced/#putting-it-all-together","text":"The last thing left to do is now to combine all of this into one single dialog system and run it! * Sending an emty message to gen_user_utterance will trigger the domain tracker * The domian tracker will then see that we're on the first turn with no active domain, thus generating a system message which will inform the user of all available domains (lecturers and canteen) ds = DialogSystem ( services = [ user_in , user_out , # interfaces domain_tracker , lecturer_nlu , dining_hall_nlu , # NLUs lecturer_bst , dining_hall_bst , # BSTs lecturer_policy , dining_hall_policy , # Policies lecturer_nlg , dining_hall_nlg , # NLGs ]) ds . run_dialog ({ 'gen_user_utterance' : \"\" }) Alternatively, you can have a look at the run_chat.py file * calling python run_chat lecturers mensa from your terminal in the ADVISER main folder will do exactly the same * you can specify more options, e.g. for using ASR, TTS, etc.","title":"Putting it All Together"},{"location":"tutorials/advanced/#running-a-distributed-dialog-system","text":"If you're relying on computationally intense services, e.g. ASR or TTS modules, ADVISER 2.0 provdies a way to split up dialog processing so these services can be run remotely, e.g. on more powerful machines, while the rest of the dialog system remains local. The easiest way to do this is to use ssh port-forwarding , but you can also specify arbitrary IP-adresses (you might have to adapt your router settings for this approach). Therefore, we will use the port-forwarding approach in the following description. The good news first: running some modules remotely, does not require any large changes! 1. The first change is that you will need to pass a unique identifier to your service constructor; so rather than just taking in a domain your service will also need to take in an identifier as shown below: class ConcatenateServiceWithDomain ( Service ): \"\"\" new here: identifier argument\"\"\" def __init__ ( self , domain : str = \"mydomain\" , identifier : str = None ): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain , identifier = identifier ) \"\"\" nothing changes here \"\"\" @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } Next create an instance of your service with an identifier of your choosing in a script on your remote machine ; The only important thing when choosing the identifier is that you don't use the same identifier for two different service instances. But it is recommended that the name is at least somewhat descriptive. In the same script, call this services's run_standalone() method. This will kickoff a registration routine with the dialog system instance we're going to run on your local machine concatenate_service = ConcatenateServiceWithDomain ( identifier = \"myconcatenateservice1\" ) concatenate_service . run_standalone () On your local machine which is going to run the dialog system, create a placeholder, RemoteService (This is really just a dummy class storing the identifier). This allows the remote service to register with the dialog system; important is that you use the same identifier here as you used to create the remote service Then, go ahead and instantiate your dialog system, providing the remote service intance instead of the real service to the service list # create dummy service remote_concatenate_service = RemoteService ( identifier = \"myconcatenateservice1\" ) # pass dummy service in as part of dialog system ds_with_remote = DialogSystem ( services = [ remote_concatenate_service , # remote service placeholder print_service ]) # local print service From here on, you can call your dialog system with the usual run_dialog(...) routine But to be able to connect to the remote machine, you need to forward the required ports. For this, on your local machine, call port forwarding for * subscriber port (default: 65533) * publisher port (default: 65534) * remote register port (default: 65535) ssh -fNR 65533 :localhost:65533 adress.to.your.remote@machine ssh -fNR 65534 :localhost:65534 adress.to.your.remote@machine ssh -fNR 65535 :localhost:65535 adress.to.your.remote@machine If those ports are already in use on your machine, you may change them explicitly in the Service AND DialogSystem constructors, just be consistent. See the docstrings on these classes for more information. Once you start the concatenate_service.run_standalone() on your remote machine and the ds_with_remote.run_dialog(...) on your local machine, you will see notifications on the terminal giving you information about the connection state between your local and remote services. If you want to have a look at another example (with both services running on the same machine, so you don't need to call ssh for this), look at the run_chat.py file with --gui option enabled: this starts a webserver as a remote service connecting to the dialog system.","title":"Running A Distributed Dialog System"},{"location":"tutorials/dialogsystem/","text":"Todo Add link to notebook Task Oriented Dialog Systems with ADVISER 2.0 Already we have seen a little bit how services operate and the basic modules needed to make a dialog system. In this tutorial, we will introduce service based implementations of these modules which come as part of the ADVISER 2.0 toolkit. # FIRST SET UP ENVIRONMENT import sys import os from typing import List import time sys . path . append ( os . path . abspath ( '../..' )) from utils.topics import Topic from services.service import Service , PublishSubscribe , RemoteService from utils.domain.domain import Domain from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from services.hci import ConsoleInput , ConsoleOutput from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.nlg import HandcraftedNLG from services.domain_tracker import DomainTracker from services.service import DialogSystem from tensorboardX import SummaryWriter from services.policy.rl.experience_buffer import NaivePrioritizedBuffer from services.simulator import HandcraftedUserSimulator from services.policy import DQNPolicy from services.stats.evaluation import PolicyEvaluator Domains, Ontologies, and Databases/APIs Since this is a tutorial about task-oriented dialog systems, we need to introduce the concept of a domain here. A domain is a limited topic of conversation, e.g. weather, lecturers, or restaurants. In the context of the ADVISER 2.0 toolkit, a domain is defined by an ontology - which describes the types of entities which can be discussed in a domain, their properties, and which properties the user and system can ask after - and a database which can be queried by the system to anser user requests. Databases/APIs When we discuss task oriented dialog systems in this tutorial, we primarly mean systems where the user is trying to find an appropriate entity and/or information about a given entity's properties. For example, a user is trying to find the best superhero to save their city and once they find one, they want to know their last known location. To enable this, however, the system needs access to a database (or web API) which stores this kind of information. In the rest of this tutorial, we will work under the assumption that our dialog systems have access to an SQLite database which contains all relevant information for a domain. Ontology Ontologies are responsible for defining what things (entities and their properties) can be discussed in a given domain (topic). Below is an example ontology for a superhero domain. The entities in this domain are superheroes, and their properties include things such as name , primary_uniform_color , main_superpower , last_known_location . These properties are then split into three (overlapping) categories: * informables: Properties the user can tell the system to help accomplish their goal * eg. constraints to help them find the right superhero for their job * requestables: Properties the user can ask the system about to find out more information about an entity * eg. \"what is their secret identity?\" something that only makes sense after an entity has been suggested * system requestables: Properties the system can ask the user for to help it figure out what entity best fills the user's goal The general properties (loyalty, name, etc.) are called slots, and the specific instances of a slot (\"Avengers\", \"Aqua Man\", etc.) are called values. As one of the ontology's main purposes is to support in natural language understanding and a user will only provide values for informable slots, these are the only values which must be listed in the ontology. { \"informable\" : { \"loyality\" : [ \"Avengers\" , \"Justice League\" , \"Guardians of the Galaxy\" , ... ], \"main_superpower\" : [ \"Claws\" , \"Gadgets\" , \"Magic\" , ... ], \"name\" : [ \"Aqua Man\" , \"Batman\" , \"Black Widow\" , ... ], \"primary_uniform_color\" : [ \"Black\" , \"Blue\" , \"Yellow\" , ... ] }, \"key\" : \"name\" , \"requestable\" : [ \"name\" , \"primary_uniform_color\" , \"main_superpower\" , \"last_known_location\" , \"loyality\" , \"description\" , \"real_name\" ], \"system_requestable\" : [ \"primary_uniform_color\" , \"main_superpower\" , \"loyality\" ] } {'informable': {'loyality': ['Avengers', 'Justice League', 'Guardians of the Galaxy', Ellipsis], 'main_superpower': ['Claws', 'Gadgets', 'Magic', Ellipsis], 'name': ['Aqua Man', 'Batman', 'Black Widow', Ellipsis], 'primary_uniform_color': ['Black', 'Blue', 'Yellow', Ellipsis]}, 'key': 'name', 'requestable': ['name', 'primary_uniform_color', 'main_superpower', 'last_known_location', 'loyality', 'description', 'real_name'], 'system_requestable': ['primary_uniform_color', 'main_superpower', 'loyality']} This information is useful to e.g. NLU and Policy: A regular expression based NLU can match known values from the ontology against user input e.g. is italian in the user input or a synonym defined in the NLU? if so, this could be an inform act for the slot food A policy can construct actions based on the slots e.g. slot food is requestable and informable: inform_food request_food The Domain Class In the ADVISER 2.0 Toolkit, domains are subclasses of utils.domain.domain.Domain . The Domain class provides an abstract interface for connecting to the ontology and database associated with a domain e.g. the weather domain would provide means to contact a WebAPI for querying with user-specified constraints like location, day,... or could provide access to the ontology so the system would know what system requestable slots existed in the weather domain. In thins domain, rather than working with the abstract Domain class, we will primarily be using the class JSONLookupDomain , a subclass which provides querying functionality for an SQLite-Database (found in resources/databases ) and an access to an ontology file (found in resources/ontologies ) in JSON-format. Example: Let's create an example domain. For this we'll work with a domain called superhero which allows users to find the correct superhero for whatever problem is at hand. As mentioned domains require an ontology and a database to define them, therefore as we instantiate a new Domain, we will pass both of these is as files. If the ontology and database file names follow the following format: * ontologies/{domain_name}.json * databasees/{domain_name}.db then only the domain_name is necessary to pass to the JSONLookupDomain object to instantiate it as shown below: # Here we can instantiate the domain with just the name string since the paths to our ontology # and database files follow the correct pattern super_domain = JSONLookupDomain ( name = \"superhero\" ) Topics and Domains If you're providing domain-objects (or, equivalently, domain name strings) to a Service constructor, all subscribed and published topics for this service will implicitly append the domain name to allow for multi domain dialog systems. The exact reasons for this will be explained in more depth in the mutlidomain section of the next tutorial. Let's alter our ConcatenateService to accept a domain name: class ConcatenateServiceWithDomain ( Service ): def __init__ ( self , domain : str = \"mydomain\" ): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain ) @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" NOTE: This function did not change at all \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } If we would run the dialog system example above again, replacing the old ConcatenateService with the new ConcatenateServiceWithDomain , we would observe no more prints from it and also no more messages to topics C and D . This is because the toics for ConcatenateServiceWithDomain were internally remapped to: * A -> A/mydomain * B -> B/mydomain * C -> C/mydomain * D -> D/mydomain Subscribers perform prefix-based topic matching , that means in this case: * A/mydomain is NOT a prefix of A - no messages are received when publishing to A (or B or any other topic here) * same argument holds for B However: if concatenate would be called, we would see output by PrintService ! This is because * concatenate publishes to C/mydomain and PrintService subscribes to C * C is a prefix of C/mydomain ! * same argument holds for D If you provide all your services with the same domain, you're not going to experience any problems and do nothave to worry about these internal details in any way. However, in case you want to * go multidomain (see next tutorial) * combine domain-agnostic with domain-aware services (eg. a console input module and an NLU module) * change routing behaviour of our provided services without subclassing them and overwriting the respective functions the Service constructor offers a way to overwrite topics on instantiation: class Service : __init__ ( domain : Union [ str , Domain ] = \"\" , sub_topic_domains : Dict [ str , str ] = {}, pub_topic_domains : Dict [ str , str ] = {}, ... ) sub_topic_domains is a mapping for overwriting subscriber topics key : the original topic as given in the PublishSubscribe -decorator value : the domain name to append if len(value) > 0 : the value will be appended to the subscribed topic and a slash: key/value if len(value) == 0 : empty domain, subscribed topic will be simply: key pub_topic_domains works analogously So, if we change our constructor as follows: class ConcatenateServiceWithDomain ( Service ): def __init__ ( self , domain : str = \"mydomain\" , sub_topic_domains = { 'A' : '' , 'B' : '' }): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain ) @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" NOTE: This function did not change at all \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } everything will work again, meaning we will observe prints and published messages to C and D again, because we explicitly overwrite the appended domain with the empty string * A/mydomain -> A * B/mydomain -> B Another way to alter topics is to append domain strings manually in the return dictionary of any Publish/Subscribe function (Note: This only works, if you didn't provide a domain (or domain name) to the service base class constructor .): You may append any domain string to the dictionary keys, seperated by a slash: / . We could e.g. alter our ConcatenateService class: class ConcatenateService ( Service ): @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D/domain1' : result } else : return { 'C/domain2' : result } Now, our ConcatenateService gets all messages for topics starting with A and B (and independent of their domain) again, like in our very first ConcatenateService example. But, on the publishing side, we're now publishing to two different domains, domain1 and domain2 , by appending these domain names explicitly after the topic followed by the topic-domain-seperator: C/domain2 and D/domain1 . Equipped with these insights into the inner workings of the message routing mechanism, we can evolve our tutorial system to a multi-domain dialog system in the following chapter. Automatic Speech Recognition (ASR) To support spoken dialog systems, the ADVISER 2.0 toolkit provides an ASR module which converts spoken user utterances to text. In the current implementation, we provide the end-to-end ASR model for English language based on Transformer neural network architecture, however the exact ASR system can be swapped out to support other languages or architectures. We use the end-to-end speech processing toolkit ESPnet and the IMS-speech English multi-dataset recipe . The system was trained on LibriSpeech, Switchboard, TED-LIUM\\~3, AMI, WSJ, Common\\~Voice\\~3, SWC, VoxForge, and M-AILABS datasets. The output of the ASR model is a sequence of subword units, which include single characters as well as combinations of several characters, making the model lexicon independent and thus able to handle unseen words. Using the Speech Recognition Module To use the ASR module, provided in the ADVISER 2.0 toolkit, requires three classes: * SpeechRecorder : responsible for recording the user input * SpeechInputFeatureExtracter : responsible for feature extraction from recorded input * SpeechInputDecoder : responsible for converting input features to subword units The functionality is broken up in this way to allow other modules, such as the emotion recognition and backchanneling modules which will be seen in Tutorial Four, to also make use of the data extracted at each step. Example: To create instances of each of these three classes, see the code below NOTE: This only works if you have installed the requirements for the multimodal system (they are large, so this is not recommended if you will only be working with text) from services.hci.speech import SpeechInputDecoder from services.hci.speech import SpeechInputFeatureExtractor from services.hci.speech import SpeechRecorder conversation_log_dir = \"tutorial_logs\" use_cuda = False recorder = SpeechRecorder ( conversation_log_dir = conversation_log_dir ) speech_in_feature_extractor = SpeechInputFeatureExtractor () speech_in_decoder = SpeechInputDecoder ( conversation_log_dir = conversation_log_dir , use_cuda = use_cuda ) Rule-based Natural Language Understanding (NLU) Semantic representation of user actions The NLU module is responsible for mapping natural language user input to a machine readable semantic frame representation. In this case the semantic frame is composed of up to three parts: * intent : which determines what type of action the user wants to perform (eg. \"hello\", \"inform\", \"request\", etc.) * slot : type of entity property the user is talking about (eg. \"name\", \"super_power\", etc.) * value : exact value of the entity property (eg. \"Superman\", \"super strength\", etc.) For example the following utterances could be mapped to to the following intents: * \"Hello\" $\\rightarrow$ hello () * \"I want a superhero who wears blue\" $\\rightarrow$ inform ( primary_uniform_color = \"blue\" ) * \"What is the hero's secret identity? and their team affiliation?\" $\\rightarrow$ request ( secret_identity ), request ( loyalty ) Slots and values are defined in the ontology, but the intents which the system currently expects are found in the file utils/useract.py and listed here below: * Inform : user provides system with new constraints (eg. \"speed\" as a super power) * NegativeInform : user tells system new negative constraint (eg. \"not speed\" as a super power) * Request : user asks system for value of a slot (eg. \"what is the super power?\") * Hello : user greets system * Bye : user ends session * Thanks : user thanks system * Confirm : user confirms system utterance (eg. \"yes, I do want super speed\") * Deny : user denies system utterance (eg. \"No, I do not want super speed\") * RequestAlternatives : user asks for other entities that meet their constraints besides the one the system recommended (eg. \"is there anyone else besides the Flash?\") * Bad : user utterance couldn't be parsed to any other act * SelectDomain : only needed for multidomain systems, user says keyword associated with starting the domain These intents can be broken down into two sections: General and Domain-Specific. General acts are those like \"Hello\" and \"Bye\" which do not have slots or values associated with them and their regexes remain the same regardless of the domain. Specifying rules In order to understand the user input, one can specify a list of possible natural language realisations for each user act. For example, the user act hello() could be expressed by saying Hello , Hi or Hey . A common way of specifying these rules computationally is to create regular expressions. For example, the dialogue agent could recognise the user act hello() if the user input string matches the regular expression (hello|hi|hey) . However, it would be time-consuming and messy to write a list of natural language realisations for all possible combinations of intent, slot and value. Therefore, we created a new syntax which allows you to reduce the number of rules by creating functions so that you only need to write a rule once and can simply apply it to all needed slots/values. In the following subsections, we present the most important parts of this syntax. 1 General syntax The syntax uses keywords and indentation to create a nested command structure. This means that each line represents one command and each command starts with a keyword identifying the command type. Commands have a \"block level\" which is represented by their number of leading spaces (Level 0: 0 spaces, Level 1: 4 spaces, Level 2: 8 spaces, ...). Rule and function declaration commands are Level 0 commands. Any other commands can be inserted at any level >0 and are automatically added to their \"parent\" command. A parent command is the last command on the current level -1. In the following example, Command2 is added to Command1, Command4 is added to Command3 and Command5 is added to Command4. Command1 arguments Command2 arguments Command3 arguments Command4 arguments Command5 arguments 2 Commands Currently, the ADVISER NLU syntax provides five possible commands. Each command individually defines what its arguments have to look like and what kind of child commands it allows. This section will show how to use the commands. 2.1 Rule The rule command specifies a mapping from a regular expression to a specific intent (user act). The command itself consists of the keyword \"rule\" and a description of the user act as intent() for user acts which do not contain slots (e.g. hello() , bye() ) or intent(slot) for user acts with a slot (e.g. inform(primary_uniform_color) . The regex command can later be used as a child command to add information about the user utterances accepted and the slot's value. Regarding the child commands, a rule can have an infinite amount of child commands. These include the regular expressions for each intent and below those, any exceptions and additions that need to be specified. Exceptions are checked in the order of their appearance. Note: General user acts (those which do not take slots or values as input) are not autogenerated. If you want to edit these, you may do so directly in the file resources/nlu_regexes/GeneralRules.json , however be careful as this file is currently shared across all domains. 2.2 Regular Expression The regex command specifies a regular expression should map to the user act specified in the current rule block. RegEx commands consist of the keyword \"regex\" and a string wrapped by double quotes. They are usually added as child commands to rules, functions, exceptions and additions. The following example shows a valid rule specification, which matches to either \"hero\" or \"superhero\" and both the American and British spellings of the word \"color\". rule request(primary_uniform_color) regex \"what is the( super)?hero's uniform colo(u)?r\\?\" It is also possible to add multiple regular expressions to rule in order to account for more varied user utterances without making the regular expressions too complicated. rule request(primary_uniform_color) regex \"what is the( super)? hero's uniform colo(u)?r\\?\" regex \"what is the colo(u)?r of the( super)? hero's uniform\\?\" regex \"which colo(u)?r does the( super)? hero wear\\?\" For user acts such as inform , we also need to have access to the slot's value. The value can be accessed in the regular expression using curly braces. rule inform(primary_uniform_color) regex \"the colo(u)?r should be {primary_uniform_color}\" This way, we can specify one rule for each value of primary_uniform_color. For example, if the user types the colour should be green , the system detects the user act inform(primary_uniform_color=green) . Note: RegEx commands cannot take any child commands. 2.3 Exceptions Exceptions can be called inside a rule command/function to override the default messages. Exceptions consist of the keyword \"if\" and take a constraint as an argument. A constraint can currently only match the pattern variable = \"string\" . Exceptions particularly make sense in cases where you might prefer to use a synonym rather than the exact value in the database. For example, if a database stores colors by hexadecimal code, the user cannot be expected to know the code for each color. Therefore, we could add an exception using the common name for the color, so that instead of expecting colors in hexadecimal, the system will only recognize the common name for the color. rule inform(primary_uniform_color) regex \"the colo(u)?r should be {primary_uniform_color}\" if primary_uniform_color = \"#ff11bb\" regex \"the colo(u)?r should be pink\" Note : Exception commands can take the same child commands as rule commands. 2.4 Additions Additions work very similar to exceptions. The only differences are that \"add_if\" is used as the keyword and that the messages of the addition command do not override the regexes of the parent command, but instead add possible regexes to the existing ones, this is in particularly well suited to adding synonyms. In the following example, we allow the user to also say cyan or blue as a way to map to the primary_uniform_color blue . rule inform(primary_uniform_color) regex \"(the colo(u)?r|) should be {primary_uniform_color}\" if primary_uniform_color = \"#ff11bb\" regex \"the colo(u)?r should be pink\" add_if primary_uniform_color = \"blue\" regex \"the colo(u)?r should be cyan\" Note: Addition commands can take the same child commands as rule commands. 2.5 Functions Functions are similar to rules. They can take an arbitrary number of parameters and return a regular expression (or normal string). The function command consists of the keyword \"function\" and the function description using the pattern function_name(argument_one, argument_two) . Functions are particularly useful to improve the structure of your files. In the previous example, we have added cyan to be a synonym of blue . If we want to add synonyms for all colours, we would have to list all possible regexes for all possible synonyms which would result in a huge number of lines and would be quite a mess. Instead, we can specify a function which lists all synonymous colour strings for each possible colour value centrally at one point in the file and whenever we want to use synonyms, we can simply call this function: function color_synonym ( generic_color ) # the color itself is almost always a synonym regex \"{generic_color}\" # 'add_if' adds regular expressions to the existing ones ( see above ) add_if generic_color = \"red\" regex \"maroon\" add_if generic_color = \"green\" regex \"lime( green)?\" regex \"olive( green)?\" regex \"neon green\" add_if generic_color = \"blue\" regex \"cyan\" regex \"turquoise\" # 'if' overwrites ( ! ) existing regular expressions if generic_color = \"#ff11bb\" \"pink\" \"magenta\" The inform rule would then be simplified to: rule inform(color) \"(the colo(u)?r|it) should be {color_synonym(color)}\" Note: Function commands can take the same child commands as rule commands. 3 Shortcuts and syntax simplification The examples in the previous section show the ADVISER NLU syntax, as it is read by the interpreter. For simplifications and for a better overview, we allow some simplifications and shortcuts. In a preprocessing step, the simplified template is automatically transformed into a valid syntax. 3.1 Comments and empty lines While the original syntax requires one command per line, in the preprocessing step, empty lines and lines that start with a hashtag (#) are removed from the template file. Please note that non-leading hashtags are not recognised as comments currently. 3.2 Tabs The original syntax requires four spaces per block level. Alternatively, you can also use a tab instead, since all tabs are replaced by four spaces in the preprocessing step. 3.3 Automatic insertion of the regex keyword Regexes do not necessarily need to be marked via the regex keyword. For all lines that start with double quotes, a regex keyword is automatically inserted at the beginning of the line in the preprocessing step. Example: rule request(primary_uniform_color) \"what is the( super)? hero's uniform colo(u)?r\\?\" 3.4 Colons A neater version of the example in 3.3 would be the following example: rule request(primary_uniform_color): \"what is the( super)? hero's uniform colo(u)?r\\?\" To allow this syntax, the preprocessor interprets everything coming after a colon (that\u2019s not wrapped by double quotes) as a new child command and moves it to the next line with the respective block level + 1. This way, the above example and the example from 3.3 are exactly the same after preprocessing. The NLU module ADVISER's NLU module makes use of NLU files which specify the regular expressions with the previously presented syntax. The pipeline for creating the NLU is the following: Make sure you have created a domain . Write your NLU file using the custom syntax (see above), name it {domain_name}.nlu and place it in the folder resources/nlu_regexes . Execute the script gen_regexes.py in the folder tools/regextemplates like this: python3 tools/regextemplates/gen_regexes.py {domain_name} {domain_name} Example: python3 tools/regextemplates/gen_regexes.py superhero superhero Check that the tool has created the files {domain_name}InformRules.json for inform acts and {domain_name}RequestRules.json for request acts inside the resources/nlu_regexes folder. Once you have all these files, you can use the HandcraftedNLU module in services/nlu by simply passing your domain object in the constructor. from utils.domain.jsonlookupdomain import JSONLookupDomain from services.nlu.nlu import HandcraftedNLU domain = JSONLookupDomain ( 'superhero' ) nlu = HandcraftedNLU ( domain = domain ) You can type some exemplary messages and see which user acts are recognised by the NLU, when you are done, type \"bye\" to exit the loop: user_input = input ( '>>> ' ) while user_input . strip () . lower () not in ( '' , 'exit' , 'bye' , 'goodbye' ): user_acts = nlu . extract_user_acts ( user_input )[ 'user_acts' ] print ( ' \\n ' . join ([ repr ( user_act ) for user_act in user_acts ])) user_input = input ( '>>> ' ) Rule-based Belief State Tracker (BST) The BST maintains a representation of the current dialog state. It is responsible for tracking the constraints a user provides over the course of a dialog and their probabilities, recording any requests from the current turn, tracking the types of user acts in the current turn, and registering the number of database matches for the given constraints. In the ADVISER 2.0 Toolkit, this state is built up over the course of the dialog as the user expresses more constraints. Probabilities for each constraint are determined by the NLU and are not currently further processed. An example of the beliefstate for the second turn in a dialog about IMS Courses can be seen below. {'user_acts': {<UserActionType.Inform: 'inform'>} 'informs': {'bachelor': {'true': 1.0 } 'turn': {'sose': 1.0 } 'ects': {'6': 1.0 } } 'requests': {} 'num_matches': 4 'discriminable': True } As mentioned previously the beliefstate is built up over time. Therfore there are currently only three entries in the informs dictionary as up to this point the user has only provided three constraints. Each constraint has a probability of 1.0 because neither the NLU nor BST have complex rules for handling ambiguous user utterances, but this is an area we may look to improve in the future. Example: Instantiating a rules based BST is as simple as running the code below bst = HandcraftedBST ( domain = super_domain ) Policy Rule-based Policy The policy is responsible for determining the system's next action. In ADVISER 2.0, we provide two implementations of a rule-based policy (one designed to work with a database and one designed to work with an API backend). Both follow a similar decision flow. Since we focus here on task oriented dialog systems, the policy tries to help a user fulfill their goal as quickly as possible. A simplified version of a the decision making process in a rules based policy can be seen below: On each turn, the policy is capable of choosing one next action, these actions include: Welcome : greet the user InformByName : tell the user some new information InformByAlternatives : provide the user an alternative entity Request : ask the user for more information Select : ask the user to select between a given set of choices RequestMore : ask the user if they need more help Bad : inform the user their last utterance couldn't be parsed Bye : end the dialog As seen in the above diagram, the policy first works to handle general (non-domain specific) user actions. It then queries the database and only asks the user for more information if there are too many entries and asking for more information will help narrow down results. In the actual policy the decisions are a bit more nuanced, but the graphic gives the general idea of the types of rules required for a rules-based policy. Example: Instantiating a rules-based policy can be done with the code below: policy = HandcraftedPolicy ( domain = super_domain ) Reinforcement Learning Policy Why reinforcement Learning Developing handcrafted policies can be quite time consuming and have difficulties adapting to unseen scenarios. Therefore a machine learning approach can be preferable. In this type of scenario, training a machine learning agent would circumvent needing to hard code a rule for every edge case scenario. Unfortunately this type of approach normally requires a lot of data to train the policy. Especially for new domains, this kind of data just does not exist, which is where reinforcement learning comes in. The basic idea behind reinforcement learning is that an agent has a certain set of actions which it can take and is placed in a certain environment (which it may either know in advance or must learn as it explores). The agent then tries out the different actions it can take, each action altering the state (or the agent's perception of the environment) and generating a reward. In this way, the agent learns how to navigate through it's environment and find the path which yields the highest reward. This process is shown in the graph below. As mentioned before, as an input the agent receives the current state and reward and it uses these to choose what it thinks the next best action will be. This action results in a new state and a new reward. RL in the Context of Dialog Policy In the context of dialog systems, the RL agent is the dialog policy and the actions it can take are defined by the SysActs . The environment is a user (simulated or real) and the state is represented by the beliefstate. The reward for each action backpropagates and is inversely proportional to the number of turns it took to complete the dialog + a fixed reward for dialogs where a user was able to fulfill their goal. In ADVISER 2.0, the RL policy is implemented using deep reinforcement learning. Similar to the Deep Q-learning algorithm , an action-value function is approximated by a neural network which outputs a value for each possible system action, given the vectorised representation of a turn\u2019s beliefstate as input. The exact action set is defined in the class RLPolicy where a set of base actions templates is defined with slot names from the ontology e.g. if you have a slot food in your ontology, it will create actions like inform#food , request#food and select#food which are used to inform a user about a certain type of food, to request the food type from the user or to let the user choose between multiple food types. These action templates are the initial output of the reinforcement learning policy, which then get expanded using beliefstate and database information. For more information on the architecture see the ADVISER paper . Example: As there are so many parameters for the RL policy, instantiating it requires slightly more code than instantiating other modules. To instantiate an RL policy with the parameters used in the ADVISER paper, see the code below: # Allows you to track training progress using tensorboard summary_writer = SummaryWriter ( os . path . join ( 'logs' , \"tutorial\" )) # logs summary statistics for each train/test epoch logger = DiasysLogger ( console_log_lvl = LogLevel . RESULTS , file_log_lvl = LogLevel . DIALOGS ) # Create RL policy instance with parameters used in ADVISER paper policy = DQNPolicy ( domain = domain , lr = 0.0001 , eps_start = 0.3 , gradient_clipping = 5.0 , buffer_cls = NaivePrioritizedBuffer , replay_buffer_size = 8192 , shared_layer_sizes = [ 256 ], train_dialogs = 1000 , target_update_rate = 3 , training_frequency = 2 , logger = logger , summary_writer = summary_writer ) logger : state space dim : 74 logger : action space dim : 9 logger : Gradient Clipping : 5.0 logger : Architecture : Dueling logger : Update : Double REPLAY MEMORY : NAIVE Prioritized ARCHITECTURE : Dueling User Simulator To train a reinforcement learning (RL) policy, it is often useful to use a simulated user instead of an actual one at least in the beginning. Simulations, while seldom accurate representations of real users, are substantially more patient. That is, to train or evaluate a dialog policy, thousands of dialogs are required. Having a real human sit through this many dialogs would be very expensive and tedious, especially since at the beginning of training, an RL policy will produce utterly nonsensical dialogs. In comparison, a simulated user is very cheap, will not be bored or annoyed, and can be called whenever you are ready to train or test a dialog. After initial training has been performed with a simulation, it is possible to conduct further training with human users. Since a user simulator is an important part of the training process for an RL policy, the next question becomes how to create one. In the ADVISER 2.0 Toolkit, we use an agenda based user simulator based off of work by Schatzmann et al. . The basic function of the simulator can be seen in the graphic below: To start a dialog, the user simulator will randomly generate a goal (shown in gray in panel 1). This goal will include all of the constraints (informs) the user wants to provide and all of the questions (requests) they will want to ask. Then this goal will be transformed into a series of user actions and placed in the action stack. On each turn after that, the user simulator will receive a system action as input and need to respond to it (panel 2) Here the user response is hardcoded in a similar way to the handcrafted policy. Any new actions generated to respond to the system will be placed at the top of the stack. Then a random number of actions between one and n will popped from the top of the stack and given out as the user acts for that turn. In addition to the hardcoded response for each type of system act, the user simulator's behavior is also controlled by configuration parameters. These control behavior such as the maximum number of actions the user takes per turn (default 3), and whether user goals should be possible to fulfill or if it doesn't matter. These additional parameters are stored in an external configuration file. Example: To create an instance of user simulator see below: user_sim = HandcraftedUserSimulator ( domain = super_domain ) Evaluation In order to train an RL policy, in addition to a user simulator, we need a reward signal. That is where the evaluation module comes in. There are two evaluation classes which are important to consider. The first one is teh ObjectiveReachedEvaluator which provides the reward signal to the RL policy. The second is the PolicyEvaluator which tracks the percent of successful dialogs, average reward, and average turn number for an epoch. As a note, while the ObjectiveReachedEvaluator is already part of the RLPolicy class, to log statistics, you need to explicitely add the PolicyEvaluator to the dialog graph. As a default, a reward of -1 for every turn is assigned to encourage the policy to keep dialogs as short as possible. For every dialog where the user goal is fulfilled, a reward of 20 is given. Example: A PolicyEvaluator can be created with the code below: evaluator = PolicyEvaluator ( domain = domain , use_tensorboard = True , experiment_name = \"tutorial\" , logger = logger , summary_writer = summary_writer ) Training a reinforcement learning policy Now that we have a user simulator and an evaluator, we can start using them to train our RL policy. This requires configuring the dialog graph slightly differently. Rather than the graph we saw in Tutorial One, we will only use the beliefstate tracker, RL Policy and a user simulator (optionally an evaluator as well to log statistics). This new graph can be seen below: To initialize training and evaluation, a random seed is generally used to set initial parameters. For the sake of reproducibility, it is recommended to store this seed along with the results so that in the future, you can initialize all random generators used in your pipeline with it. If you run the system twice with the same seed, you should get exactly the same results and dialogs. To train the system, a dialog graph is created with all necessary modules, then for the number of training epochs desired, dialogs are carried out and evaluated. During each training epoch, weights are updated for the RL policy and during each testing epoch, the success rate and length of dialogs are evaluated and recorded. The number of dialogs per epoch and the number of epochs can be determined by the user. As a note, when evaluating the overall performance of an RL policy, it is important to run the train/test loop multiple times with different random seeds to make sure that a good performance is not simply because of a good random seed. Example: Example training and evaluation code (warning takes some time to run): # SET CONSTANTS TRAIN_EPOCHS = 1 TRAIN_EPISODES = 1000 EVAL_EPISODES = 1000 MAX_TURNS = 25 # Choose how many repeated trials for i in range ( 1 ): common . init_random () # add seed here as a parameter to the init_random if wanted ds = DialogSystem ( services = [ user_sim , bst , policy , evaluator ], protocol = 'tcp' ) # Start train/eval loop for j in range ( TRAIN_EPOCHS ): # START TRAIN EPOCH evaluator . train () policy . train () evaluator . start_epoch () for episode in range ( TRAIN_EPISODES ): if episode % 100 == 0 : print ( \"DIALOG\" , episode ) logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () # START EVAL EPOCH evaluator . eval () policy . eval () evaluator . start_epoch () for episode in range ( EVAL_EPISODES ): logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () policy . save () ds . shutdown () Handcrafted Natural Language Generation (NLG) To transform system acts into natural language utterances, ADVISER 2.0 uses handcrafted templates. Although machine learning generated output can have more breadth of expression, using templates guarentees that all system utterances will be grammatic and sensical. Using templates additionally allows dialog systems for new domains to be created even when there is not sufficient data for those domains to train a machine learning based NLG. In ADVISER 2.0, rather than mapping every sys_act, slot, value combination to an individual utterance, templates are used to generalize this process by specifying placeholders for a system act's slots and/or values. An example of this can be seen below: inform(name={X}, ects={Y}) \u2192 \"The course {X} is worth {Y} ECTS.\" During the dialog, the system iterates through the templates and chooses the first one for which the system act fits the template's signature. Types of templates Under adviser/resources/templates the handcrafted templates are stored in text files. The templates have the format where the left side represents the system act and the right side represents the natural language utterance. Variables are used instead of concrete slot values so that the templates can be reused as much as possbile. Each file is divided into several sections, we add examples: Templates for system general acts template hello(): \"Welcome to the IMS courses chat bot. How may I help you?\" Templates for system requests template request(lang): \"In which language shall the course be held?\" Methods for system informs function info(slot, value) if slot = \"ects\": \"is worth {value} ECTS\" if slot = \"turn\" if value = \"sose\": \"is offered in the summer semester\" if value = \"wise\": \"is offered in the winter semester\" Templates for system informs template inform_byname(name): \"I found the course {name}. What do you want to know about it?\" template inform_byname(name, turn): \"The course {name} {info(\"turn\", turn)}.\" Similarly, templates for system confirm, request more and select are included. Example: If system act is: inform(name='computational linguistics team laboratory', turn='wise') The NLG output will be: \"The course computational linguistics team laboratory is offered in the winter semester.\" Notes: Each domain has a ist own YourDomainNameMessages.nlg file No python script needs to be modified (domain independent) Example: The code to create an NLG service for the superhero domain is shown below: nlg = HandcraftedNLG ( domain = super_domain ) Text to Speech (TTS) The TTS module is an options module which converts the text natural language output to speech. In the ADVISER 2.0 toolkit, this is done using the ESPnet-TTS toolkit , which is an extension of the ESPnet toolkit mentioned in the ASR section. We use FastSpeech as a synthesis model, which provides substantially faster voice generation. Additionally, we are able to provide a \"cleaner\" file to optimize the synthesizer for abbreviations, such as Prof., Univ., IMS, NLP, ECTS, and PhD , as well as for German proper names, such as street names. These optimizations can be easily extended by adding additional words and pronunciation mappings to services/speech/cleaners.py . Example: Similar to how the ASR module also required a SpeechInputRecorder module, the TTS module also requires a SpeechOutputPlayer in order for the user to be able to hear the generated sound file. The SpeechOutputPlayer and SpeechOutputGenerator can be instantiated with the code below. NOTE: This code will only work if you have installed the requirements for the multimodal dialog system (they are large, so this is not recommended if you will only be working with text) from services.hci.speech import SpeechOutputGenerator from services.hci.speech import SpeechOutputPlayer # (GPU: 0.4 s/per utterance, CPU: 11 s/per utterance) speech_out_generator = SpeechOutputGenerator ( use_cuda = False ) speech_out_player = SpeechOutputPlayer ( conversation_log_dir = conversation_log_dir ) Cleaning up TTS output To improve the speech generation, we also provide a file servicse/hci/speech/cleaners.py which allows you to manually correct pronunciation of words. This allows you to provide either phonetic transcriptions for acronyms, abbreviations, and foreign words or pronunciation patterns for things such as email addresses or telephone numbers. One of the methods from this file is shown below. def expand_abbreviations ( text ): \"\"\" Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for regex , replacement in _abbreviations : text = re . sub ( regex , replacement , text ) return text # List of (word, replacement) pairs for acronym or special words: _acronym = [ ( ' a ' , ' ae ' ), ( ' s ' , ' eh s, ' ), ( 'array' , 'ER RAY' ), ( 'API' , 'AE P I' ), ( 'distributional' , 'distributionall' ), ( 'ECTS' , 'E C T EH S,' ), ( 'Erasmus' , 'E RAS MOUS' ), ( 'ID' , 'I D' ), ( 'IMS' , 'I M EH S' ), ( 'NLP' , 'N L P' ), ( 'PhD' , 'P h D' ), ( 'PWR 05B' , 'Pfaffen vaald ring five B, ' ), ( 'psycholinguistics' , 'psycho linguistics' ), ( 'stuttgart' , 'stu gart' ), ( 'Stuttgart' , 'Stu gart' ), ( 'vegan' , 'viygan' ), ( 'Vegan' , 'Viygan' ), ( 'ImsLecturers' , 'I M EH S Lecturers' ), ( 'imsLecturers' , 'I M EH S Lecturers' ), ] Chatting with the dialog system There are two main ways to interact with an ADVISER 2.0 dialog system: 1) by typing input and reading system output from the terminal or 2) by speaking to the system and receiving audio responses. Since we've already taken a quick look at a spoken dialog system, let's quickly discuss a text based one. In short, a text based system is much simpler. Instead of needing multiple modules for input/output, the text based system just needs ConsoleInput and ConsoleOutput . When these are added to the dialog system, the system utterances will appear on the terminal and the user can give their response by typing and pressing enter to end an utterance. Example: An example of a dialog system constructed this way can be seen below. NOTE: There is a problem with the user input in Jupyter Notebook. To try the code out, copy the code below to a new file in the adviser folder and run it from the dialog system # Importing everything we need for a dialog system from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from services.hci import ConsoleInput , ConsoleOutput from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.nlg import HandcraftedNLG from services.domain_tracker import DomainTracker from services.service import DialogSystem # create domain super_domain = JSONLookupDomain ( name = \"superhero\" ) # create domain specific modules nlu = HandcraftedNLU ( domain = super_domain ) bst = HandcraftedBST ( domain = super_domain ) policy = HandcraftedPolicy ( domain = super_domain ) nlg = HandcraftedNLG ( domain = super_domain ) d_tracker = DomainTracker ( domains = [ super_domain ]) # Input modules (just allow access to terminal for text based dialog) user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" ) logger = DiasysLogger ( console_log_lvl = LogLevel . DIALOGS ) ds = DialogSystem ( services = [ d_tracker , user_in , user_out , nlu , bst , policy , nlg ], debug_logger = logger ) error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_inconsistencies () ds . draw_system_graph ( name = 'system' , show = False ) # start dialog for _ in range ( 1 ): ds . run_dialog ({ 'gen_user_utterance' : \"\" }) ds . shutdown () Check Your Understanding (Optional) Now that you have read how each of the basic modules provided by the ADVISER 2.0 Toolkit works, let's actually test it out. Run a Dialog System There should be a program in the tutorials folder called tutorial_chat.py All the modules you will need are already imported, but you will need to follow the comments and create a dialog system for yourself. Create a basic NLU Right now we have provided a very simple .nlu file for the superhero domain. Try adding more synonyms/more regexes to the rules in superhero.nlu so that it can capture more realistic user utterances. Update the NLG Try adding some more NLG templates to the superhero domain, or updating existing ones to sound more natural (the file is located in the resources/nlg_templates folder). Test out your new system Once you are satisfied with your NLU and NLG files, test out the system again. Make sure you remembered to recomile the regexes first though!","title":"Dialog System"},{"location":"tutorials/dialogsystem/#task-oriented-dialog-systems-with-adviser-20","text":"Already we have seen a little bit how services operate and the basic modules needed to make a dialog system. In this tutorial, we will introduce service based implementations of these modules which come as part of the ADVISER 2.0 toolkit. # FIRST SET UP ENVIRONMENT import sys import os from typing import List import time sys . path . append ( os . path . abspath ( '../..' )) from utils.topics import Topic from services.service import Service , PublishSubscribe , RemoteService from utils.domain.domain import Domain from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from services.hci import ConsoleInput , ConsoleOutput from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.nlg import HandcraftedNLG from services.domain_tracker import DomainTracker from services.service import DialogSystem from tensorboardX import SummaryWriter from services.policy.rl.experience_buffer import NaivePrioritizedBuffer from services.simulator import HandcraftedUserSimulator from services.policy import DQNPolicy from services.stats.evaluation import PolicyEvaluator","title":"Task Oriented Dialog Systems with ADVISER 2.0"},{"location":"tutorials/dialogsystem/#domains-ontologies-and-databasesapis","text":"Since this is a tutorial about task-oriented dialog systems, we need to introduce the concept of a domain here. A domain is a limited topic of conversation, e.g. weather, lecturers, or restaurants. In the context of the ADVISER 2.0 toolkit, a domain is defined by an ontology - which describes the types of entities which can be discussed in a domain, their properties, and which properties the user and system can ask after - and a database which can be queried by the system to anser user requests.","title":"Domains, Ontologies, and Databases/APIs"},{"location":"tutorials/dialogsystem/#databasesapis","text":"When we discuss task oriented dialog systems in this tutorial, we primarly mean systems where the user is trying to find an appropriate entity and/or information about a given entity's properties. For example, a user is trying to find the best superhero to save their city and once they find one, they want to know their last known location. To enable this, however, the system needs access to a database (or web API) which stores this kind of information. In the rest of this tutorial, we will work under the assumption that our dialog systems have access to an SQLite database which contains all relevant information for a domain.","title":"Databases/APIs"},{"location":"tutorials/dialogsystem/#ontology","text":"Ontologies are responsible for defining what things (entities and their properties) can be discussed in a given domain (topic). Below is an example ontology for a superhero domain. The entities in this domain are superheroes, and their properties include things such as name , primary_uniform_color , main_superpower , last_known_location . These properties are then split into three (overlapping) categories: * informables: Properties the user can tell the system to help accomplish their goal * eg. constraints to help them find the right superhero for their job * requestables: Properties the user can ask the system about to find out more information about an entity * eg. \"what is their secret identity?\" something that only makes sense after an entity has been suggested * system requestables: Properties the system can ask the user for to help it figure out what entity best fills the user's goal The general properties (loyalty, name, etc.) are called slots, and the specific instances of a slot (\"Avengers\", \"Aqua Man\", etc.) are called values. As one of the ontology's main purposes is to support in natural language understanding and a user will only provide values for informable slots, these are the only values which must be listed in the ontology. { \"informable\" : { \"loyality\" : [ \"Avengers\" , \"Justice League\" , \"Guardians of the Galaxy\" , ... ], \"main_superpower\" : [ \"Claws\" , \"Gadgets\" , \"Magic\" , ... ], \"name\" : [ \"Aqua Man\" , \"Batman\" , \"Black Widow\" , ... ], \"primary_uniform_color\" : [ \"Black\" , \"Blue\" , \"Yellow\" , ... ] }, \"key\" : \"name\" , \"requestable\" : [ \"name\" , \"primary_uniform_color\" , \"main_superpower\" , \"last_known_location\" , \"loyality\" , \"description\" , \"real_name\" ], \"system_requestable\" : [ \"primary_uniform_color\" , \"main_superpower\" , \"loyality\" ] } {'informable': {'loyality': ['Avengers', 'Justice League', 'Guardians of the Galaxy', Ellipsis], 'main_superpower': ['Claws', 'Gadgets', 'Magic', Ellipsis], 'name': ['Aqua Man', 'Batman', 'Black Widow', Ellipsis], 'primary_uniform_color': ['Black', 'Blue', 'Yellow', Ellipsis]}, 'key': 'name', 'requestable': ['name', 'primary_uniform_color', 'main_superpower', 'last_known_location', 'loyality', 'description', 'real_name'], 'system_requestable': ['primary_uniform_color', 'main_superpower', 'loyality']} This information is useful to e.g. NLU and Policy: A regular expression based NLU can match known values from the ontology against user input e.g. is italian in the user input or a synonym defined in the NLU? if so, this could be an inform act for the slot food A policy can construct actions based on the slots e.g. slot food is requestable and informable: inform_food request_food","title":"Ontology"},{"location":"tutorials/dialogsystem/#the-domain-class","text":"In the ADVISER 2.0 Toolkit, domains are subclasses of utils.domain.domain.Domain . The Domain class provides an abstract interface for connecting to the ontology and database associated with a domain e.g. the weather domain would provide means to contact a WebAPI for querying with user-specified constraints like location, day,... or could provide access to the ontology so the system would know what system requestable slots existed in the weather domain. In thins domain, rather than working with the abstract Domain class, we will primarily be using the class JSONLookupDomain , a subclass which provides querying functionality for an SQLite-Database (found in resources/databases ) and an access to an ontology file (found in resources/ontologies ) in JSON-format. Example: Let's create an example domain. For this we'll work with a domain called superhero which allows users to find the correct superhero for whatever problem is at hand. As mentioned domains require an ontology and a database to define them, therefore as we instantiate a new Domain, we will pass both of these is as files. If the ontology and database file names follow the following format: * ontologies/{domain_name}.json * databasees/{domain_name}.db then only the domain_name is necessary to pass to the JSONLookupDomain object to instantiate it as shown below: # Here we can instantiate the domain with just the name string since the paths to our ontology # and database files follow the correct pattern super_domain = JSONLookupDomain ( name = \"superhero\" )","title":"The Domain Class"},{"location":"tutorials/dialogsystem/#topics-and-domains","text":"If you're providing domain-objects (or, equivalently, domain name strings) to a Service constructor, all subscribed and published topics for this service will implicitly append the domain name to allow for multi domain dialog systems. The exact reasons for this will be explained in more depth in the mutlidomain section of the next tutorial. Let's alter our ConcatenateService to accept a domain name: class ConcatenateServiceWithDomain ( Service ): def __init__ ( self , domain : str = \"mydomain\" ): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain ) @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" NOTE: This function did not change at all \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } If we would run the dialog system example above again, replacing the old ConcatenateService with the new ConcatenateServiceWithDomain , we would observe no more prints from it and also no more messages to topics C and D . This is because the toics for ConcatenateServiceWithDomain were internally remapped to: * A -> A/mydomain * B -> B/mydomain * C -> C/mydomain * D -> D/mydomain Subscribers perform prefix-based topic matching , that means in this case: * A/mydomain is NOT a prefix of A - no messages are received when publishing to A (or B or any other topic here) * same argument holds for B However: if concatenate would be called, we would see output by PrintService ! This is because * concatenate publishes to C/mydomain and PrintService subscribes to C * C is a prefix of C/mydomain ! * same argument holds for D If you provide all your services with the same domain, you're not going to experience any problems and do nothave to worry about these internal details in any way. However, in case you want to * go multidomain (see next tutorial) * combine domain-agnostic with domain-aware services (eg. a console input module and an NLU module) * change routing behaviour of our provided services without subclassing them and overwriting the respective functions the Service constructor offers a way to overwrite topics on instantiation: class Service : __init__ ( domain : Union [ str , Domain ] = \"\" , sub_topic_domains : Dict [ str , str ] = {}, pub_topic_domains : Dict [ str , str ] = {}, ... ) sub_topic_domains is a mapping for overwriting subscriber topics key : the original topic as given in the PublishSubscribe -decorator value : the domain name to append if len(value) > 0 : the value will be appended to the subscribed topic and a slash: key/value if len(value) == 0 : empty domain, subscribed topic will be simply: key pub_topic_domains works analogously So, if we change our constructor as follows: class ConcatenateServiceWithDomain ( Service ): def __init__ ( self , domain : str = \"mydomain\" , sub_topic_domains = { 'A' : '' , 'B' : '' }): \"\"\" NEW: domain name! \"\"\" Service . __init__ ( self , domain = domain ) @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" NOTE: This function did not change at all \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } everything will work again, meaning we will observe prints and published messages to C and D again, because we explicitly overwrite the appended domain with the empty string * A/mydomain -> A * B/mydomain -> B Another way to alter topics is to append domain strings manually in the return dictionary of any Publish/Subscribe function (Note: This only works, if you didn't provide a domain (or domain name) to the service base class constructor .): You may append any domain string to the dictionary keys, seperated by a slash: / . We could e.g. alter our ConcatenateService class: class ConcatenateService ( Service ): @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D/domain1' : result } else : return { 'C/domain2' : result } Now, our ConcatenateService gets all messages for topics starting with A and B (and independent of their domain) again, like in our very first ConcatenateService example. But, on the publishing side, we're now publishing to two different domains, domain1 and domain2 , by appending these domain names explicitly after the topic followed by the topic-domain-seperator: C/domain2 and D/domain1 . Equipped with these insights into the inner workings of the message routing mechanism, we can evolve our tutorial system to a multi-domain dialog system in the following chapter.","title":"Topics and Domains"},{"location":"tutorials/dialogsystem/#automatic-speech-recognition-asr","text":"To support spoken dialog systems, the ADVISER 2.0 toolkit provides an ASR module which converts spoken user utterances to text. In the current implementation, we provide the end-to-end ASR model for English language based on Transformer neural network architecture, however the exact ASR system can be swapped out to support other languages or architectures. We use the end-to-end speech processing toolkit ESPnet and the IMS-speech English multi-dataset recipe . The system was trained on LibriSpeech, Switchboard, TED-LIUM\\~3, AMI, WSJ, Common\\~Voice\\~3, SWC, VoxForge, and M-AILABS datasets. The output of the ASR model is a sequence of subword units, which include single characters as well as combinations of several characters, making the model lexicon independent and thus able to handle unseen words.","title":"Automatic Speech Recognition (ASR)"},{"location":"tutorials/dialogsystem/#using-the-speech-recognition-module","text":"To use the ASR module, provided in the ADVISER 2.0 toolkit, requires three classes: * SpeechRecorder : responsible for recording the user input * SpeechInputFeatureExtracter : responsible for feature extraction from recorded input * SpeechInputDecoder : responsible for converting input features to subword units The functionality is broken up in this way to allow other modules, such as the emotion recognition and backchanneling modules which will be seen in Tutorial Four, to also make use of the data extracted at each step. Example: To create instances of each of these three classes, see the code below NOTE: This only works if you have installed the requirements for the multimodal system (they are large, so this is not recommended if you will only be working with text) from services.hci.speech import SpeechInputDecoder from services.hci.speech import SpeechInputFeatureExtractor from services.hci.speech import SpeechRecorder conversation_log_dir = \"tutorial_logs\" use_cuda = False recorder = SpeechRecorder ( conversation_log_dir = conversation_log_dir ) speech_in_feature_extractor = SpeechInputFeatureExtractor () speech_in_decoder = SpeechInputDecoder ( conversation_log_dir = conversation_log_dir , use_cuda = use_cuda )","title":"Using the Speech Recognition Module"},{"location":"tutorials/dialogsystem/#rule-based-natural-language-understanding-nlu","text":"","title":"Rule-based Natural Language Understanding (NLU)"},{"location":"tutorials/dialogsystem/#semantic-representation-of-user-actions","text":"The NLU module is responsible for mapping natural language user input to a machine readable semantic frame representation. In this case the semantic frame is composed of up to three parts: * intent : which determines what type of action the user wants to perform (eg. \"hello\", \"inform\", \"request\", etc.) * slot : type of entity property the user is talking about (eg. \"name\", \"super_power\", etc.) * value : exact value of the entity property (eg. \"Superman\", \"super strength\", etc.) For example the following utterances could be mapped to to the following intents: * \"Hello\" $\\rightarrow$ hello () * \"I want a superhero who wears blue\" $\\rightarrow$ inform ( primary_uniform_color = \"blue\" ) * \"What is the hero's secret identity? and their team affiliation?\" $\\rightarrow$ request ( secret_identity ), request ( loyalty ) Slots and values are defined in the ontology, but the intents which the system currently expects are found in the file utils/useract.py and listed here below: * Inform : user provides system with new constraints (eg. \"speed\" as a super power) * NegativeInform : user tells system new negative constraint (eg. \"not speed\" as a super power) * Request : user asks system for value of a slot (eg. \"what is the super power?\") * Hello : user greets system * Bye : user ends session * Thanks : user thanks system * Confirm : user confirms system utterance (eg. \"yes, I do want super speed\") * Deny : user denies system utterance (eg. \"No, I do not want super speed\") * RequestAlternatives : user asks for other entities that meet their constraints besides the one the system recommended (eg. \"is there anyone else besides the Flash?\") * Bad : user utterance couldn't be parsed to any other act * SelectDomain : only needed for multidomain systems, user says keyword associated with starting the domain These intents can be broken down into two sections: General and Domain-Specific. General acts are those like \"Hello\" and \"Bye\" which do not have slots or values associated with them and their regexes remain the same regardless of the domain.","title":"Semantic representation of user actions"},{"location":"tutorials/dialogsystem/#specifying-rules","text":"In order to understand the user input, one can specify a list of possible natural language realisations for each user act. For example, the user act hello() could be expressed by saying Hello , Hi or Hey . A common way of specifying these rules computationally is to create regular expressions. For example, the dialogue agent could recognise the user act hello() if the user input string matches the regular expression (hello|hi|hey) . However, it would be time-consuming and messy to write a list of natural language realisations for all possible combinations of intent, slot and value. Therefore, we created a new syntax which allows you to reduce the number of rules by creating functions so that you only need to write a rule once and can simply apply it to all needed slots/values. In the following subsections, we present the most important parts of this syntax.","title":"Specifying rules"},{"location":"tutorials/dialogsystem/#1-general-syntax","text":"The syntax uses keywords and indentation to create a nested command structure. This means that each line represents one command and each command starts with a keyword identifying the command type. Commands have a \"block level\" which is represented by their number of leading spaces (Level 0: 0 spaces, Level 1: 4 spaces, Level 2: 8 spaces, ...). Rule and function declaration commands are Level 0 commands. Any other commands can be inserted at any level >0 and are automatically added to their \"parent\" command. A parent command is the last command on the current level -1. In the following example, Command2 is added to Command1, Command4 is added to Command3 and Command5 is added to Command4. Command1 arguments Command2 arguments Command3 arguments Command4 arguments Command5 arguments","title":"1 General syntax"},{"location":"tutorials/dialogsystem/#2-commands","text":"Currently, the ADVISER NLU syntax provides five possible commands. Each command individually defines what its arguments have to look like and what kind of child commands it allows. This section will show how to use the commands.","title":"2 Commands"},{"location":"tutorials/dialogsystem/#21-rule","text":"The rule command specifies a mapping from a regular expression to a specific intent (user act). The command itself consists of the keyword \"rule\" and a description of the user act as intent() for user acts which do not contain slots (e.g. hello() , bye() ) or intent(slot) for user acts with a slot (e.g. inform(primary_uniform_color) . The regex command can later be used as a child command to add information about the user utterances accepted and the slot's value. Regarding the child commands, a rule can have an infinite amount of child commands. These include the regular expressions for each intent and below those, any exceptions and additions that need to be specified. Exceptions are checked in the order of their appearance. Note: General user acts (those which do not take slots or values as input) are not autogenerated. If you want to edit these, you may do so directly in the file resources/nlu_regexes/GeneralRules.json , however be careful as this file is currently shared across all domains.","title":"2.1 Rule"},{"location":"tutorials/dialogsystem/#22-regular-expression","text":"The regex command specifies a regular expression should map to the user act specified in the current rule block. RegEx commands consist of the keyword \"regex\" and a string wrapped by double quotes. They are usually added as child commands to rules, functions, exceptions and additions. The following example shows a valid rule specification, which matches to either \"hero\" or \"superhero\" and both the American and British spellings of the word \"color\". rule request(primary_uniform_color) regex \"what is the( super)?hero's uniform colo(u)?r\\?\" It is also possible to add multiple regular expressions to rule in order to account for more varied user utterances without making the regular expressions too complicated. rule request(primary_uniform_color) regex \"what is the( super)? hero's uniform colo(u)?r\\?\" regex \"what is the colo(u)?r of the( super)? hero's uniform\\?\" regex \"which colo(u)?r does the( super)? hero wear\\?\" For user acts such as inform , we also need to have access to the slot's value. The value can be accessed in the regular expression using curly braces. rule inform(primary_uniform_color) regex \"the colo(u)?r should be {primary_uniform_color}\" This way, we can specify one rule for each value of primary_uniform_color. For example, if the user types the colour should be green , the system detects the user act inform(primary_uniform_color=green) . Note: RegEx commands cannot take any child commands.","title":"2.2 Regular Expression"},{"location":"tutorials/dialogsystem/#23-exceptions","text":"Exceptions can be called inside a rule command/function to override the default messages. Exceptions consist of the keyword \"if\" and take a constraint as an argument. A constraint can currently only match the pattern variable = \"string\" . Exceptions particularly make sense in cases where you might prefer to use a synonym rather than the exact value in the database. For example, if a database stores colors by hexadecimal code, the user cannot be expected to know the code for each color. Therefore, we could add an exception using the common name for the color, so that instead of expecting colors in hexadecimal, the system will only recognize the common name for the color. rule inform(primary_uniform_color) regex \"the colo(u)?r should be {primary_uniform_color}\" if primary_uniform_color = \"#ff11bb\" regex \"the colo(u)?r should be pink\" Note : Exception commands can take the same child commands as rule commands.","title":"2.3 Exceptions"},{"location":"tutorials/dialogsystem/#24-additions","text":"Additions work very similar to exceptions. The only differences are that \"add_if\" is used as the keyword and that the messages of the addition command do not override the regexes of the parent command, but instead add possible regexes to the existing ones, this is in particularly well suited to adding synonyms. In the following example, we allow the user to also say cyan or blue as a way to map to the primary_uniform_color blue . rule inform(primary_uniform_color) regex \"(the colo(u)?r|) should be {primary_uniform_color}\" if primary_uniform_color = \"#ff11bb\" regex \"the colo(u)?r should be pink\" add_if primary_uniform_color = \"blue\" regex \"the colo(u)?r should be cyan\" Note: Addition commands can take the same child commands as rule commands.","title":"2.4 Additions"},{"location":"tutorials/dialogsystem/#25-functions","text":"Functions are similar to rules. They can take an arbitrary number of parameters and return a regular expression (or normal string). The function command consists of the keyword \"function\" and the function description using the pattern function_name(argument_one, argument_two) . Functions are particularly useful to improve the structure of your files. In the previous example, we have added cyan to be a synonym of blue . If we want to add synonyms for all colours, we would have to list all possible regexes for all possible synonyms which would result in a huge number of lines and would be quite a mess. Instead, we can specify a function which lists all synonymous colour strings for each possible colour value centrally at one point in the file and whenever we want to use synonyms, we can simply call this function: function color_synonym ( generic_color ) # the color itself is almost always a synonym regex \"{generic_color}\" # 'add_if' adds regular expressions to the existing ones ( see above ) add_if generic_color = \"red\" regex \"maroon\" add_if generic_color = \"green\" regex \"lime( green)?\" regex \"olive( green)?\" regex \"neon green\" add_if generic_color = \"blue\" regex \"cyan\" regex \"turquoise\" # 'if' overwrites ( ! ) existing regular expressions if generic_color = \"#ff11bb\" \"pink\" \"magenta\" The inform rule would then be simplified to: rule inform(color) \"(the colo(u)?r|it) should be {color_synonym(color)}\" Note: Function commands can take the same child commands as rule commands.","title":"2.5 Functions"},{"location":"tutorials/dialogsystem/#3-shortcuts-and-syntax-simplification","text":"The examples in the previous section show the ADVISER NLU syntax, as it is read by the interpreter. For simplifications and for a better overview, we allow some simplifications and shortcuts. In a preprocessing step, the simplified template is automatically transformed into a valid syntax.","title":"3 Shortcuts and syntax simplification"},{"location":"tutorials/dialogsystem/#31-comments-and-empty-lines","text":"While the original syntax requires one command per line, in the preprocessing step, empty lines and lines that start with a hashtag (#) are removed from the template file. Please note that non-leading hashtags are not recognised as comments currently.","title":"3.1 Comments and empty lines"},{"location":"tutorials/dialogsystem/#32-tabs","text":"The original syntax requires four spaces per block level. Alternatively, you can also use a tab instead, since all tabs are replaced by four spaces in the preprocessing step.","title":"3.2 Tabs"},{"location":"tutorials/dialogsystem/#33-automatic-insertion-of-the-regex-keyword","text":"Regexes do not necessarily need to be marked via the regex keyword. For all lines that start with double quotes, a regex keyword is automatically inserted at the beginning of the line in the preprocessing step. Example: rule request(primary_uniform_color) \"what is the( super)? hero's uniform colo(u)?r\\?\"","title":"3.3 Automatic insertion of the regex keyword"},{"location":"tutorials/dialogsystem/#34-colons","text":"A neater version of the example in 3.3 would be the following example: rule request(primary_uniform_color): \"what is the( super)? hero's uniform colo(u)?r\\?\" To allow this syntax, the preprocessor interprets everything coming after a colon (that\u2019s not wrapped by double quotes) as a new child command and moves it to the next line with the respective block level + 1. This way, the above example and the example from 3.3 are exactly the same after preprocessing.","title":"3.4 Colons"},{"location":"tutorials/dialogsystem/#the-nlu-module","text":"ADVISER's NLU module makes use of NLU files which specify the regular expressions with the previously presented syntax. The pipeline for creating the NLU is the following: Make sure you have created a domain . Write your NLU file using the custom syntax (see above), name it {domain_name}.nlu and place it in the folder resources/nlu_regexes . Execute the script gen_regexes.py in the folder tools/regextemplates like this: python3 tools/regextemplates/gen_regexes.py {domain_name} {domain_name} Example: python3 tools/regextemplates/gen_regexes.py superhero superhero Check that the tool has created the files {domain_name}InformRules.json for inform acts and {domain_name}RequestRules.json for request acts inside the resources/nlu_regexes folder. Once you have all these files, you can use the HandcraftedNLU module in services/nlu by simply passing your domain object in the constructor. from utils.domain.jsonlookupdomain import JSONLookupDomain from services.nlu.nlu import HandcraftedNLU domain = JSONLookupDomain ( 'superhero' ) nlu = HandcraftedNLU ( domain = domain ) You can type some exemplary messages and see which user acts are recognised by the NLU, when you are done, type \"bye\" to exit the loop: user_input = input ( '>>> ' ) while user_input . strip () . lower () not in ( '' , 'exit' , 'bye' , 'goodbye' ): user_acts = nlu . extract_user_acts ( user_input )[ 'user_acts' ] print ( ' \\n ' . join ([ repr ( user_act ) for user_act in user_acts ])) user_input = input ( '>>> ' )","title":"The NLU module"},{"location":"tutorials/dialogsystem/#rule-based-belief-state-tracker-bst","text":"The BST maintains a representation of the current dialog state. It is responsible for tracking the constraints a user provides over the course of a dialog and their probabilities, recording any requests from the current turn, tracking the types of user acts in the current turn, and registering the number of database matches for the given constraints. In the ADVISER 2.0 Toolkit, this state is built up over the course of the dialog as the user expresses more constraints. Probabilities for each constraint are determined by the NLU and are not currently further processed. An example of the beliefstate for the second turn in a dialog about IMS Courses can be seen below. {'user_acts': {<UserActionType.Inform: 'inform'>} 'informs': {'bachelor': {'true': 1.0 } 'turn': {'sose': 1.0 } 'ects': {'6': 1.0 } } 'requests': {} 'num_matches': 4 'discriminable': True } As mentioned previously the beliefstate is built up over time. Therfore there are currently only three entries in the informs dictionary as up to this point the user has only provided three constraints. Each constraint has a probability of 1.0 because neither the NLU nor BST have complex rules for handling ambiguous user utterances, but this is an area we may look to improve in the future. Example: Instantiating a rules based BST is as simple as running the code below bst = HandcraftedBST ( domain = super_domain )","title":"Rule-based Belief State Tracker (BST)"},{"location":"tutorials/dialogsystem/#policy","text":"","title":"Policy"},{"location":"tutorials/dialogsystem/#rule-based-policy","text":"The policy is responsible for determining the system's next action. In ADVISER 2.0, we provide two implementations of a rule-based policy (one designed to work with a database and one designed to work with an API backend). Both follow a similar decision flow. Since we focus here on task oriented dialog systems, the policy tries to help a user fulfill their goal as quickly as possible. A simplified version of a the decision making process in a rules based policy can be seen below: On each turn, the policy is capable of choosing one next action, these actions include: Welcome : greet the user InformByName : tell the user some new information InformByAlternatives : provide the user an alternative entity Request : ask the user for more information Select : ask the user to select between a given set of choices RequestMore : ask the user if they need more help Bad : inform the user their last utterance couldn't be parsed Bye : end the dialog As seen in the above diagram, the policy first works to handle general (non-domain specific) user actions. It then queries the database and only asks the user for more information if there are too many entries and asking for more information will help narrow down results. In the actual policy the decisions are a bit more nuanced, but the graphic gives the general idea of the types of rules required for a rules-based policy. Example: Instantiating a rules-based policy can be done with the code below: policy = HandcraftedPolicy ( domain = super_domain )","title":"Rule-based Policy"},{"location":"tutorials/dialogsystem/#reinforcement-learning-policy","text":"","title":"Reinforcement Learning Policy"},{"location":"tutorials/dialogsystem/#why-reinforcement-learning","text":"Developing handcrafted policies can be quite time consuming and have difficulties adapting to unseen scenarios. Therefore a machine learning approach can be preferable. In this type of scenario, training a machine learning agent would circumvent needing to hard code a rule for every edge case scenario. Unfortunately this type of approach normally requires a lot of data to train the policy. Especially for new domains, this kind of data just does not exist, which is where reinforcement learning comes in. The basic idea behind reinforcement learning is that an agent has a certain set of actions which it can take and is placed in a certain environment (which it may either know in advance or must learn as it explores). The agent then tries out the different actions it can take, each action altering the state (or the agent's perception of the environment) and generating a reward. In this way, the agent learns how to navigate through it's environment and find the path which yields the highest reward. This process is shown in the graph below. As mentioned before, as an input the agent receives the current state and reward and it uses these to choose what it thinks the next best action will be. This action results in a new state and a new reward.","title":"Why reinforcement Learning"},{"location":"tutorials/dialogsystem/#rl-in-the-context-of-dialog-policy","text":"In the context of dialog systems, the RL agent is the dialog policy and the actions it can take are defined by the SysActs . The environment is a user (simulated or real) and the state is represented by the beliefstate. The reward for each action backpropagates and is inversely proportional to the number of turns it took to complete the dialog + a fixed reward for dialogs where a user was able to fulfill their goal. In ADVISER 2.0, the RL policy is implemented using deep reinforcement learning. Similar to the Deep Q-learning algorithm , an action-value function is approximated by a neural network which outputs a value for each possible system action, given the vectorised representation of a turn\u2019s beliefstate as input. The exact action set is defined in the class RLPolicy where a set of base actions templates is defined with slot names from the ontology e.g. if you have a slot food in your ontology, it will create actions like inform#food , request#food and select#food which are used to inform a user about a certain type of food, to request the food type from the user or to let the user choose between multiple food types. These action templates are the initial output of the reinforcement learning policy, which then get expanded using beliefstate and database information. For more information on the architecture see the ADVISER paper . Example: As there are so many parameters for the RL policy, instantiating it requires slightly more code than instantiating other modules. To instantiate an RL policy with the parameters used in the ADVISER paper, see the code below: # Allows you to track training progress using tensorboard summary_writer = SummaryWriter ( os . path . join ( 'logs' , \"tutorial\" )) # logs summary statistics for each train/test epoch logger = DiasysLogger ( console_log_lvl = LogLevel . RESULTS , file_log_lvl = LogLevel . DIALOGS ) # Create RL policy instance with parameters used in ADVISER paper policy = DQNPolicy ( domain = domain , lr = 0.0001 , eps_start = 0.3 , gradient_clipping = 5.0 , buffer_cls = NaivePrioritizedBuffer , replay_buffer_size = 8192 , shared_layer_sizes = [ 256 ], train_dialogs = 1000 , target_update_rate = 3 , training_frequency = 2 , logger = logger , summary_writer = summary_writer ) logger : state space dim : 74 logger : action space dim : 9 logger : Gradient Clipping : 5.0 logger : Architecture : Dueling logger : Update : Double REPLAY MEMORY : NAIVE Prioritized ARCHITECTURE : Dueling","title":"RL in the Context of Dialog Policy"},{"location":"tutorials/dialogsystem/#user-simulator","text":"To train a reinforcement learning (RL) policy, it is often useful to use a simulated user instead of an actual one at least in the beginning. Simulations, while seldom accurate representations of real users, are substantially more patient. That is, to train or evaluate a dialog policy, thousands of dialogs are required. Having a real human sit through this many dialogs would be very expensive and tedious, especially since at the beginning of training, an RL policy will produce utterly nonsensical dialogs. In comparison, a simulated user is very cheap, will not be bored or annoyed, and can be called whenever you are ready to train or test a dialog. After initial training has been performed with a simulation, it is possible to conduct further training with human users. Since a user simulator is an important part of the training process for an RL policy, the next question becomes how to create one. In the ADVISER 2.0 Toolkit, we use an agenda based user simulator based off of work by Schatzmann et al. . The basic function of the simulator can be seen in the graphic below: To start a dialog, the user simulator will randomly generate a goal (shown in gray in panel 1). This goal will include all of the constraints (informs) the user wants to provide and all of the questions (requests) they will want to ask. Then this goal will be transformed into a series of user actions and placed in the action stack. On each turn after that, the user simulator will receive a system action as input and need to respond to it (panel 2) Here the user response is hardcoded in a similar way to the handcrafted policy. Any new actions generated to respond to the system will be placed at the top of the stack. Then a random number of actions between one and n will popped from the top of the stack and given out as the user acts for that turn. In addition to the hardcoded response for each type of system act, the user simulator's behavior is also controlled by configuration parameters. These control behavior such as the maximum number of actions the user takes per turn (default 3), and whether user goals should be possible to fulfill or if it doesn't matter. These additional parameters are stored in an external configuration file. Example: To create an instance of user simulator see below: user_sim = HandcraftedUserSimulator ( domain = super_domain )","title":"User Simulator"},{"location":"tutorials/dialogsystem/#evaluation","text":"In order to train an RL policy, in addition to a user simulator, we need a reward signal. That is where the evaluation module comes in. There are two evaluation classes which are important to consider. The first one is teh ObjectiveReachedEvaluator which provides the reward signal to the RL policy. The second is the PolicyEvaluator which tracks the percent of successful dialogs, average reward, and average turn number for an epoch. As a note, while the ObjectiveReachedEvaluator is already part of the RLPolicy class, to log statistics, you need to explicitely add the PolicyEvaluator to the dialog graph. As a default, a reward of -1 for every turn is assigned to encourage the policy to keep dialogs as short as possible. For every dialog where the user goal is fulfilled, a reward of 20 is given. Example: A PolicyEvaluator can be created with the code below: evaluator = PolicyEvaluator ( domain = domain , use_tensorboard = True , experiment_name = \"tutorial\" , logger = logger , summary_writer = summary_writer )","title":"Evaluation"},{"location":"tutorials/dialogsystem/#training-a-reinforcement-learning-policy","text":"Now that we have a user simulator and an evaluator, we can start using them to train our RL policy. This requires configuring the dialog graph slightly differently. Rather than the graph we saw in Tutorial One, we will only use the beliefstate tracker, RL Policy and a user simulator (optionally an evaluator as well to log statistics). This new graph can be seen below: To initialize training and evaluation, a random seed is generally used to set initial parameters. For the sake of reproducibility, it is recommended to store this seed along with the results so that in the future, you can initialize all random generators used in your pipeline with it. If you run the system twice with the same seed, you should get exactly the same results and dialogs. To train the system, a dialog graph is created with all necessary modules, then for the number of training epochs desired, dialogs are carried out and evaluated. During each training epoch, weights are updated for the RL policy and during each testing epoch, the success rate and length of dialogs are evaluated and recorded. The number of dialogs per epoch and the number of epochs can be determined by the user. As a note, when evaluating the overall performance of an RL policy, it is important to run the train/test loop multiple times with different random seeds to make sure that a good performance is not simply because of a good random seed. Example: Example training and evaluation code (warning takes some time to run): # SET CONSTANTS TRAIN_EPOCHS = 1 TRAIN_EPISODES = 1000 EVAL_EPISODES = 1000 MAX_TURNS = 25 # Choose how many repeated trials for i in range ( 1 ): common . init_random () # add seed here as a parameter to the init_random if wanted ds = DialogSystem ( services = [ user_sim , bst , policy , evaluator ], protocol = 'tcp' ) # Start train/eval loop for j in range ( TRAIN_EPOCHS ): # START TRAIN EPOCH evaluator . train () policy . train () evaluator . start_epoch () for episode in range ( TRAIN_EPISODES ): if episode % 100 == 0 : print ( \"DIALOG\" , episode ) logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () # START EVAL EPOCH evaluator . eval () policy . eval () evaluator . start_epoch () for episode in range ( EVAL_EPISODES ): logger . dialog_turn ( \" \\n\\n !!!!!!!!!!!!!!!! NEW DIALOG !!!!!!!!!!!!!!!!!!!!!!!!!!!! \\n\\n \" ) ds . run_dialog ( start_signals = { f 'user_acts/ { domain . get_domain_name () } ' : []}) evaluator . end_epoch () policy . save () ds . shutdown ()","title":"Training a reinforcement learning policy"},{"location":"tutorials/dialogsystem/#handcrafted-natural-language-generation-nlg","text":"To transform system acts into natural language utterances, ADVISER 2.0 uses handcrafted templates. Although machine learning generated output can have more breadth of expression, using templates guarentees that all system utterances will be grammatic and sensical. Using templates additionally allows dialog systems for new domains to be created even when there is not sufficient data for those domains to train a machine learning based NLG. In ADVISER 2.0, rather than mapping every sys_act, slot, value combination to an individual utterance, templates are used to generalize this process by specifying placeholders for a system act's slots and/or values. An example of this can be seen below: inform(name={X}, ects={Y}) \u2192 \"The course {X} is worth {Y} ECTS.\" During the dialog, the system iterates through the templates and chooses the first one for which the system act fits the template's signature.","title":"Handcrafted Natural Language Generation (NLG)"},{"location":"tutorials/dialogsystem/#types-of-templates","text":"Under adviser/resources/templates the handcrafted templates are stored in text files. The templates have the format where the left side represents the system act and the right side represents the natural language utterance. Variables are used instead of concrete slot values so that the templates can be reused as much as possbile. Each file is divided into several sections, we add examples: Templates for system general acts template hello(): \"Welcome to the IMS courses chat bot. How may I help you?\" Templates for system requests template request(lang): \"In which language shall the course be held?\" Methods for system informs function info(slot, value) if slot = \"ects\": \"is worth {value} ECTS\" if slot = \"turn\" if value = \"sose\": \"is offered in the summer semester\" if value = \"wise\": \"is offered in the winter semester\" Templates for system informs template inform_byname(name): \"I found the course {name}. What do you want to know about it?\" template inform_byname(name, turn): \"The course {name} {info(\"turn\", turn)}.\" Similarly, templates for system confirm, request more and select are included. Example: If system act is: inform(name='computational linguistics team laboratory', turn='wise') The NLG output will be: \"The course computational linguistics team laboratory is offered in the winter semester.\" Notes: Each domain has a ist own YourDomainNameMessages.nlg file No python script needs to be modified (domain independent) Example: The code to create an NLG service for the superhero domain is shown below: nlg = HandcraftedNLG ( domain = super_domain )","title":"Types of templates"},{"location":"tutorials/dialogsystem/#text-to-speech-tts","text":"The TTS module is an options module which converts the text natural language output to speech. In the ADVISER 2.0 toolkit, this is done using the ESPnet-TTS toolkit , which is an extension of the ESPnet toolkit mentioned in the ASR section. We use FastSpeech as a synthesis model, which provides substantially faster voice generation. Additionally, we are able to provide a \"cleaner\" file to optimize the synthesizer for abbreviations, such as Prof., Univ., IMS, NLP, ECTS, and PhD , as well as for German proper names, such as street names. These optimizations can be easily extended by adding additional words and pronunciation mappings to services/speech/cleaners.py . Example: Similar to how the ASR module also required a SpeechInputRecorder module, the TTS module also requires a SpeechOutputPlayer in order for the user to be able to hear the generated sound file. The SpeechOutputPlayer and SpeechOutputGenerator can be instantiated with the code below. NOTE: This code will only work if you have installed the requirements for the multimodal dialog system (they are large, so this is not recommended if you will only be working with text) from services.hci.speech import SpeechOutputGenerator from services.hci.speech import SpeechOutputPlayer # (GPU: 0.4 s/per utterance, CPU: 11 s/per utterance) speech_out_generator = SpeechOutputGenerator ( use_cuda = False ) speech_out_player = SpeechOutputPlayer ( conversation_log_dir = conversation_log_dir )","title":"Text to Speech (TTS)"},{"location":"tutorials/dialogsystem/#cleaning-up-tts-output","text":"To improve the speech generation, we also provide a file servicse/hci/speech/cleaners.py which allows you to manually correct pronunciation of words. This allows you to provide either phonetic transcriptions for acronyms, abbreviations, and foreign words or pronunciation patterns for things such as email addresses or telephone numbers. One of the methods from this file is shown below. def expand_abbreviations ( text ): \"\"\" Preprocesses a text to turn abbreviations into forms that the TTS can pronounce properly text (string): Text to be preprocessed \"\"\" for regex , replacement in _abbreviations : text = re . sub ( regex , replacement , text ) return text # List of (word, replacement) pairs for acronym or special words: _acronym = [ ( ' a ' , ' ae ' ), ( ' s ' , ' eh s, ' ), ( 'array' , 'ER RAY' ), ( 'API' , 'AE P I' ), ( 'distributional' , 'distributionall' ), ( 'ECTS' , 'E C T EH S,' ), ( 'Erasmus' , 'E RAS MOUS' ), ( 'ID' , 'I D' ), ( 'IMS' , 'I M EH S' ), ( 'NLP' , 'N L P' ), ( 'PhD' , 'P h D' ), ( 'PWR 05B' , 'Pfaffen vaald ring five B, ' ), ( 'psycholinguistics' , 'psycho linguistics' ), ( 'stuttgart' , 'stu gart' ), ( 'Stuttgart' , 'Stu gart' ), ( 'vegan' , 'viygan' ), ( 'Vegan' , 'Viygan' ), ( 'ImsLecturers' , 'I M EH S Lecturers' ), ( 'imsLecturers' , 'I M EH S Lecturers' ), ]","title":"Cleaning up TTS output"},{"location":"tutorials/dialogsystem/#chatting-with-the-dialog-system","text":"There are two main ways to interact with an ADVISER 2.0 dialog system: 1) by typing input and reading system output from the terminal or 2) by speaking to the system and receiving audio responses. Since we've already taken a quick look at a spoken dialog system, let's quickly discuss a text based one. In short, a text based system is much simpler. Instead of needing multiple modules for input/output, the text based system just needs ConsoleInput and ConsoleOutput . When these are added to the dialog system, the system utterances will appear on the terminal and the user can give their response by typing and pressing enter to end an utterance. Example: An example of a dialog system constructed this way can be seen below. NOTE: There is a problem with the user input in Jupyter Notebook. To try the code out, copy the code below to a new file in the adviser folder and run it from the dialog system # Importing everything we need for a dialog system from utils.domain.jsonlookupdomain import JSONLookupDomain from utils.logger import DiasysLogger , LogLevel from services.hci import ConsoleInput , ConsoleOutput from services.nlu import HandcraftedNLU from services.bst import HandcraftedBST from services.policy import HandcraftedPolicy from services.nlg import HandcraftedNLG from services.domain_tracker import DomainTracker from services.service import DialogSystem # create domain super_domain = JSONLookupDomain ( name = \"superhero\" ) # create domain specific modules nlu = HandcraftedNLU ( domain = super_domain ) bst = HandcraftedBST ( domain = super_domain ) policy = HandcraftedPolicy ( domain = super_domain ) nlg = HandcraftedNLG ( domain = super_domain ) d_tracker = DomainTracker ( domains = [ super_domain ]) # Input modules (just allow access to terminal for text based dialog) user_in = ConsoleInput ( domain = \"\" ) user_out = ConsoleOutput ( domain = \"\" ) logger = DiasysLogger ( console_log_lvl = LogLevel . DIALOGS ) ds = DialogSystem ( services = [ d_tracker , user_in , user_out , nlu , bst , policy , nlg ], debug_logger = logger ) error_free = ds . is_error_free_messaging_pipeline () if not error_free : ds . print_inconsistencies () ds . draw_system_graph ( name = 'system' , show = False ) # start dialog for _ in range ( 1 ): ds . run_dialog ({ 'gen_user_utterance' : \"\" }) ds . shutdown ()","title":"Chatting with the dialog system"},{"location":"tutorials/dialogsystem/#check-your-understanding-optional","text":"Now that you have read how each of the basic modules provided by the ADVISER 2.0 Toolkit works, let's actually test it out.","title":"Check Your Understanding (Optional)"},{"location":"tutorials/dialogsystem/#run-a-dialog-system","text":"There should be a program in the tutorials folder called tutorial_chat.py All the modules you will need are already imported, but you will need to follow the comments and create a dialog system for yourself.","title":"Run a Dialog System"},{"location":"tutorials/dialogsystem/#create-a-basic-nlu","text":"Right now we have provided a very simple .nlu file for the superhero domain. Try adding more synonyms/more regexes to the rules in superhero.nlu so that it can capture more realistic user utterances.","title":"Create a basic NLU"},{"location":"tutorials/dialogsystem/#update-the-nlg","text":"Try adding some more NLG templates to the superhero domain, or updating existing ones to sound more natural (the file is located in the resources/nlg_templates folder).","title":"Update the NLG"},{"location":"tutorials/dialogsystem/#test-out-your-new-system","text":"Once you are satisfied with your NLU and NLG files, test out the system again. Make sure you remembered to recomile the regexes first though!","title":"Test out your new system"},{"location":"tutorials/introduction/","text":"Todo Add link to notebook Introduction to Dialog Systems Dialog Systems At it's simplest, a dialog system is a computer program with which humans can talk. As technology has improved, dialog systems have become more popular and more complex. They include everyday personal assistants such as Siri, Alexa, or Google Home, as well as more specialized systems like those you might encounter if you call your bank, or need to chat with an online customer service agent. Dialog systems even include some which try to mimic more natural human conversations and have the ability to discuss about \"open-world\" topics rather than being limited to specific domains. Task oriented v. Chatbot Systems Chatbot Systems Chatbot systems have been around since 1964 when Joseph Weizenbaum created the ELIZA chatbot system, a virtual therapist that could hold a conversation by mirroring back user utterances (eg. http://www.med-ai.com/models/eliza.html if you want to test it out). The main goal of chatbot systems is to create an experience that engages a user. Conversations do not need to be about any one topic in particular and can wander from topic to topic without trying to fulfill any type of concrete goal. Often, these systems work to form some type of emotional bond with the user and their success is measured by how long a user is willing to talk with the system (usually measured in turns). One of the most advanced chatbot systems currently available is Microsoft's XiaoIce with whom user's have kept a single conversation going for more than 24 hours (7,000 turns). Task Oriented Dialog Systems In comparison to chatbot systems, task oriented dialog systems seek to help the user accomplish a defined goal as efficiently as possible. These types of goals could include things such as finding a suitable restaurant, resolving a customer service complaint, or even just registering a new credit card. These systems are generally much more limited in scope than chatbots, but have been gaining popularity commercially as a way for companies to offer a more interactive/efficient/flexible interface for users than traditional websites/customer service telephone lines. Task oriented dialog systems are generally evaluated by how few turns it takes to complete a dialog and how frequently a user is able to accomplish their goal. The remainder of this tutorial will focus on task oriented dialog systems. Domains in Task Oriented Dialog A domain here refers to the specific type of task that a task oriented dialog system handles. For example, a \"restaurant\" domain system could help a user find a restaurant to have dinner at. A \"lecturer\" domain system might help a user locate which lecturer is in charge of eg. coordinating the Erasmus program and it could then provide information about that lecturer's office hours or email address. Normally the topics which can be discussed in a domain are defined in an ontology and the knowledge about entities in a domain is stored in a database. Modular Dialog Systems There are two main strategies when it comes to designing a dialog system: 1) using a neural model to directly map the sequence of words in the user utterance to a sequence of words for a system utterance. Or 2) breaking up dialog processessing functionality into a series of modules where each module is responsible for a step in the processing pipeline. The first approach is more common in chatbot type systems, while the second is more common in task oriented dialog systems. The general modules included in a task oriented dialog system are listed below and a brief overview of their functionality is provided: ASR: The Automatic Speech Recognition (ASR) module is optional. It converts a spoken user utterance to text in the case of a spoken dialog system. NLU: The Natural Language Understanding (NLU) module is responsible for mapping the natural language (text) user utterance to a semantic frame (machine readable) version. BST: The Belief State Tracker (BST) is responsible for keeping track of information the user has provided up to the current turn in the dialog. Policy: The Policy is responsible for deciding the next action the system should take based on the current system belief state. NLG: The Natural Language Generation (NLG) module is responsible for converting the machine readable (semantic frame) representation of the system's next action into a natural language representation. TTS: The Text To Speech (TTS) module is again optional and used in a spoke dialog system to convert a text based system utterance into speech. It is also important to note that the functionality of these modules can be combined. These modules may additionally be rule-based or machine learning-based and a dialog system can be made of a combination of rules based and machine learning based modules. In the case of machine learning-based modules, depending on the architectures, modules may be trained independently or jointly.","title":"Introduction"},{"location":"tutorials/introduction/#introduction-to-dialog-systems","text":"","title":"Introduction to Dialog Systems"},{"location":"tutorials/introduction/#dialog-systems","text":"At it's simplest, a dialog system is a computer program with which humans can talk. As technology has improved, dialog systems have become more popular and more complex. They include everyday personal assistants such as Siri, Alexa, or Google Home, as well as more specialized systems like those you might encounter if you call your bank, or need to chat with an online customer service agent. Dialog systems even include some which try to mimic more natural human conversations and have the ability to discuss about \"open-world\" topics rather than being limited to specific domains.","title":"Dialog Systems"},{"location":"tutorials/introduction/#task-oriented-v-chatbot-systems","text":"","title":"Task oriented v. Chatbot Systems"},{"location":"tutorials/introduction/#chatbot-systems","text":"Chatbot systems have been around since 1964 when Joseph Weizenbaum created the ELIZA chatbot system, a virtual therapist that could hold a conversation by mirroring back user utterances (eg. http://www.med-ai.com/models/eliza.html if you want to test it out). The main goal of chatbot systems is to create an experience that engages a user. Conversations do not need to be about any one topic in particular and can wander from topic to topic without trying to fulfill any type of concrete goal. Often, these systems work to form some type of emotional bond with the user and their success is measured by how long a user is willing to talk with the system (usually measured in turns). One of the most advanced chatbot systems currently available is Microsoft's XiaoIce with whom user's have kept a single conversation going for more than 24 hours (7,000 turns).","title":"Chatbot Systems"},{"location":"tutorials/introduction/#task-oriented-dialog-systems","text":"In comparison to chatbot systems, task oriented dialog systems seek to help the user accomplish a defined goal as efficiently as possible. These types of goals could include things such as finding a suitable restaurant, resolving a customer service complaint, or even just registering a new credit card. These systems are generally much more limited in scope than chatbots, but have been gaining popularity commercially as a way for companies to offer a more interactive/efficient/flexible interface for users than traditional websites/customer service telephone lines. Task oriented dialog systems are generally evaluated by how few turns it takes to complete a dialog and how frequently a user is able to accomplish their goal. The remainder of this tutorial will focus on task oriented dialog systems.","title":"Task Oriented Dialog Systems"},{"location":"tutorials/introduction/#domains-in-task-oriented-dialog","text":"A domain here refers to the specific type of task that a task oriented dialog system handles. For example, a \"restaurant\" domain system could help a user find a restaurant to have dinner at. A \"lecturer\" domain system might help a user locate which lecturer is in charge of eg. coordinating the Erasmus program and it could then provide information about that lecturer's office hours or email address. Normally the topics which can be discussed in a domain are defined in an ontology and the knowledge about entities in a domain is stored in a database.","title":"Domains in Task Oriented Dialog"},{"location":"tutorials/introduction/#modular-dialog-systems","text":"There are two main strategies when it comes to designing a dialog system: 1) using a neural model to directly map the sequence of words in the user utterance to a sequence of words for a system utterance. Or 2) breaking up dialog processessing functionality into a series of modules where each module is responsible for a step in the processing pipeline. The first approach is more common in chatbot type systems, while the second is more common in task oriented dialog systems. The general modules included in a task oriented dialog system are listed below and a brief overview of their functionality is provided: ASR: The Automatic Speech Recognition (ASR) module is optional. It converts a spoken user utterance to text in the case of a spoken dialog system. NLU: The Natural Language Understanding (NLU) module is responsible for mapping the natural language (text) user utterance to a semantic frame (machine readable) version. BST: The Belief State Tracker (BST) is responsible for keeping track of information the user has provided up to the current turn in the dialog. Policy: The Policy is responsible for deciding the next action the system should take based on the current system belief state. NLG: The Natural Language Generation (NLG) module is responsible for converting the machine readable (semantic frame) representation of the system's next action into a natural language representation. TTS: The Text To Speech (TTS) module is again optional and used in a spoke dialog system to convert a text based system utterance into speech. It is also important to note that the functionality of these modules can be combined. These modules may additionally be rule-based or machine learning-based and a dialog system can be made of a combination of rules based and machine learning based modules. In the case of machine learning-based modules, depending on the architectures, modules may be trained independently or jointly.","title":"Modular Dialog Systems"},{"location":"tutorials/services/","text":"Todo Add link to notebook Introduction to ADVISER 2.0 Services In this tutorial, we will discuss Services which are the backbone of the ADVISER 2.0 toolkit and allow for the creation of multi-modal dialog systems. What are Services? A dialog system created with ADVISER 2.0 is constructed from services , with a service for each module from the modular dialog system graph shown in the previous tutorial. Each service receives inputs from previous services, processes them, and then passes the results on to the next services. An example of this can be seen in the dialog system graph below: Each block represents one service (module) in the dialog system and each arrow represents the inputs/outputs of that service. To communicate with each other, services use a publisher/subscriber pattern. This will be explained later in this tutorial, but basically means, that a service defines a list of inputs it expects and that it outputs. The service is then asynchronously called once all the expected inputs are available. Example: Let's take the HandcraftedNLU service class as an example: * The service receives a string user_utterance as input * It is important to note: the source of this input is unknown to the service and does not matter. In this example, it comes from the console, but it could just as easily come from a GUI or an automatic speech recognition (ASR) service The service outputs a list of user acts extracted from the user utterance The receiver(s) of the outputs is not known to the service and does not matter In summary, a service does not posess nor require any knowledge about a dialog system - its purpose is to process a piece or stream of information and send the result out so other services might use it. This allows dialog systems to be created where it is very easy to swap out (or combine) different services. Publish Subscribe at a high level Information is passed between services using the publisher/subscriber pattern which enables for asynchronous communication between services: * A Publisher publishes messages to a certain topic (where a topic is just a string specifying the name of an information channel) * A Subscriber subscribes to a certain topic, and is notified everytime a new message is published to this topic If a method is a subscriber, it is automatically called as soon as it has recieved a message for each of the topics it subscribes to. This means that rather than relying on a traditional linear architecture, where each module in the dialog system must be called sequentially, we can break away and allow modules to run arbitrarily in parallel - which is critical for handling multimodal input which might need continuous processing. As a note, methods in a service class may act as both a publisher and a subscriber, only one, or neither. Implementing a Service With this terminology in mind, let's look at the way a service subscribes to and publishes messages. As a first step we'll handle all the imports needed for this tutorial. # FIRST SET UP ENVIRONMENT import sys import os from typing import List import time sys . path . append ( os . path . abspath ( '../..' )) from services.service import Service , PublishSubscribe , RemoteService from utils.topics import Topic from services.service import DialogSystem from utils.domain.domain import Domain from utils.logger import DiasysLogger , LogLevel Creating our First Service For our first service, we are going to make a simple class with a method that subscribes to two input topics, \"A\" and \"B\" and can publish to two output topics: \"C\" and \"D\". The code for this can be seen below: class ConcatenateService ( Service ): @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" A method to concatenate the content of two input topics and conditionally publish to either topic \"C\" or topic \"D\" Args: A (int): message for topic \"A\" B (str): message for topic \"B\" Return: (dict): dictionary where key is the topic to be published to (conditionally \"C\" or \"D\" depending on whether the value of A is 3) and the value is the concatenation of inputs A and B \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } Inheriting from the Service class: Any service that wants to send / receive messages in the ADVISER 2.0 system must inherit from services.service.Service . This class handles the communication mechanisms between services and makes sure the service is properly registered with the dialog system so that messages are properly delivered to and received by the appropriate services. Decorating Methods with PublishSubscribe: Each service method that should send / receive messages must be decorated with the services.service.PublishSubscribe decorator. Let's have a look at the decorator arguments: sub_topics : a list of topics the method needs as inputs. The method will be called as soon as at least 1 message for each subscribed topic has been received and in cases where multiple messages for a topic are received, only the most recent message will be used. Every topic in the sub_topics list, must be also be included as a method argument with the same name . This allows the system to map message content to method arguments. pub_topics : a list of topics the function wants to publish messages to. You don't have to publish anything during a function call, even if you include entries in the pub_topics list. But if you do want to publish a message, make sure: Only publish dictionaries! Otherwise, the system does not know what topic to send your return values to You are free to choose not to publish to all topics declared in pub_topics In our example, we have the option to publish to topic C and to topic D , but this method will only to publish to one or the other depending on the message content of A Dictionary keys must correspond to the topics in the pub_topics list Example: Assume the decorated function receives the following input as shown above: A: 1 A: 2 A: 3 B: \"dropped Messages\" How will the concatenate method be called: * The concatenate method will only be called after the fourth message, because this is the first time where at least one message per topic is available (3 messages for A , 1 for B ). * Since only the most recent messages will be used, the function will receive the following input: ( A=3 , B=\"dropped Messages\" ) * The variable result will thus contain the string 3 dropped Messages and this will be publised to topic D * As a note: There are mechanisms for collecting all messages instead of dropping them, but those will be introduced later. Creating a Second Service Finally, we need a second service which is responsible for generating the messages for topics A and B . This new service will also be responsible for shutting down the dialog loop when the example is over, by publishing True to the topic DIALOG_END . This topic is one of the default control message topics and is required to end a dialog. When we create our first dialog system, we will explain this in more detail. For now, let's take a look at our second service: class PrintService ( Service ): @PublishSubscribe ( sub_topics = [ \"D\" ], pub_topics = [ Topic . DIALOG_END ]) def print_d ( self , D : str ): \"\"\" A method which prints the content of topic D and then publishes the end dialog signal Args: D (str): content of topic D, represents the output of the method concatenate Return: (dict): key represents the topic DIALOG_END which should be publsihed to with the value True \"\"\" print ( f \"RECEIVED D= { D } \" ) return { Topic . DIALOG_END : True } @PublishSubscribe ( sub_topics = [ \"start\" ]) def turn_start ( self , start : bool = True ): \"\"\" A method to start the example communication, it waits for the signal to start the dialog and then calls the send_a method three times followed by the send_b method once Args: start (bool): The signal to start the dialog system (will be published by whatever DialogSystem object that this class is registered to) \"\"\" a = 1 while a < 4 : time . sleep ( 0.5 ) self . send_a ( a ) a += 1 time . sleep ( 0.5 ) self . send_b () @PublishSubscribe ( pub_topics = [ \"A\" ]) def send_a ( self , a : int ): \"\"\" A method to print a given integer a and then publish it to topic \"A\" Args: a (int): the integer to publish to topic \"A\" Return: (dict): where the key is \"A\" (topic to publish to) and the value is the given int a \"\"\" print ( \"SENDING A=\" , a ) return { 'A' : a } @PublishSubscribe ( pub_topics = [ \"B\" ]) def send_b ( self ): \"\"\" A method to publish \"messages dropped!\" to topic \"B\" Return: (dict): where the key is \"B\" (topic to publish to) and the value is \"messages dropped!\" \"\"\" print ( \"SENDING B\" ) return { 'B' : \"messages dropped!\" } print_d(): This method subscribes to the content of topic D and when it receives a message, prints the content and publishes a signal to DIALOG_END to finish the dialog. turn_start(): This method is called once it receives a message from the start topic. It then sends three messages to topic A (by calling send_a ) and one message to topic B (by calling send_b ). The sleep calls are inserted here so we can watch the messages in the correct order (which is otherwise not guaranteed, since this is a multithreaded system). In real applications, such sleep statements are not necessary send_a(): This method does not subscribe to anything, but publishes a given int a to topic A send_b(): This method does not subscribe to anything, but publishes a given string b to topic B Instantiating and Shutting Down a Dialog System With these two services, we can test the message behavior we just described. The first step is creating a dialog system and then registering these two services to it. A dialog system is important, because it is responsible for handling synchronization and message passing, registering remote services, and providing debugging functionality. Creating a New Dialog System To get started, we will create an instance of each of our services and register them with a dialog system by passing them in to the services parameter as a list: concatenate_service = ConcatenateService () print_service = PrintService () ds = DialogSystem ( services = [ concatenate_service , print_service ], debug_logger = None ) Note: Because a dialog system also sets up the communications pipelines for each of the services, it is important that you only have one dialog system active at a time. If you try to instantiate a new dialog system without shutting down the previous one, you will get an error as the ports are already in use. You can shut down the dialog system by typing: ds.shutdown() Debugging a Dialog System Checking for Inconsistencies To see if all of our required / offered service topics are actually connected to something, we can check the dialog system for inconsistencies: ds . print_inconsistencies () \u001b[91m (Potential) Errors (subscribed topics without publishers): topic: 'start', subscribed to in services: {'PrintService'} \u001b[0m \u001b[93m Warnings (published topics without subscribers): topic: 'C', published in services: {'ConcatenateService'} topic: 'dialog_end', published in services: {'PrintService'} \u001b[0m Here, we can see that PrintService has to receive an external start -topic message to be able to function - without that, turn_start will never be called. In this case, this is okay because the dialog system can provide this start message, however in a case where we would want start turn to be called multiple times, this would be a problem. Additionally, we publish to topic C but no service subscribes to this. As you can see, when your functions are not called as expected, this output might help you track down bugs in your system. If you want to get even more detailed debug output (print all messages and associated topics), you can provide a utils.logger.DiasysLogger instance to the debug_logger argument of the DialogSystem constructor and to the constructor for each service you want to log information from. Displaying the System Graph To get an overview of the system, we can also draw a graph of all services and their connections which is helpful to make sure that all services are connected in the ways that we thought they were. The code for drawing this graph can be seen below: ds . draw_system_graph ( name = 'tutorialgraph' , show = False ) # render image to tutorials/tutorialgraph.gv.png # render image in jupyter notebook from IPython.display import Image display ( Image ( filename = 'tutorialgraph.gv.png' )) You can see in the system graph that PrintService needs an outside message to a start topic (which in turn triggers the counter for $a=1,\\dots,3$). Both topics, A and B , are published by PrintService and subscribed to by ConcatenateService . Similarly, ConcatenateService publishes to topic C and D , where D is subscribed to by PrintService . C however is published but never subscribed to - which is shown by the arrow from ConcatenateService to the UNCONNECTED SERVICES node in the dialog graph. Logging In order to debug more effectively, ADVISER 2.0 also comes with logging functionality through the class utils.logger.DiasysLogger . The logger has the option to log to the console and/or to a file with the following log levels: * NONE: No information will be logged * RESULTS: Summary information will be logged about the success rate/# of turns after an epoch of training/testing * DIALOGS: All user/system utterances and summary statistics The logger can be passed to any of the modules, to log that module's output, however when passed to the dialog system itself, the logger will additionally be able to log any messages sent through and all received by the dialog system - including the message's topic and content. A DiasysLogger can be instantiated as below: # create logger to log everything to a file logger = DiasysLogger ( console_log_lvl = LogLevel . NONE , file_log_lvl = LogLevel . DIALOGS ) And passed to a dialog system to log all message communication by passing it in with the debug_logger parameter on instantiation. #ds = DialogSystem(services=[concatenate_service, print_service], debug_logger=logger) Running a Dialog To start a new dialog you can call the DialogSystem object's run_dialog method. When doing this, it is important to specify a start_signal in the form of a dictionary where keys are the topics the signal will be published to and values are the message content to be published. We need an external signal because the run_dialog method is blocking and no function calls after run_dialog will be executed until the dialog sends an exit signal. Therefore, the start signal is an external one time message (or multiple messages) which kickstart the normal dialog loop. In our case, the start signal is to publish to the start topic and since the value of this is never used, we simply set it to True . ds . run_dialog ( start_signals = { 'start' : True }) ds . shutdown () SENDING A= 1 SENDING A= 2 SENDING A= 3 SENDING B CONCATENATING 3 AND messages dropped! RECEIVED D=3 messages dropped! ... And we get exactly the output described in the previous section! concatenate was only called after a message from both topics, A and B , arrived - and since A received multiple messages before B , those messages were dropped so only one concatenated string is printed. Since the dialog system loop is blocking for a whole dialog, it is very important to make sure there is an end condition to close the loop (i.e. publishing True to the topic DIALOG_END ). If none of our services did this, this notebook code would be stuck after calling the run_dialog and no new code could be executed. To prove this is not the case, try running the code cell below :) print ( \"Not stuck in a dialog loop!\" ) Not stuck in a dialog loop!","title":"Services"},{"location":"tutorials/services/#introduction-to-adviser-20-services","text":"In this tutorial, we will discuss Services which are the backbone of the ADVISER 2.0 toolkit and allow for the creation of multi-modal dialog systems.","title":"Introduction to ADVISER 2.0 Services"},{"location":"tutorials/services/#what-are-services","text":"A dialog system created with ADVISER 2.0 is constructed from services , with a service for each module from the modular dialog system graph shown in the previous tutorial. Each service receives inputs from previous services, processes them, and then passes the results on to the next services. An example of this can be seen in the dialog system graph below: Each block represents one service (module) in the dialog system and each arrow represents the inputs/outputs of that service. To communicate with each other, services use a publisher/subscriber pattern. This will be explained later in this tutorial, but basically means, that a service defines a list of inputs it expects and that it outputs. The service is then asynchronously called once all the expected inputs are available. Example: Let's take the HandcraftedNLU service class as an example: * The service receives a string user_utterance as input * It is important to note: the source of this input is unknown to the service and does not matter. In this example, it comes from the console, but it could just as easily come from a GUI or an automatic speech recognition (ASR) service The service outputs a list of user acts extracted from the user utterance The receiver(s) of the outputs is not known to the service and does not matter In summary, a service does not posess nor require any knowledge about a dialog system - its purpose is to process a piece or stream of information and send the result out so other services might use it. This allows dialog systems to be created where it is very easy to swap out (or combine) different services.","title":"What are Services?"},{"location":"tutorials/services/#publish-subscribe-at-a-high-level","text":"Information is passed between services using the publisher/subscriber pattern which enables for asynchronous communication between services: * A Publisher publishes messages to a certain topic (where a topic is just a string specifying the name of an information channel) * A Subscriber subscribes to a certain topic, and is notified everytime a new message is published to this topic If a method is a subscriber, it is automatically called as soon as it has recieved a message for each of the topics it subscribes to. This means that rather than relying on a traditional linear architecture, where each module in the dialog system must be called sequentially, we can break away and allow modules to run arbitrarily in parallel - which is critical for handling multimodal input which might need continuous processing. As a note, methods in a service class may act as both a publisher and a subscriber, only one, or neither.","title":"Publish Subscribe at a high level"},{"location":"tutorials/services/#implementing-a-service","text":"With this terminology in mind, let's look at the way a service subscribes to and publishes messages. As a first step we'll handle all the imports needed for this tutorial. # FIRST SET UP ENVIRONMENT import sys import os from typing import List import time sys . path . append ( os . path . abspath ( '../..' )) from services.service import Service , PublishSubscribe , RemoteService from utils.topics import Topic from services.service import DialogSystem from utils.domain.domain import Domain from utils.logger import DiasysLogger , LogLevel","title":"Implementing a Service"},{"location":"tutorials/services/#creating-our-first-service","text":"For our first service, we are going to make a simple class with a method that subscribes to two input topics, \"A\" and \"B\" and can publish to two output topics: \"C\" and \"D\". The code for this can be seen below: class ConcatenateService ( Service ): @PublishSubscribe ( sub_topics = [ \"A\" , \"B\" ], pub_topics = [ \"C\" , \"D\" ]) def concatenate ( self , A : int = None , B : str = None ) -> dict ( C = str , D = str ): \"\"\" A method to concatenate the content of two input topics and conditionally publish to either topic \"C\" or topic \"D\" Args: A (int): message for topic \"A\" B (str): message for topic \"B\" Return: (dict): dictionary where key is the topic to be published to (conditionally \"C\" or \"D\" depending on whether the value of A is 3) and the value is the concatenation of inputs A and B \"\"\" print ( \"CONCATENATING \" , A , \"AND \" , B ) result = str ( A ) + \" \" + B if A == 3 : return { 'D' : result } else : return { 'C' : result } Inheriting from the Service class: Any service that wants to send / receive messages in the ADVISER 2.0 system must inherit from services.service.Service . This class handles the communication mechanisms between services and makes sure the service is properly registered with the dialog system so that messages are properly delivered to and received by the appropriate services. Decorating Methods with PublishSubscribe: Each service method that should send / receive messages must be decorated with the services.service.PublishSubscribe decorator. Let's have a look at the decorator arguments: sub_topics : a list of topics the method needs as inputs. The method will be called as soon as at least 1 message for each subscribed topic has been received and in cases where multiple messages for a topic are received, only the most recent message will be used. Every topic in the sub_topics list, must be also be included as a method argument with the same name . This allows the system to map message content to method arguments. pub_topics : a list of topics the function wants to publish messages to. You don't have to publish anything during a function call, even if you include entries in the pub_topics list. But if you do want to publish a message, make sure: Only publish dictionaries! Otherwise, the system does not know what topic to send your return values to You are free to choose not to publish to all topics declared in pub_topics In our example, we have the option to publish to topic C and to topic D , but this method will only to publish to one or the other depending on the message content of A Dictionary keys must correspond to the topics in the pub_topics list Example: Assume the decorated function receives the following input as shown above: A: 1 A: 2 A: 3 B: \"dropped Messages\" How will the concatenate method be called: * The concatenate method will only be called after the fourth message, because this is the first time where at least one message per topic is available (3 messages for A , 1 for B ). * Since only the most recent messages will be used, the function will receive the following input: ( A=3 , B=\"dropped Messages\" ) * The variable result will thus contain the string 3 dropped Messages and this will be publised to topic D * As a note: There are mechanisms for collecting all messages instead of dropping them, but those will be introduced later.","title":"Creating our First Service"},{"location":"tutorials/services/#creating-a-second-service","text":"Finally, we need a second service which is responsible for generating the messages for topics A and B . This new service will also be responsible for shutting down the dialog loop when the example is over, by publishing True to the topic DIALOG_END . This topic is one of the default control message topics and is required to end a dialog. When we create our first dialog system, we will explain this in more detail. For now, let's take a look at our second service: class PrintService ( Service ): @PublishSubscribe ( sub_topics = [ \"D\" ], pub_topics = [ Topic . DIALOG_END ]) def print_d ( self , D : str ): \"\"\" A method which prints the content of topic D and then publishes the end dialog signal Args: D (str): content of topic D, represents the output of the method concatenate Return: (dict): key represents the topic DIALOG_END which should be publsihed to with the value True \"\"\" print ( f \"RECEIVED D= { D } \" ) return { Topic . DIALOG_END : True } @PublishSubscribe ( sub_topics = [ \"start\" ]) def turn_start ( self , start : bool = True ): \"\"\" A method to start the example communication, it waits for the signal to start the dialog and then calls the send_a method three times followed by the send_b method once Args: start (bool): The signal to start the dialog system (will be published by whatever DialogSystem object that this class is registered to) \"\"\" a = 1 while a < 4 : time . sleep ( 0.5 ) self . send_a ( a ) a += 1 time . sleep ( 0.5 ) self . send_b () @PublishSubscribe ( pub_topics = [ \"A\" ]) def send_a ( self , a : int ): \"\"\" A method to print a given integer a and then publish it to topic \"A\" Args: a (int): the integer to publish to topic \"A\" Return: (dict): where the key is \"A\" (topic to publish to) and the value is the given int a \"\"\" print ( \"SENDING A=\" , a ) return { 'A' : a } @PublishSubscribe ( pub_topics = [ \"B\" ]) def send_b ( self ): \"\"\" A method to publish \"messages dropped!\" to topic \"B\" Return: (dict): where the key is \"B\" (topic to publish to) and the value is \"messages dropped!\" \"\"\" print ( \"SENDING B\" ) return { 'B' : \"messages dropped!\" } print_d(): This method subscribes to the content of topic D and when it receives a message, prints the content and publishes a signal to DIALOG_END to finish the dialog. turn_start(): This method is called once it receives a message from the start topic. It then sends three messages to topic A (by calling send_a ) and one message to topic B (by calling send_b ). The sleep calls are inserted here so we can watch the messages in the correct order (which is otherwise not guaranteed, since this is a multithreaded system). In real applications, such sleep statements are not necessary send_a(): This method does not subscribe to anything, but publishes a given int a to topic A send_b(): This method does not subscribe to anything, but publishes a given string b to topic B","title":"Creating a Second Service"},{"location":"tutorials/services/#instantiating-and-shutting-down-a-dialog-system","text":"With these two services, we can test the message behavior we just described. The first step is creating a dialog system and then registering these two services to it. A dialog system is important, because it is responsible for handling synchronization and message passing, registering remote services, and providing debugging functionality.","title":"Instantiating and Shutting Down a Dialog System"},{"location":"tutorials/services/#creating-a-new-dialog-system","text":"To get started, we will create an instance of each of our services and register them with a dialog system by passing them in to the services parameter as a list: concatenate_service = ConcatenateService () print_service = PrintService () ds = DialogSystem ( services = [ concatenate_service , print_service ], debug_logger = None ) Note: Because a dialog system also sets up the communications pipelines for each of the services, it is important that you only have one dialog system active at a time. If you try to instantiate a new dialog system without shutting down the previous one, you will get an error as the ports are already in use. You can shut down the dialog system by typing: ds.shutdown()","title":"Creating a New Dialog System"},{"location":"tutorials/services/#debugging-a-dialog-system","text":"","title":"Debugging a Dialog System"},{"location":"tutorials/services/#checking-for-inconsistencies","text":"To see if all of our required / offered service topics are actually connected to something, we can check the dialog system for inconsistencies: ds . print_inconsistencies () \u001b[91m (Potential) Errors (subscribed topics without publishers): topic: 'start', subscribed to in services: {'PrintService'} \u001b[0m \u001b[93m Warnings (published topics without subscribers): topic: 'C', published in services: {'ConcatenateService'} topic: 'dialog_end', published in services: {'PrintService'} \u001b[0m Here, we can see that PrintService has to receive an external start -topic message to be able to function - without that, turn_start will never be called. In this case, this is okay because the dialog system can provide this start message, however in a case where we would want start turn to be called multiple times, this would be a problem. Additionally, we publish to topic C but no service subscribes to this. As you can see, when your functions are not called as expected, this output might help you track down bugs in your system. If you want to get even more detailed debug output (print all messages and associated topics), you can provide a utils.logger.DiasysLogger instance to the debug_logger argument of the DialogSystem constructor and to the constructor for each service you want to log information from.","title":"Checking for Inconsistencies"},{"location":"tutorials/services/#displaying-the-system-graph","text":"To get an overview of the system, we can also draw a graph of all services and their connections which is helpful to make sure that all services are connected in the ways that we thought they were. The code for drawing this graph can be seen below: ds . draw_system_graph ( name = 'tutorialgraph' , show = False ) # render image to tutorials/tutorialgraph.gv.png # render image in jupyter notebook from IPython.display import Image display ( Image ( filename = 'tutorialgraph.gv.png' )) You can see in the system graph that PrintService needs an outside message to a start topic (which in turn triggers the counter for $a=1,\\dots,3$). Both topics, A and B , are published by PrintService and subscribed to by ConcatenateService . Similarly, ConcatenateService publishes to topic C and D , where D is subscribed to by PrintService . C however is published but never subscribed to - which is shown by the arrow from ConcatenateService to the UNCONNECTED SERVICES node in the dialog graph.","title":"Displaying the System Graph"},{"location":"tutorials/services/#logging","text":"In order to debug more effectively, ADVISER 2.0 also comes with logging functionality through the class utils.logger.DiasysLogger . The logger has the option to log to the console and/or to a file with the following log levels: * NONE: No information will be logged * RESULTS: Summary information will be logged about the success rate/# of turns after an epoch of training/testing * DIALOGS: All user/system utterances and summary statistics The logger can be passed to any of the modules, to log that module's output, however when passed to the dialog system itself, the logger will additionally be able to log any messages sent through and all received by the dialog system - including the message's topic and content. A DiasysLogger can be instantiated as below: # create logger to log everything to a file logger = DiasysLogger ( console_log_lvl = LogLevel . NONE , file_log_lvl = LogLevel . DIALOGS ) And passed to a dialog system to log all message communication by passing it in with the debug_logger parameter on instantiation. #ds = DialogSystem(services=[concatenate_service, print_service], debug_logger=logger)","title":"Logging"},{"location":"tutorials/services/#running-a-dialog","text":"To start a new dialog you can call the DialogSystem object's run_dialog method. When doing this, it is important to specify a start_signal in the form of a dictionary where keys are the topics the signal will be published to and values are the message content to be published. We need an external signal because the run_dialog method is blocking and no function calls after run_dialog will be executed until the dialog sends an exit signal. Therefore, the start signal is an external one time message (or multiple messages) which kickstart the normal dialog loop. In our case, the start signal is to publish to the start topic and since the value of this is never used, we simply set it to True . ds . run_dialog ( start_signals = { 'start' : True }) ds . shutdown () SENDING A= 1 SENDING A= 2 SENDING A= 3 SENDING B CONCATENATING 3 AND messages dropped! RECEIVED D=3 messages dropped! ... And we get exactly the output described in the previous section! concatenate was only called after a message from both topics, A and B , arrived - and since A received multiple messages before B , those messages were dropped so only one concatenated string is printed. Since the dialog system loop is blocking for a whole dialog, it is very important to make sure there is an end condition to close the loop (i.e. publishing True to the topic DIALOG_END ). If none of our services did this, this notebook code would be stuck after calling the run_dialog and no new code could be executed. To prove this is not the case, try running the code cell below :) print ( \"Not stuck in a dialog loop!\" ) Not stuck in a dialog loop!","title":"Running a Dialog"}]}